{"/AGT/0-Algorithmic-game-theory":{"title":"","content":"\n# Algorithmic game theory - by Tim Roughgarden\n\n---\n\n## Info corso\n\n* **Docente**: Tim Roughgarden\n* **A.A.**: 2013/2014\n* **Semestre**: -\n* **CFU**: -\n* **Università**: Stadford\n\n---\n\n## Table of contents\n\n* [2 - Mechanism Design Basics](2%20-%20Mechanism%20Design%20Basics.md)\n* [3 - Myerson’s Lemma](3%20-%20Myerson%E2%80%99s%20Lemma.md)\n* [4 -  Knapsack Auctions](4%20-%20%20Knapsack%20Auctions.md)\n* [5 - Revenue-Maximizing Auctions](5%20-%20Revenue-Maximizing%20Auctions.md)\n* [6 - Simple Near-Optimal Auctions](6%20-%20Simple%20Near-Optimal%20Auctions.md)\n* Problem sets:\n  * [Exercise Set 2](Exercise/Exercise%20Set%202.md)\n","lastmodified":"2022-08-29T13:39:16.755063684+02:00","tags":null},"/AGT/2-Mechanism-Design-Basics":{"title":"","content":"\n# Mechanism Design Basics\n\n## Single item auction\n\nIl **mechanism design** può essere vista come la *scienza del rule-making*.\nIn questi appunti verrà trattato un noto problema di mechanism desing, ovvero il problema dell'**asta a singolo oggetto**.\n\nCome *setup* consideriamo una situazione in cui vogliamo mettere all'astra un oggetto, e dove partecipano $n$ acquirenti.\nOgni acquirente è intenzionato a vincere l'asta, e ognuno ha una **informazione privata**, ovvero quanto secondo lui vale l'oggetto.\nCi riferiremo a tela informazione privata con il termine **valutazione**.\nIndichiamo con $v_i$ la valutazione del partecipante $i$-esimo.\n\nDalla partecipazione all'asta ogni acquirente ne ricava un guadadno, espresso sotto forma di **utilità**.\n\nUn partecipante $i$ che perde l'asta avrà utilità $u_i = 0$.\nIl votante $i$ che vince avrà utilità $u_i = v_i - p$, dove con $p$ si indica il **pagamento** del debito che il vincitore dovrà risarcire.\nTale modello di utilià è noto come **quasilineare**.\n\nL'**obiettivo** del designer dell'asta è quello di assegnare l'oggetto al partecipante con valutazione *più alta*, nonostante tali informazioni sono private.\n\n### Sealed-Bid Auctions\n\nUn primo modello di meccanismo d'asta è il seguente:\n\n1. Ogni player $i$ comunica privatamente al banditore dell'asta un'**offerta**, che indichiamo con $b_i$. ^9c5bb1\n1. Il banditore *sceglie* un vincitore. ^8059f6\n1. In fine decide a quale prezzo $p$ verrà venduto l'oggetto. ^6127d0\n\nPer quanto riguarda il punto [(1)](2%20-%20Mechanism%20Design%20Basics.md#9c5bb1) e [(2)](2%20-%20Mechanism%20Design%20Basics.md#8059f6) una soluzione semplice è quella di scegliere il partecipante che ha fatto l'offerta $b_i$ più alta.\n\nPer quanto riguarda il punto [(3)](2%20-%20Mechanism%20Design%20Basics.md#6127d0) invece non è banale scegliere il pagamento $p$, in quanto dipende fortemente dalle offerte $b_1, ..., b_n$.\n\nPer esempio (volendo essere totalmente generosi) poniamo $p = 0$ sempre.\nIn tal caso ogni partecipante sarebbe incenitvato a dichiarare $\\infty$, e in tal caso non sarebbe possibbile identificare un vincitore.\n\n### First-Price Auctions\n\nUn primo approccio naturale sarebbe quello di far pagare al vincitore i suoi debiti, ovvero quanto offerto.\nIn tal caso avremo che se il vincitore risultante è il giocatore $i$-esimo, allora esso avrà utilità $u_i = v_i - b_i$.\n\nIn tal caso a nessun partecipante conviene proporre un'offerta maggiore della propria valutazione, perché se dovessa avere la (s)fortuna di vincere otterrebbe una utilità *negativa*.\n\nInoltre non si ha alcuna certezza che dichiarando di meno si può massimizzare la probabilità di vittoria (anzi ...).\n\n### Vickrey's Second-Price Auctions\n\nUn meccanismo invece molto ragionevole è il meccanismo di *Vickrey*, noto anche come **second-price auctions**.\nIn questo sistema il vincitore dell'asta, ovvero colui che offre più di tutti, dovrà pagare un prezzo $p$ pari alla **seconda** maggiore offerta.\n\nQuesto meccanismo può sembrare banale, ma in realtà nasconde delle proprietà molto interessanti.\n\n \u003e \n \u003e **Claim 1** Nella second-price auctions ogni partecipante ha una **strategia dominante**: proporre $b_i$ pari alla propria valutazione privata $v_i$. \n \u003e Ovvero la strategia che massimizza l'utilità di ogni player $i$ è quella di dichiarare il vero, **indipendentemente** dalle offerte degli altri partecipanti.\n\n^94869b\n\nQuesta proprietà implica che questo meccanismo è *facile* da applicare da parte dei partecipanti (che non dovranno impegnarsi troppo per capire qual è la strategia ottimale).\n\nQuando in un meccanismo è *strategia dominante* dichiarare sempre il vero è detto **truthful**.\n\n \u003e \n \u003e **Proof** Indichiamo con $b = (b_1, ..., b_n)$ il *vettore* di offerte fatte dai partecipanti, e con $b\\_{-i} = (b_1, ..., b\\_{i-1}, b\\_{i+1}, ... b_n)$ il vettore di tutte le offerte fatte, esclusa quella del partecipante $i$-esmo.\n \u003e \n \u003e Si vuole dimostrare che per ogni partecipante $i$, indipendente da quanto offrono gli altri in $b\\_{-i}$, la strategia che massimizza $u_i$ è quella di porre $b_i = v_i$.\n \u003e \n \u003e Sia $B$ la massima offerta in $b\\_{-i}$, ovvero\n \u003e $$B = \\max\\_{j \\ne i}{b_j}$$\n \u003e Se $b_i \\\u003cB$ certamente $i$ non vince, e quindi avrà utilità $u_i = 0$. Consideriamo quindi il caso in cui $b_i \\geq B$. In tal caso $i$ vince e avrà utilità $u_i = v_i - B$. Perciò l'utilità del giocatore $i$ sarà\n \u003e $$u_i = \\max{{v_i - B, 0}}$$\n \u003e Consideriamo i due scenari possibili.\n \u003e Nel caso $v_i \\\u003c B$ avremo che la massima utilità che può ottenere $i$ è pari a $0$, e questo può ottenerlo dichiarando il vero $b_i = v_i$. Infatti se $i$ pone $b_i = v_i \\\u003c B$ allora $i$ non vince. Se invece dichiara $b_i \u003e v_i$ rischia di vencere, e quindi di ottenere *utilità negativa*.\n \u003e \n \u003e Nel caso invece $v_i \\geq B$ l'utilità massima che può ottenere $i$ è $v_i - B$. Questo valore si ottiene certamente con $b_i = v_i$. Se invece dichiara $b_i \\\u003c v_i$ rischia di perdere e di ottenere *utilità nulla* $\\square$.\n\nDa questa prima proprietà si può derivare una seconda proprietà importante.\n\n \u003e \n \u003e **Claim 2** Nella second-price auctions è garantita una utilità **non negativa** ad ogni offerente *sincero*.\n \u003e \n \u003e **Proof:** Dalla proprietà [(1)](2%20-%20Mechanism%20Design%20Basics.md#94869b) abbiamo visto che *indipendentemente* dalle altre offerte $b\\_{-i}$ al partecipante $i$ è garantita una utilità pari a $u_i = \\max{{v_i - B, 0}} \\geq 0$ $\\square$. \n\n^bffa08\n\n \u003e \n \u003e **Theorem 1** *The Vickrey auction is awesome.* Ovvero tale meccanismo gode delle seguenti tre proprietà desiderabili da un meccanismo d'asta:\n \u003e \n \u003e 1. **strong incentive guarantees**: Il meccanismo è detto **dominant-strategy incentive-compatible** (in breve DSIC). Questa proprietà è l'unione delle proprietà [(1)](2%20-%20Mechanism%20Design%20Basics.md#94869b) e [(2)](2%20-%20Mechanism%20Design%20Basics.md#bffa08), ovvero la strategia ottimale per ogni partecipante è quella di dichiarare sempre la propria valutazione privata, e ciò è sufficiente a garantire utilità *non negative*.\n \u003e 1. **strong performance guarantees**: Se tutti i partecipanti dichiarano il vero, allora si massimizza il **costo sociale** (o **social surplus**). Ricordando gli obiettivi del problema, per costo sociale si intende la valutazione privata del vincitore. Per motivi che vedremo, indichiamo il costo sociale con la seguente espressione\n \u003e    $$\\sum\\_{i=1}^{n}v_i x_i$$\n \u003e    Dove $x_i$ vale $1$ sei il giocatore $i$ vince, altrimenti $0$.\n \u003e 1. **computational eciency**: l'asta può essere implementata in **tempo polinomiale** (in realtà in tempo **lineare**).\n\n^e83fd1\n\nLa prima proprietà è dimostratà dai claim [(1)](2%20-%20Mechanism%20Design%20Basics.md#94869b) e [(2)](2%20-%20Mechanism%20Design%20Basics.md#bffa08).\nLa seconda proprietà è banalmente verificabile dal fatto che, se tutti dichiarano il vero, vincerà certamente il partecipante $i$ con valutazione *massima*. Perciò, supponiamo che il partecipante $i$ vince l'asta, avremo che\n$$\\sum\\_{i=1}^{n} v_ix_i = v_1 \\cdot 0 + ... + v\\_{i-1} \\cdot 0 + v\\_{i} \\cdot 1 + v\\_{i+1} \\cdot 0 + ... + v\\_{n} \\cdot 0 = v_i = \\max\\_{j=1,...,n}{v_j}  $$\nL'ultimo punto è ancor più semplice da constatare perché in tempo costante ogni partecipante sa qual è la sua strategia ottimale, mentre al banditore basterà semplicemente scorrere tutte le offerte e trovare le due più alte per ricavare vincitore e pagamento.\n\n## Sponsored Search Auctions\n\nUna ricerca sul web comporta un insieme di **pagine** *\"organiche\"* (ovvero pagine inerenti alla ricerca restituite da un algoritmo come il [PageRank](https://it.wikipedia.org/wiki/PageRank)) e un insieme di pagine *\"sponsorizzate\"*, ovvero link pagati per essere posti come pubblicità.\n\nOgni volta che si effettua una ricerca su un motore di ricerca viene effettuata un'asta in real time per determinare quali pagine sponsorizzare e in quale ordine.  Quest'asta è nota come **sponsored search auction**.\n\n### The Basic Model\n\nIntroduciamo un primo modello *semplicistico* ma comunque interessante da analizzare.\n\nSupponiamo di avere solamente $k\u003e1$ *\"slot\"* disponibili per le sponsorizzazioni, e supponiamo inoltre che le pagine partecipanti all'asta siano *inerenti* alla ricerca.\n\nUn'altra assunzione è che gli slot non abbiano tutti lo stesso valore, in termini di qualità. Quantifichiamo le qualità degli slot tramite il concetto di **click-through-rate** (o CTR). Il CTR $\\alpha_j$ rappresenta la probabilità che lo slot $j$-esimo venga cliccato in seguito alla ricerca. Dato che si tratta di una distribuzione, avremo che\n$$\\sum\\_{j=1}^{k} \\alpha_j = 1$$\nUn'assunzione ragionevole che si può fare è che gli slot sono ordinati in senso non crescente di CTR, ovvero $\\alpha_1 \\geq \\alpha_2 \\geq ... \\geq \\alpha_k$. Infatti è ragionevole assumere che una pagina in posizione 1 ha una probabilità più alta di essere visitata, piuttosto che la pagina in posizione 10. ^af7b13\n\nUn'altra assunzione, poco ragionevole ma necessaria per questioni di complessità, è che i CTR sono **indipendenti** dai propri accupanti.\n\nAssumiamo in fine che la valutazione privata di ogni partecipante è misurata tramite al guadagno $v_i$ che ha *per ogni click*.\nPerciò se la pagina $i$ viene assegnata allo slot $j$, mediamente risceverà un guadagno di $v_i \\cdot \\alpha_j$.\n\nCiò che vogliamo è definire un meccanismo che abbia le stesse proprietà ottenute dal meccanismo di [Vickrey](2%20-%20Mechanism%20Design%20Basics.md#e83fd1)  nell'asta a singolo oggetto, ovvero:\n\n1. **DSIC.** Deve essere strategia dominante dichiarare il vero (ovvero la propria valutazione privata), e inoltre questo deve essere sufficiente a garantire utilita *non negativa*. ^a63f67\n1. **Social surplus maximization.** Il costo sociale è massimizzato quando tutti dichiarano il vero. In questo il costo sociale è definito sempre come\n   $$\\sum\\_{i=1}^{n}v_ix_i$$\n   dove per $x_i$ è pari al CTR dello slot $j$ assegnato al partecipante $i$-esiamo ($0$ se la pagina non è tra i $k$ vincitori). ^db3c63\n1. **Polynomial running time.** Questo punto è importantissimo, dato che un numero immenso di ricerche vengono effettuate ogni giorno. ^92a5ec\n\n### Our Design Approach\n\nPossiamo dividere il problema in due sottoproblemi: decidere *chi vince cosa* e poi dicidere *quanto pagano*.\nIl nostro approccio sarà quindi:\n\n* **Step 1:** Assumiamo, senza giustificazioni, che tutti i partecipanti dichiarino il vero. Cerchiamo un modo di definire i vincitori (e cosa vincono) in modo tale da rispettare le proprietà [(2)](2%20-%20Mechanism%20Design%20Basics.md#db3c63) e [(3)](2%20-%20Mechanism%20Design%20Basics.md#92a5ec). ^40f690\n* **Step 2:** Dati i vincitori e i premi dallo Step 1, cerchiamo di definire uno *schema di pagamenti* per i vincitori in modo tale da assicurarci che gli convenga sempre dichiarare il vero, ovvero che occora la proprietà [(1)](2%20-%20Mechanism%20Design%20Basics.md#a63f67). ^9a8ea2\n\nSe riusciamo a *\"centrare\"* entrambi i punti correttamente, avremo definito un meccanismo con le proprietà desiderate.\n","lastmodified":"2022-08-29T13:39:16.834012635+02:00","tags":null},"/AGT/3-Myersons-Lemma":{"title":"","content":"\n# Myerson’s Lemma\n\nNegli [appunti precedenti](2%20-%20Mechanism%20Design%20Basics.md) è stata introdotta la [Vickrey's Second-Price Auctions](2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions) e provato che essa garantisce le [tre proprietà desiderabili](2%20-%20Mechanism%20Design%20Basics.md#e83fd1).\n\nPer estendere la garanzia di queste proprietà desiderabili ad aste più complesse, come la [sponsored search auctions](2%20-%20Mechanism%20Design%20Basics.md#sponsored-search-auctions), abbiamo introdotto [l'approccio da adottare](2%20-%20Mechanism%20Design%20Basics.md#our-design-approach).\n\nPer esempio, il [primo punto](2%20-%20Mechanism%20Design%20Basics.md#40f690)  può essere implementato con un ***approccio greedy*** semplicemente assegnando gli slot in ordine *non crescente* di offerte, ovvero lo slot $j$-esimo è assegnato al player che ha fatto la $j$-esima offerta più alta.\nInfatti è facile verificare che tale approccio \u003cu\u003emassimizza\u003c/u\u003e il [social surplus](2%20-%20Mechanism%20Design%20Basics.md#db3c63), inoltre è computabile in [tempo polinomiale](2%20-%20Mechanism%20Design%20Basics.md#92a5ec) semplicemente **ordinando** in ordine *non crescente* le offerte in $b$. ^cbc983\n\nPer implementare il [secondo punto](2%20-%20Mechanism%20Design%20Basics.md#9a8ea2) invece verrà enunciato e dimostrato ***Myerson’s Lemma***.\n\n---\n\n## Single-Parameter Environments\n\nIntroduciamo l'*environment* che sarà utile a dimostrare il *lemma di Myerson*.\n\nAbbiamo $n$ partecipanti ad un'asta, ognuno dei quali possiede una **valutazione privata** $v_i$ del valore che otterrebbe dalla vincita dell'asta.\n\nSia $X$ l'insieme delle **soluzioni ammissibili**.\nTale insieme $X$ è composto da vettori $n$-dimensionali $\\underline{x} = (x_1, ..., x_n) \\in \\mathbb{R}^n$, dove $x_i$ indica una sorta di *\"ammontare\"* dato al partecipante $i$-esimo. ^43b362\n\nPer esempio, nell'asta a [asta a signolo oggetto](2%20-%20Mechanism%20Design%20Basics.md#single-item-auction) $X$ è formato da vettori di 0-1 con **al più** un 1, nella posizione corrispondente al vincitore.\nPer esempio, se abbiamo $n=6$ partecipanti e il vincitore dell'asta risulta essere il player $i = 4$ il corrispondente vettore in $X$ risulta essere $(0,0,0,1,0,0)$.\nAl più 1, perché nel caso in cui non si riesce a definire un vincitore, il vettore relativo risulta essere composto da tutti zeri.\nOsserviamo quindi che $\\sum_i x_i \\leq 1$.\n\nOppure, in un asta con $k$ identici oggetti, ognuno dei quali assegnati a $k$ differenti vincitori, avremo un vettore di 0-1 tale che $\\sum_i x_i \\leq k$.\n\nNella sponsored search auction invece, $X$ invece è l'insieme dei vettori $n$-dimensionali tali che, se al partecipante $i$-esimo viene assegnato lo slot $j$ allora avremo che in posizione $i$ del vettore corrispondente ci sarà il [CTR](2%20-%20Mechanism%20Design%20Basics.md#af7b13) $\\alpha_j$.\nIn tutte le altre posizione (ovvero le posizioni dei partecipanti che non hanno vinto) invece ci sarà uno $0$.\nDato che per definizione di [CTR](2%20-%20Mechanism%20Design%20Basics.md#af7b13) esso è una **distribuzione di probabilità**, allora anche in questo caso avremo che $\\sum_i x_i \\leq 1$.\n\n## Allocation and Payment Rules\n\nRicordiamo che nel problema dell'asta bisogna effettuare due scelte: chi vince e quanto paga.\nQueste due decisioni sono formalizzate con le **allocation rule** (*regole di allocazione*, chi vince) e **payment rule** (*regole di pagamento*, quanto paga).\n\nPerciò formalmente il problema d'asta è suddiviso in tre step:\n\n1. Il banditore colleziona le offerte dei singoli partecipanti $\\mathbf{b}=(b_1, ..., b_n)$. D'ora in avanti ci riferiremo a $\\mathbf{b}$ con il termine **profilo di strategie**, o semplicemente **profilo**.\n1. **allocation rule.** Viene scelto una assegnazione di vincitori accettabile $\\mathbf{x}(\\mathbf{b}) \\in X \\subseteq \\mathbb{R}^n$ in funzione del del profilo $\\mathbf{b}$. Per convezione indichiamo con $x_i(\\mathbf{b})$ l'allocazione di player $i$-esimo in funzione del profilo.\n1. **payment rule.** Vengono definiti i pagamenti $\\mathbf{p}(\\mathbf{b}) \\in \\mathbb{R}^n$  in funzione del del profilo $\\mathbf{b}$. Per convezione indichiamo con $p_i(\\mathbf{b})$ il pagamento del player $i$-esimo in funzione del profilo.\n\nDati quindi un profilo $\\mathbf{b}$, una regola di assegnazione $\\mathbf{x}$ e uno schema di pagamenti $\\mathbf{p}$, definiamo in fine l'utilità del player $i$-esimo in funzione di $\\mathbf{b}$ come\n$$u_i(\\mathbf{b}) = v_i \\cdot x_i(\\mathbf{b}) - p_i(\\mathbf{b})$$\nOsserviamo che siamo interessati ad analizzare pagamenti nell'intervallo\n$$p_i(\\mathbf{b}) \\in \\left\\[ 0, b_i \\cdot x_i(\\mathbf{b}) \\right\\]$$\nSicuramente il pagamento deve essere \u003cu\u003enon negativo\u003c/u\u003e (altrimenti non avrebbe senso).\nInvece il vincolo $p_i(\\mathbf{b}) \\leq b_i \\cdot x_i(\\mathbf{b})$ garantisce invece che i partecipanti **sinceri** ricevano utilità \u003cu\u003enon negativo\u003c/u\u003e.\n\n---\n\n## Myerson’s Lemma\n\n \u003e \n \u003e Def. (**Implementable Allocation Rule**) Una regola di allocazione $\\mathbf{x}$ per un sistema a singolo parametro è detta **implementabile** se esiste uno schema di pagamento $\\mathbf{p}$ tale che il meccanismo $(\\mathbf{x}, \\mathbf{p})$ è [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67).\n\n^1898c6\n\nPerciò implementare un meccanismo DSIC per un asta equivale a restringersi a tutte le regola di allocazione $\\mathbf{x}$ che sono *implementabili*.\n\nUna domanda che possiamo porci è:\n\n \u003e \n \u003e la regola di allocazione che massimizza il social surplus nella *sponserd search auction* (vedi [qui](3%20-%20Myerson%E2%80%99s%20Lemma.md#cbc983)), ovvero quella che associa la $j$-esima offerta più alta al $j$-esimo slot migliore, risulta essere *implementabile*?\n\nPer esempio, considerando l'asta a signolo oggetto, la regola di allocazione che assegna l'oggetto all'offerente migliore è implementabile: abbiamo infatti visto la [second-price rule](2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions), la quale è DSIC.\n\n \u003e \n \u003e Def. (**Monotone Allocation Rule**) Una regola di allocazione $\\mathbf{x}$ per un sistema a singolo parametro è detta **monotona** se per ogni offerente $i$, e per ogni insieme di altre offerte $\\mathbf{b}*{-i}$ (tutte le offerte tranne quella $i$-esima), l'allocazione $x_i(z, \\mathbf{b}*{-i})$ del player $i$ è **non decrescente** nell'offerta $z$.\n \u003e \n \u003e Più intuitivamente, indipendentemente dalle altre offerte, l'allocazione del player $i$ *non decresce al crescere della sua offerta*: se offro di più non posso andare peggio.\n\n^3c29c4\n\nPer esempio, la regola del miglio offerente è monotona, in quanto (fissando le altre offerte) se offrendo $b_i$ il player $i$ vince, se offre di più continua a vincere.\n\nIn questo caso dire che [l'apporccio greedy](3%20-%20Myerson%E2%80%99s%20Lemma.md#cbc983) che massimizza il social surplus nella *sponserd search auction* è monotona.\nInfatti, offrendo di più, un player può solo salire in classifica, ottenendo quindi uno slotto con CTR migliore.\n\n### Theorem (Mayerson's Lemma)\n\nConsideriamo un ambiente a singolo parametro, allora:\n\n* ***(a)*** Una regola di allocazione $\\mathbf{x}$ è *implementabile* \u003cu\u003ese e solo se\u003c/u\u003e è *monotona*. ^d589da\n* ***(b)*** Assumendo che $b_i = 0 \\implies p_i(\\mathbf{b}) = 0$, se $\\mathbf{x}$ è *monotona*, esiste un \u003cu\u003eunico\u003c/u\u003e *schema di pagamento* $\\mathbf{p}$ tale che il meccanismo d'asta $(\\mathbf{x}, \\mathbf{p})$ è DSIC. ^3bc8f8\n* ***(c)*** Il pagamento nel punto precedente può essere espresso con una *formula esplicita*. ^9c8cc8\n\n### Proof of Myerson’s Lemma (informal)\n\nConsideriamo un $\\mathbf{x}$ monotono.\nPer esempio nella seguente immagine possiamo vedere le regole di assegnazione per un generico player $i$ al crescere dell'offerta, per il problema dell'asta a singolo oggetto e per la ricerca sponsorizzata.\n\n![](lecture03-1.png)\n\nSupponimo che $\\mathbf{x}$ sia *implementabile*, e cerchiamo di capire come può essere fatto uno schema di pagamento $\\mathbf{p}$ in modo tale che il meccanismo d'asta $(\\mathbf{x}, \\mathbf{p})$ sia DSIC.\n\nFissiamo un player $i$ e un $\\mathbf{b}*{-i}$ arbitrari.\nPer comodità, indichiamo con $x(z)$ l'allocazione $x_i(z, \\mathbf{b}*{-i})$ del player $i$ se dichiara $z$, e con $p(z)$ il pagamento $p_i(z, \\mathbf{b}\\_{-i})$ che dovrà fare.\n\nConsideriamo due valori $0 \\leq z \\\u003c y$.\n\nSfruttando il fatto che  $(\\mathbf{x}, \\mathbf{p})$ è DSIC, se $v_i = z$ allora avremo che\n$$\\underbrace{z \\cdot x(z) - p(z)}*{u_i(z, \\mathbf{b}*{-i})} \\geq \\underbrace{z \\cdot x(y) - p(y)}*{u_i(y, \\mathbf{b}*{-i})}$$\nAnalogamente, se $v_i = y$ allora\n$$\\underbrace{y \\cdot x(y) - p(y)}*{u_i(y, \\mathbf{b}*{-i})} \\geq \\underbrace{y \\cdot x(z) - p(z)}*{u_i(z, \\mathbf{b}*{-i})}$$\nRiarrangiando queste due equazioni otterremo un range nel quale è contanuta la differenza di pagamenti $\\Delta_p = p(y) - p(x)$\n$$\nz \\cdot \\left\\[ x(y) - x(z) \\right\\] \\leq p(y) - p(z) \\leq y \\cdot \\left\\[ x(y) - x(z) \\right\\]\n$$\n\n^af2847\n\n \u003e \n \u003e Osserviamo che il precedente intervallo può esistere solamente se $\\mathbf{x}$ è **monotona**.\n \u003e Infatti, supponiamo che $v_i = z$.\n \u003e Se $\\mathbf{x}$ fosse non monotona, allora esisterebbe certamente un $y \u003e z$ tale che $x(y) \\\u003c x(z)$.\n \u003e In tal caso avremo che la differenza $x(y) - x(z) \\\u003c 0$, e quindi avremo che $\\Delta_p$ deve necessariamente essere\n \u003e $$ z \\cdot \\left\\[ x(z) - x(y) \\right\\] \\geq \\Delta_p \\geq y \\cdot \\left\\[ x(z) - x(y) \\right\\] $$\n \u003e e questo intervallo è vuoto perche $z \\\u003c y$.\n\nA questo punto facciamo tendere $y$ dall'alto a $z$, ottenendo quindi che\n$$\\lim\\_{y \\to z^+} \\Delta_p = z \\cdot \\left\\[ x(y) - x(z) \\right\\]$$\nCerchiamo ora di analizzare che succede a questo limite.\n\nDato che $x(\\cdot)$ procede *\"a scalini\"*, possono capitare due cose: $z$ e $y$ si trovano in uno stesso scalino, oppure $z$ si trova in un punto di discontinuità e essendo che $y$ lo approssima da destra essi si trovano su due scalini differenti.\n\nNel primo caso allora il limite è $0$.\nNel secondo invece avremo che $\\Delta_p$, ovvero il *\"salto*\" di pagamento che otterrebbe $i$ nel dichiarare $z$ oppure $y$, è pari al *\"salto\"* che c'è nella funzione $x(\\cdot)$ nel pungo $z$ moltiplicato per $z$.\nOvvero\n$$\\Delta_p = z \\cdot \\left\\[ \\text{salto di } x(\\cdot) \\text{ in } z \\right\\]$$\nAssumendo che $p(0) = 0$ è possibile ricavare che\n\n$$p_i(b_i, \\mathbf{b}*{-i}) = \\sum*{j=1}^{\\ell} z_j \\cdot \\left\\[ \\text{salto di } x_i(\\cdot, , \\mathbf{b}\\_{-i}) \\text{ in } z_j \\right\\]$$ ^232507\n\ndove $z_1, ..., z\\_\\\\ell$ sono i punto di $x_i(\\cdot, , \\mathbf{b}\\_{-i})$ dove avvengono i salti, rispetto all'intervallo $\\left\\[ 0, b_i \\right\\]$.\n\n \u003e \n \u003e Un ragionamento simile si può applicare per funzioni $x$ che non sono necessariamente *\"a gradini\"*.\n \u003e Per esempio, consideriamo un $x$ derivabile, e dividiamo le precedenti disuguaglianze per $y-z$.\n \u003e $$\\frac{z \\cdot \\left\\[ x(y) - x(z) \\right\\]}{y-z} \\leq \\frac{p(y) - p(z)}{y-z} \\leq \\frac{y \\cdot \\left\\[ x(y) - x(z) \\right\\]}{y-z}$$\n \u003e Come prima, facendo tendere $y$ a $z$ da destra otteremo che\n \u003e $$p'(z) = z \\cdot x'(z)$$\n \u003e Da cui poi\n \u003e $$p_i(b_i, \\mathbf{b}\\_{-i}) = \\int_0^{b_i} z \\cdot x'*i(z, \\mathbf{b}*{-i}) , dz$$\n\n^539c5a\n\nRibadiamo che, partendo dall'assunzione che dall'assunzione che $x_i(\\cdot)$ è monotona, abbiamo ricavato una [formula](3%20-%20Myerson%E2%80%99s%20Lemma.md#232507) per lo schema di pagamanto $p_i(\\cdot)$, tale che $p_i(\\cdot)$ rispetta il vincolo di monotonia di $x_i(\\cdot)$.\nDato che abbiamo ricavato $p_i(\\cdot)$ come \u003cu\u003eunico\u003c/u\u003e risultato di una equazione, allora possiamo dire che $p_i(\\cdot)$ è \u003cu\u003eunica\u003c/u\u003e.\n\nPer completare la dimostrazione basta dimostrare che se $\\mathbf{x}$ è monotona allora il meccanismo $(\\mathbf{x}, \\mathbf{p})$ (con lo schema $\\mathbf{p}$ ricavato come appena visto) è DSIC.\n\nConsideriamo il caso in cui un player $i$ dichiara il vero $b_i = v_i$.\nLa sua utilità sarà quindi pari a\n$$u_i(b_i, \\mathbf{b}*{-i}) = v_i \\cdot x_i(z*\\\\ell) - \\sum\\_{j = 1}^\\ell z_j \\cdot (x_i(z_j) - x_i(z\\_{j-1}))$$\ndove $z_0 = 0$ e $z_1, ..., z\\_\\\\ell$ i punto di $x_i(\\cdot, , \\mathbf{b}\\_{-i})$ dove avvengono i salti, rispetto all'intervallo $\\left\\[ 0, b_i \\right\\]$.\n\n**Immagine**\n\nVediamo ora che accadrebbe se dovesse offrire meno $b_i = y^{(-)} \\\u003c v_i$.\nIn tal caso l'utilità sarà\n$$u_i(y^{(-)}, \\mathbf{b}*{-i}) = v_i \\cdot x_i(z_m) - \\sum*{j = 1}^m z_j \\cdot (x_i(z_j) - x_i(z\\_{j-1}))$$\ndove $z_0 = 0$ e $z_1, ..., z_m$ i punto di $x_i(\\cdot, , \\mathbf{b}\\_{-i})$ dove avvengono i salti, rispetto all'intervallo $\\left\\[ 0, y^{(-)} \\right\\]$.\nOsserviamo che essendo $y^{(-)} \\\u003c v_i$ allora $m \\leq \\ell$.\n\n* **Caso $m = \\ell$**. In questo caso avremo che la differenza di utilità sarà pari a\n  $$u_i(v_i, \\mathbf{b}*{-i}) - u_i(y^{(-)}, \\mathbf{b}*{-i}) = 0$$\n* **Caso $m \\\u003c \\ell$**. In tal caso avremo che $p_i(b_i) \u003e p_i(y^{(-)})$, perciò\n  $$\\begin{align\\*}\n  u_i(v_i, \\mathbf{b}*{-i}) - u_i(y^{(-)}, \\mathbf{b}*{-i})\n  \u0026= v_i \\cdot (x_i(v_i) - x_i(y^{(-)})) - p_i(v_i) + p_i(y^{(-)})\\\\\n  \u0026= v_i \\cdot (x_i(v_i) - x_i(y^{(-)})) + \\underbrace{\\left\\[p_i(y^{(-)}) - p_i(v_i)\\right\\]}*{\\\u003c 0}\\\\\n  \u0026\u003e v_i \\cdot (x_i(v_i) - x_i(y^{(-)}))\\\\\n  \u0026= v_i \\cdot \\underbrace{(x_i(z*\\\\ell) - x_i(z_m))}*{\\geq 0}\\\\\n  \u0026\\geq 0\n  \\\\end{align\\*}$$\n  Ovvero $u_i(v_i, \\mathbf{b}*{-i}) \u003e u_i(y^{(-)}, \\mathbf{b}\\_{-i})$.\n\nSimmetricamente, possiamo applicare lo stesso ragionamento nel caso in cui si dichiara di più $b_i = y^{(+)} \u003e v_i$ (vedi [Exercise 12](Exercise/Exercise%20Set%202.md#exercise-12)).\n\nCon lo stesso ragionamento si può dimostrare lo stesso anche nel caso di funzioni $x_i(\\cdot)$ differenziabili $\\square$.\n\n![](lecture03-2.png)\n\n### Osservazione sui pagamenti\n\nRiformulando la [formula](3%20-%20Myerson%E2%80%99s%20Lemma.md#232507) per lo schema di pagamenti, essa si può riscrivere come segue\n$$ p_i(b_i, \\mathbf{b}*{-i}) = b_i \\cdot x_i(b_i) - \\left\\[\\\\sum*{j=1}^{\\ell-1} (z\\_{j+1} - z_j) \\cdot x_i(z_j) + (b_i - z\\_{\\ell}) \\cdot x_i(b_i) \\right\\]$$\nGraficamente si può intuire meglio\n![\\|380](lecture03-5.png)\n\nSi può ricavare lo stesso risultato anche nel caso di funzione di allocazione [differenziabile](3%20-%20Myerson%E2%80%99s%20Lemma.md#539c5a)\n$$\\begin{align}\np_i(b_i, \\mathbf{b}*{-i})\n\u0026= \\int_0^{b_i} z \\cdot x'*i(z, \\mathbf{b}*{-i}) , dz\\\\\n\u0026= z \\cdot x_i(z, \\mathbf{b}*{-i}) - \\int_0^{b_i} x_i(z, \\mathbf{b}*{-i}) , dz ; \\Bigg\\vert^{b_i}*0\\\\\n\u0026= b_i \\cdot x_i(b_i, \\mathbf{b}*{-i}) - \\int_0^{b_i} x_i(z, \\mathbf{b}*{-i}) , dz\n\\\\end{align}$$\nsemplicemente integrando per parti.\n\n---\n\n## Payment Formula for Sponsored Search Solved\n\nCerchiamo di capire come poter applicare la [formula](3%20-%20Myerson%E2%80%99s%20Lemma.md#232507) per lo schema di pagamento al problema della *sponsored search auction*.\n\nRicordiamo che abbiamo $k$ slots, ordinati per i rispettivi valori di click-through-rates (CTRs) $\\alpha_1 \\geq \\alpha_2 \\geq ... \\geq \\alpha_k$.\nAbbiamo anche una regola di assegnazione $\\mathbf{x}(\\mathbf{b}) \\in \\mathbb{R}^n$ che assegna il $j$-esimo slot più \"migliore\" al player che ha fatto la $j$-esima offerta più alta, per $j = 1, ..., k$, oppure $0$ per $j \u003e k$.\nRicordiamo anche che tale regola è **monotona**, e che sotto assunzione di *sincerità* dei partecipanti garantisce la massimizzazione del *social surplus*.\n\nApplicando il [Myerson's lemma](3%20-%20Myerson%E2%80%99s%20Lemma.md#theorem-mayerson-s-lemma) possiamo derivare uno schema di pagamento $\\mathbf{p}$ (\u003cu\u003eunico\u003c/u\u003e) tale che il meccanismo $(\\mathbf{x}, \\mathbf{p})$ sia DSIC.\n\nSenza perdita di generalità, ordiniamo i partecipanti in ordine di offerta $b_1 \\geq b_2 \\geq ... \\geq b_n$.\nIntuitivamente, la funzione di assegnazione $\\mathbf{x}$ sarà della seugente forma.\n\n![\\|500](lecture03-4.png)\n\nPer non avere un assegnazione pari a $0$, è necessario offrire di più di $b_k$.\nAnalogamente, per ottenere ancora di più (ovvero per *salire di gradino*) sarà necessario offrire più di $b\\_{k-1}$, e così via...\n\nSeguendo la [formula](3%20-%20Myerson%E2%80%99s%20Lemma.md#232507) avremo che\n$$\n\\\\begin{align\\*}\np_k(\\mathbf{b}) \u0026= b_k \\cdot \\alpha_k\\\\\np\\_{k-1}(\\mathbf{b}) \u0026= b\\_{k-1}(\\alpha\\_{k-1} - \\alpha_k) + b_k \\cdot \\alpha_k\\\\\np\\_{k-2}(\\mathbf{b}) \u0026= b\\_{k-2}(\\alpha\\_{k-2} - \\alpha\\_{k-1}) + b\\_{k-1}(\\alpha\\_{k-1} - \\alpha_k) + b_k \\cdot \\alpha_k\\\\\n\u0026\\vdots\n\\\\end{align\\*}\n$$\n\nIn generale, quando si sale di gradino, il valore di assegnazione fa un salto di magnitudo $\\alpha_j - \\alpha\\_{j+1}$.\nPerciò, fissato un qualsiasi $i$ e un qualsiasi $\\mathbf{b}$ avremo\n$$p_i(\\mathbf{b}) = \\sum\\_{j = i}^{k} b_j \\cdot (\\alpha_j - \\alpha\\_{j+1})$$\ndove $\\alpha\\_{k+1} = 0$.\n","lastmodified":"2022-08-29T13:39:16.848356438+02:00","tags":null},"/AGT/4-Knapsack-Auctions":{"title":"","content":"\n# Knapsack Auctions\n\n## Problem Definition\n\nSupponiamo di essere un'emittente televisiva, e di voler vendere uno *spazio pubblicitario* durante la finale del [Super Bowl](https://en.wikipedia.org/wiki/Super_Bowl) a diverse ditte interessate.\nPer fare ciò avviamo un'asta.\n\nAbbiamo una quantità $W$ di tempo disponibile, e vogliamo decidere come spartirlo tra i partecipanti.\nOgni partecipante $i$ possiede una quantità $w_i$ che indica la **durata** del proprio spot pubblicitario, e un una propria **valuitazione privata** $v_i$ che indica quanto secondo loro vale mostrare il proprio spot plubbicitario durante la finale del Super Bowl.\n\nL'insieme delle soluzioni ammissibili $X$ è composto da quei vettori $n$-dimensionali $\\underline{x} = (x_1, ..., x_n)$ composti da soli 0-1 tali che\n$$\n\\\\sum\\_{i=1}^{n} w_i \\cdot x_i \\leq W\n$$\n\n^adc6eb\n\nCiò significa che l'insieme delle pubblicità scelte per essere mostrate non deve superare il tempo a disposizione $W$.\n\nOsserviamo che un'asta di $k$ identici oggetti è un caso particolare di quest'asta dove $w_i = 1$ per ogni partecipante $i$, e con $W = k$.\n\nQuello che si vuole massimizzare è il guadagno ottenuto dall'asta, cercando però di rispettare il [vincolo d'integrità](4%20-%20%20Knapsack%20Auctions.md#adc6eb) (non posso vendere 13 minuti di pubblicità se ho solo 10 minuti disponibili, sarebbe una truffa...).\n\nPiù formalmente, ogni partecipante all'asta propone un'*offerta* $b_i$ e la *regola di derivazione* che massimizza il **social surplus** è la seguente\n$$\n\\\\mathbf{x}(\\mathbf{b}) = \\max\\_{x \\in X} \\sum\\_{i = 1}^{n} b_i \\cdot x_i\n$$\nQuesta appena descritta è una istanza del problema combinatorico di ottimizzazione [Knapsack problem](https://en.wikipedia.org/wiki/Knapsack_problem).\n\n## Soglia critica di pagamento\n\nIl [lemma di Myerson](3%20-%20Myerson%E2%80%99s%20Lemma.md#theorem-mayerson-s-lemma) ci garantisce l'**esistenza** di una configurazione di pagamenti $\\mathbf{p}$ tale che il meccanismo $(\\mathbf{x}, \\mathbf{p})$ è [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67) (grazie al fatto che $\\mathbf{x}$ è [monotona](3%20-%20Myerson%E2%80%99s%20Lemma.md#3c29c4)).\n\nFissiamo un player $i$ e le offerte $\\mathbf{b}*{-i}$.\nDato che la regola di allocazione è *binaria* ($x_i$ può essere solo $0$ o $1$) allora l'andamento di $x_i(\\cdot, \\mathbf{b}*{-i})$ è facile da intuire: vale sempre $0$ finché non si raggiunge una **soglia critica** $\\theta_i$ dalla quale in poi è sempre $1$.\n\nRicordando la [formula](3%20-%20Myerson%E2%80%99s%20Lemma.md#232507) avremo che il pagamento sarà pari a $0$ per ogni offerta $b_i \\\u003c \\theta_i$, e pari a $\\theta_i \\cdot (1 - 0) = \\theta_i$ per ogni $b_i \\geq \\theta_i$, un po' come accadeva nella [Vickrey's second auction](2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions).\n\n## Intrattabilità del problema\n\nÈ ben noto che il problema Knapsack è un problema NP-Hard.\nPerciò, a meno che non sia $P = NP$, non c'è speranza di soddisfare *entrambe le proprietà* [social surplus maximization](2%20-%20Mechanism%20Design%20Basics.md#db3c63) e [polynomial running time](2%20-%20Mechanism%20Design%20Basics.md#92a5ec).\n\nPerciò l'idea è quella di **rilassare** una delle due proprietà, rinunciando quindi ad *efficacia* o *efficienza*.\n\nMa cosa è possibile rinuciare per garantire la terza proprietà necessaria, ovvero [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67)?\n\nPer esempio, è ben noto un algoritmo [pseudo-polinomiale](https://it.wikipedia.org/wiki/Tempo_pseudopolinomiale) di [programmazione dinamica](https://en.wikipedia.org/wiki/Dynamic_programming) che risolve il problema del Knapsack all'*ottimo* in tempo $O(nW)$.\nQuesto algoritmo però rinuncia all'efficienza perché $W$ rappresenta un **valore numerico** e non la grandezza dell'istanza, perciò sono necessari $O(\\log{W})$ bit per rappresentarlo.\nQuindi $W$ è **esponenziale** nella sua *\"grandezza\"*.\n\nUn altro approccio invece è quello di preservare l'efficienza perdendo in ottimalità, ma **non troppo**.\nAlgoritmi che appliccano questo approccio sono detti [algoritmi approssimanti](https://it.wikipedia.org/wiki/Algoritmo_di_approssimazione).\n\nPer esempio un algoritmo approssimante per il knapsack segue la seguente euristica greedy:\n\nAssumiamo che tutti i pesi siano $w_i \\leq W$.\nSe ce ne dovessero essere di più pesanti basta rimuoverli.\nA questo punto:\n\n1. Ordianiamo (e indiciziamo) gli elementi nel seguente ordine $$\\frac{b_1}{w_1} \\geq \\frac{b_2}{w_2} \\geq ... \\geq \\frac{b_n}{w_n}$$\n1. Iterativamente, seguendo l'ordinamento, inserisci un player all'interno della soluizione a meno che non *\"entri nello zaino\"*.\n1. Ritorna il massimo tra il miglior offerente e ciò che si è ricavato dal punto 2.\n\n````julia\nfunction greedy_knapsack(bids::Vector{Float64}, weights::Vector{Float64}, W::Float64)\n    rates = Tuple[]\n    for i = 1:length(bids)\n        append!(rates, [(bids[i] / weights[i], i)])\n    end\n\n    sort!(rates, by = x -\u003e x[1], rev = true)\n\n    result = Float64[]\n    current_load = 0.0\n\n    for t ∈ rates\n        i = t[2]\n        b = bids[i]\n        w = weights[i]\n\n        if current_load + w ≤ W\n            append!(result, b)\n            current_load += w\n        end\n    end\n\n    max(bids...) \u003e sum(result) ? [max(bids...)] : result\nend\n````\n\n^adfe61\n\nQuello appena descritto è un algoritmo $\\frac{1}{2}$-approssimante per il problema del Knapsack, ovvero garantisce che (nel caso peggiore) il risultato trovato è almeno la metà del valore del risultato ottimo.\n\n \u003e \n \u003e **Theorem** Assumendo che le offerte sia sincere, ovvero che $b_i = v_i$ per ogni partecipante, allora il *social surplus* ottenuto tramite l'algoritmo greedy è *almeno* il 50% del *massimo social surplus*.\n\n \u003e \n \u003e **Proof**  **TODO**\n\nQuesto approccio greedy funziona anche meglio sotto certe assunzioni.\nPer esempio, se per ogni partecipante $i$ abbiamo che $w_i \\leq \\alpha W$, con $0 \\\u003c \\alpha \\leq \\frac12$, allora l'algoritmo garantisce un'approssimazione di $1-\\alpha$ (anche omettendo il terzo punto).\n\nSi può dimostrare che massimizzare il social surplus induce in un algoritmo $\\mathbf{x}$ [monotono](3%20-%20Myerson%E2%80%99s%20Lemma.md#3c29c4) (vedi [esercizio 14](Exercise/Exercise%20Set%202.md#exercise-14)), il quale a sua volta implica l'**esistenza** di uno schema di pagamento $\\mathbf{p}$ tale che il meccanismo $(\\mathbf{x},\\mathbf{p})$ è DSIC.\n$$\n\\\\text{exact surplus-maximization} \\implies \\text{DSIC/monotone \"for free\"}\n$$\nCosa possiamo dire invece riguardo l'**approssimazione** del social surplus? Si può garantire la *monotonia*? (vedi [esercizio 18](Exercise/Exercise%20Set%202.md#exercise-18))\n\n## Black-Box Reductions\n\nVerrebbe da pensare che qualsiasi regola di allocazione ragionevole è necessariamente anche *monotona*.\nIn realtà non è sempre detto.\n\nPer esempio, per knapsack, esiste un [FPTAS](https://en.wikipedia.org/wiki/Fully_polynomial-time_approximation_scheme) che dato un $\\varepsilon \u003e 0$ calcola una $(1-\\varepsilon)$-approssimazione in tempo polinomiale nell'istanza e in $1/\\varepsilon$, inducendo però in una regola di allocazione **non**-monotona.\n\nÈ però possibile **riarrangiare** tale regola ottenuta tramite l'FPTAS in modo tale da garantire la monotonia, \u003cu\u003esenza degradare l'efficienza\u003c/u\u003e.\n\nQuello che si può chiedere è quindi:\n\n \u003e \n \u003e Esiste un problema a **singolo parametro** per il quale la migliore approssimazione garantita ottenuta tramite un algoritmo polinomiale è **strettamente migliore** della migliore approssimazione garantita ottenuta tramite un algoritmo polinomiale e *monotono*?\n\nO più semplicemente:\n\n \u003e \n \u003e esiste un problema a singolo parametro per il quale il miglior risultato che si può ottenere in tempo polinomiale è **strettamente migliore** del miglior risultato che si può ottenere sfruttando entrambi tra tempo polinomiale e monotonia?\n\nUn modo per dimostrare una risposta negativa sarebbe attraverso una \"**black-box reduction**\":\nun modo **generico** che dato un algoritmo polinomiale non-monotono genera un algoritmo polinomiale monotono senza *degradare* il fattore di apporssimazione.\nQuesto risultato sarebbe fantastico in quanto significherebbe che se un problema a singolo parametro è apporssimante allora si può garantire *\"gratis\"* anche le proprietà di monotonia e DSIC!\n\nTale riduzione black-box sarebbe interessante anche se la trasformazione genererebbe un algoritmo polinomiale e monotono con un fattore di approssimazione degenrato di un fattore **costante**.\n\nPurtroppo nel 2012 è stato dimostrato che non è possibile definire un metodo **generale**  di riduzione black-box per i tipi di porblemi a singolo parametro appena citati (vedi [qua](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.307.8197\u0026rep=rep1\u0026type=pdf)).\nD'altro canto esistono larghe classi di problemi a singolo parametro per i quali è possibile definrie una riduzione black-box (vedi Exercise 16).\n\n---\n\n# The Revelation Principle\n\nFin ora ci siamo interessati di meccanismi [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67), e questo è ragionevole per alcuni validi motivi:\n\n1. Per ogni player è facile definire quale strategia adottre: basta adottare la strategia dominante (ovvero dichiarere il vero).\n1. Il designer invece può facilmente predire il risultato dell'asta sotto la (forte) assunzione che tutti i partecipanti adottino la strategia dominante.\n\nCiò che si può chiedere è:\n\n \u003e \n \u003e Possono i meccanismo non-DSIC garantire proprietà che i meccanismi DSIC non possono?\n \u003e Ovvero, sono anche utili da studiare i meccanismi che non sono DSIC?\n\nPer cercare di dare una risposta, iniziamo col osservera un paio di assunzione che abbiamo dato per scontato nei meccanismi DSIC:\n\n* (a) Ogni partecipante ha **sempre** una strategia dominante, indipendentemente dalla sua valutazione privata. ^4a68e4\n* (b) Questa strategia dominante è la **direct revelation** (ovvero dichiarare il vero). ^c7388e\n\nPer esempio, esistono meccanismi nei quali non esiste una strategia dominante, come la [first-price auction](2%20-%20Mechanism%20Design%20Basics.md#first-price-auctions) oppure la [morra cinese](https://it.wikipedia.org/wiki/Morra_cinese).\n\nOppure ancora esistono meccanismi per i quali vale [(a)](4%20-%20%20Knapsack%20Auctions.md#4a68e4) ma non [(b)](4%20-%20%20Knapsack%20Auctions.md#c7388e).\nPer esempio, supponiamo di avere un'[asta a singolo oggetto](2%20-%20Mechanism%20Design%20Basics.md#single-item-auction), dove i partecipanti dichiarano $\\mathbf{b}$ e di eseguire la [Vickrey's auction](2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions) con offerte $2\\mathbf{b}$.\nIn tal caso la strategia dominante non sarebbe pià quella di dichiarare la propria valutazione privata $v_i$, bensì la sua metà $v_i/2$.\n\n### Beyond Dominant-Strategy Equilibria\n\nIn pratica spesso accade di trovarsi in contesti in cui non esistono *strategie dominanti*.\nPerciò è ragionevole chiedersi che succede se rilassiamo il punto [(a)](4%20-%20%20Knapsack%20Auctions.md#4a68e4).\n\nIn tal caso è necessario assumere delle proprietà più forti, ovvero bisogna assumere la presenza di [equilibri di Nash](https://en.wikipedia.org/wiki/Nash_equilibrium#Nash_Equilibrium) o [equilibri di Bayes-Nash](https://en.wikipedia.org/wiki/Bayesian_game).\n\nDato quindi che assumiamo la presenza di equilibri, ci si può chiedere se si possono progettare meccanismi migliori di quelli [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67).\nLa risposto a questa domanda è *\"a volte\"*.\n\nPer questa ragione (e anche perché i meccanismo non-DSIC sono abbastanza comuni in pratica) è importante nello studio del mechanism design tenere in considerazione e progettare meccanismi al di la di quelli DSIC.\n\n### The (dominant-strategy) Revelation Principle and the Irrelevance of Truthfulness\n\nIl **Revelation Principle** afferma che se è presente la proprietà [(a)](4%20-%20%20Knapsack%20Auctions.md#4a68e4) allora la proprietà [(b)](4%20-%20%20Knapsack%20Auctions.md#c7388e) è automaticamente grantita (*\"for free\"*).\n\nPiù formalmente\n\n \u003e \n \u003e **Theorem 3.1 (Revelation Principle)** For every mechanism $M = \\langle \\mathbf{x}, \\mathbf{p} \\rangle$ in which every participant has a **dominant strategy** (\u003cu\u003eno matter what its private information\u003c/u\u003e), there is an equivalent direct-revelation DSIC mechanism $M'$.\n\n^ec0935\n\nIn breve ciò che dice il *pricipio di rivalazione* è che se riesci a progettare un meccanismo che ha delle strategie dominanti allora può progettare un meccanismo la cua strategia dominante è la diretta rivelazione delle proprie informazioni private (ovvero conviene sempre dichiarare il vero).\n\n \u003e \n \u003e **Proof:** Supponiamo che per ogni partecipante $i$, e per ogni possibile informazione privata $v_i$ che esso può avere, esiste una *strategia dominante* $s_i(v_i)$ che esso può adottare nel meccanismo $M$.\n \u003e \n \u003e Costruiamo ora un meccanismo $M'$.\n \u003e $M'$ prende in input le offerte $b_1, ..., b_n$ dei partecipanti $1, ..., n$.\n \u003e Dopodiché esso sottopone al meccanismo $M$ i valori $s_1(b_1), ..., s_n(b_n)$.\n \u003e Infine l'outcome di $M$ sarà dato come outcome di $M'$.\n \u003e ![\\|500](lecture04-1.png)\n \u003e Si può dimostrare che $M'$ è DSIC.\n \u003e \n \u003e Infatti se un player $i$ ha come valutazione privata $v_i$, se esso propone $b_i=v_i$ allora il meccanismo $M'$ sottometterà ad $M$ il valore $s_i(v_i)$, ovvero la strategia *migliore* che può applicare.\n \u003e Perciò offrendo un valore differente da $v_i$ l'utilità di $i$ non può migliorare $\\square$.\n","lastmodified":"2022-08-29T13:39:16.823244441+02:00","tags":null},"/AGT/5-Revenue-Maximizing-Auctions":{"title":"","content":"\n# Revenue-Maximizing Auctions\n\n## The Challenge of Revenue Maximization\n\nFin ora ci siamo interessati alla progettazione di meccanismi che massimizzasserro (*esattamente* o *approsimativamente*) una sorta di **benessere** sociale, ovvero\n$$\n\\\\text{social-surplus} = \\sum\\_{i=1}^{n} v_i x_i\n$$\ndove $(x_1,...,x_n) \\in X$ è una [soluzione ammissibile](3%20-%20Myerson%E2%80%99s%20Lemma.md#43b362).\n\nUn'asta è detta **welfare-maximizing** se ha come obiettivo quelli di massimizzare il social-surplus (come visto fin ora).\n\nCi siamo interessati a *welfare-maximizing auctions* per due semplici motivi:\n\n1. è un obiettivo che spesso si incontra in scenari reali\n1. in ogni ambiente a [singolo parametro](3%20-%20Myerson%E2%80%99s%20Lemma.md#single-parameter-environments) esiste sempre un meccanismo DSIC che massimizza il *\"benessere\"* (esattamente come se il designer conoscesse in anticipo tutte le valutazioni private $v_i$).\n\nIn tali aste vengono generate dei **pagamenti**, però col solo scopo di incentivare i partecipanti a dichiarare il vero (ovvero per ottenere un meccanismo [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67)).\n\nCosa accade se ci prefissiamo l'ulteriore obiettivo di **massimizzare il ricavato** dell'asta il più possibile?\n\n## One Bidder and One Item\n\nConsideriamo il seguente esempio, ovvero una semplificazione dell'asta a singolo oggetto.\n\nSupponiamo che oltre a un solo oggetto abbiamo un solo partecipante, con valutazione $v$.\n\nNon essendoci altri concorrenti avversari, sarebbe troppo facile per il partecipante accaparrarsi l'oggetto facendo qualsiasi offerta.\nPerciò assumiamo che l'oggetto all'asta abbia un prezzo $r$, fissato dal designer.\n\nIn tal caso lo spazio dei meccanismi si riduce al semplice meccanismo del **\"prendere o lasciare\"**.\n\nSe il partecipante deciderà di *prende* l'oggetto pagherà il prezzo $r$.\nPerciò, per non avere utilità negativa l'unica strategia (*dominante*) è quella di prendere se $v \\geq r$, e non prendere se $v \\\u003c r$.\nCosì facendo non solo si garantisce utilità non negatica, ma la si massimizza anche\n$$\nu = \\max{{0, v-r}}\n$$\nVisto in termini di **rivcavi** (*revenue*) dell'asta, avremo che\n$$\n\\\\text{revenue} = \\begin{cases}\nr \u0026v \\geq r\\\\\n0 \u0026v \\\u003c r\n\\\\end{cases}\n$$\n\nIl social-surplus in questo problema sarà semplicemente pari a $v \\cdot x$, dove $x =1$ se il partecipante accetta (ovvero $v \\geq r$) o $x=0$ se rifiuta ($v \\\u003c r$).\n\nÈ molto semplice massimizzare il surplus (il *benessere*), basta porre $r=0$.\nCosì facendo si da sempre l'oggetto *\"gratis\"*, ottenendo sempre utilità massima pari a $v$.\nNotare che $r$ è **indipendente** dal valore di $v$.\n\nCosì facendo (massimizzando il benessere del partecipante) però stiamo minimizzando i **ricavi** (*revenue*) dell'asta, il quale avrà sempre valore pari a $0$.\n\nSe volessimo invece massimizzare i ricavi dell'asta basterebbe porre $r = v$.\nCosì, il partecipante comprerebbe sempre l'oggeto, al prezzo massimo il quale è disposto a pagare.\nMa non conoscendo $v$ come potremmo fare a massimizzare i guadagni?\n\nIl problema fondamentale è che differenti meccanismi funzionano meglio o peggio in base a differenti input.\nPer esempio, il meccanismo che consiste nel porre $r=20$ funziona bene quando $v$ è uguale o poco maggiore di $20$.\nHa invece pessime performance quando $v \\\u003c 20$, con surplus e revenue pari a $0$. ^5f39d8\n\n## Bayesian Analysis\n\nCome abbiamo visto [prima](5%20-%20Revenue-Maximizing%20Auctions.md#5f39d8), nel problema della massimizzazione dei guadagni le performance di un meccanismo dipendono dai diversi input (perché non conosciamo le valutazioni private).\n\nIntroduciamo e studiamo quindi il modello noto come **avarage-case** o **Bayesiano**, nel quale si assume che le valutazioni dei partecipanti rispettano certe **distribuzioni**, aprendo quindi la possibilità di studiare i **guadagni medi**.\n\nPiù formalmente, gli ingredianti sono:\n\n* Un *enviroment* a [singolo parametro](3%20-%20Myerson%E2%80%99s%20Lemma.md#single-parameter-environments).\n* La valutazione privata $v_i$ del partecipante $i$ segue una *distribuzione* con funzione di ripartizione $F_i$ e funzione di densità $f_i$, con **supporto** $\\left\\[0, v\\_{\\max} \\right\\]$. Assumiamo inoltre che le distribuzioni $F_1,...,F_n$ siano **indipendenti**.\n* Le distribuzioni $F_1,...,F_n$ sono note *a priori* dal designer. Mentre le reali valutazioni $v_1,...,v_n$ sono *private* (come al solito).\n\nOsservare che, dato che siamo interessati a meccanismi [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67) per i quali (\u003cu\u003eper definizione\u003c/u\u003e) esiste sempre una strategia dominante, i partecipanti non hanno bisogno di conoscere le relative distribuzioni $F_1,...,F_n$.\n\nIn questo ambiente **Bayesiano** è semplice definire un'asta *\"ottima\"* che massimizza il guadagno (revenue).\nIl meccanismo ottimo è quello che tra tutti i meccanismi DSIC ha il più alto **valore atteso** rispetto alla distribuzione $F_1 \\times F_2 \\times ... \\times F_n$ rispetto alle valutazioni $\\mathbf{v}$.\n\nPer esempio, rispetto all'asta [one-bidder one-item](5%20-%20Revenue-Maximizing%20Auctions.md#one-bidder-and-one-item) il guadagno atteso rispetto al prezzo $r$ sarà\n$$ r \\cdot (1 - F(r)) $$\ndove $F(r)$ è la probabilità che $v \\leq r$.\n\nModellando in questa maniera è semplice identificare il valore ottimo (in media) del prezzo $r$.\nChiamiamo il prezzo ottimo $r$ con il nome **monopoly price** della distribuzione $F$.\n\nPer esempio, se $v \\sim U\\left\\[0,1\\right\\]$ è uniforme (ovvero quando $F(x) = x$) è facile constatare che il *monopoly price* dell'asta [one-bidder one-item](5%20-%20Revenue-Maximizing%20Auctions.md#one-bidder-and-one-item) è $r = 1/2$, involvendo in un guadagno medio di $1/4$.\n\nLo stesso ragionamento si può applicare anche con due partecipanti, dove lo spazio dei meccanismi DSIC si espande.\nPer esempio, consideriamo la solita asta a singolo oggetto con due partecipanti, le quali valutazioni sono **i.i.d.** dall'uniforme in $\\left\\[0, 1\\right\\]$.\nIn tal caso si potrebbe applicare la solita [Vickrey's second-price auctions](2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions), è constatare che il *guadagno medio* è esattamente il valore atteso dell'offerta più bassa, ovvero $1/3$ (vedi **\\[esercizi\\]**).\n\nUn altro esempio potrebbe essere quello di integrare nell'asta di Vickrey un **prezzo soglia**, come accade nelle aste su eBay.\nPiù precisamente, vince il partecipante che offre di più, a meno che tutte le offerte non siano minori del *prezzo soglia* $r$, e in tal caso non vince nessuno.\nIl pagamento del vincitore sarà pari al massimo tra $r$ è la seconda miglior offerta.\nIn questo sistema ci sono sia dei vantaggi che svantaggi dal punto di vista dei guadagni, ovvero:\n\n* se tutti offrono meno di $r$ nessuno vince e il guadagno sarà $0$.\n* se un solo partecipante offre più di $r$ allora aumenta il guadagno, anziché far pagare l'offerta del secondo miglior offerente.\n  Si può verificare (**\\[vedi esercizio\\]**) che il guadagno medio in questa asta è di $5/12$ (meglio di $1/3$ senza la presenza del prezzo soglia).\n\nCiò che ci chiedimo è quindi:\nsi può fare meglio, per esempio cambiando il prezzo soglia $r$ oppure totalmente approccio ?\n\n---\n\n# Expected Revenue Equals Expected Virtual Welfare\n\nCerchiamo ora di *caratterizzare* come è fatta un'asta DSIC *ottima* (ovvero che massimizza in valore atteso i guadagni) per ogni ambiente a singolo parametro e per ogni distribuzione $F_1,...,F_n$.\n\n### Step 0\n\nPer il [revelation principle](4%20-%20%20Knapsack%20Auctions.md#ec0935) sappiamo che ogni asta per la quale esiste una *strategia dominante* esiste un'asta equivalente e DSIC.\nPerciò d'ora in poi consideriamo solo meccanismi *truthful*, ovvero dove $\\mathbf{b} = \\mathbf{v}$.\n\nIl valore atteso dei guadagni di tali aste $(\\mathbf{x}, \\mathbf{p})$ è\n$$\\mathbb{E}*{\\mathbf{v}} \\left\\[ \\sum*{i=1}^{n} p_i(\\mathbf{v}) \\right\\]$$\ndove tale media è calcolata rispetto a $\\mathbf{v} \\sim F_1 \\times ... \\times F_n$ (ovvero le offerte dei partecipanti).\n\n### Step 1\n\nFissiamo un $i$ e un $\\mathbf{v}*{-i}$.\nRicordiamo che $\\mathbf{v}*{-i}$ è una v.a. e quindi integreremo su di essa in seguito.\nPer la [formula dei pagamenti](3%20-%20Myerson%E2%80%99s%20Lemma.md#539c5a) possiamo calcolare il pagamento atteso del partecipante $i$ dati le altre offerte $\\mathbf{v}*{-i}$\n$$\\mathbb{E}*{v_i \\sim F_i} \\left\\[ p_i(\\mathbf{v}) \\right\\] = \\int_0^{v\\_{\\max}}p_i(\\mathbf{v})f_i(v_i) ,dv_i = \\int_0^{v\\_{\\max}} \\left\\[ \\int\\_{0}^{v_i} z \\cdot x'*i(z, \\mathbf{v}*{-i}) ,dz \\right\\] f_i(v_i) ,dv_i$$\nNotare che nella prima uguaglianza stiamo sfruttando l'**indipendenza** delle offerte dei partecipanti, ovvero $\\mathbf{v}\\_{-i}$ non ha alcuna influenza sulla distribuzione $F_i$.\n\nCerchiamo ora di riscrivere la media dei pagamenti in funzione della sola regola di allocazione $x_i$.\n\n### Step 2\n\nInvertendo l'ordine del doppo integrale otterremo che\n$$\\begin{align}\n\\\\int_0^{v\\_{\\max}} \\left\\[ \\int\\_{0}^{v_i} z \\cdot x'*i(z, \\mathbf{v}*{-i}) ,dz \\right\\] f_i(v_i) ,dv_i\n\u0026= \\int_0^{v\\_{\\max}} \\overbrace{\\left\\[ \\int\\_{z}^{v\\_{\\max}} f_i(v_i) ,dv_i \\right\\]}^{P(v_i \\geq z)} z \\cdot x'*i(z, \\mathbf{v}*{-i}) ,dz \\\\\n\u0026= \\int_0^{v\\_{\\max}} (1 - F_i(z)) \\cdot z \\cdot x'*i(z, \\mathbf{v}*{-i}) ,dz \n\\\\end{align}$$\n\n### Step 3\n\nIntegrando per parti\n$$\\begin{align}\n\u0026\\int_0^{v\\_{\\max}} \\underbrace{(1 - F_i(z)) \\cdot z}*{f} \\cdot \\underbrace{x'*i(z, \\mathbf{v}*{-i})}*{g'} ,dz =\\\\\n=\u0026 (1 - F_i(z)) \\cdot z \\cdot x_i(z, \\mathbf{v}*{-i}) \\Big\\vert_0^{v*{\\max}} - \\int_0^{v\\_{\\max}} (-zf_i(z) + 1 - F_i(z)) \\cdot x_i(z, \\mathbf{v}*{-i}) ,dz\\\\\n=\u0026 (1 - \\underbrace{F_i(v*{\\max})}*1) \\cdot z \\cdot x_i(v*{\\max}, \\mathbf{v}*{-i}) - (1 - F_i(0)) \\cdot z \\cdot \\underbrace{x_i(0, \\mathbf{v}*{-i})}*0 - \\int_0^{v*{\\max}} \\frac{f_i(z)}{f_i(z)}\\left(1 - F_i(z)-z\\right) \\cdot x_i(z, \\mathbf{v}*{-i}) ,dz\\\\\n=\u0026 -\\int_0^{v*{\\max}} \\left(\\frac{1 - F_i(z)}{f_i(z)}-z\\right) \\cdot x_i(z, \\mathbf{v}*{-i}) \\cdot f_i(z) ,dz\\\\\n=\u0026 \\int_0^{v*{\\max}} \\left(z-\\frac{1 - F_i(z)}{f_i(z)}\\right) \\cdot x_i(z, \\mathbf{v}*{-i}) \\cdot f_i(z),dz\n\\\\end{align}$$\nPer comodità indichiamo la funzione\n$$\\varphi_i(z) := z - \\frac{1-F_i(z)}{f_i(z)}$$\nperchiò\n$$\\mathbb{E}*{v_i \\sim F_i} \\left\\[ p_i(\\mathbf{v}) \\right\\] = \\int_0^{v\\_{\\max}} \\varphi_i(z) \\cdot x_i(z,\\mathbf{b}\\_{-i}) \\cdot f_i(z) , dz$$\n\n### Step 4\n\nDefiniamo la **valutazione virtuale** (**virtual valuation**) $\\varphi_i(v_i)$ del player $i$ con valutazione $v_i \\sim F_i$\n$$\\varphi_i(v_i) := v_i - \\frac{1-F_i(v_i)}{f_i(v_i)}$$\nNotare che tale *valutazione virtuale* dipende **solamente** dalla valutazione privata del relativo player, e non da quelle degli altri. ^9edaa0\n\nOsservare che\n$$\\mathbb{E}*{v_i \\sim F_i} \\left\\[ \\varphi_i(v_i) \\right\\] = \\int_0^{v*{\\max}} \\varphi_i(z) \\cdot f_i(z), dz $$\nperciò possiamo semplificare il tutto e dire che per ogni $i$ e per ogni $\\mathbf{v}\\_{-i}$ **fissato** avremo che il pagamento medio di $i$ campionando la sua valutazione privata $v_i \\sim F_i$ sarà\n\n$$\\mathbb{E}*{v_i \\sim F_i} \\left\\[ p_i(\\mathbf{v}) \\right\\] = \\int_0^{v*{\\max}} \\varphi_i(z) \\cdot x_i(z,\\mathbf{b}*{-i}) \\cdot f_i(z), dz = \\mathbb{E}*{v_i \\sim F_i} \\left\\[ \\varphi_i(v_i) \\cdot x_i(\\mathbf{v}) \\right\\]$$ ^2b6eca\n\n#### Esempio\n\nSupponiamo che $v_i \\sim U\\left\\[ 0,1 \\right\\]$.\nAvremo quindi che $F_i(z) = z$ e $f_i(z) = F'*i(z) = 1$.\nPerciò $$\\varphi_i(z) = z - \\frac{1-z}{1} = 2z - 1$$ per ogni $z \\in \\left\\[ 0, v*{\\max} \\right\\]$.\nOsserviamo inoltre che $\\varphi_i(z) \\in \\left\\[ -1, 1 \\right\\]$.\n\n#### Interpretazione della valutazione virtuale\n\nLa *valutazione virtuale* gioca un ruolo importante nella progettazione di aste bayesiane ottimali.\nÈ utile chiedersi se si può dare un qualche significato *intuitivo* a $\\varphi_i(v_i)$.\n\nUn modo per interpretare i due addendi che compongono $\\varphi_i(v_i)$ è considerando $v_i$ il **massimo guadagno** che è possibile ottenere da $i$ (di più $i$ non può pagare altrimenti avrebbe utilità negativa) mentre il secondo elemento $(1-F_i(v_i))/f_i(v_i)$ la **perdita** di guadagno causata dalla **mancata conoscenza a priori** di $v_i$ (aka *\"information rent\"*).\n$$\\varphi_i(v_i) = \\underbrace{v_i}*{\\text{what you'd like to charge }i} - \\underbrace{\\frac{1-F_i(v_i)}{f_i(v_i)}}*{\\text{\"information rent\" earned by bidder} i}$$\n\nUn secondo modo più accurato è quello di pensare a $\\varphi_i(v_i)$ come la **pendenza** di una *\"curva dei ricavi\"*, dove tale curva traccia il *guadagno atteso* dal player $i$ campionando $v_i \\sim F_i$. \n\n### Step 5\n\nApplichiamo al [formula](5%20-%20Revenue-Maximizing%20Auctions.md#2b6eca) ad ogni elemento di $\\mathbf{v}$, ottenendo\n$$\\begin{align}\n\\\\mathbb{E}*{\\mathbf{v} \\sim F_1 \\times ... \\times F_n} \\left\\[ p_i(\\mathbf{v}) \\right\\]\n\u0026= \\idotsint*{\\left\\[0,v\\_{\\max} \\right\\]^n} p_i(z_1, ..., z_n) \n\\\\cdot f_1(z_1) f_2(z_2) \\dots f_n(z_n) , dz_1 \\dots dz_n\\\\\n\u0026= \\idotsint\\_{\\left\\[0,v\\_{\\max} \\right\\]^n} \\varphi_i(z_i)x_i(z_1, ..., z_n) \\cdot f_1(z_1) f_2(z_2) \\dots f_n(z_n), dz_1 \\dots dz_n\\\\\n\u0026= \\mathbb{E}*{\\mathbf{v} \\sim F_1 \\times ... \\times F_n} \\left\\[ \n\\\\varphi_i(v_i)\\cdot x_i(\\mathbf{v})\\right\\]\n\\\\end{align}$$\no in maniera più compatta\n$$\\mathbb{E}*{\\mathbf{v}} \\left\\[ p_i(\\mathbf{v}) \\right\\] = \\mathbb{E}\\_{\\mathbf{v}} \\left\\[ \\varphi_i(v_i) \\cdot x_i(\\mathbf{v}) \\right\\]$$\n\n### Step 6\n\nApplicando la **linearità** del valore atteso\n$$\\mathbb{E}*{\\mathbf{v}} \\left\\[ \\sum*{i=1}^{n} p_i(\\mathbf{v}) \\right\\] = \\sum\\_{i=1}^{n} \\mathbb{E}*{\\mathbf{v}} \\left\\[ p_i(\\mathbf{v}) \\right\\] = \\sum*{i=1}^{n}\\mathbb{E}*{\\mathbf{v}} \\left\\[ \\varphi_i(v_i) \\cdot x_i(\\mathbf{v}) \\right\\] = \\mathbb{E}*{\\mathbf{v}} \\left\\[ \\sum\\_{i=1}^{n}\\varphi_i(v_i) \\cdot x_i(\\mathbf{v}) \\right\\]$$\n\nAbbiamo quindi riscritto il pagamento medio in funzione della sola funzione di allocazione $\\mathbf{x}$  , e delle probabilità $F_1,...,F_n$.\n\n$$\\mathbb{E}*{\\mathbf{v}} \\left\\[ \\mathbf{p}(\\mathbf{v}) \\right\\] = \\mathbb{E}*{\\mathbf{v}} \\left\\[ \\Phi(\\mathbf{v}) \\cdot \\mathbf{x}(\\mathbf{v}) \\right\\] $$\nOsserviamo che nella formula appena trovata, se rimovessimo la funzione $\\Phi$ ci ritroveremmo con il **social-surplus atteso**, ovvero\n$$\\text{EXPECTED SURPLUS} = \\mathbb{E}*{\\mathbf{v}}\\left\\[\\\\sum*{i=1}^{n} v_i \\cdot x_i(\\mathbf{v})\\right\\] $$\nperciò (analogamente a prima) ci riferiremo alla quantità $\\sum\\_{i=1}^{n} \\varphi_i(v_i) \\cdot x_i(\\mathbf{v})$ con il termine **virtual surplus**\n\n$$\\text{VIRTUAL SURPLUS} = \\sum\\_{i=1}^{n} \\varphi_i(v_i) \\cdot x_i(\\mathbf{v})$$ ^7b8481\n\nIn conclusione possiamo dire che massimizzare i guadagni attesi (\u003cu\u003enello spazio dei meccanismi DSIC\u003c/u\u003e) equivale a massimizzare il virtual surplus atteso\n\n \u003e \n \u003e **EXPECTED REVENUE = EXPECTED VIRTUAL WELFARE**\n\n^c86ff2\n\n---\n\n# Bayesian Optimal Auctions\n\nIl [risultato](5%20-%20Revenue-Maximizing%20Auctions.md#c86ff2) appena trovato è molto comodo, in quanto ci consente di trascurare i pagamenti e concentrarci solamente su un problema di ottimizzazione che riguarda solamente la regola di allocazione.\n\n## Maximizing Expected Virtual Welfare\n\nPrima di cercare di caratterizzare l'asta *\"ottima\"* (in termini di ricompense) per un \u003cu\u003equalsiasi\u003c/u\u003e problema a singolo parametro, partiamo da casi più semplici e restrittivi.\n\nInnanzitutto partiamo col considerare un'asta a singolo oggetto.\nDopodiché, assumiamo che le valutazioni private siano **i.i.d**, ovvero $F_1 = F_2 = ... F_n = F$.\n\nCosì facendo avremo anche che $f_1 = f_2 = ... = f_n = f$ e quindi $\\varphi_1 = \\varphi_2 = ... = \\varphi_n = \\varphi$.\n\nIndichiamo con $\\mathbf{F}$ la distribuzione congiunta $F_1 \\times ... \\times F_n \\equiv F^n$.\n\nIn questo contesto e con queste assunzioni, come possiamo scegliere un $\\mathbf{x}$ (DSIC) che massimizzi \u003cu\u003ein media\u003c/u\u003e il [virtual surplus](5%20-%20Revenue-Maximizing%20Auctions.md#7b8481)?\n\n$$\\mathbf{x} = \\arg \\max\\_{(x_1,...,x_n) \\in X} ; \\mathbb{E}*{\\mathbf{v} \\sim \\mathbf{F}} \\left\\[ \\sum*{i=1}^{n} \\varphi(v_i) x_i(\\mathbf{v}) \\right\\]$$ ^8ee749\n\nPurtroppo non abbiamo controllo sulla distribuzione $\\mathbf{F}$, perciò su $\\mathbf{v}$ e $\\varphi$.\n\nIl modo più semplice è quello di massimizzare il *virtual surplus* separatamente per ogni input $\\mathbf{v}$ (*pointwise*).\n\nNell'asta a singolo oggetto abbiamo che $\\mathbf{x}(\\mathbf{v}) \\in {0,1}^n$ con la costrizione che *al più* una sola entry deve essere $1$.\nPerciò la regola di allocazione $\\mathbf{x}$ che massimizza il *virtual surplus* equivale semplicemente alla regola che elegge come vincitore il player $i$ con **[valutazione virtuale](5%20-%20Revenue-Maximizing%20Auctions.md#9edaa0)** $\\varphi(v_i)$, massima.\n\n \u003e \n \u003e Ricordiamo che la valutazione virtuale può anche assumere valori **negativi** ([vedi esempio](5%20-%20Revenue-Maximizing%20Auctions.md#esempio)).\n \u003e Perciò, nel caso in cui tutti i $\\varphi(v_i)$ siano $\\\u003c 0$, la regola $\\mathbf{x}$ che massimizza il *virtual surplus* è quella che non dichiara nessun vincitore.\n\nTrovare un $\\mathbf{x}$ che massimizza il *[virtual surplus](5%20-%20Revenue-Maximizing%20Auctions.md#7b8481)* per separatamente per ogni $\\mathbf{v}$ definisce una regola di allocazione che lo massimizza anche in [media](5%20-%20Revenue-Maximizing%20Auctions.md#8ee749) tra tutte le possibili regole di allocazione possibili in $X$ (monotone o no).\n\nNoi però vorremmo anche che tale regola di allocazione $\\mathbf{x}$ che massimizza il *virtual surplus* abbia una *strategia dominante*.\nPer il [principio di rivelazione](4%20-%20%20Knapsack%20Auctions.md#ec0935) sappiamo che possiamo estendere $\\mathbf{x}$ ad essere [DSIC](2%20-%20Mechanism%20Design%20Basics.md#a63f67), e per il [Mayerson's Lemma](3%20-%20Myerson%E2%80%99s%20Lemma.md#theorem-mayerson-s-lemma) ciò equivale a dire che $\\mathbf{x}$ è [monotona](3%20-%20Myerson%E2%80%99s%20Lemma.md#3c29c4).\nIn fine sappiamo che se $\\mathbf{x}$ è monotona allora tale meccanismo che massimizza il *virtual surplus* (in media) massimizzerebbe anche i *guadagni medi* (vedi [Step 6](5%20-%20Revenue-Maximizing%20Auctions.md#step-6)).\n\nLa risposta a tale domanda chiave dipende dalla distribuzione $F$.\nInfatti si può dimostrare che se $F$ è tale che la [valutazione virtuale](5%20-%20Revenue-Maximizing%20Auctions.md#9edaa0) $\\varphi$ è **strettamente crescente**, allora la regola di allocazione $\\mathbf{x}$ che abbiamo trovato che massimizza il *virtual surplus* allora è **monotona** (e quindi massimizza anche il *guadagno atteso*).\n\n \u003e \n \u003e **Def.** Una distribuzione $F$ è **regolare** se la corrispondente [valutazione virtuale](5%20-%20Revenue-Maximizing%20Auctions.md#9edaa0) $v - \\frac{1-F(v)}{f(v)}$ è **strettamente crescente**.\n\nPer esempio la distribuzione uniformo vista nell'[Esempio](5%20-%20Revenue-Maximizing%20Auctions.md#esempio) è *regolre*.\nAnche altre distribuzioni lo sono, come per esempio quella [esponenziale](https://en.wikipedia.org/wiki/Exponential_distribution) o quella [log-normale](https://en.wikipedia.org/wiki/Log-normal_distribution).\n\nPerciò possiamo dire che nell'asta a singolo oggetto con distribuzioni i.i.d. e con l'assunzione di *regolarità* delle distribuzioni, la regola di allocazione $\\mathbf{x}$ che elegge vincitore il partecipante con massima (\u003cu\u003enon negativa\u003c/u\u003e) *valutazione virtuale* $\\varphi(v_i)$ (se esiste), è *monotona* e quindi induce in un'asta *\"ottima\"* che **massimizza il social-surplus e il guadagno atteso**.\n\nOsservare inoltre che dato che tutti i partecipanti condividono la stesso funzione di *valutazione virtuale* $\\varphi$, e dato che stiamo assumendo che $F$ è regolare, allora il player con $\\varphi(v_i)$ più alto equivale al player con valutazione privata $v_i$ più alta.\n\nNotare che l'unica differenza tra la [Vickrey's second-price auctions](2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions) che elegge il partecipante con offerta (o valutazione dato che è DSIC) maggiore e la regola $\\mathbf{x}$ appena descritta che elegge il partecipante con *valutazione virtuale* $\\varphi$ massima, è che nella seconda possono capitare casi in cui non viene eletto nessun vincitore (ovvero quando $\\max \\varphi(v_i) \\\u003c 0$).\n\nIn poche parole la regola $\\mathbf{x}$ appena trovata equivale sostanzialmente alla [Vickrey's second-price auctions](2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions) con **prezzo minimo** $r = \\varphi^{-1}(0)$.\nInfatti se la valutazione massima $v^\\* \\geq r = \\varphi^{-1}(0)$ allora avremo una *valutazione virtuale*\n$$\\varphi(v^*) \\geq \\varphi(r) = \\varphi(\\varphi^{-1}(0)) = 0 \\implies \\varphi(v^*) \\geq 0$$\ne quindi esiste un vincitore.\n\nIn maniera pià generale vedremo che in un qualsiasi ambiente a singolo parametro con distribuzioni $F_1,...,F_n$, se tali distribuzioni sono **tutte regolari** allora la regola di allocazione $\\mathbf{x}$ che massimizza (dipendentemente da $\\mathbf{v}$) il [surplus virtuale](5%20-%20Revenue-Maximizing%20Auctions.md#7b8481) è **monotona**, perciò avremo trovato un meccanismo DSIC e che massimizza in valore atteso i guadagni.\n\nIn questo senso possiamo dire di aver risolto le aste Bayesiane per ogni ambiente a singolo parametro a patto di avere distribuzioni regolari.\n","lastmodified":"2022-08-29T13:39:17.115769045+02:00","tags":null},"/AGT/6-Simple-Near-Optimal-Auctions":{"title":"","content":"\n# Simple Near-Optimal Auctions\n","lastmodified":"2022-08-29T13:39:16.802211654+02:00","tags":null},"/AGT/Exercise/Exercise-Set-2":{"title":"","content":"\n# Problem set 2\n\n## Lecture 3 Exercises\n\n### Exercise 9\n\nUse [Myerson’s Lemma](../3%20-%20Myerson%E2%80%99s%20Lemma.md#theorem-mayerson-s-lemma) to prove that the [Vickrey auction](../2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions) is the unique single-item auction that is [DSIC](../2%20-%20Mechanism%20Design%20Basics.md#a63f67), always awards the good to the highest bidder, and charges losers 0.\n\n#### Solution\n\nÈ facile verificare che la regola di assegnazione $\\mathbf{x}$ che assegna l'oggetto al più alto offerente è [monotona](../3%20-%20Myerson%E2%80%99s%20Lemma.md#3c29c4).\nInfatti, fissiando un $i$ e un $\\mathbf{b}*{-i}$ e $B = \\max{{b_j : b_j \\in \\mathbf{b}*{-i}}}$, si può vedere che al variare dell'offerta $b_i$ avremo che:\n\n* $\\mathbf{x}(b_i, \\mathbf{b}\\_{-i}) = 0$ per ogni $b_i \\leq B$.\n* $\\mathbf{x}(b_i, \\mathbf{b}\\_{-i}) = 1$ per ogni $b_i \u003e B$.\n\nIl punto [(a)](../3%20-%20Myerson%E2%80%99s%20Lemma.md#d589da) ci garantisce che se $\\mathbf{x}$ è monotona allora è anche [implementabile](../3%20-%20Myerson%E2%80%99s%20Lemma.md#1898c6) (ovvero abbiamo DSIC).\nIl punto [(b)](../3%20-%20Myerson%E2%80%99s%20Lemma.md#3bc8f8) invece garanti l'esistenza di un **unico** sistema di pagamento $\\mathbf{p}$.\nIl punto [(c)](../3%20-%20Myerson%E2%80%99s%20Lemma.md#9c8cc8) ci dice invece che il pagamento è definito tramite una [formula esplicita](../3%20-%20Myerson%E2%80%99s%20Lemma.md#232507), ottenendo che\n$$\np_i(b_i, \\mathbf{b}\\_{-i}) = \\begin{cases}\nB \u0026\\mbox{se } b_i \u003e B\\\\\n0 \u0026\\mbox{se } b_i \\leq B\n\\\\end{cases}\n$$\novvero lo schema di pagamento del [Vickrey auction](../2%20-%20Mechanism%20Design%20Basics.md#vickrey-s-second-price-auctions).\n\n---\n\n### Exercise 10\n\nUse the [\"payment difference sandwich\"](../3%20-%20Myerson%E2%80%99s%20Lemma.md#af2847)  in the [proof of Myerson's Lemma](../3%20-%20Myerson%E2%80%99s%20Lemma.md#proof-of-myerson-s-lemma-informal) to prove that if an allocation rule **is not** [monotone](../3%20-%20Myerson%E2%80%99s%20Lemma.md#3c29c4), then it **is not** [implementable](../3%20-%20Myerson%E2%80%99s%20Lemma.md#1898c6).\n\n#### Solution\n\nAbbiamo che dati due valori $0 \\\u003c z \\leq y$, se $\\mathbf{x}$ è monotona allora\n$$ z \\cdot \\left\\[ x(z) - x(y) \\right\\] \\geq \\Delta_p \\geq y \\cdot \\left\\[ x(z) - x(y) \\right\\] $$\ndove $$\\Delta_p = p(y) - p(z)$$\nIl precedente intervallo può esistere (ovvero è **non vuoto**) solamente se $\\mathbf{x}$ è **monotona**.\nInfatti, supponiamo che $v_i = z$.\nSe $\\mathbf{x}$ fosse **non** monotona, allora esisterebbe certamente un $y \u003e z$ tale che $x(y) \\\u003c x(z)$.\nIn tal caso avremo che la differenza $x(y) - x(z) \\\u003c 0$, e quindi avremo che $\\Delta_p$ deve necessariamente appartenere all'intervallo\n$$ z \\cdot \\left\\[ x(z) - x(y) \\right\\] \\geq \\Delta_p \\geq y \\cdot \\left\\[ x(z) - x(y) \\right\\] $$\ne questo intervallo è vuoto perche $z \\\u003c y$ $\\square$.\n\n---\n\n### Exercise 11\n\nWe concluded the [proof of Myerson’s Lemma](../3%20-%20Myerson%E2%80%99s%20Lemma.md#proof-of-myerson-s-lemma-informal) by giving a *\"proof by picture\"* that coupling a monotone and piecewise constant allocation rule $\\mathbf{x}$ with the payment formula\n\n$$p_i(b_i, \\mathbf{b}*{-i}) = \\sum*{j=1}^{\\ell} z_j \\cdot \\left\\[ \\text{salto di } x_i(\\cdot, , \\mathbf{b}*{-i}) \\text{ in } z_j \\right\\]$$\nwhere $z_1,...,z*\\\\ell$ are the **breakpoints** of the allocation function $x_i(\\cdot, \\mathbf{b}\\_{-i})$ in the range $\\left\\[0, b_i \\right\\]$, yields a DSIC mechanism. ^8fc753\n\nWhere does the proof-by-picture break down if the piecewise constant allocation rule $\\mathbf{x}$ is **not** monotone?\n\n#### Solution\n\nOsserviamo cosa accade *graficamente* se si dichiara di più del vero nel caso in cui $\\mathbf{x}$ non è monotona.\n\n![](exercise11-1.png)\nOsservare che $p(b)$ (nel caso in cui $b\u003ev$) racchiude un rettangolo tratteggiato.\nCiò sta ad indicare un \"**pagamento negativo**\", ovvero dei soldi da ricevere anziché saldare.\nCiò accade perché avviene un *\"salto\"* verso il basso, e quindi viene sottratto del pagamento anziché aggiunto.\n\nIn colcusione, se $\\mathbf{x}$ è non monotona, potrebbe accadere di avere utilità maggiore dichiarando il falso (in questo caso di più).\n\n---\n\n### Exercise 12\n\nGive a purely algebraic proof that coupling a monotone and piecewise constant allocation rule x with the [payment rule](Exercise%20Set%202.md#8fc753) yields a DSIC mechanism.\n\n#### Solution\n\nFissiamo un player $i$ e consideriamo il caso in cui dichiara il vero $b_i = v_i$.\nLa sua utilità sarà pari a\n$$u_i(b_i, \\mathbf{b}*{-i}) = v_i \\cdot x_i(z*\\\\ell) - \\sum\\_{j = 1}^\\ell z_j \\cdot (x_i(z_j) - x_i(z\\_{j-1}))$$\ndove $z_0 = 0$ e $z_1, ..., z\\_\\\\ell$ i punto di $x_i(\\cdot, , \\mathbf{b}\\_{-i})$ dove avvengono i salti, rispetto all'intervallo $\\left\\[ 0, b_i \\right\\]$.\n\n**Immagine**\n\nVediamo ora cosa accadrebbe se dovesse offrire meno $b_i = y^{(-)} \\\u003c v_i$.\nIn tal caso l'utilità sarà\n$$u_i(y^{(-)}, \\mathbf{b}*{-i}) = v_i \\cdot x_i(z_m) - \\sum*{j = 1}^m z_j \\cdot (x_i(z_j) - x_i(z\\_{j-1}))$$\ndove $z_0 = 0$ e $z_1, ..., z_m$ i punto di $x_i(\\cdot, , \\mathbf{b}\\_{-i})$ dove avvengono i salti, rispetto all'intervallo $\\left\\[ 0, y^{(-)} \\right\\]$.\n\nOsserviamo che essendo $y^{(-)} \\\u003c v_i$ allora $m \\leq \\ell$, ovvero il numero di gradini non può essere maggiore rispetto a prima.\n\n* **Caso $m = \\ell$**. In questo caso avremo che la differenza di utilità sarà pari a\n  $$u_i(v_i, \\mathbf{b}*{-i}) - u_i(y^{(-)}, \\mathbf{b}*{-i}) = 0$$\n* **Caso $m \\\u003c \\ell$**. In tal caso avremo che $p_i(b_i) \u003e p_i(y^{(-)})$, perciò\n  $$\\begin{align\\*}\n  u_i(v_i, \\mathbf{b}*{-i}) - u_i(y^{(-)}, \\mathbf{b}*{-i})\n  \u0026= v_i \\cdot (x_i(v_i) - x_i(y^{(-)})) - p_i(v_i) + p_i(y^{(-)})\\\\\n  \u0026= v_i \\cdot (x_i(v_i) - x_i(y^{(-)})) + \\underbrace{\\left\\[p_i(y^{(-)}) - p_i(v_i)\\right\\]}*{\\\u003c 0}\\\\\n  \u0026\u003e v_i \\cdot (x_i(v_i) - x_i(y^{(-)}))\\\\\n  \u0026= v_i \\cdot \\underbrace{(x_i(z*\\\\ell) - x_i(z_m))}*{\\geq 0}\\\\\n  \u0026\\geq 0\n  \\\\end{align\\*}$$\n  Ovvero $u_i(v_i, \\mathbf{b}*{-i}) \u003e u_i(y^{(-)}, \\mathbf{b}\\_{-i})$ (non conviene dichiarare meno).\n\nSimmetricamente, possiamo applicare lo stesso ragionamento nel caso in cui si dichiara di più $b_i = y^{(+)} \u003e v_i$.\n\nInfatti, l'utilità sarà\n$$u_i(y^{(+)}, \\mathbf{b}*{-i}) = v_i \\cdot x_i(z_t) - \\sum*{j = 1}^t z_j \\cdot (x_i(z_j) - x_i(z\\_{j-1}))$$\ndove $z_0 = 0$ e $z_1, ..., z_t$ i punto di $x_i(\\cdot, , \\mathbf{b}\\_{-i})$ dove avvengono i salti, rispetto all'intervallo $\\left\\[ 0, y^{(+)} \\right\\]$.\n\nOsserviamo che essendo $y^{(+)} \u003e v_i$ allora $t \\geq \\ell$, ovvero il numero di gradini non può essere minore rispetto a prima.\n\n* **Caso $t = \\ell$**. In questo caso avremo che la differenza di utilità sarà pari a\n  $$u_i(v_i, \\mathbf{b}*{-i}) - u_i(y^{(+)}, \\mathbf{b}*{-i}) = 0$$\n* **Caso $t \u003e \\ell$**. In tal caso avremo che $p_i(y^{(+)}) \u003e p_i(b_i)$.\n  Inoltre per monotonia $x_i(y^{(+)}) \\geq x_i(v_i)$. Perociò avremo che  \n  $$\\begin{align\\*}\n  u_i(v_i, \\mathbf{b}*{-i}) - u_i(y^{(+)}, \\mathbf{b}*{-i})\n  \u0026= v_i \\cdot (x_i(v_i) - x_i(y^{(+)})) - p_i(v_i) + p_i(y^{(+)})\\\\\n  \u0026= v_i \\cdot \\underbrace{(x_i(v_i) - x_i(y^{(+)}))}*{\\leq 0} + \\left\\[p_i(y^{(+)}) - p_i(v_i)\\right\\]\\\\\n  \u0026\\geq p_i(y^{(+)}) - p_i(v_i)\\\\\n  \u0026\u003e 0\n  \\\\end{align\\*}$$\n  Ovvero $u_i(v_i, \\mathbf{b}*{-i}) \u003e u_i(y^{(+)}, \\mathbf{b}\\_{-i})$ (non conviene dichiarare di più).\n\nCon lo stesso ragionamento si può dimostrare anche nel caso di funzioni $x_i(\\cdot)$ differenziabili $\\square$.\n\n---\n\n## Lecture 4 Exercises\n\n### Exercise 13\n\nConsider the following extension of the sponsored search setting discussed in lecture.\nEach bidder $i$ now has a **publicly known quality** $\\beta_i$ (in addition to a private valuation $v_i$ per click).\n\nAs usual, each slot $j$ has a CTR $\\alpha_j$, and $\\alpha_1 \\geq \\alpha_2 \\geq ··· \\geq \\alpha_k$.\nWe assume that if bidder $i$ is placed in slot $j$, its probability of a click is $\\beta_i\\alpha_j$ — thus, bidder $i$ derives value $v_i\\beta_i\\alpha_j$ from this outcome.\n\nDescribe the surplus-maximizing allocation rule in this generalized sponsored search setting.\nArgue that this rule is monotone.\nGive an explicit formula for the per-click payment of each bidder that extends this allocation rule to a DSIC mechanism.\n\n#### Solution\n\n$$\nx_i(b_i, \\mathbf{b}*{-i}) = \\begin{cases}\n\\\\beta_i\\alpha_j \u0026\\text{se a } i \\text{ viene assegnato lo slot } j\\\\\n\\\\\n0 \u0026\\text{altrimenti}\n\\\\end{cases}\n$$\nSenza perdita di generalità, ordiniamo i player nel seguente ordine\n$$\nv_1\\beta_1 \\geq v_2\\beta_2 \\geq ... \\geq v_n\\beta_n\n$$\nIn tal modo, quello che si vuole massimizzare è\n$$\n\\\\sum*{i=1}^{k} v_i\\beta_i\\alpha_i\n$$\nOrdinando nello stesso modo in base alle offerte dichiarate (ovvero $b_1\\beta_1 \\geq ... \\geq b_n\\beta_n$).\nUna regola di allocazione che massimizza il social-surplus è quindi quella che assegna i $k$ slot ai primi $k$ player secondo l'ordine precedentemente descritto.\nIn tal caso quindi avremo come social surplus la seguente quantità\n$$\n\\\\sum\\_{i=1}^{k} b_i \\cdot x_i(b_i) = \\sum\\_{i=1}^{k} b_i\\beta_i\\alpha_i\n$$\nSe tale regola di allocazione $\\mathbf{x}$ è DSIC allora il social-surplus sarà **massimizzato**.\n\nGrazie al [Mayerson's Lemma](../3%20-%20Myerson%E2%80%99s%20Lemma.md#theorem-mayerson-s-lemma) per dimostrare che $\\mathbf{x}$ è DSIC basta dimostrare che $\\mathbf{x}$ è [monotona](../3%20-%20Myerson%E2%80%99s%20Lemma.md#3c29c4).\n\nFissiamo un $i$, un $\\mathbf{b}*{-i}$ e vediamo come varia $x_i(z, \\mathbf{b}*{-i})$ al crescere di $z$.\nConsideriamo senza perdita di generalità che i CTR siano ordinati in modo tale che $\\beta_1\\alpha_1 \\geq ... \\geq \\beta_k\\alpha_k$ (esattamente come le offerte).\nÈ facile verificare che $x_i(\\cdot, \\mathbf{b}*{-i})$ è fatta a gradini esattamente come nell'asta sposorizzata semplice\n![](exercise-13.png)\nfacendo salti di magnitudo $\\beta_j\\alpha_j - \\beta*{j+1}\\alpha\\_{j+1}$ nel punto $b_j\\beta_j$.\n\nPerciò, per $z \\in \\left\\[ b_j\\beta_j, ;; b\\_{j-1}\\beta\\_{j-1}\\right.)$ avremo che $x_i(z) = \\beta_j\\alpha_j$, per ogni $j \\leq k$.\nAumentando $z \\geq b\\_{j-1}\\beta\\_{j-1}$ avremo che $x_i(z)$ **non diminuisce mai**, assumendo un valore $\\beta\\_{j-1}\\alpha\\_{j-1} \\geq \\beta_j\\alpha_j$.\nPerciò $x_i(\\cdot)$ è *monotona*.\n\nInfine lo schema di pagamento sarà\n$$\np_i(b_i, \\mathbf{b}*{-i}) = \\sum*{j=i}^{k} \\beta_j \\cdot \\left\\[ b_j \\cdot (\\alpha_j - \\alpha\\_{j+1}) \\right\\]\n$$\ndove $\\alpha\\_{k+1} = 0$ $\\square$.\n\n---\n\n### Exercise 14\n\nConsider an arbitrary [single-parameter environment](../3%20-%20Myerson%E2%80%99s%20Lemma.md#single-parameter-environments), with feasible set $X$.\nThe surplus-maximizing allocation rule is $\\mathbf{x}(\\mathbf{b}) = arg \\max\\_{(x_1,...,x_n) \\in X} \\sum\\_{i=1}^{n}b_ix_i$.\nProve that this allocation rule is monotone.\n*\\[You should assume that ties are broken in a deterministic and consistent way, such as lexicographically.\\]*\n\n#### Solution\n\nAssumiamo per assurdo che la regola di allocazione $\\mathbf{x}(\\mathbf{b}) = arg \\max\\_{(x_1,...,x_n) \\in X} \\sum\\_{i=1}^{n}b_ix_i$ che massimizza il *surplus* sia **non monotona**.\n\nPerciò $\\mathbf{x}$ è **non monotona** se esiste un $i$ tale che la funzione $x_i = x_i(z, \\mathbf{b}\\_{-i})$ è **non non-decrescente**, ovvero tale che esistono due $z,y$ tali che $z \\\u003c y$ e $x_i(z) \u003e x_i(y)$.\n\nSe $\\mathbf{x}(\\mathbf{b})$ massimizza $\\sum\\_{i=1}b_ix_i$ allora certamente massimizza $\\mathbf{x}(c \\cdot \\mathbf{b})$ per ogni $c \u003e 1$.\nPiù precisamente avremo che $\\mathbf{x}(c \\cdot \\mathbf{b}) = c \\cdot \\mathbf{x}(\\mathbf{b})$.\n\nSe però $\\mathbf{x}$ è non monotona allora esiste certamente un $\\hat{c} \u003e 1$ tale $x_i(\\hat{c} \\cdot b_i) \\\u003c x_i(b_i)$.\n\nConsideriamo ora una $\\mathbf{x^*}$ **monotona** totalmente simile ad $\\mathbf{x}$ con la differenza che $x^*\\_i(\\cdot)$ è **non decrescente**.\n\nAllora avremo che per un $\\hat{c}$ sufficientemente grande\n$$\\mathbf{x^*}(\\hat{c} \\cdot \\mathbf{b}) \u003e \\mathbf{x}(\\hat{c} \\cdot \\mathbf{b}) \\implies \\hat{c} \\cdot \\mathbf{x^*}(\\mathbf{b}) \u003e \\hat{c} \\cdot \\mathbf{x}(\\mathbf{b}) \\implies \\mathbf{x^\\*}(\\mathbf{b}) \u003e \\mathbf{x}(\\mathbf{b})$$\novvero $\\mathbf{x}$ non massimizzava $\\sum\\_{i=1}b_ix_i$ $\\square$.\n\n---\n\n### Exercise 15\n\nContinuing the previous exercise, restrict now to feasible sets $X$ that contain only $0$-$1$ vectors – that is, each bidder either wins or loses.\nWe can thus identify each feasible outcome with a *\"feasible set\"* of bidders (the winners in that outcome).\nAssume further that the environment is *\"downward closed\"*, meaning that subsets of a feasible set are again feasible.\n\nRecall from lecture that [Myerson’s payment formula](../3%20-%20Myerson%E2%80%99s%20Lemma.md#232507) dictates that a winning bidder pays its *\"critical bid\"* $\\theta_i$ — the lowest bid at which it would continue to win.\n\nProve that, when $S^*$ is the set of winning bidders and $i \\in S^*$, $i$’s critical bid $\\theta_i$'s equals the difference between:\n(i) the maximum surplus of a feasible set that excludes $i$ (you should assume there is at least one such set); and\n(ii) the surplus $\\sum\\_{j \\in S^*\\\\setminus{i}} v_j$ of the bidders other than $i$ in the chosen outcome $S^*$.\n\nAlso, is this dfference always **non-negative**? ^23a43f\n\n**Remark:** In the above sense, a winning bidder pays its *\"externality\"* — the surplus loss it imposes on others.\n\n#### Solution\n\nDalla  [formula dei pagamenti](../3%20-%20Myerson%E2%80%99s%20Lemma.md#232507) sappiamo che il pagamento di un player $i \\in S$ sarà\n$$p_i(b_i) = \\theta_i \\cdot \\left\\[ \\text{salto in } \\theta_i \\right\\] = \\theta_i$$\no più in generale\n$$p_i(b_i, \\mathbf{b}\\_{-i}) = \\begin{cases}\n0 \u0026b_i \\\u003c \\theta_i\\\\\n\\\\theta_i \u0026b_i \\geq \\theta_i\n\\\\end{cases}$$\n\nSi vule dimostrare che\n$$p_i(b_i, \\mathbf{b}*{-i}) = \\theta_i = \\left\\[ \\max*{(x_1,...,x_n)}\\sum\\_{j \\neq i}v_j \\cdot x_j(\\mathbf{b}*{-i}) \\right\\] - \\sum*{j \\in S^\\* \\setminus {i}}v_j$$ ^fd6c21\n\nOsserviamo innanzitutto che tale differenza è sempre **[non negativa](Exercise%20Set%202.md#23a43f)**.\nInfatti, supponiamo che nell'insieme delle soluzioni ammissibili $X$ ci siano vettori $\\mathbf{x}$ con \u003cu\u003eal più\u003c/u\u003e $k$ $1$.\nAllora nel primo elemento della sottrazione avremo le $k-1$ *valutazioni* più alte (esclusa $v_i$) mentre nel secondo elemento avremo semplicemente \u003cu\u003eal più\u003c/u\u003e $k-1$ valutazioni qualasiasi (sempre esclusa $v_i$).\nCiò garantisce sempre che $p_i \\geq 0$.\n\nDA FINIRE...\n\n---\n\n### Exercise 16\n\nContinuing the [previous exercise](Exercise%20Set%202.md#exercise-15), consider a $0$-$1$ downward-closed single-parameter environment.\n\nSuppose you are given a *\"black box\"* that can compute the surplus-maximizing allocation rule $\\mathbf{x}(\\mathbf{b})$ for an arbitrary input $\\mathbf{b}$.\n\nExplain how to compute the payments identified in the previous exercise by invoking this black box multiple times.\n\n#### Solution\n\nIndichiamo con $\\phi$ tale *\"black box\"*.\nAvremo quindi che dando \"in pasto\" un qualsiasi $\\mathbf{b}$ a $\\phi$ \n$$\\mathbf{b} ; \\xrightarrow{\\text{input}} ; \\phi ; \\xrightarrow{\\text{output}} ; \\mathbf{x}(\\mathbf{b}) = \\arg \\max\\_{(x_1,...,x_n)} \\sum\\_{i=1}^{n} v_ix_i$$\nPer brevità indichiamo con $\\phi(\\mathbf{b})$ il nostro output.\n\nDall'[esercizio 15](Exercise%20Set%202.md#fd6c21) abbiamo quindi che data una **qualsiasi soluzione ammissibile** $\\mathbf{x}(\\mathbf{b}) \\in X$, il relativo schema di pagamenti sarà\n$$p_i = \\phi(\\mathbf{b}*{-i}) - \\mathbf{x}*{-i} \\cdot \\mathbf{v}\\_{-i} ;; \\square$$\n\n---\n\n### Exercise 17\n\nReview the Knapsack problem and what one learns about it in an undergraduate algorithms class.\n\nSpecifically:\n(i) it is NP-hard;\n(ii) with integer values and/or item sizes, it can be solved in pseudopolynomial time via dynamic programming;\n(iii) a simple greedy algorithm gives a $\\frac12$-approximation in near-linear time;\n(iv) rounding and dynamic programming gives a ($1 - \\varepsilon$)-approximation in time polynomial in the number $n$ of items and in $\\frac{1}{\\varepsilon}$ .\n\nRefer to your favorite algorithms textbook or to the videos by the instructor on the course site.\n\n---\n\n### Exercise 18\n\nProve that the Knapsack auction allocation rule induced by the greedy $\\frac12$-[approximation algorithm covered in lecture](../4%20-%20%20Knapsack%20Auctions.md#adfe61) is monotone.\n\n#### Solution\n\nSappiamo che i player sono ordinati nel seguente ordine\n$$\\frac{b_1}{w_1} \\geq ... \\geq \\frac{b_i}{w_i} \\geq ... \\geq \\frac{b_n}{w_n}$$\nOrdinati in questa maniera, avremo come soluzione ammissibile il vettore\n$$\\mathbf{x}(\\mathbf{b}) = (\\underbrace{1 ; 1 ... 1}*k ; \\underbrace{0 ; 0 ... 0}*{n-k})$$\nPerciò, fissato un generico $i$ e un generico $\\mathbf{b}*{-i}$ avremo che $\\mathbf{x}$ è monotona, infatti\n$$x_i(b_i, \\mathbf{b}*{-i}) = \\begin{cases}\n0 \u0026\\text{se } b_i \\\u003c w_i \\cdot \\frac{b_k}{w_k}\\\\\n1 \u0026\\text{se } b_i \\geq w_i \\cdot \\frac{b_k}{w_k}\n\\\\end{cases}$$\n\n---\n\n### Exercise 19\n\nThe [Revelation Principle](../4%20-%20%20Knapsack%20Auctions.md#ec0935) states that direct-revelation DSIC mechanisms can simulate all other mechanisms in which bidders always have dominant strategies.\nCritique the Revelation Principle from a practical perspective.\nName at least one situation in which you might prefer a non-direct-revelation DSIC mechanism over a direct-revelation one.\n","lastmodified":"2022-08-29T13:39:16.801191727+02:00","tags":null},"/AR/0-Analisi-di-reti":{"title":"","content":"\n# Analisi di Reti\n\n---\n\n## Info corso\n\n* **Docente**: Miriam Di Ianni\n* **A.A.**: 2021/2022\n* **Semestre**: 1°\n* **CFU**: 6\n* **Università**: Tor Vergata\n\n---\n\n## Table of contents\n\n* [1 - Erdos-Renyi Random Graph](1%20-%20Erdos-Renyi%20Random%20Graph.md)\n* [2 - Power Law](2%20-%20Power%20Law.md)\n* [4 - Grafi geometrici aleatori](4%20-%20Grafi%20geometrici%20aleatori.md)\n* [6 - Small World](6%20-%20Small%20World.md)\n* [7 - Communities - Part 1](7%20-%20Communities%20-%20Part%201.md)\n* [8 - Communities - Part 2](8%20-%20Communities%20-%20Part%202.md)\n* [9 - Processi di diffusione - Part 1](9%20-%20Processi%20di%20diffusione%20-%20Part%201.md)\n* [10 - Processi di diffusione - Part 2](10%20-%20Processi%20di%20diffusione%20-%20Part%202.md)\n* [11 - Processi di diffusione - Part 3](11%20-%20Processi%20di%20diffusione%20-%20Part%203.md)\n* [12 - Herding](12%20-%20Herding.md)\n* [13 - Sistemi di voto - Part 1](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md)\n* [14 - Sistemi di voto - Part 2](14%20-%20Sistemi%20di%20voto%20-%20Part%202.md)\n* [15 - Sistemi di voto - Part 3](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md)\n* [16 - Sistemi di voto - Part 4](16%20-%20Sistemi%20di%20voto%20-%20Part%204.md)\n* [17 - Web Search - Part 1](17%20-%20Web%20Search%20-%20Part%201.md)\n* [18 - Web Search - Part 2](18%20-%20Web%20Search%20-%20Part%202.md)\n","lastmodified":"2022-08-29T13:39:16.944428281+02:00","tags":null},"/AR/1-Erdos-Renyi-Random-Graph":{"title":"","content":"\n# Analisi di Reti - definizione\n\nNel senso più ampio del termine, una **rete** è uno schema di *interconnessioni* tra entità.\nA seconda del tipo di entità e di interconnessioni, possono esistere diverse tipologie di reti, come:\n\n* reti di calcolatori che interagiscono tra di loro per eseguire task di computazione distribuita\n* le reti sociali, come per esempio una rete di conoscenza di un social network\n* le reti di informazioni, ovvero il *web*\n* ...\n\nLo studio di una rete po' interessare ed essere affrontato da differenti discipline: nella matematica/informatica studiando i modelli che le rappresentano e gli algoritmi che le coinvolgono, nell'economia studiando le dinamiche di incentivo/disincentivo che influenzano il comportamento delle entità, o anche nelle scienze sociali per quanto riguarda i fenomeni che influenzano i singoli individui o l'intera popolazione.\nSostanzialmente, il modo in cui ci interesserà osservare una rete è come un ampio insieme di individui che reagisce in base al comportamento dei singoli.\nQuindi ci interesserà osservare come il comportamento locale di una entità influenza i fenomeni globali\ndell'intera rete.\n\nL'analisi di una rete, nel nostro ambito d'interesse, verrà fatta considerando numerosi aspetti, come per esempio le **prestazioni**, la **struttura** e il loro **utilizzo**,e verranno anche analizzate le **tecniche** impiegate nell'analisi stessa.\nAlcuni aspetti strutturali che sono interessanti di analizzare sono:\n\n## Fenomeno di diffusione\n\nIn questo esempio verrà mostrato come i legami influiscono sul comportamento dei singoli individui. Supponiamo di giocare a una variante probabilistica del gioco del telefono in cui siamo disposti tutti in cerchio, e un volta ricevuto il messaggio lo passo solo se lanciando una moneta esce testa. La moneta è la stessa per tutti, però è **non** equa, ovvero esce testa con probabilità $p = 0.6$ e croce con probabilità $1-p = 0.4$. Se il cerchio è molto grande, è davvero molto poco probabile che il messaggio arrivi a un numero elevato di persone.\n\nSe invece per ogni persona nel cerchio associassimo un terzo \"vicino\" totalmente a caso a cui poter trasmettere il messaggio, succederà che *molto probabilmente* il messaggio arriverà a una grossa porzione di\npersone in poco tempo.\n\nQuesto esempio può essere paragonato al fenomeno della diffusione di un'infezione, in cui la probabilità di infettare un vicino non infetto (o che non è stato infettato in precedenza) è $p$ (vedi [qui](https://arxiv.org/abs/2103.16398)).\n\n## Fenomeno di stabilità\n\nUn classico esempio in cui invece la presenza di legami influisce sulla struttura della rete è il seguente: consideriamo di avere una rete sociale in cui *Bob* è amico di *Alice* e di *Carol*, ma *Alice* e *Carol* non si sopportano (perché entrambe segretamente innamorate di *Bob*).\n\nQuesta rete è detta **instabile**, in quanto per *Bob* sarà difficile uscire con entrambe. Dovendo scegliere per forza una delle due con la quale passare più tempo, necessariamente il legame con l'altra tenderà a rompersi, rendendo così la rete più stabile. (Proprio non vorrei essere nei panni di *Bob*...).\n\n---\n\n# Struttura di una Rete\n\nGeneralmente si è interessati a studiare reti di dimensioni enormi, perciò diventa estremamente complicato studiare ed analizzare ciò che accade ad ogni singolo individuo. Infatti ciò che si studia sono delle **proprietà globali** della rete.\nEsempi di proprietà globali interessanti sono\n\n1. esistenza di **componenti giganti**, ovvero se in un rete esiste una [componente fortemente connessa](https://en.wikipedia.org/wiki/Strongly_connected_component) molto grande (ovvero paragonabile alla grandezza della rete stessa).\n   Un esperimento famoso a riguardo fu quello del 2006 condotto da *Leskovec \u0026 Horvitz* in cui presero i dati (in maniera anonima?) delle comunicazioni fatte in un mese da 240 milioni di utenti di Instant Messenger. Su questi dati costruirono un grafo in cui i nodi erano i 240M di utenti, e inserirono un arco tra due nodi se i rispettivi utenti si scambiarono almeno un messaggio in quel mese. Risultò fuori l'esistenza di una componente fortemente connessa di circa 200 milioni di utenti.\n1. presenza di componenti (o porzioni di esse) **densamente connesse** (ovvero con un elevato numero di connessioni)\n1. verificare se la struttura della rete è di tipo **centro/periferica**\n1. verificare se la rete ha un **diametro** piccolo nonostante sia poco denso.\n\nRiguardo quest'ultimo punto è di dovere citare il famoso esperimento dello psicologo Stanley Milgram sui *\"6 gradi di separazione\"*.\nIn pratica supponiamo di avere una lettera di volerla recapitare al presidente degli stati uniti. Sappiamo esattamente a chi farla arrivare, ma non come.\nSupponiamo di dare la lettera in mano al nostro conoscente che secondo noi è più probabile che la faccia arrivare al presidente, e diciamogli di fare lo stesso.\nMediamente, tramite solo 5 intermediari, la lettera arriverà al presidente Joe Biden.\n\nLo studio di queste proprietà globali sarà fatto sia a *livello di popolazione*, ovvero considerando mediamente ciò che succede agli individui, sia a *livello di singolo individui*, andando a considerare la topologia della rete (relazione per relazione).\n\n---\n\n# Rappresentazione di una rete\n\nCome si è potuto facilmente intuire in precedenza, il modo in cui verrà raffigurata una rete sarà tramite il modello matematico di *Grafo*.\nSi assume che i concetti e le definizioni base della teoria dei grafi siano ben note al lettore (se così non fosse, questi appunti non fanno per te... e nemmeno questo corso!).\n\nSupponiamo quindi di riuscire ad avere le informazioni di una rete reale (cosa che all'atto pratico non accade molto spesso), si potrebbe modellare semplicemente associando un nodo ad ogni entità della rete, e un arco per ogni interconnessione (facile no?).\n\nFatto ciò si può \"tranquillamente\" procedere con l'analisi, alla ricerca di tutte le proprietà viste nella [precedente sezione](1%20-%20Erdos-Renyi%20Random%20Graph.md#struttura-di-una-rete).\n\nPerò, ammettendo pure di avere a disposizione questi dati, è difficile essere interessati a studiare le proprietà di una singola rete.\nGeneralmente si è interessati a sapere proprietà **generali**, come per esempio qual è il diametro medio di una rete espresso in funzione del numero delle sue entità, oppure dato il grado medio dei nodi quanto sono grandi (mediamente) le componenti connesse.\n\nPer fare ciò bisognerebbe osservare un gran numero di reti!\nE in un contesto reale non si hanno così tante informazioni; un po' perché generalmente chi è in possesso di questi dati così preziosi difficilmente li condivide col mondo, un po' perché di reti reali non ne esistono abbastanza da poter consentire di fare un'analisi statistica.\n\nPerciò quello che si fa generalmente è *inventare* nuovi modelli di grafi che rispecchino il più possibile le proprietà che una rete reale possiede.\nOvviamente non è possibile creare un modo che abbia **tutte** le proprietà di una rete reale, per via del grado di complessità delle ultime.\nPerò in base al fenomeno che si desidera studiare, esistono dei modelli che presentano alcune proprietà abbastanza utili ai fini analitici.\n\nPerciò, una volta creato un modello, si possono **campionare** (o **istanziare**) quanti grafi si necessita.\n\n---\n\n# Il modello Erdős-Rényi\n\nUno dei modelli più semplici e classici della letteratura è il cosiddetto *modello **Erdős-Rényi***, noto anche come *Erdős-Rényi random graph*.\nTale modello è definito come segue:\nsiano $n \\in \\mathbb{N}$ e $p \\in \\left\\[ 0, 1 \\right\\]$, $G\\_{n,p}$ è un grafo tale che:\n\n* $V = \\left\\[ n \\right\\] \\equiv {1,  2, ..., n }$\n* $E \\subseteq \\binom{ V }{ 2 } : \\forall u,v \\in V ; \\left\\[ \\mathcal{P}( {u, v} \\in E) = p \\right\\]$\n\nCome si può notare tale modello è un **modello aleatorio**, da cui il nome *random graph*.\nSe ci si sofferma, l'insieme di archi $E$ segue una [distribuzione binomiale](https://it.wikipedia.org/wiki/Distribuzione_binomiale), perciò è corretto parlare anche di **distribuzione Erdős-Rényi**.\n\n## Componenti Giganti\n\nUna definizione più precisa di **componente gigante** equivale a una **componente connessa** grande una **frazione costante** dei nodi del grafo.\n\nPer frazione costante, si intende che al variare del numero di nodi del grafo, il rapporto tra $n$ e la grandezza della componente gigante rimane invariato.\nSi dice quindi che una componente gigante ha grandezza $\\Theta(n)$, dove (ribadendo) $n$ è il numero di nodi del grafo.\n\nPer quanto riguarda la distribuzione *distribuzione Erdős-Rényi* ci si potrebbe chiedere se esiste un valore di $p$ per cui esiste (con buona probabilità) una componente gigante in $G\\_{n,p}$, e se sì, per quale valore.\n\nUn risultato già noto dice che se $p \u003e \\frac{ \\ln{64} }{ n }$ allora con **alta probabilità** (in breve **w.h.p.**) esisterà una componente connessa con **almeno** la metà dei nodi.\n\nIl termine *\"alta probabilità\"* non è usato in maniera impropria, bensì cela un significato rigoroso e preciso. Per alta probabilità si intende con probabilità dell'ordine di \u003cu\u003ealmeno\u003c/u\u003e $\\left( 1 - \\frac{ b }{ n^c } \\right)$, per qualche coppia di costanti\n$b,c$ strettamente positive.\n\nDa cui quindi il seguente teorema:\n\n \u003e \n \u003e **THM** sia $G\\_{n,p}$ un Erdős--Rényi random graph di parametri $n,p$, e sia $X$ la *variabile aleatori* che indica il numero di nodi della più grande componente connessa di $G\\_{n,p}$.\n \u003e $$p \u003e \\frac{ \\ln{64} }{ n } \\implies \\mathcal{P} \\left( X \\geq \\frac{n}{2} \\right) \\geq 1 - 2^{-n/8}$$\n\nPer dimostrare il teorema è prima necessario introdurre il seguente lemma\n\n \u003e \n \u003e **Lemma** Se $X \\\u003c \\frac{n}{2}$ allora esiste un insieme $A \\subset \\left\\[ n \\right\\]$, detto ***insieme buono***, tale che\n \u003e $$ \\frac{n}{4} \\leq |A| \\\u003c    \\frac{3}{4}n $$ e\n \u003e $$ \\nexists { u,v } \\in E : u \\in A \\land v \\in \\[n\\] \\setminus A $$\n \u003e **Proof (Lemma)** Siano $C_1, C_2, ..., C_k$ tutte le componenti connesse di $G\\_{n,p}$ ordinate in senso non decrescente di grandezza, ovvero $$ |C_1| \\leq |C_2| \\leq ... \\leq |C_k| := X \\\u003c \\frac{n}{2} $$\n \u003e Si scelga un indice $h$ tale che\n \u003e $$ |C_1| + |C_2| + ... |C\\_{h-1}| \\\u003c \\frac{n}{4} $$ e\n \u003e $$ |C_1| + |C_2| + ... |C\\_{h-1}| + |C_h| \\geq \\frac{n}{4} $$Si osservi che necessariamente $h \\\u003c k$.\n \u003e Infatti poiché $|C_k| \\\u003c \\frac{n}{2}$, se fosse $h=k$ risulterebbe\n \u003e $$ |C_1| + |C_2| + ... |C\\_{k-1} | + |C_k | \\\u003c \\frac{n}{4} + \\frac{n}{2} \\\u003c n $$\n \u003e e questo è assurdo in quanto $C_1, C_2, ..., C_k$ sono una **partizione** di $V$, perciò la dimensione della loro unione è esattamente $n$.\n \u003e \n \u003e Scelto un $h$ adeguato, poniamo $A = \\bigcup\\_{i=1}^{h} C_h$.\n \u003e Necessariamente $A \\neq \\emptyset$ in quanto è composto da almeno $C_1$ (il quale ha almeno un nodo per definizione di componente), e $\\left\\[ n \\right\\] \\setminus A \\neq \\emptyset$ in quanto al più $h$ può valere $k-1$ (lasciando fuori $C_k$ dall'insieme $A$).\n \u003e \n \u003e Seguono quindi le condizioni del lemma\n \u003e \n \u003e * $|A| \\geq \\frac{n}{4}$ per costruzione\n \u003e * $|A| = \\underbrace{|C_1| + |C_2| + ... + |C\\_{k-1}|}*{ \\\u003c n/4 } + \\underbrace{|C_k|}*{\\\u003c n/2} \\\u003c \\frac{n}{4} + \\frac{n}{2} = \\frac{3}{4}n$\n \u003e * Non ci possono essere archi nel taglio $(A,\\left\\[ n \\right\\] \\setminus A)$, in quanto i due insiemi sono composti da componenti connesse.\n \u003e   Infatti se esistesse un arco nel taglio, i due estremi apparterrebbero a due componenti connesse $C_i, C_j$ distinte, ma ciò significherebbe che $C_i \\cup C_j$ è a sua volta una componente connessa (**assurdo!**). $\\square$\n\nUna diretta conseguenza del lemma è che la probabilità che la più grande componente connessa di $G\\_{n,p}$ sia più piccola di $n/2$ è **minore o uguale** alla probabilità sia presente un *insieme buono*.\nIn fatti, in probabilità, dati due eventi $\\mathcal{E_1},\\mathcal{E_2}$, se $\\mathcal{E_1} \\implies \\mathcal{E_2}$ allora $\\mathcal{P}(\\mathcal{E_1}) \\leq \\mathcal{P}(\\mathcal{E_2})$.\n\nIn questo caso gli eventi corrispondono a\n\n* $\\mathcal{E_1}$ = \"$X \\\u003c n/2$\".\n* $\\mathcal{E_2}$ = \"esiste un insieme buono $A$\".\n\n \u003e \n \u003e **Proof (THM)** Si desidera calcolare $\\mathcal{P}\\left( X \\\u003c \\frac{n}{2} \\right)$, ovvero il complementare della probabilità che si desidera dimostrare.\n \u003e \n \u003e Dal **Lemma** avremo che\n\n$$\\begin{align\\*}\n\\\\mathcal{P}\\left( X \\\u003c \\frac{n}{2} \\right)\n\u0026\\leq \\mathcal{P}( \\exists A \\subset \\left\\[ n \\right\\] : A \\mbox{ è buono})\\\\\n\\\\mbox{(per def. di insieme buono)} \u0026= \\mathcal{P}\\left( \\bigcup\\_{A \\subset \\left\\[ n \\right\\] \\land \\frac{n}{4} \\leq |A| \\\u003c \\frac{3}{4}n }  A : \\mbox{ non ci sono archi nel taglio } (A, \\overline{A}) \\right)\\\\\n\\\\mbox{(union bound)} \u0026\\leq \\sum\\_{A \\subset \\left\\[ n \\right\\] \\land \\frac{n}{4} \\leq |A| \\\u003c \\frac{3}{4}n } \\mathcal{P}\\left(\\mbox{ non ci sono archi nel taglio } (A, \\overline{A}) \\right)\\\\\n(1) \u0026= \\sum\\_{A \\subset \\left\\[ n \\right\\] \\land \\frac{n}{4} \\leq |A| \\\u003c \\frac{3}{4}n } (1-p)^{|A| \\cdot |\\overline{A}|}\\\\\n(2) \u0026\\leq \\sum\\_{A \\subset \\left\\[ n \\right\\] \\land \\frac{n}{4} \\leq |A| \\\u003c \\frac{3}{4}n } (1-p)^{\\frac{3}{16}n^2} \\\\\n(3) \u0026\\leq 2^{n} (1-p)^{\\frac{3}{16}n^2}\\\\\n(4) \u0026\\\u003c 2^{n} \\left(1 - \\frac{ \\ln{64} }{n} \\right)^{\\frac{3}{16}n^2}\\\\\n\u0026= 2^{n} \\left\\[ \\left(1- \\frac{ \\ln{64} }{n} \\right)^n \\right\\]^{\\frac{3}{16}n}\\\\\n\u0026= 2^{n} \\left\\[ \\left(1- \\frac{ \\ln{64} }{n} \\right)^{n \\cdot \\left( \\frac{ -\\ln{64} }{ -\\ln{64} }  \\right)  } \\right\\]^{\\frac{3}{16}n}\\\\\n(5) \u0026\\approx 2^{n} \\left\\[ e^{-\\ln{64}}  \\right\\]^{\\frac{3}{16}n}\\\\\n\u0026= 2^{n} \\left\\[ 64^{-1}  \\right\\]^{\\frac{3}{16}n}\\\\\n\u0026= 2^{n} \\left\\[ 2^{-6}  \\right\\]^{\\frac{3}{16}n} = 2^{n} 2^{ -\\frac{18}{16}n } = 2^{-\\frac{n}{8}} ;;; \\square\\end{align\\*}$$\n\n \u003e \n \u003e Di seguito spiegate le disuguaglianze:\n \u003e \n \u003e * **(1)** è data dal fatto che tale probabilità è data dalla probabilità che **non** esista un arco nel taglio, ovvero $(1-p)$, moltiplicato tante volte quanti i archi possono esistere tra $A$ e $\\overline{A}$, ovvero $|A| \\cdot |\\overline{A}|$.\n \u003e * **(2)** è invece data dal fatto chef il punto di *minimo* della funzione $|A| \\cdot |\\overline{A}|$ è per valori di $|A| = \\frac{1}{4}, \\frac{3}{4}$. Ci interessano i punti di minimo in quanto essendo $(1-p) \\\u003c 1$, $(1-p)^{x}$ assume valori massimi per $x$ minimo.\n \u003e * **(3)** è dato dal fatto che il numero *massimo* di sottoinsiemi $A \\subseteq \\left\\[ n \\right\\]$ è $2^n$.\n \u003e * **(4)** per ipotesi del teorema\n \u003e * **(5)** perché $\\lim\\_{n \\rightarrow \\infty} \\left( 1 + \\frac{1}{n} \\right) = e^{n}$\n\nUna versione più generale del precedente teorema è la seguente\n\n \u003e \n \u003e **Teorema generale** Sia $G\\_{n,p}$ un grafo aleatorio campionato dalla *distribuzione Erdős-Rényi*, allora:\n \u003e \n \u003e 1. se $p(n-1) \\\u003c 1$ allora *quasi sicuramente* (*asymptotically almost surely*, o in breve *a.a.s.*) tutte le componenti connesse di $G\\_{n,p}$ avranno $O( \\log{n} )$ nodi (ovvero saranno molto piccole).\n \u003e 1. se $p(n-1) = 1$ allora *a.a.s.* $G\\_{n,p}$ avrà una componente connessa grande $\\approx n^{ \\frac{2}{3} }$.\n \u003e 1. se $p(n-1) \u003e 1$ allora *a.a.s.* $G\\_{n,p}$ avrà una componente connessa grande $\\Omega (n)$ nodi e tutte le altre grandi $O(\\log{n})$.\n\nCiò che suggerisce il teorema più generale è che la presenza di componenti connesse dipende in qualche modo dal prodotto $p(n-1)$, ma cosa rappresenta questa quantità?\nQuesto verrà mostrato nella seguente sezione.\n\n## Grado dei nodi\n\nDato un grafo *Erdős-Rényi* $G\\_{n,p}$, definiamo col simbolo $\\delta_i$ la *variabile aleatoria* che esprime il **grado** del nodo $i$.\nSia inoltre la v.a. binaria tale che $\\forall j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace$ $$\nX\\_{i,j} = \\begin{cases}\n1 \u0026\\mbox{se esiste l'arco }(j,i) \\in E\\\\\n0 \u0026\\mbox{altrimenti}\n\\\\end{cases}\n$$ Perciò il [valore atteso](https://it.wikipedia.org/wiki/Valore_atteso) di $\\delta_i$ sarà\n\n$$\\begin{align\\*}\n\\\\mathbb{E} \\left\\[ \\delta_i  \\right\\]\n\u0026= \\mathbb{E} \\left\\[ \\sum\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace } X\\_{j,i} \\right\\]\\\\\n\\\\mbox{(per linearità)} \u0026= \\sum\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace }  \\mathbb{E} \\left\\[  X\\_{j,i} \\right\\]\\\\\n\u0026= \\sum\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace } 1 \\cdot p + 0 \\cdot (1-p) = (n-1)p\n\\\\end{align\\*}$$\n\nPerciò la quantità $p(n-1)$ vista nella precedente sezione, altro non è che il *grado medio* di un nodo.\n\nCiò significa che, fissato un $p$ **costante**, ogni individuo nella rete sarà in contatto con una porzione constante della reta stessa, ovvero il grado medio cresce in maniera *lineare nel numero di nodi*!\n\nOvviamente è inverosimile che in una rete di un social network composta da centinaia di milioni (se non miliardi) di nodi, io abbia un numero di amicizie proporzionale al numero di utenti (non penso sarà mai così famoso).\n\nPerciò, per modellare una rete che sia più verosimile, si potrebbe volere che $p$ sia una funzione di $n$, e che magari *decresca* in maniera inversamente proporzionale, del tipo\n$$ p = p(n) = \\frac{ \\lambda }{n} $$Scegliendo $p$ in questa maniera, avremo che il grado medio di un nodo sarà pari alla **costante** $\\lambda$, indipendentemente dalla dimensione della rete.\n\nUn'altra domanda che è utile chiedersi è: fissato un $k \\leq n$, con quale probabilità un nodo $i \\in \\left\\[ n \\right\\]$ ha **esattamente** grado $k$?\n\nIntuitivamente, questa è pari alla probabilità che esistano esattamente $k$ archi incidenti a $i$.\nTale probabilità è esattamente definita dalla [legge binomiale](https://it.wikipedia.org/wiki/Distribuzione_binomiale) $\\mathcal{B}(n-1,p)$, ovvero $$\n\\\\mathcal{P}\\left( \\delta_i = k \\right) = \\binom{n-1}{k} p^k \\left( 1-p \\right)^{(n-1) - k}\n$$ Questo perché:\n\n1. $\\binom{n-1}{k}$ è il numero di tutte le possibili $k$-uple di nodi in $\\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace$.\n1. $p^k$ è la probabilità che esistano gli archi tra $i$ e i nodi di una $k$ -upla.\n1. $\\left( 1-p \\right)^{(n-1) - k}$ è la probabilità che non esista nessun altro arco (ne vogliamo solo $k$).\n\nScegliendo $p = \\frac{ \\lambda }{n}$ in funzione di $n$ come detto in precedenza, avremo che la probabilità che un nodo abbia grado medio esattamente $k$ è\n\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}\\left( \\delta_i = k \\right)\n\u0026= \\binom{n-1}{k} p^k \\left( 1-p \\right)^{(n-1) - k}\\\\\n\u0026= \\binom{n-1}{k} \\left(  \\frac{ \\lambda }{n} \\right)^k \\left( 1-  \\frac{ \\lambda }{n} \\right)^{(n-1) - k}\\\\\n\u0026= \\frac{(n-1) \\cdot (n-2) \\cdot ... \\cdot (n-k)}{k!} \\frac{ \\lambda^k }{ n^k } \\left( 1-  \\frac{ \\lambda }{n} \\right)^{(n-1) - k}\\\\\n(1) \u0026\\\u003c \\frac{(n-1) \\cdot (n-2) \\cdot ... \\cdot (n-k)}{k!} \\frac{ \\lambda^k }{ n^k } e^{ \\frac{-\\lambda (n - 1 - k)}{n}} \\\\\n\u0026\\\u003c \\frac{n^k}{k!} \\frac{ \\lambda^k }{ n^k } e^{ \\frac{-\\lambda (n - 1 - k)}{n}}\\\\\n\u0026\\approx \\frac{ \\lambda^k }{ k! } e^{ -\\lambda } ;;; \\mbox{per } n \\mbox{ sufficientemente grande}\n\\\\end{align\\*}\n$$\n\nPiù semplicemente\n$$ \\mathcal{P}\\left( \\delta_i = k \\right) \\\u003c \\frac{ \\lambda^k }{ k! } e^{ -\\lambda } $$\nLa disuguaglianza **(1)** è data dal fatto che $\\forall x \\\u003c 1$ vale sempre che $1-x \\\u003c e^{-x}$.\n\nApplicando l'[approssimazione di Stirling](https://it.wikipedia.org/wiki/Approssimazione_di_Stirling) secondo la quale $k! \\thicksim \\sqrt{2 \\pi k} \\left( \\frac{k}{e}  \\right)^k$, possiamo semplificare il tutto con $$\n\\\\mathcal{P} \\left( \\delta_i = k \\right) \\\u003c \\frac{ (\\lambda e)^k }{ \\sqrt{2 \\pi k} k^k }e^{ -\\lambda }\n= \\frac{ e^{ -\\lambda } }{ \\sqrt{2 \\pi k} } \\left( \\frac{ \\lambda e }{k}  \\right)^k\n$$\nQuest'ultima disuguaglianza ci suggerisce che la probabilità che un generico nodo abbia grado $k$ *decresce* molto velocemente al crescere di $k$, più precisamente decresce *esponenzialmente* in $k$ (come $k^{-k}$).\n\nUna volta stabilità questa probabilità, si può calcolare il numero atteso di nodi che hanno grado esattamente $k$.\nPer prima cosa definiamo la variabile aleatoria binaria $\\delta\\_{i,k}$ tale che $$\n\\\\delta\\_{i,k} = \\begin{cases}\n1 \u0026\\mbox{se } \\delta_i = k\\\\\n0 \u0026\\mbox{altrimenti}\n\\\\end{cases}\n$$\nDefiniamo in oltre la v.a. $F_k$ che indica la *frazione* di nodi della rete che hanno grado $k$\n$$ F_k = \\frac{ \\sum\\_{i \\in \\left\\[ n \\right\\] } \\delta\\_{i,k}  }{n} $$\ncon valore atteso\n$$\n\\\\begin{align\\*}\n\\\\mathbb{E} \\left\\[ F_k \\right\\]\n\u0026= \\mathbb{E} \\left\\[ \\frac{ \\sum\\_{i \\in \\left\\[ n \\right\\] } \\delta\\_{i,k}  }{n} \\right\\]\\\\\n\u0026= \\frac{1}{n} \\sum\\_{i \\in \\left\\[ n \\right\\] } \\mathbb{E} \\left\\[ \\delta\\_{i,k} \\right\\]\\\\\n\u0026= \\frac{1}{n} \\sum\\_{i \\in \\left\\[ n \\right\\] } \\left( 1 \\cdot \\mathcal{p}(\\delta\\_{i,k} = 1) + 0 \\cdot \\mathcal{p}(\\delta\\_{i,k} = 0) \\right)\\\\\n\u0026= \\frac{1}{n} \\sum\\_{i \\in \\left\\[ n \\right\\] } \\left( 1 \\cdot \\mathcal{p}(\\delta_i = k) + 0 \\cdot \\mathcal{p}(\\delta_i \\neq k) \\right)\\\\\n\u0026= \\frac{1}{n} \\sum\\_{i \\in \\left\\[ n \\right\\] } \\mathcal{p}(\\delta_i = k)\\\\\n\u0026\\\u003c \\frac{1}{n} \\sum\\_{i \\in \\left\\[ n \\right\\] } \\frac{ e^{ -\\lambda } }{ \\sqrt{2 \\pi k} } \\left( \\frac{ \\lambda e }{k}  \\right)^k\\\\\n\u0026= \\frac{ e^{ -\\lambda } }{ \\sqrt{2 \\pi k} } \\left( \\frac{ \\lambda e }{k}  \\right)^k\n\\\\end{align\\*}\n$$\n\nPerciò, in un grafo *Erdős--Rényi* $G\\_{n,p}$ con grado medio constante, ovvero con parametro $p = \\frac{\\lambda}{n}$, il numero di nodi di grado esattamente $k$ decresce esponenzialmente in $k$ (come $k^{-k}$).\n","lastmodified":"2022-08-29T13:39:16.923402901+02:00","tags":null},"/AR/10-Processi-di-diffusione-Part-2":{"title":"","content":"\n# The Cascade Capacity on Infinite Network with bounded Degree\n\nQuesta lezione è il continuo della [precedente ←](9%20-%20Processi%20di%20diffusione%20-%20Part%201.md)\n\nDagli esempi precedenti è facile notare che la soglia di adozione massima nella griglia infinita è minore di quella della catena infinita, per via di una struttura più ricca è densa. \nComunque, in entrambi i casi, non si può **mai** avere una soglia di adozione maggiore di\n$\\frac{1}{2}$.\n\nQuindi viene da pensare che, almeno in questi due modelli, l'innovazione `A` deve essere appettibile **almeno** quanto lo stato dominante `B`.\nIn effetti questo è un ragionamento abbastanza ragionevole anche applicato in un contesto reale.\n\nSorge però la domanda:\n\n \u003e \n \u003e Esiste una conformazione di una rete infinita in cui si può ottenere una capacita di cascata maggiore di $\\frac{1}{2}$?\n \u003e Ovvero, è possibile fare in modo che si adotti `A`, nonostante `B` sia più conveniente?\n\nPer fortuna la risposta è **no**, e questo verrà dimostrato nel seguente teorema\n\n \u003e \n \u003e **THM** Per ogni grafo infinito $G=(\\mathbb{N},E)$ i cui nodi hanno grado finito, la capacità di cascata di $G$ è al più $q_G \\leq \\frac{1}{2}$.\n\n \u003e \n \u003e **Proof** Supponiamo \u003cu\u003eper assurdo\u003c/u\u003e che esista un insieme **finito** di iniziatori $V_0$, che nonostante ci sia una soglia di adozione $q \u003e \\frac{1}{2}$, genera comunque una cascata completa dell'innovazione `A`.\n \u003e \n \u003e Definiamo con $V_t$ l'insieme di nodi che adottano `A` al tempo $t \\geq 0$, con l'insieme $$S_t \\equiv \\bigcup\\_{i = 0}^{t} V_t$$\n \u003e l'insieme di tutti i nodi che al tempo $t$ si trovano nello stato `A`.\n \u003e \n \u003e Definiamo con $I_t$ l'insieme di archi del **taglio** $(S_t, V \\setminus S_t)$, ovvero $$I_t \\equiv \\lbrace (u,v) : u \\in S_t \\land v \\in V \\setminus S_t \\rbrace$$\n \u003e \n \u003e Dato che $V_0$ genera una *cascata completa* di `A` con soglia di adozione $q \u003e 0.5$, si può dimostrare che per ogni $t \\geq 0$, allora è vero che $$\\vert I_t \\vert \u003e \\vert I\\_{t+1} \\vert ;; \\mbox{oppure} ;; I_t \\equiv I\\_{t+1}$$\n \u003e Dato che il grado massimo di $G$ è **limitato**, allora $\\vert I_0 \\vert$ sarà una quantità finita $k \u003e 0$.\n \u003e Inoltre, è facile convincersi che il processo termina quando abbiamo che $I_t \\equiv I\\_{t+1}$.\n \u003e Però visto che $V_0$ genera un processo **infinito** di cascata di `A`, allora per ogni $t \\geq 0$, non deve mai accadere che $I_t \\equiv I\\_{t+1}$, ovvero accade sempre che $\\vert I_t \\vert \u003e \\vert I\\_{t+1} \\vert$.\n \u003e Ma ciò è assurdo, perché per via della dimensione finita di $I_0$, può accadere \u003cu\u003eal più\u003c/u\u003e $k$ volte consecutive che il processo procedi.\n \u003e Perciò deve esistere necessariamente un tempo $\\tau \\geq k$, tale che $I\\_\\\\tau \\equiv I\\_{\\tau + 1}$ (**assurdo**).\n \u003e \n \u003e Procediamo quindi con la dimostrazione dei due eventi.\n \u003e Per farlo, basta dimostrare la mutua esclusione degli eventi, ovvero che se $I_t \\not\\equiv I\\_{t+1}$ allora necessariamente $\\vert I_t \\vert \u003e \\vert I\\_{t+1} \\vert$ (e implicando quindi che non può nemmeno mai accadere che $\\vert I_t \\vert \\\u003c \\vert I\\_{t+1} \\vert$).\n \u003e \n \u003e Se per ipotesi abbiamo che $I_t \\not\\equiv I\\_{t+1}$, ciò implica che esiste \u003cu\u003ealmeno\u003c/u\u003e un nodo $v$ che ha adottato `A` al tempo $t + 1$, e che quindi $V\\_{t+1} \\neq \\emptyset$.\n \u003e Affinché ciò sia vero, è necessario che $v$ abbia \u003cu\u003ealmeno\u003c/u\u003e un vicino $u \\in N(v)$ che è anche nello stato `A`, ovvero $u \\in N(v) \\cap S_t$.\n \u003e \n \u003e Più in generale, per ogni nodo $v \\in V\\_{t+1}$ esiste alemno un arco del tipo $(u,v) \\in I_t$, inoltre tale arco non apparterrà a $I\\_{t+1}$.\n \u003e Viceversa, tutti gli archi che apparterranno a $I\\_{t+1}$ certamente non erano in $I_t$.\n \u003e \n \u003e ![$v \\in V\\_{t+1}$: $v$ adotta `A` al tempo $t + 1$.](ar-lesson10-img1.png)\n \u003e \n \u003e Perciò in base a quanto osservato (e anche osservando la [figura](images/ar-lesson10-img1.png)) avremo che $$I\\_{t+1} \\equiv \\left( I_t ; \\setminus ; \\left\\[ \\bigcup\\_{v \\in V\\_{t+1}} \\lbrace (u,v) \\in E : u \\in S_t \\rbrace \\right\\] \\right) \\cup \\left\\[ \\bigcup\\_{v \\in V\\_{t+1}} \\lbrace (v,z) \\in E : z \\in V \\setminus S\\_{t+1} \\rbrace \\right\\]$$\n \u003e \n \u003e È anche facile verificare che $\\forall v,w \\in V\\_{t+1}$ $$\n \u003e \\\\begin{equation\\*}\n \u003e \\\\begin{split}\n \u003e \\\\lbrace (u,v) \\in E : u \\in S_t \\rbrace \u0026\\cap \\lbrace (u,w) \\in E : u \\in S_t \\rbrace = \\emptyset\\\\\n \u003e \u0026\\land\\\\\n \u003e \\\\lbrace (v,z) \\in E : z \\in V \\setminus S\\_{t+1} \\rbrace \u0026\\cap \\lbrace (w,z) \\in E : z \\in V \\setminus S\\_{t+1} \\rbrace = \\emptyset\n \u003e \\\\end{split}\n \u003e \\\\end{equation\\*}$$\n \u003e Per comprendere meglio la precedente conclusione, osservare la [seguente immagine](images/ar-lesson10-img2.png)\n \u003e \n \u003e ![Esempio.|400](ar-lesson10-img2.png)\n \u003e \n \u003e Tutto ciò implica che $$\\vert I\\_{t+1} \\vert = \\vert I_t \\vert - \\sum\\_{v \\in V\\_{t+1}} \\vert \\lbrace (u,v) \\in E : u \\in S_t \\rbrace \\vert + \\sum\\_{v \\in V\\_{t+1}} \\vert \\lbrace (v,z) \\in E : z \\in V \\setminus S\\_{t+1} \\rbrace \\vert$$\n \u003e Per semplificare la precedente formula, possiamo definire i seguenti insiemi come:\n \u003e \n \u003e * $\\lbrace (u,v) \\in E : u \\in S_t \\rbrace = N(v) \\cap S_t$\n \u003e * $\\lbrace (v,z) \\in E : z \\in V \\setminus S\\_{t+1} \\rbrace = N(u) \\setminus S\\_{t+1}$\n \u003e   perciò la formula per $\\vert I\\_{t+1} \\vert$ risulterà essere: $$\\begin{align\\*}\n \u003e   \\\\vert I\\_{t+1} \\vert \u0026= \\vert I_t \\vert - \\sum\\_{v \\in V\\_{t+1}} \\vert N(v) \\cap S_t \\vert + \\sum\\_{v \\in V\\_{t+1}} \\vert N(u) \\setminus S\\_{t+1} \\vert\\\\\n \u003e   \u0026= \\vert I_t \\vert - \\sum\\_{v \\in V\\_{t+1}} \\left ( \\vert N(v) \\cap S_t \\vert - \\vert N(u) \\setminus S\\_{t+1} \\vert \\right)\n \u003e   \\\\end{align\\*}$$\n \u003e   Osserviamo adesso che, dato che un $v \\in V\\_{t+1}$ ha adottato il nuovo stato `A`, e dato che la soglia di adozione è $q \u003e \\frac{1}{2}$, allora più della metà dei suoi vicini era in $S_t$, ovvero $$\\frac{\\vert N(v) \\cap S_t \\vert}{\\vert N(v) \\vert} \\geq q \u003e \\frac{1}{2}$$\n \u003e   oppure, visto in altri termini $$\\vert N(v) \\cap S_t \\vert \u003e \\vert N(v) \\setminus S_t \\vert \\geq \\vert N(v) \\setminus S\\_{t+1} \\vert$$\n \u003e   Perciò avremo che $$\\begin{align\\*}\n \u003e   \\\\vert I\\_{t+1} \\vert \u0026= \\vert I_t \\vert - \\sum\\_{v \\in V\\_{t+1}} \\left ( \\vert N(v) \\cap S_t \\vert - \\vert N(u) \\setminus S\\_{t+1} \\vert \\right)\\\\\n \u003e   \u0026\\leq \\vert I_t \\vert - \\sum\\_{v \\in V\\_{t+1}} \\left ( \\vert N(v) \\cap S_t \\vert - \\vert N(u) \\setminus S_t \\vert \\right)\\\\\n \u003e   \u0026= \\vert I_t \\vert - \\sum\\_{v \\in V\\_{t+1}} 1 = \\vert I_t \\vert - \\vert V\\_{t+1} \\vert \\\u003c \\vert I_t \\vert\n \u003e   \\\\end{align\\*}$$\n \u003e   dove l'ultima disuguaglianza viene dall'assunzione che $V\\_{t+1} \\neq \\emptyset$ $\\square$.\n\n---\n\n# Modello eterogeneo\n\nIl modello studiato in precedenza era un modello **uniforme** (o **omogeneo**), nel quale si assume che tutti i nodi abbiano lo stesso vantaggio nell'usare la tecnologia `A` o `B`. \n\nSarebbe più reale invece considerare un modello **eterogeneo**, in cui ogni individuo ricava un proprio profitto personale dall'adottare una nuova tecnologia.\nIn questo caso possiamo modellare i vantaggi tra le coppie di invidui con un `A-B` **heterogeneous coordination game**\n\n![`A-B` *heterogeneous coordination game* table.](ar-lesson10-img3.png)\n\nPerciò, se un nodo $v$ ha una frazione $p$ di vicini nello stato `A` e una frazione $(1-p)$ nello stato `B`, il guadagno scegliendo `A` sarà $pa_v$ e quello rimanendo in `B` sarà $(1-p)b_v$. \n\nPerciò possiamo affermare che `A` è una scelta migliore se $$p \\geq \\frac{b_v}{a_v + b_v}$$\nDefiniamo con $q_v = \\frac{b_v}{a_v + b_v}$ la personale **soglia di adozione** dell'individuo $v$.\n\nConsideriamo il seguente esempio, con insieme di nodi iniziatori $V_0 = \\lbrace 1 \\rbrace$.\n\n![Esempio giocattolo, con $V_0 = \\lbrace 1 \\rbrace$.](ar-lesson10-img4.png)\n\nOsservare che il nodo 1 è una elemento abbastanza centrale nella comunità $\\lbrace 1,2,3,4,5,6 \\rbrace$.\n\nPurtroppo, nonostante la sua posizione strategica, è dificcile che riesca a convincere i suoi vicini ad adottare `A`.\nPer fortuna c'è il vicino 3 che è **facilmente influenzabile**, il quale ha una soglia di adozione $q_3 = 0.1$ parecchio più bassa degli altri.\nPerciò, se 1 riesce a convincere il nodo 3 ad adottare `A`, allora si scatenerebbe una cascata su tutta la comunità $\\lbrace 1,2,3,4,5,6 \\rbrace$.\n\n![](ar-lesson10-img5.png)\n\nCiò ci suggerisce che scegliere un iniziatore in un posto strategico non è più una **condizione sufficiente** a garantire la diffusione di `A`, quantomeno all'interno di una comunità.\nInvece, è necessario che gli iniziatori abbiano anche la possibilità di avere accesso a individui **facilmente influenzabili**.\n\nRicordiamo che nel modello omogeneo ciò che impediva una cascata completa era la presenza di **cluster di densita** $1 - q$, ovvero un sottoinsieme di nodi $V'$ tale che $$\\frac{\\vert N(u) \\cap V' \\vert}{\\vert N(u) \\vert} \\geq 1 - q ;; \\forall u \\in V'$$\nAnalogamente per il modello eterogeneo, definiamo i **blocking cluster** quei sottoinsiemi di nodi $V'$ tali che $$\\frac{\\vert N(u) \\cap V' \\vert}{\\vert N(u) \\vert} \\geq 1 - q_u ;; \\forall u \\in V'$$\nAnche per il modello eterogeno, la presenza di tali strutture è un ostacolo alle cascate complete!\n\nTale osservazione è formalmente espressa dal seguente teorema\n\n \u003e \n \u003e **THM** Sia il grafo $G=(V,E)$ e l'insieme di iniziatori $V_0 \\subseteq V$. L'insieme $V_0$ **non** genera una cascata completa di `A` **se e solo so** $G-V_0$ congiene un *blocking cluster*.\n\n---\n\n# Azioni collettive\n\nI processi di diffusione sono utili anche per modellare situazioni in cui bisogna prendere decisione collettive.\n\nConsideriamo come esempio una situazione in cui è presente un regime totalitario su una popolazione. \nIl popolo ha organizzato una grande manifestazione/rivolta.\nOvviamente solo se un numero considerevole di individui aderirà si riusciranno ad ottenere dei reali benefici.\nViceversa, se non partecipa molta gente, tutti coloro che avranno aderito verranno arrestati.\n\nSecondo questo scenario è ragionevole pensare che ogni individuo vada se \u003cu\u003esa\u003c/u\u003e che un certo numero di altri individui partecipi. \n(Il gioco deve valerne la candela).\n\nAssumiamo inoltre che tale regime ostacola le comunicazioni, cosiché un individuo può sapere solo cosa faranno i suoi diretti conoscenti (e non l'intera popolazione).\n\nTale esempio è facilmente modellabile col modello di adozione di una nuova innovazione visto in precedenza.\nPer ogni individuo $v$, definiamo con $k_v$ la sua **soglia di confidenza**, ovvero il numero minimo di persone che devono partecipare alla protesta affinché il nodo $v$ si convinca a partecipare.\nPiù precisamente, $v$ partecila alla protesta se sa che altre $k_v - 1$ persone partecipano[^1].\n\nDato che però $v$ non può sapere l'afflusso globale (per via delle comunicazioni ristrette), possiamo dire che $v$ parteciperà alla protesta solamente se se sa che altri $k_v - 1$ \u003cu\u003esuoi vicini\u003c/u\u003e partecipano.\nPurtroppo però, per via della natura rischiosa dell'informazione, $v$ non può sapere se i suoi parteciperanno o meno, ma solamente la loro *soglia di confidenza*.\n\nRicapitolando, ogni individuo $v$ conosce solamente le soglie di confidenza $k_u$ dei suoi vicini $u \\in N(v)$ e la rete di conoscenza della comunità.\n\nConsideriamo il seguente esempio\n\n![](ar-lesson10-img6.png)\n\nCertamente $w$ non parteciperà perché non ha abbastanza vicini per rientrare nella sua soglia di confidenza.\nIl nodo $v$ per partecipare richiede che entrambi i suoi vicini, $u$ e $w$, aderiscano.\nPerò, dato che non può dire nulla sulla partecipazione di $w$, può solamente assumere che lui non partecipi per via della sua soglia di confidenza $k_w$ troppo alta.\nInfine $u$ per partecipare richiede che solo un suo vicino partecipi.\nPerò, dato che per lo stesso ragionamento può dedurre che $w$ non aderisce, rimane col dubbio rispetto all'adesione di $v$.\n\nPerciò ad $u$ conviene realmente parteciapre e rischiare di essere l'unico a farlo?\nIn realtà non gli conviene, in quanto può intuire che anche $v$ abbia fatto lo stesso ragionamento in merito a $w$, e che quindi molto probabilmente $v$ non parteciperà.\n\n![](ar-lesson10-img7.png)\n\nIl secondo esempio è più simmetrico, perciò consideriamo solamente la prospettiva del nodo $u$.\nLui sa che entrambi i suoi vicini $v$ e $w$ hanno soglia di confidenza 3, perciò tutti e tre $u,v,w$ potrebbero tranquillamente aderire alla protesta.\nPerò $u$ sa anche che $v$ non ha informazioni riguardo la confidenza di $w$, e viceversa $w$ non ne ha riguardo $v$, perciò non può dare per scontato che entrambi partecipino.\nInfatti $u$ non ha idea di quale sia la soglia di confidenza di $x$.\nNel caso $k_x$ fosse molto alta, allora potrebbe intuire che sia $v$ che $w$ non siano confidenti nel partecipare.\nApplicando questo ragionamento in maniera simmetrica su tutti i noi, possiamo dedurre che nessuno parteciperà alla protesta.\n\n![](ar-lesson10-img8.png)\n\nConsideriamo in fine quest'ultimo esempio meno simmetrico del precedente.\nTutti i nodi hanno bisogno di sapere che almeno altri due parteciperanno alla manifestazione per essere confidenti e aderire a loro volta.\nPartendo dal punto di vista del nodo $u$, esso sa benissimo che la soglia di adozione del triangolo formato con $w$ e $v$ è 3.\nSa anche molto bene che sia $w$ che $v$ sanno le stesse cose che sa $u$.\nOvvero tutti e tre i nodi del triangolo sanno tutto riguardo loro stessi (tranne la decisione di partecipare ovviamente).\nDato che siamo in una situazione del tipo *\"io so che tu sai che io so\"* tra $u,v,w$, tutti e tre i nodi possono ben pensare di partecipare tranquillamente alla protesta.\nNotare che $w$ riesce a prendere la decisione di parteciapre senza nemmeno considerare il nodo $x$, il quale certamente non parteciperà perché ha una soglia di confidenza troppo alta rispetto al suo numero di vicini.\n\nIn maniera intuitiva possiamo dire che in assenza di informazioni è molto difficile riuscire a prendere una decisione collettiva, persino quando la maggior parte degli individui è d'accordo su un pensiero comune.\nInfatti per questo comune le dittature spingono molto sul controllo delle informazioni e tendono a chiudere al mondo esterno le conoscenze.\nQuesto fenomeno è conosciuto come **ignoranza pluralistica**.\nA conferma di quanto detto, nell'ultimo esempio si riesce a prendere una decisione collettiva proprio perché i nodi $u,v,w$ disponevano di una stessa **base d'informazioni comune**.\n\n[^1]: $v$ è il $k_v$-esimo partecipante.\n","lastmodified":"2022-08-29T13:39:16.971975395+02:00","tags":null},"/AR/11-Processi-di-diffusione-Part-3":{"title":"","content":"\nLezioni predenti collegate:\n\n* [← Lezione 9](9%20-%20Processi%20di%20diffusione%20-%20Part%201.md)\n* [← Lezione 10](10%20-%20Processi%20di%20diffusione%20-%20Part%202.md)\n\n# Processi di diffusione in presenza di Compatibilità\n\nNelle lezioni precedenti abbiamo visto come un gioco di coordinazione molto semplice possa portare ad una vasta quantità di domande e relative analisi non banali.\nUna prima generalizzazione è stata passare da un modello *omogeneo*, in cui tutti i nodi traevano uno stesso vantaggio dall'adottare una nuova tecnologia `A`, ad uno *eterogeneo*, in cui ciascun individuo ricava un personale guadagno dall'adottare l'innovazione.\n\nIn tutti i modelli analizzati però si assumeva la **mutua esclusione** degli stati `A-B`. In un contesto reale però succede spesso che due stati coesistono in un individuo.\nAd esempio, `A` e `B` potrebbero essere lingue diverse che coesistono lungo un confine nazionale, oppure `A` e `B` potrebbero essere due applicazioni di messaggistica differenti.\n\nInfatti gli individui che si trovano al confine tra un'area in cui prevale `A` ed una in cui prevale `B`, conviene adottare entrambi gli stati: ovvero essere in qualche modo \"bilingua\".\n\nAdottare però due stati contemporaneamente può comportare un costo aggiuntivo non trascurabile.\nUn individuo sceglie di utilizzare entrambi i comportamenti disponibili, barattando la maggiore facilità di interazione con persone di più tipi, contro il costo di dover acquisire e mantenere entrambe le forme di comportamento (cioè i costi di dover imparare una lingua aggiuntiva, mantenere due diverse versioni di una tecnologia e così via ...).\n\nUn'oservazione da fare riguardo il costo del \"bilinguismo\", è che tale *effort*[^1] viene pagato \u003cu\u003euna sola volta\u003c/u\u003e.\nPerciò, se si è in contatto con tanta gente nello stato `A` ed altrettanta nello stato `B`, potrebbe convenire adottare il doppio stato `AB`, in qunato il guadagno ricavato sarebbe molto maggiore dell'unico costo che pago nell'avere il doppio stato: *il gioco ne vale la candela*.\n\nModellando in maniera più formale, possiamo definire un nuovo *coordination game* in accordo alla seguente tabella\n\n![Nuovo coordination game con opzione di doppio stato (bilingua).](ar-lesson11-img1.png)\n\ndove con $(a,b)^+$ si indica il massimo tra $a$ e $b$.\n\nIndichiamo ora con $V_A, V_B, V\\_{AB}$ l'insieme dei nodi negli stati `A`, `B` e `AB` rispettivamente, i quali compongono una *partizione* dell'insieme $V$ di tutti gli individui.\nPerciò, fissando con $c \\geq 0$ il costo di adozione del *doppio stato* `AB`, possiamo dire che il guadagno complessivo del nodo $u$ che adotta `AB` è pari a $$\\Big(\\sum\\_{v \\in N(u) \\cap V_A} a\\Big) + \\Big(\\sum\\_{v \\in N(u) \\cap V_B} b\\Big) + \\Big(\\sum\\_{v \\in N(u) \\cap V\\_{AB}} (a,b)^+\\Big) - c$$\n\nIndichiamo quindi con $p_A(u), p_B(u), p\\_{AB}(u)$ i rispettivi guadagni che ha il nodo $u$ nell'assumere gli stati `A`, `B` o `AB` come segue\n\n$$\n\\\\begin{align\\*}\np_A(u) \u0026= \\sum\\_{v \\in N(u) \\cap V_A} a + \\sum\\_{v \\in N(u) \\cap V\\_{AB}} a \\\\\np_B(u) \u0026= \\sum\\_{v \\in N(u) \\cap V_B} b + \\sum\\_{v \\in N(u) \\cap V\\_{AB}} b\\\\\np\\_{AB}(u) \u0026= \\Big(\\sum\\_{v \\in N(u) \\cap V_A} a\\Big) + \\Big(\\sum\\_{v \\in N(u) \\cap V_B} b\\Big) + \\Big(\\sum\\_{v \\in N(u) \\cap V\\_{AB}} (a,b)^+\\Big) - c\n\\\\end{align\\*}\n$$\n\nPer rendere meglio le idee consideriamo un esempio.\nConsideriamo ancora una volta la catenta infinita $\\mathbb{Z}$, e poniamo come parametri $(a,b,c) = (5,3,1)$.\nSupponiamo di partire da un solo nodo iniziatore $u$, e senza perdita di generalità consideriamo solamente lo sviluppo del porcesso alla sua destra (tanto a sinistra è simmetrico).\n\nPrendiamo il nodo $v$ alla usa destra.\nI suoi guadagni nell'essere negli stati `A`, `B` e `AB` saranno\n$$\n\\\\begin{align\\*}\np_A(v) \u0026= 5\\\\\np_B(v) \u0026= 3\\\\\np\\_{AB}(v) \u0026= 5+3-1 = 7\n\\\\end{align\\*}\n$$\n\nPerciò a $v$ converrà diventare *bilingua* e adottare il doppio stato `AB`.\n\nConsideriamo ora il succesivo nodo $w$ sulla destra. I suoi guadagni saranno\n$$\n\\\\begin{align\\*}\np_A(w) \u0026= 5\\\\\np_B(w) \u0026= 3+3 = 6\\\\\np\\_{AB}(w) \u0026= 5+3-1 = 7\n\\\\end{align\\*}\n$$\nPerciò anche a $w$ converrà passare ad `AB`.\n\nAdesso, la situazione rispetto a $v$ è cambiata, in quanto ora ha un vicino nello stato `A` ed uno nello stato `AB`.\nInfatti anche i suoi guadagni sono ora cambiati, e risultano essere\n$$\n\\\\begin{align\\*}\np_A(v) \u0026= 10\\\\\np_B(v) \u0026= 3\\\\\np\\_{AB}(v) \u0026= 5+5-1 = 9\n\\\\end{align\\*}\n$$\n\nperciò ora $v$ passa nello stato `A`.\n\nÈ facile convincersi che si genera una cascata completa di `A`.\n\n![$(a,b,c) = (5,3,1)$ e $V_0 = \\lbrace u \\rbrace$.](ar-lesson11-img2.gif)\n\nAnalizzeremo ora il processo di diffusione nel nuovo modello con compatibilità, e cercheremo di capire in quali situazioni si ha una cascata completa.\n\n## Analisi\n\nDalle precedenti lezioni sappiamo che nel modello omogeneo, `A` \u003cu\u003enon\u003c/u\u003e si diffonde su reti infinite di grado finito se la sua soglia d'adozione è $q \u003e \\frac{1}{2}$, ovvero se $a$ non è **almeno** pari al valore di $b$.\n\nUno studio di *Kleinberg* del 2007 ha invece dimostrato uno strano comportamento riguardo il modello con compatibilità, ovvero che:\n\n* `A` si diffonde facilmente se $a$ è parecchio più grande di $c$ (**ragionevole**)\n* `A` fa fatica a diffondersi se $c$ è parecchio grande rispetto ad $a$ (**ragionevole**)\n* `A` fa fatica a diffondersi anche se $c$ non è molto grande rispetto ad $a$ (**strano**)\n\nAnalizziamo cosa succede nella rete infinita più semplice, la catena infinita $\\mathbb{Z}$.\n\nDato che fare un'analisi su tre parametri $a,b,c$ risulta molto complessa, conviene **normalizzare** $b$ ad 1, e quindi descrivere il processo solo in funzione di $a(b) = a$ e $c$. \nPerciò, in questo modello semplificato (ma non meno espressivo) la soglia d'adozione di `A` sarà $$q(b) = q = \\frac{1}{a+1}$$\nConsideriamo la situazione in cui c'è un unico nodo iniziatore $x$.\nIl suo vicino $u$ avrà un vicino in $V_A$ e l'altro in $V_B$.\n\n![Il nodo $u$ deve scegliere quale stato conviene adottare.](ar-lesson11-img3.png)\n\nAvremo che i guadagni nell'adottare uno stato sono\n$$\n\\\\begin{align\\*}\np_A(u) \u0026= a\\\\\np_B(u) \u0026= 1\\\\\np\\_{AB}(u) \u0026= a + 1 - c\n\\\\end{align\\*}\n$$\nSicuramente $u$ assume `A` se $p_A(u) \\geq p_B(u)$ e se $p_A(u) \\geq p\\_{AB}(u)$\n$$\n\\\\begin{equation}\n\\\\begin{cases}\np_A(u) \\geq p_B(u)\\\\\np_A(u) \\geq p\\_{AB}(u)\n\\\\end{cases}\n\\\\implies\n\\\\begin{cases}\na \\geq 1\\\\\nc \\geq 1\n\\\\end{cases}\n\\\\end{equation}\n$$\n\nInvece, $u$ rimane nello stato `B` se $p_B(u) \u003e p_A(u)$ e se $p_B(u) \u003e p\\_{AB}(u)$\n$$\n\\\\begin{equation}\n\\\\begin{cases}\np_b(u) \\geq p_A(u)\\\\\np_b(u) \\geq p\\_{AB}(u)\n\\\\end{cases}\n\\\\implies\n\\\\begin{cases}\na \\\u003c 1\\\\\na \\\u003c c\n\\\\end{cases}\n\\\\end{equation}\n$$\n\nInfine, $u$ adotta il bilinguismo `AB` se $p\\_{AB}(u) \u003e p_A(u)$ e se $p\\_{AB}(u) \\geq p_B(u)$\n$$\n\\\\begin{equation}\n\\\\begin{cases}\np\\_{AB}(u) \u003e p_A(u)\\\\\np\\_{AB}(u) \\geq p_B(u)\n\\\\end{cases}\n\\\\implies\n\\\\begin{cases}\nc \\\u003c 1\\\\\nc \\leq a\n\\\\end{cases}\n\\\\end{equation}\n$$\nPossiamo riassumere tutto in un grafico con assi $a$-$c$.\n\n![Grafico $a$-$c$.](ar-lesson11-img4.png)\n\nDalle precedenti osservazioni possiamo trarre due prime conclusioni:\n\n* se il nodo $u$ rimane nello stato `B`, allora la diffusione di `A` è bloccata e non potrà mai più procedere in alcun modo.\n* se $u$ invece passa \u003cu\u003edirettamente\u003c/u\u003e allo stato `A`, allora certamente avverrà una cascata completa di `A` in maniera diretta, senza transitare mai per `AB`.\n\nResta ora da capire che succede se $u$ passa allo stato `AB`.\nIn tal caso, avremo che il nodo $v$ avrà un nodo vicino nello stato `AB` e uno nello stato `B`, come nella seguente immagine\n\n![Il nodo $v$ deve scegliere quale stato conviene adottare.](ar-lesson11-img5.png)\n\nDato che stiamo assumendo che $u$ è ricaduto nella zone verde del grafico, fissiamo le relazioni $c \\\u003c 1$ e $c \\leq a$.\nCi chiediamo ora:\n\n* Per quali valori la diffusione di `A` si blocca?\n* Oppure, per quali valori si genera una cascata completa di `A`?\n* Oppure ancora, è possibile che si generi una cascata completa di `AB`?\n\nIniziamo col calcolare i vantaggi che avrebbe $v$ ad adottare uno stato\n$$\n\\\\begin{align\\*}\np_A(v) \u0026= a\\\\\np_B(v) \u0026= 2\\\\\np\\_{AB}(v) \u0026= \\max{\\lbrace a, 1 \\rbrace} + 1 - c\n\\\\end{align\\*}\n$$\n\nA questo punto possiamo dividere l'analisi in due casi:\n\n1. $a \\\u003c 1$, ovvero quando la coppia $(a,c)$ cade all'interno del triangolo verde $(0,0), (1,0), (1,1)$.\n1. $a \\geq 1$, ovvero quando la coppia $(a,c)$ cade all'interno della restante area verde.\n\nConsideriamo il caso `(1)`.\nIn tale situazione avremo che i rispettivi guadagni sono\n$$\n\\\\begin{align\\*}\np_A(v) \u0026\\\u003c 1\\\\\np_B(v) \u0026= 2\\\\\np\\_{AB}(v) \u0026= 2 - c\n\\\\end{align\\*}\n$$\n\novvero avremo che $p_A(v) \\\u003c p_B(v)$ e $p\\_{AB}(v) \\\u003c p_B(v)$.\nIn tal csaso accadrà che $v$ adotta `B`, e quindi la diffusione di `A` si blocca dopo un'altro passo.\nPossiamo quindi estendere la parte blu del grafico come nell'immagine seguente\n\n![Estensione area blu.](ar-lesson11-img6.png)\n\nNon resta che considerare il caso `(2)`, quando $a \\geq 1$.\n\nAnche in questo caso conviene dividere l'analisi in due casi disgiunti:\nil caso $1 \\leq a \\\u003c 2$ e il caso $a \u003e 2$.\n\nNel caso $a \u003e 2$ avremo che i guadagni di $v$ sono\n$$\n\\\\begin{align\\*}\np_A(v) \u0026= a \u003e 2\\\\\np_B(v) \u0026= 2\\\\\np\\_{AB}(v) \u0026= a + 1 - c \u003e a\n\\\\end{align\\*}\n$$\n\nPossiamo dire $v$ adotterà `AB`, perché abbiamo la catena di disuguaglianze $p\\_{AB}(v) \u003e p_A(v) \u003e p_B(v)$.\nDopo un passo osserviamo che il nodo $u$ passa dalla stato `AB` allo stato `A`.\nPossiamo quindi concludere che quando quando sono vere le seguenti condizioni, dopo una fase transitoria allo stato `AB`, avviene una cascata completa di `A`.\n$$\n\\\\begin{cases}\nc \\\u003c 1\\\\\na \u003e 2\n\\\\end{cases}\n$$\n\n![](ar-lesson11-img7.png)\n\nInfine, consideriamo l'ultimo caso $1 \\leq a \\\u003c 2$.\nIn queste condizioni, i valori di guadagno di $v$ risultano essere\n$$\n\\\\begin{align\\*}\np_A(v) \u0026= a \\\u003c 2\\\\\np_B(v) \u0026= 2\\\\\np\\_{AB}(v) \u0026= a + 1 - c\n\\\\end{align\\*}\n$$\n\nDato che $p_A(v) \\\u003c p_B(v)$, sappiamo che in qeull'area il processo di diffusione di `A` si ferma, e quindi non avremo mai una cascata completa di `A`.\nPoi, $p_B(v) \u003e p\\_{AB}(v)$ se e solo se $2 \u003e a + 1 - c$, ovvero se $a \\\u003c c + 1$. In tal caso $v$ adotterà lo stato `B`, e in un altro passo verrà bloccato il processo di diffusione di `A`.\nViceversa, se $a \u003e c + 1$, allora avremo che $p\\_{AB}(v) \u003e p_B(v)$, e quindi $v$ adotterà lo stato `AB`. Come prima, dopo un passo il nodo $u$ adotterà `A`, e così via dopo il nodo $v$, scatenando una cascata completa di `A`, dove però tutti i nodi transitano prima per `AB`.\n\nIl grafico risultante finale è il seguente\n\n![](ar-lesson11-img8.png)\n\nRiassumendo:\n\n* quando la coppia $(a,c)$ cade nell'area blu, allora il processo di diffusione di `A` si blocca definitivamente in un passo.\n* quando la coppia $(a,c)$ cade nell'area gialla, si scatena una cascata completa di `A`, senza che nessun nodo transiti mai attraverso lo stato `AB`.\n* quando la coppia $(a,c)$ cade nell'area verde, tutti i nodi passeranno allo stato `A` dopo però essere prima transitati attraverso lo stato `AB`.\n\n[^1]: sforzo.\n","lastmodified":"2022-08-29T13:39:16.90783924+02:00","tags":null},"/AR/12-Herding":{"title":"","content":"\n# Herding - Seguire il Gregge\n\nAbbiamo visto che quando degli individui sono connessi tra di loro in una *rete*, le loro decisioni e comportamenti possono essere influenzati (ed influenzare) da quello degli altri individui vicini.\n\nNello studio dei [processi di diffusione](9%20-%20Processi%20di%20diffusione%20-%20Part%201.md) abbiamo visto come il comportamento dei singoli individui veniva influenzato dalla *diretta comunicazione* col proprio viciano.\nIn questa sezione vedremo come le decisioni dei singoli individui possono essere influenzate dalle osservazioni fatte sul comportamento degli altri, senza lo scambio di alcuna informaione. In sostanza come è possibile *estrapolare informazioni* dal comportamento della massa.\n\nCome primo esempio supponiamo di essere in vacanza in un nuovo posto e di dover scegliere un ristorante in cui mangiare.\nIn base alle nostre recerche **personali** scopriamo che il ristorante `A` è il migliore che ci sia in zona, e quindi decidiamo di andarci.\nPoco prima di entrare vediamo che nel ristorante accanto, il ristorante `B`, c'è moltissima clientela, mentre il ristorante `A` è praticamente vuoto.\nNon è del tutto irrazionale pensare che tutte le persone che vanno al ristorante `B` abbiano **informazioni private** che noi non abbiamo, e supporre che in realtà il ristorante è il migliore.\nIn effetti il fatto che il ristorante `A` sia quasi vuoto non aiuta:\nverrebbe da pensare che siamo in possesso di informazioni non del tutto esatte o complete.\nPerciò decidiamo anche noi di andare al ristorante `B`.\n\nIn questo caso diremo che è avvenuta una **cascata informativa** (o **herding**).\nIn poche parole, una cascata informativa occorre quando gli individui prendono decisioni in maniera sequenziale, osservando ciò che hanno fatto gli altri prima e cercando di inferire qualche informazione aggiuntiva che ha spinto gli altri ad agire in tale maniera.\n\nLa cosa più interessante è che gli individui che *\"imitano\"* gli altri non lo fanno del tutto stupida, bensì facendo una serie di ragionamenti ed inferenze più che sensate.\nNaturalmente, l'imitazione può verificarsi anche a causa della pressione sociale all'esigienza di volersi conformare, senza alcuna causa informativa sottostante, e non è sempre facile distinguere questi due fenomeni.\nConsideriamo infatti l'esperimento di *Milgram*, *Bickman* e *Berkowitz* del 1960, in cui venivano poste agli angoli delle strade dei gruppi di persone (da un minimo di 1 a un massimo di 15) a guardare il cielo senza alcun motivo.\nSi è osservato quanti passanti si sono fermati e hanno volto lo sguardo al cielo.\nCome prima osservazione si è visto che con una sola persona, pochissimi passanti si fermavano. Se invece 5 persone fissavano il cielo, alcuni passanti si fermavanom a imitare, ma la maggior parte li ignorava.\nInfine, con un gruppo di 15 persone che guardano verso l'alto, hanno scoperto che il 45% dei passanti imitava, fermandosi e guardare il cielo cercando di capire.\n\nQuest'ultimo esperimento lascia pensare che esiste una **soglia critica** oltre la quale si scatena l'*herding* su una considerevole porzione di popolazione.\nInfatti, se camminando per strada vediamo due persone che fissano il cielo, è naturale pensare che i due individui non siano proprio sani mentalmente.\nSe invece ne vediamo 15, molto propbabilmente guarderemo anche noi verso l'alto, per cercare di capire cosa c'è di interessante.\n\nAlcune domande nascono spontanee:\n\n* esiste sempre una soglia critica che scatena l'herding di massa?\n* e se esiste, come fare a trovarla?\n\n## A Simple Herding Experiment: Il Gioco delle Urne\n\nConsideriamo un genere di gioco con la seguente tipologia di regole\n\n1. C'è una decisione da prendere\n1. I giocatori prendono le proprie decisioni in sequenza (uno dopo l'altro), e ogni persona può osservare le scelte fatte da coloro che hanno agito prima.\n1. Ogni giocatore ha alcune *informazioni private* che aiutano a guidare la propria decisione.\n1. Un giocatore non può osservare direttamente le informazioni private che gli altri giocatori hanno, ma può trarre deduzioni su queste informazioni private da ciò che fanno.\n\nSecondo queste indicazioni, instanziamo un gioco con le seguenti regole:\n\n* C'è uno **scommettitore** in una stanza chiusa, e una serie di **giocatori** all'esterno.\n* Lo scommettitore inserisce due palline rosse ed una blu in un'urna (che chiameremo `MR`, a *Maggioranza Rossa*), e due palline blu e una rossa in un'altra urna (che chiameremo `MB`, a *Maggioranza Blu*).\n* Lo scommettitore poi mischia le due urne e ne sceglie una a caso (senza avere la possibilità di vederne il contenuto).\n* Un giocatore alla volta entra nella stanza ed estrae una pallina dall'urna, e poi la reinserisce.\n* Il giocatore comunica a tutti quanti se ritiene che l'urna sia `MR` o `MB` (sulla base delle sue informazioni). **Importante:** il giocatore non deve comunicare il colore della pallina pescata.\n* Al termine vinceranno solo i giocatori che hanno indovinato quale urna è stata scelta inizialmente (`MR` o `MB`).\n\nPer definizione di questo gioco, l'informazione privata dei singoli giocatori è l'esito dell'estrazione (pallina blu o pallina rossa), e questa non viene mai condivisa con gli altri.\nUn giocatore però può inferire quale urna è meglio scegliere in base alle scelte fatte dagli altri prima (come vedremo adesso).\n\nPrimo giocatore\n\n \u003e \n \u003e prima di estrarre la pallina, il primo giocatore è in possesso della sola informazione *\"l'urna è `MR` o `MB`\"*.\n \u003e Non avnedo altre informazioni, a prescindere da cosa pescherà il primo giocatore, la probabilità che l'urna sia `MR` o `MB` è la stessa.\n \u003e Perciò gli conviene scomettere sul colore della pallina estratta: se pesca una pallina blu gli conviene scommettere su `MB` (stesso discorso per `MR`).\n\nSecondo giocatore\n\n \u003e \n \u003e a questo punto il secondo giocatore può dedurre l'esito dell'estrazione del primo giocatore sulla base della sua scommessa.\n \u003e Senza perdita di generalità, supponiamo che il primo giocatore abbia scommesso `MB` (e che quindi abbia estratto una pallina blu).\n \u003e Se il secondo estrae una pallina blu, allora sa che sono state esatratte due palline blu consecutive, e che quindi è più conveniente scommettere su `MB`.\n \u003e Se invece estrae una pallina rossa, si ritrova nella stessa situazione inizale del primo giocatore (senza alcuna informazione rilevante), perciò gli conviene scommettere `MR` in accordo alla sua estrazione.\n\nTerzo giocatore\n\n \u003e \n \u003e anche il terzo giocatore è in grado di dedurre le estrazioni dei giocatori precedenti: se sono discordi allora sono avvenute due estrazioni discorde, se sono concorde allora sono avvenute due estrazioni di palline dello stesso colore.\n \u003e Consideriamo il caso in cui le prime due estrazioni siano discordi, in questo caso al terzo giocatore conviene rispondere in accordo a ciò che pesca (se pesca una pallina blu gli conviene votare `MB`, se ne pesca una rossa gli conviene votare `MR`).\n \u003e Consideriamo ora il caso in cui i primi due giocatori abbiamo voti condori, e senza perdita di generalità supponiamo che abbiano entrambi votato `MB`.\n \u003e Se il terzo giocatore pesca una pallina blu, allora vuol dire che sono state estratte tre palline blu di seguito, rafforzando la propbailità che `MB` sia la risposta esatta.\n \u003e Se invece estrae una rossa, comunque è più probabile che la risposta esatta sia `MB`, perché sono state estratte due palline blu di seguito e poi una rossa.\n \u003e Quindi in ogni caso gli conviene votare `MB`.\n\nQuarto giocatore\n\n \u003e \n \u003e a questo punto il quarto giocatore può dedurre ciò che hanno fatto \u003cu\u003etutti\u003c/u\u003e i giocatori precedenti solamente se ci sono 2 voti concordi ed uno discorde (2 a 1). \n \u003e Perché se ci fossero 3 voti concordi, sappiamo che il terzo giocatore avrebbe votato in accordo ai primi due in ogni caso a prescindere dall'esito della sua estrazione.\n \u003e Supponiamo di essere nella situazione di *\"3 a 0\"* per `MB`. Al quarto giocatore conviene votare `MB` in ogni caso (esattamente come per il terzo giocatore).\n\nA questo punto, dal quinto giocatore in poi, si genera una *cascata informativa* a favore di `MB`, a prescindere dalle singole estrazioni.\n\n## Teorema di Bayes\n\nPer formalizzare meglio la meccanica precedentemente descritta è necessario enunciare il **Teorema di Bayes**.\n\n \u003e \n \u003e **Teorema di Bayes** siano i due eventi $A,B \\in \\Omega$ di probabilità \u003cu\u003enon nulla\u003c/u\u003e, allora $$\\mathcal{P}(A | B) = \\frac{\\mathcal{P}(B | A) \\cdot \\mathcal{P}(A)}{ \\mathcal{P}(B) }$$\n\n^967e98\n\n \u003e \n \u003e **Proof** per definizione di probabilità condizionata abbiamo che $$\n \u003e \\\\begin{align\\*}\n \u003e \\\\mathcal{P}(A | B) \u0026= \\frac{\\mathcal{P}(A \\cap B)}{\\mathcal{P}(B)}\\\\\n \u003e \\\\mathcal{P}(B | A) \u0026= \\frac{\\mathcal{P}(A \\cap B)}{\\mathcal{P}(A)}\n \u003e \\\\end{align\\*}$$\n \u003e ciò implica che $$\\mathcal{P}(A \\cap B) = \\mathcal{P}(A | B) \\cdot \\mathcal{P}(B) = \\mathcal{P}(B | A) \\cdot \\mathcal{P}(A)$$ Sostituendo opportunamente otteniamo l'enunciato del teorema $$\\mathcal{P}(A | B) = \\frac{\\mathcal{P}(A \\cap B)}{\\mathcal{P}(B)} = \\frac{\\mathcal{P}(B | A) \\cdot \\mathcal{P}(A)}{\\mathcal{P}(B)} ;; \\square$$\n\nFacendo qualche opportuna sostituzione, possiamo riscrivere $\\mathcal{P}(B)$ come segue\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(B) \u0026= \\mathcal{P}(B \\cap \\Omega)\\\\\n\u0026= \\mathcal{P}(B \\cap (A \\cup A^{\\mathcal{C}}))\\\\\n\u0026= \\mathcal{P}((B \\cap A) \\cup (B \\cap A^{\\mathcal{C}}))\\\\\n\u0026= \\mathcal{P}(B \\cap A) + \\mathcal{P}(B \\cap A^{\\mathcal{C}})\\\\\n\u0026= \\mathcal{P}(B | A) \\cdot \\mathcal{P}(A) + \\mathcal{P}(B | A^{\\mathcal{C}}) \\cdot \\mathcal{P}(A^{\\mathcal{C}})\n\\\\end{align\\*}\n$$\n\n^61562b\n\nperciò $$\\mathcal{P}(A | B) = \\frac{\\mathcal{P}(B | A) \\cdot \\mathcal{P}(A)}{ \\mathcal{P}(B | A) \\cdot \\mathcal{P}(A) + \\mathcal{P}(B | A^{\\mathcal{C}}) \\cdot \\mathcal{P}(A^{\\mathcal{C}}) }$$\n\nSiano gli eventi:\n\n* $MR$ : *\"l'urna è a maggioranza rossa\"*\n* $MB$ : *\"l'urna è a maggioranza blu\"*\n* $r$ : *\"è stata estratta una pallina rossa\"*\n* $b$ : *\"è stata estratta una pallina blu\"*\n\nOsserviamo inoltre che i precedenti eventi sono mutualmente complementari\n$$\n\\\\begin{align\\*}\nMR \u0026= MB^{\\mathcal{C}}\\\\\nMB \u0026= MA^{\\mathcal{C}}\\\\\nb \u0026= r^{\\mathcal{C}}\\\\\nr \u0026= b^{\\mathcal{C}}\n\\\\end{align\\*}$$\n\nSecondo le regole del gioco sappiamo che\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MR) \u0026= \\mathcal{P}(MB) = \\frac{1}{2}\\\\\n\\\\mathcal{P}(r | MR) \u0026= \\frac{2}{3}; ;; \\mathcal{P}(b | MR) = \\frac{1}{3}\\\\\n\\\\mathcal{P}(r | MB) \u0026= \\frac{1}{3}; ;; \\mathcal{P}(b | MB) = \\frac{2}{3}\n\\\\end{align\\*}$$\n\n**Giocatore 1:** Supponiamo senza perdita di generalità che il primo giocatore estrae una pallina blu, essi dovrà calcolare la probabilità che l'urna sia a maggioranza blu o rossa, e questo si può fare grazie al [teorema di Bayes](12%20-%20Herding.md#967e98)\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | b) \u0026= \\frac{\\mathcal{P}(b | MB) \\cdot \\mathcal{P}(MB)}{\\mathcal{P}(b | MB) \\cdot \\mathcal{P}(MB) + \\mathcal{P}(b | MR) \\cdot \\mathcal{P}(MR)} = \\frac{2}{3}\\\\\n\\\\\n\\\\mathcal{P}(MR | b) \u0026= \\frac{\\mathcal{P}(b | MR) \\cdot \\mathcal{P}(MR)}{\\mathcal{P}(b | MR) \\cdot \\mathcal{P}(MR) + \\mathcal{P}(b | MB) \\cdot \\mathcal{P}(MB)} = \\frac{1}{3}\n\\\\end{align\\*}\n$$\n\nperciò al primo giocatore conviene votare in accordo alla sua estrazione.\n\n**Giocatore 2:** Vediamo ora quale strategia è migliore per il secondo giocatore.\nConsideriamo come prima situazione quella in cui esso estrae una pallina rossa, ed indichiamo con $br$ l'evento *\"sono state estratte in ordine una pallina blu e poi una rossa\"*.\nDato che il secondo giocatore sa esasttamente cosa ha pescato il primo (dato che lo può inferire con certezza assumendo che il primo giocaotre giochi correttamente), si può affermare che il secondo giocatore si trova a dover calcolare le seguenti probabilità\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | br) \u0026= \\frac{\\mathcal{P}(br | MB) \\cdot \\mathcal{P}(MB)}{\\mathcal{P}(br | MB) \\cdot \\mathcal{P}(MB) + \\mathcal{P}(br | MR) \\cdot \\mathcal{P}(MR)} = \\frac{1}{2}\\\\\n\\\\\n\\\\mathcal{P}(MR | br) \u0026= \\frac{\\mathcal{P}(br | MR) \\cdot \\mathcal{P}(MR)}{\\mathcal{P}(br | MR) \\cdot \\mathcal{P}(MR) + \\mathcal{P}(br | MB) \\cdot \\mathcal{P}(MB)} = \\frac{1}{2}\n\\\\end{align\\*}\n$$\n\nperciò il secondo giocatore non può estrarre alcuna informazione utile dall'estrazione del primo, e quindi gli conviene scommettere in accordo a ciò che estrae.\n\nConsideriamo ora il caso in cui il secondo giocate estrae una pallina blu.\nIn questo l'informazione riguardo la prima estrazione è realmente utile, in quanto possiamo dire che la probabilità è nettamente più sbilanciata verso `MB`\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bb) \u0026= \\frac{\\mathcal{P}(bb | MB) \\cdot \\mathcal{P}(MB)}{\\mathcal{P}(bb | MB) \\cdot \\mathcal{P}(MB) + \\mathcal{P}(bb | MR) \\cdot \\mathcal{P}(MR)} = \\frac{4}{5}\\\\\n\\\\\n\\\\mathcal{P}(MR | bb) \u0026= \\frac{\\mathcal{P}(bb | MR) \\cdot \\mathcal{P}(MR)}{\\mathcal{P}(bb | MR) \\cdot \\mathcal{P}(MR) + \\mathcal{P}(bb | MB) \\cdot \\mathcal{P}(MB)} = \\frac{1}{5}\n\\\\end{align\\*}\n$$\n\n**Giocatore 3:** A questo punto (sempre supponendo che la prima estrazione sia stata una pallina blu) possiamo essere in due situazioni differenti\n\n* $br$: sono avvenute in sequenza le estrazioni *blu-rossa*\n* $bb$: sono avvenute in sequenza le estrazioni *blu-blu*\n\nPartendo dalla prima, vediamo quale è la strategia migliore per il terzo giocatore.\n**Caso $brb$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | brb) \u0026= \\frac{\\mathcal{P}(brb | MB) \\cdot \\mathcal{P}(MB)}{\\mathcal{P}(brb | MB) \\cdot \\mathcal{P}(MB) + \\mathcal{P}(brb | MR) \\cdot \\mathcal{P}(MR)} = \\frac{2}{3}\\\\\n\\\\\n\\\\mathcal{P}(MR | brb) \u0026= \\frac{\\mathcal{P}(brb | MR) \\cdot \\mathcal{P}(MR)}{\\mathcal{P}(brb | MR) \\cdot \\mathcal{P}(MR) + \\mathcal{P}(brb | MB) \\cdot \\mathcal{P}(MB)} = \\frac{1}{3}\n\\\\end{align\\*}\n$$\n\n**Caso $brr$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | brr) \u0026= \\frac{\\mathcal{P}(brr | MB) \\cdot \\mathcal{P}(MB)}{\\mathcal{P}(brr | MB) \\cdot \\mathcal{P}(MB) + \\mathcal{P}(brr | MR) \\cdot \\mathcal{P}(MR)} = \\frac{1}{3}\\\\\n\\\\\n\\\\mathcal{P}(MR | brr) \u0026= \\frac{\\mathcal{P}(brr | MR) \\cdot \\mathcal{P}(MR)}{\\mathcal{P}(brr | MR) \\cdot \\mathcal{P}(MR) + \\mathcal{P}(brr | MB) \\cdot \\mathcal{P}(MB)} = \\frac{2}{3}\n\\\\end{align\\*}\n$$\n\nPerciò se i pirmi due voti sono discordi al terzo giocatore conviene votare in accordo alla sua estrazione (come già intuito in precedenza).\n\nVediamo ora cosa accade se i primi due giocatori hanno voti concordi.\n**Caso $bbb$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bbb) \u0026= \\frac{\\mathcal{P}(bbb | MB) \\cdot \\mathcal{P}(MB)}{\\mathcal{P}(bbb | MB) \\cdot \\mathcal{P}(MB) + \\mathcal{P}(bbb | MR) \\cdot \\mathcal{P}(MR)} = \\frac{8}{9}\\\\\n\\\\\n\\\\mathcal{P}(MR | bbb) \u0026= \\frac{\\mathcal{P}(bbb | MR) \\cdot \\mathcal{P}(MR)}{\\mathcal{P}(bbb | MR) \\cdot \\mathcal{P}(MR) + \\mathcal{P}(bbb | MB) \\cdot \\mathcal{P}(MB)} = \\frac{1}{9}\n\\\\end{align\\*}\n$$\n\n**Caso $bbr$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bbr) \u0026= \\frac{\\mathcal{P}(bbr | MB) \\cdot \\mathcal{P}(MB)}{\\mathcal{P}(bbr | MB) \\cdot \\mathcal{P}(MB) + \\mathcal{P}(bbr | MR) \\cdot \\mathcal{P}(MR)} = \\frac{2}{3}\\\\\n\\\\\n\\\\mathcal{P}(MR | bbr) \u0026= \\frac{\\mathcal{P}(bbr | MR) \\cdot \\mathcal{P}(MR)}{\\mathcal{P}(bbr | MR) \\cdot \\mathcal{P}(MR) + \\mathcal{P}(bbr | MB) \\cdot \\mathcal{P}(MB)} = \\frac{1}{3}\n\\\\end{align\\*}\n$$\n\nIn questo caso al giocatore 3 conviene votare in accordo a ciò che hanno votato i primi due giocatori, a prescindere da quale sarà l'esito della sua estrazione.\n\n**Giocatore 4:** Senza perdita di generalità consideriamo il caso in cui le prime due estrazioni sono entrambe *blu*.\nIl giocatore 4 non può essere certo di cosa ha estratto il giocatore 3, perciò gli conviene sempre calcolare due probabilità differenti, quella in cui il terzo ha estratto una pallina *rossa* e quella in cui ne ha estratta una *blu*.\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bbbb) = \\frac{16}{17}; ;; \u0026\\mathcal{P}(MR | bbbb) = \\frac{1}{17}\\\\\n\\\\mathcal{P}(MB | bbbr) = \\frac{8}{9}; ;; \u0026\\mathcal{P}(MR | bbbr) = \\frac{1}{9}\\\\\n\\\\mathcal{P}(MB | bbrb) = \\frac{8}{9}; ;; \u0026\\mathcal{P}(MR | bbrb) = \\frac{1}{9}\\\\\n\\\\mathcal{P}(MB | bbrr) = \\frac{1}{2}; ;; \u0026\\mathcal{P}(MR | bbrr) = \\frac{1}{2}\n\\\\end{align\\*}\n$$\n\nPerciò votando `MB` il giocatore 4 non ricade mai nella strategia che minimizza la probabilità di sucesso.\nAl più può ritrovarsi nel caso in cui le probabilità di successo e insuccesso equivalgono, ovvero quando giocatori 3 e 4 estraggono entrambi una pallina *rossa*. Putroppo però il giocatore 4 non può sapere cosa ha estratto il terzo giocatore, perciò gli conviene votare comunque `MB` a prescindere dalla sua estrazione.\n\n**Giocatore 5:** sapendo che le prime due estrazioni sono state *blu-blu*, il giocatore 5 (come il giocatore 4) deve calcolare tutte le probabilità rispetto alle possibili combinazioni di estrazioni dei giocatori 3 e 4.\n\n**Caso $bbbb$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bbbbb) = \\frac{32}{33}; ;; \u0026\\mathcal{P}(MR | bbbbb) = \\frac{1}{33}\\\\\n\\\\mathcal{P}(MB | bbbbr) = \\frac{8}{9}; ;; \u0026\\mathcal{P}(MR | bbbbr) = \\frac{1}{9}\n\\\\end{align\\*}\n$$\n\n**Caso $bbbr$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bbbrb) = \\frac{8}{9}; ;; \u0026\\mathcal{P}(MR | bbbrb) = \\frac{1}{9}\\\\\n\\\\mathcal{P}(MB | bbbrr) = \\frac{2}{3}; ;; \u0026\\mathcal{P}(MR | bbbrr) = \\frac{1}{3}\n\\\\end{align\\*}\n$$\n\n**Caso $bbrb$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bbrbb) = \\frac{8}{9}; ;; \u0026\\mathcal{P}(MR | bbrbb) = \\frac{1}{9}\\\\\n\\\\mathcal{P}(MB | bbrbr) = \\frac{2}{3}; ;; \u0026\\mathcal{P}(MR | bbrbr) = \\frac{1}{3}\n\\\\end{align\\*}\n$$\n\n**Caso $bbrr$:**\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(MB | bbrrb) = \\frac{2}{3}; ;; \u0026\\mathcal{P}(MR | bbrrb) = \\frac{1}{3}\\\\\n\\\\bigstar \\mathcal{P}(MB | bbrrr) = \\frac{1}{3}; ;; \u0026\\mathcal{P}(MR | bbrrr) = \\frac{2}{3}\n\\\\end{align\\*}\n$$\n\nAl giocatore 5 conviene sempre scommettere su `MB` a meno che il terzo e il quarto giocatore non abbiano estratto due palline *rosse*.\nQuesto purtroppo il giocatore 5 non può saperlo, in quanto i giocatori 3 e 4 voteranno `MB` a prescindere dall'esito delle proprie estrazioni.\n\nPerciò possiamo dire che se le prime due estrazioni sono *blu-blu* si genera una cascata imitativa in cui tutti i giocatori voteranno `MB`, a prescindere dalle proprie informazioni private!\n\n## Un Modello Generale di Sequential Decision Making\n\nCome visto negli esperimenti precedenti o nel gioco delle due urne, il fenomeno dell'*Herding* si presenta in situazioni che hanno delle caratteristiche in comune, ovvero:\n\n1. Ogni individuo deve prendere una decisione.\n1. Ogni individuo ha una propria informazione **privata**.\n1. Ogni individuo riceve dalla rete un'informazione incompleta, ovvero sa le scelte degli altri individui ma non l'informazione che li ha spinti a prendere tali decisioni.\n1. Le decisioni vengono prese in sequenza, dopo aver osservato quello che hanno fatto gli altri in precedenza.\n1. Ogni individuo prende la propria decisione in maniera **puramente razionale**: inferisce dalle proprie osservazioni quale è la strategia migliore da adottare, senza alcuna influenza o pressione sociale.\n1. Si scatena una **cascata informativa** (**herding**), quando una certa **massa critica** prende una medesima decisione.\n\nDescriviamo ora in maniera formale un modello che cattura tutte queste caratteristiche\n\n### Punto 1: Decisioni Individuali\n\nPer semplicità assumiamo che le decisioni da prendere sono **decisioni binarie**.\nSenza perdita di generalità assumiamo che le uniche due alternative sono\n\n* `Y`: l'individuo *accetta* una proposta.\n* `N`: l'individuo *rifiuta* una proposta.\n\nSolo una delle due alternative è quella giusta. La probabilità che `Y` sia l'alternativa giusta è $\\mathcal{P}(Y) = p$, mentre la probabilità che quella giusta sia `N` è $\\mathcal{P}(N) = 1-p$.\n\nSe un individuo **accetta** (`Y`) una proposta avrà un *profitto* $v_g \u003e 0$[^1] se `Y` era la risposta corretta, o una *perdita* $v_b \\leq 0$[^2] se la risposta `Y` era errata.\n\nContrariamente, se l'individuo **non accetta** (`N`) non otterrà nessun profitto e nessuna perdita.\n\nAffinché sia *equivalente* per undividuo accettare (`Y`) o rifiutare (`N`), deve essere che\n$$v_g p + v_b(1-p) = 0$$\n\n### Punto 2: Informazioni Private\n\nOngi individuo possiede un'**informazione privata**, che possiamo assumere ricevere sottoforma di **segnale privato**.\nI due possibili segnali possono essere `A` (`Accetta`) ed `R` (`Rifiuta`).\n\nSe la scelta giusta è `Y`, allora la probabilità di ricevere come segnale privato `A` è $q \u003e \\frac{1}{2}$. \nViceversa se la scelta giusta è `N`, allora la probabilità di ricevere come segnale privato `A` è $1 - q$.\nSimmetricamente per `R`.\n\nPiù formalmente possiamo esprimere queste proprietà con probabilità condizionate\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(A | Y) = q ;; \u0026\\mathcal{P}(A | N) = 1 - q\\\\\n\\\\\n\\\\mathcal{P}(R | Y) = 1 - q ;; \u0026\\mathcal{P}(R | N) = q\n\\\\end{align\\*}\n$$\n\n### Punto 3: Osservazioni\n\nL'individuo $i$-esimo che deve prendere una decisione ricava dalla rete la sequenza $(X_1, ..., X\\_{i-1}) \\in \\lbrace Y, N \\rbrace^{i-1}$ delle decisioni prese dai precedenti $i-1$ individui.\n\n### Punto 4: Decisioni Sequenzali\n\nL'individuo $i$-esimo prende una decisione dopo che i precedenti $i-1$ individui hanno preso la loro.\n\n### Punto 5: Decisioni Razionali\n\nSupponiamo che per l'individui $i$ inizialmente `Y` ed `N` sono alternative equivalenti, ovvero che $v_g p + v_b(1-p) = 0$.\nSe dopo le decisioni dei primi $i - 1$ individui la probabilità che `Y` sia corretta diventa una certa quantità $p'$, all'individui $i$ converrà accettare se e soltanto se $$v_gp' + v_b(1 - p') \\geq 0$$\ne questo accade se $p' \\geq p$, ovvero se non peggiora la probabilità che accettare sia la strategia corretta.\n\n### Punto 6: Massa Critica\n\nCerchiamo ora di individuare quanto deve essere grande una massa critica che scatena l'*herding*.\n\nIndichiamo con $S \\in \\lbrace A, R \\rbrace^*$ la sequenza dei *segnali privati* ricevuti dagli individui. \nConsideriamo la scelta del primo individuo, ovvero quando $\\vert S \\vert = 1$.\nSe $S = (A)$, allora la probabilità che la scelta corretta sia `Y` è\n$$\\begin{align*}\n\\\\mathcal{P}(Y \\vert A)\n\u0026= \\frac{ \\mathcal{P}(A \\vert Y) \\cdot \\mathcal{P}(Y) }{ \\mathcal{P}(A \\vert Y) \\cdot \\mathcal{P}(Y) + \\mathcal{P}(A \\vert N) \\cdot \\mathcal{P}(N)}\\\\\n\u0026= \\frac{qp}{qp + (1-q)(1-p)}\\\\\n(\\bigstar q \u003e 1/2) \u0026\u003e \\frac{qp}{qp + q(1-p)} = \\frac{qp}{qp + q - qp} = p\n\\\\end{align\\*}$$\nviceversa la probabilità che la scelta corretta sia `N` ricevendo il segnale `A` è $$\\mathcal{P}(N \\vert A) = 1 - \\mathcal{P}(Y \\vert A) \\\u003c p$$\nIn maniera simmetrica, se riceviamo come primo segnale privato `R` avremo che $$\\mathcal{P}(Y \\vert R) \\\u003c p ;;;;\\mathcal{P}(N \\vert R) \u003e p$$\nSegue quindi che in assenza di ulteriori informazioni, quando un individuo ha solamente la propria informazione privata, conviene rispondere in accordo ad essa: se riceve `A` conviene rispondere `Y`, se riceve `R` conviene rispondere `N`.\n\nConsideriamo ora il caso in cui $\\vert S \\vert \u003e 1$.\nSupponiamo che in qualche maniera l'individuo che deve fare la scelta sia riuscito ad inferire tutta la sequanza di $S$ (come in alcuni casi del gioco delle due urne).\nDiciamo che nella sequenza $S$ è presente $a$ volte l'elemento `A` ed $r$ volte l'elemento `R`.\nPerciò la probabilità `Y` sia la risposta esatta, sapendo la sequenza $S$ di segnali privati sarà\n$$\\begin{align\\*}\n\\\\mathcal{P}(Y \\vert S)\n\u0026= \\frac{ \\mathcal{P}(S \\vert Y) \\cdot \\mathcal{P}(Y) }{ \\mathcal{P}(S \\vert Y) \\cdot \\mathcal{P}(Y) + \\mathcal{P}(S \\vert N) \\cdot \\mathcal{P}(N)}\\\\\n\u0026= \\frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}\n\\\\end{align\\*}$$\nSe $a \u003e r$, e dato che $q \u003e 1/2$, avremo al \u003cu\u003esecondo addendo al denominatore\u003c/u\u003e che\n$$(1-q)^a q^r = (1-q)^{a-r+r} q^r \\\u003c q^{a-r} (1-q)^r q^r = q^a (1-q)^r$$\ne quindi\n$$\\begin{align\\*}\n\\\\mathcal{P}(Y \\vert S)\n\u0026= \\frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}\\\\\n\u0026\u003e \\frac{q^a (1-q)^r p}{q^a (1-q)^r p + q^a (1-q)^r (1-p)} = p\n\\\\end{align\\*}$$\nViceversa, se $a \\\u003c r$, accade che\n$$(1-q)^a q^r = (1-q)^a q^a q^{r-a} \u003e (1-q)^a q^a (1-q)^{r-a} = q^a (1-q)^r$$\ne quindi\n$$\\begin{align\\*}\n\\\\mathcal{P}(Y \\vert S)\n\u0026= \\frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}\\\\\n\u0026\\\u003c \\frac{q^a (1-q)^r p}{q^a (1-q)^r p + q^a (1-q)^r (1-p)} = p\n\\\\end{align\\*}$$\nInfine, se $a = r$ allora $q^a (1-q)^r = (1-q)^a q^r$, e quindi $\\mathcal{P}(Y \\vert S) = p$.\n\nRicapitolando\n$$\\mathcal{P}(Y \\vert S) = \\begin{cases}\n\n \u003e \n \u003e p \u0026\\mbox{se } a \u003e r\\\\\n \u003e \\\u003c p \u0026\\mbox{se } a \\\u003c r\\\\\n \u003e = p \u0026\\mbox{se } a = r\n \u003e \\\\end{cases}$$\n \u003e Perciò se un individuo conosce l'intera sequenza di segnali privati dei giocatori precedenti, riesce a prendere la scelta che massimizza la probabilità di vincita in base alla maggioranza:\n \u003e se ci sono stati più segnali `A` conviene votare `Y`, se ce ne sono stati più `R` conviene votare `N`.\n\nOsservare che il caso in cui $a = r$ equivale sostanzialmente al caso in cui non si ha alcuna informazione aggiuntiva riguardo la decisione da prendere ($\\mathcal{P}(Y \\vert S) = \\mathcal{P}(Y)$), e quindi bisogna rifarsi solamente al proprio segnale privato.\n\nSenza perdita di generalità supponiamo che l'$n$-esimo individuo riesca ad inferire tutta la sequenza $S$ degli $n-1$ precedenti segnali, e che $a = r$.\nSia $\\sigma_n \\in \\lbrace A, R \\rbrace$ il segnale privato che riceve l'$n$-esimo individuo.\nDato che stiamo assumendo che $a = r$ avremo che\n$$\\begin{align\\*}\n\\\\sigma_n = A \\implies \\mathcal{P}(Y \\vert S \\cup \\lbrace \\sigma_n \\rbrace) = \\mathcal{P}(Y \\vert \\sigma_n) \u003e p\\\\\n\\\\sigma_n = R \\implies \\mathcal{P}(Y \\vert S \\cup \\lbrace \\sigma_n \\rbrace) = \\mathcal{P}(Y \\vert \\sigma_n) \\\u003c p\n\\\\end{align\\*}$$\nperciò l'individuo segue il suo segnale privato, qualunque esso sia.\n\nSe invece $a = r+1$ avremo che\n$$\\begin{align\\*}\n\\\\sigma_n = A \\implies \\mathcal{P}(Y \\vert S \\cup \\lbrace \\sigma_n \\rbrace) \u003e p\\\\\n\\\\sigma_n = R \\implies \\mathcal{P}(Y \\vert S \\cup \\lbrace \\sigma_n \\rbrace) = p\n\\\\end{align\\*}$$e anche in questo caso l'individuo $n$ segue il suo segnale privato.\n\nInvece se $a \\geq r+2$ all'individuo $n$ conviene sempre scommettere su `Y`, qualunque sia il suo segnale, scatenando così una cascata imitativa.\nSimmetricamente per `N` quando $r \\geq a+2$.\n\nQuindi, individuato la condizione per la quale scatta la cascata, ci si chiede in che situazione si arriva ad avere $a \\geq r+2$ (o $r \\geq a+2$)?\n\nFin quando i due segnali `A` ed `R` si alternano non può scattare l'herding, perché $\\vert a - r \\vert \\leq 1$.\nAllora verrebbe da dire che quando si ottengono **due segnali consecutivi** può scattare l'herding.\n\nQuesta condizione è necessaria, ma non sufficiente.\nInfatti, in una sequenza del tipo `ARAR...ARAA` due `A` consecutive bastano per scatenare la cascata imitativa per `Y`, ovvero bastano per avere $a \\geq r+2$.\nPurtroppo però, nella stessa sequenza, se abbiamo due `R` consecutive non è sufficiente per far scattare una cascata imitativa di `N`.\nInfatti nella sequenza `ARAR...ARR` abbiamo che $a - r= 1$.\n\nPerciò, per essere completamente certi di ottenere una cascata imitativa, si necessita di **almeno 3 segnali identici consecutivi**!\n\nCalcoliamo ora la probabilità che una cascata si scateni entro il passo $n$.\n\nIndichiamo sempre con $\\sigma_i \\in \\lbrace A, R \\rbrace$ il segnale privato dell'$i$-esimo individuo, e siano gli eventi\n$$\\begin{align\\*}\n\\\\mathcal{A} \u0026= (\\sigma_1 = \\sigma_2 = \\sigma_3) \\vee (\\sigma_2 = \\sigma_3 = \\sigma_4) \\vee ... \\vee (\\sigma\\_{n-3} = \\sigma\\_{n-2} = \\sigma\\_{n-1}) \\vee (\\sigma\\_{n-2} = \\sigma\\_{n-1} = \\sigma_n)\\\\\n\u0026= \\bigvee\\_{1 \\leq i \\leq n-2} (\\sigma_i = \\sigma\\_{i+1} = \\sigma\\_{i+2})\\\\\n\\\\\n\\\\mathcal{B} \u0026= (\\sigma_1 = \\sigma_2 = \\sigma_3) \\vee (\\sigma_4 = \\sigma_5 = \\sigma_6) \\vee ... \\vee (\\sigma\\_{n-5} = \\sigma\\_{n-4} = \\sigma\\_{n-3}) \\vee (\\sigma\\_{n-2} = \\sigma\\_{n-1} = \\sigma_n)\\\\\n\u0026= \\bigvee\\_{1 \\leq i \\leq n/3} (\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i})\n\\\\end{align\\*}$$\n\nOsserviamo che $\\mathcal{B} \\subseteq \\mathcal{A}$, perciò $\\mathcal{P}(\\mathcal{B}) \\leq \\mathcal{P}(\\mathcal{A})$.\n\nIndichiamo ora con $\\mathcal{H}*n$ l'evento *\"la cascata imitativa si innesca entro il passo $n\"*.\nLa sua probabilità sarà $$\\mathcal{P}(\\mathcal{H}*n) \\geq \\mathcal{P}(\\mathcal{A}) \\geq \\mathcal{P}(\\mathcal{B})$$\nPer la legge di *De Morgan* avremo che $$\\mathcal{P}(\\lnot \\mathcal{H}*n) \\leq \\mathcal{P}(\\lnot \\mathcal{B}) = \\mathcal{P}(\\bigwedge*{1 \\leq i \\leq n/3} \\lnot (\\sigma*{3i-2} = \\sigma*{3i-1} = \\sigma\\_{3i}))$$\nDato che gli eventi in $\\mathcal{B}$ sono tutti indipendenti tra di loro, abbiamo che $$\\mathcal{P}(\\lnot \\mathcal{H}*n) \\leq \\prod*{1 \\leq i \\leq n/3} \\mathcal{P}(\\lnot (\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i}))$$\n\nPer ogni $i \\leq n/3$ abbiamo che la probabilità dell'evento $(\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i})$ sarà\n$$\\begin{align\\*}\n\\\\mathcal{P}(\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i}) \u0026= \\mathcal{P}((\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i} = A) \\vee (\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i} = R))\\\\\n\u0026= \\mathcal{P}(\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i} = A) +  \\mathcal{P}(\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i} = R)\\\\\n\u0026= \\mathcal{P}(AAA) +  \\mathcal{P}(RRR)\\\\\n\u0026= \\mathcal{P}(AAA) +  \\mathcal{P}(RRR)\\\\\n\u0026= \\left\\[ \\mathcal{P}(AAA \\vert Y)\\mathcal{P}(Y) + \\mathcal{P}(AAA \\vert N)\\mathcal{P}(N)\\right\\] + \\left\\[ \\mathcal{P}(RRR \\vert Y)\\mathcal{P}(Y) + \\mathcal{P}(RRR \\vert N)\\mathcal{P}(N)\\right\\]\\\\\n\u0026= \\left\\[ q^3p + (1-q)^3(1-p) \\right\\] + \\left\\[ (1-q)^3p + q^3(1-p) \\right\\]\\\\\n\u0026= 1 - 3q + 3q^2\n\\\\end{align\\*}$$\n\nPerciò il complemento sarà\n$$\\mathcal{P}(\\lnot (\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i})) = 1 - \\mathcal{P}(\\sigma\\_{3i-2} = \\sigma\\_{3i-1} = \\sigma\\_{3i}) = 3q - 3q^2$$\nApplicando questa uguaglianza per ogni $i$ avremo che\n$$\\mathcal{P}(\\lnot \\mathcal{H}\\_n) \\leq (3q - 3q^2)^{n/3}$$\nOsserviamo in fine che $(3q - 3q^2) \\\u003c 1$ per ogni $q \\in \\left\\[0,1\\right\\]$.\n\n![$(3q - 3q^2) \\\u003c 1$ per ogni $q \\in \\left(0,1\\right)$.|400](ar-lesson12-img1.png)\n\nPerciò possiamo concludere che la cascata imitativa si inneschera **quasi sicuramente** al crescere degli individui.\n$$\\mathcal{P}(\\mathcal{H}*n) \\geq 1 - (3q - 3q^2)^{n/3} \\implies \\lim*{n \\rightarrow \\infty} \\mathcal{P}(\\mathcal{H}\\_n) = 1$$\n\n---\n\n## Considerazioni\n\nCome appena visto, le cascate informative sono fenomeni abbastanza semplici da innescare, in quanto richiedono lo scambio di pochissime informazioni (solo le decisioni prese).\nSe si pensa bene, in realtà le uniche informazioni realmente rilevanti sono quelle *precedenti* all'innesco della cascata in quanto, per definizione, una volta iniziata la cascata informativa tutti gli individui prenderanno la stessa decisione **indipendentemente** dalle informazioni in possesso.\nLe informazioni che vengono ricevute dopo che la cascata si innesca sono *inutili*.\n\nLe cascata informative non sono affidabili, possono portare facilmente a prendere decisioni inesatte.\nProprio perché non vengono usate tutte le informazioni presenti nella rete, bensì un piccolissima parte di esse.\n\nInoltre le cascate informative sono anche molto instabili, è possibile \"rompere\" una cascata semplicemente rendendo pubblica l'informazione privata di un individuo oppure che qualcuno voti in disaccordo alla cascata, e questo è più probabile che accada tanto più la rete è grande.\n\nTuttavia nel libro *[The Wisdom of Crowds](https://www.amazon.it/Wisdom-Crowds-James-Surowiecki/dp/0385721706)*, James Surowiecki sostiene la tesi secondo la quale\n\n \u003e \n \u003e *il comportamento aggregato di un numero elevato di persone in possesso di informazione molto limitata può produrre risultati molto accurati*\n\n^284d1a\n\nPerò l'assuzione alla base di questa tesi è che ogni individuo prende la propria decisione solamente sulla base delle proprie informazioni private, **indipendentemente** da ciò che fanno gli altri.\n\n[^1]: i pedici $g,b$ per $v_g, v_b$ stanno ad indicare *good*, *bad* rispettivamente.\n\n[^2]: i pedici $g,b$ per $v_g, v_b$ stanno ad indicare *good*, *bad* rispettivamente.\n","lastmodified":"2022-08-29T13:39:16.917808846+02:00","tags":null},"/AR/13-Sistemi-di-voto-Part-1":{"title":"","content":"\n# Sistemi di Voto\n\nIn questa parte verrà discusso e analizzato come una comunità di individui prende una decisione collettiva, senza però che i singoli possano in qualche modo scambiare alcuna informazione.\n\nContrariamente al fenomeno dell'[Herding](12%20-%20Herding.md) gli individui prendevano una scalta sulla base delle scelte degli *individui precedenti*.\nNei **sistemi di voto** si vuole estrapolare un'informazione dalla rete tramite una votazione che in qualche modo rispecchi le informazioni di tutti, però i singoli individui decidono in maniera del tutto **indipendente** dagli altri, ovvero senza poter osservare le decisioni degli altri (e quindi senza avere la possibilità di inferire informazioni aggiuntive).\n\n## Un Modello Semplice di Decision Making: Simultaneous, Sincere Voting\n\nDefiniamo un primo modello molto semplice di decision making **individuale**.\n\nGli individui devono scelgiere trai sole due alternative `X` o `Y`.\n\nUna delle due è migliore dell'altra.\nIndichiamo con `X \u003e Y` se l'alternativa `X` è migliore di `Y`, viceversa con `Y \u003e X`. \n\nPer seimplicità assumiamo inizialmente l'equiprobabilità che un'alternativa sia migliore di un'altra $$\\mathcal{P}(X \u003e Y) = \\mathcal{P}(Y \u003e X) = \\frac{1}{2}$$\n\nDopodiché ogni individuo riceve un **segnale privato indipendente**, che suggerisce quale delle due è la scelta migliore.\n\nInidichiamo con `x` il segnale che suggerisce `X`, e con `y` il segnale che suggerisce `Y`.\n\nIndichiamo con $q \u003e 1/2$ la probabilità di ricevere un segnare corretto $$\\mathcal{P}(x \\vert X \u003e Y) = \\mathcal{P}(y \\vert Y \u003e X) = q \u003e \\frac{1}{2}$$\n\nA differenza delle cascate informative, le decisioni dei singoli vengono prese **simultaneamente**, senza poter osservare le scelte degli altri.\nIn assenza di ulteriori informazioni, ogni individuo non può che scegliere un'alternativa in accordo al proprio segnale privato.\n\nMolto importante assumere che le scelte degli individui siano **sincere**, ovvero \u003cu\u003esempre\u003c/u\u003e in accordo al proprio segnale privato!\n\nSupponiamo di ricevere il segnale privato `x`.\nPer la [formula di Bayes](12%20-%20Herding.md#967e98) e per la [regola delle probabilità totali](12%20-%20Herding.md#61562b) possiamo scrivere la probabilità che `X` sia la scelta corretta avendo ricevuto il segnale `x` come\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(X \u003e Y \\vert x) \u0026= \\frac{ \\mathcal{P}(x \\vert X \u003e Y) \\cdot \\mathcal{P}(X \u003e Y) }{ \\mathcal{P}(x) }\\\\\n\u0026= \\frac{ \\mathcal{P}(x \\vert X \u003e Y) \\cdot \\mathcal{P}(X \u003e Y) }{ \\mathcal{P}(x \\vert X \u003e Y) \\cdot \\mathcal{P}(X \u003e Y) + \\mathcal{P}(x \\vert Y \u003e X) \\cdot \\mathcal{P}(Y \u003e X) }\\\\\n\u0026= \\frac{ q \\cdot \\frac{1}{2} }{ q \\cdot \\frac{1}{2} + (1-q) \\cdot \\frac{1}{2} }\\\\\n\u0026= \\frac{ q \\cdot \\frac{1}{2} }{ \\frac{1}{2} } = q \u003e \\frac{1}{2}\n\\\\end{align\\*}\n$$\nperciò è naturale concludere che a ogni individuo **conviene** votare in accordo al proprio segnale privato.\n\nA tal proposito il [Marchese di Condorcet](https://it.wikipedia.org/wiki/Nicolas_de_Condorcet) nel 1785 scrisse a riguardo ciò che oggi è noto come il **Teorema della Giuria di Condorcet**, che afferma\n\n \u003e \n \u003e **Teorema della Giuria di Condorcet**\n \u003e Senza perdita di generalità supponiamo che `X` sia l'alternativa migliore.\n \u003e Allora al crescere dei votanti, la frazione di individui che votano a favore di `X` tende *quasi sicuramente* alla probabilità $q \u003e 1/2$ di ricevere il segnale `x`.\n \u003e \n \u003e Di conseguenza, la probabilità che la maggioranza voti l'alternativa corretta `X` tende ad 1 con l'aumentare dei votanti.\n \u003e \n \u003e Più formalmente, sia $k$ il numero dei votanti e $r_i$ il voto dell'individuo $i$-esimo.\n \u003e Allora se `X \u003e Y` \n \u003e $$\\lim\\_{k \\rightarrow \\infty} \\frac{\\vert \\lbrace 1 \\leq i \\leq k : r_i = X \\rbrace \\vert}{k} = q$$\n \u003e $$\\lim\\_{k \\rightarrow \\infty} \\mathcal{P}\\left( \\frac{\\vert \\lbrace 1 \\leq i \\leq k : r_i = X \\rbrace \\vert}{k} = q \\right) = 1$$\n\nQuesto teorema mostra come il modello (semplice) di decision making appena definito manifesta la [\"saggezza della folla\"](12%20-%20Herding.md#284d1a) descritta da James Surowiecki nel libro *[The Wisdom of Crowds](https://www.amazon.it/Wisdom-Crowds-James-Surowiecki/dp/0385721706)*.\n\n## Insincere Voting\n\nIl teorema di Condorcet si basa sulla forte assunzione che i voti degli individui siano **sinceri**.\nQuesta assuzione sembra abbastanza ragionevole.\nInfatti, in assenza di informazioni condivise, un individuo non può inferire nulla che possa in qualche modo indirizzare verso un'alternativa.\nPerciò per quale motivo si dovrebbe votare in disaccordo col proprio segnale privato?\n\nIn realtà esistono molte situazioni in cui è più conveniente votare in disaccordo al proprio segnale privato, ovvero in maniera **non sincera**, anche se non è possibile osservare le scelte degli altri.\n\nCertamente la precedentemente affermazione è controintuitiva, perciò è necessario fare chiarezza con alcuni esempi.\n\n### Esempio Urne - Maggioranza\n\nSiamo in una situazione in cui abbiamo un'urna `UG` con 10 palline gialle, e un'urna `UV` con 9 palline verdi e 1 gialla.\n\nViene scelta totalmente a caso (con probabilità $1/2$) un'urna tra le due.\n\nCi sono 3 giocatori che pescano una pallina dall'urna, la reinseriscono e infine *simultanemante* devono decidere se secondo loro l'urna è `UG` o `UV`.\n\nSe la **maggioranza** ha votato l'urna esatta, allora vincono tutti, altrimenti tutti perdono.\n\nIndichiamo con `v` l'evento *\"estraggo una pallina verde\"* e con `g` *\"estraggo una pallina gialla\"*, ovvero i segnali privati che un giocatore può ricevere.\nAvremo quindi le seguenti probabilità\n$$\\begin{align\\*}\n\\\\mathcal{P}(UG \\vert g) \u0026= \\frac{ \\mathcal{P}(g \\vert UG) \\cdot \\mathcal{P}(UG) }{ \\mathcal{P}(g \\vert UG) \\cdot \\mathcal{P}(UG) + \\mathcal{P}(g \\vert UV) \\cdot \\mathcal{P}(UV) } = \\frac{10}{11}\\\\\n\\\\mathcal{P}(UV \\vert g) \u0026= \\frac{1}{11}\\\\\n\\\\\n\\\\mathcal{P}(UV \\vert v) \u0026= 1\\\\\n\\\\mathcal{P}(UG \\vert v) \u0026= 0\n\\\\end{align\\*}$$\nAi giocatori conviene rispondere in accordo a ciò che pescano.\n\nProviamo a immedesimarci nei panni di uno dei giocatori.\nSo che vinceremo se *almeno* due di noi indoviano la risposta esatta.\nPerciò quando la mia risposta è *realmente influenzate*?\n\nOvviamente la risposta è quando le risposte degli altri due sono discordi, in quanto se sono concordi avranno già raggiunto la maggioranza e la mia risposta non sarà influente nell'esito del gioco.\n\nPerò se le due risposte degli altri giocati sono discordi posso inferire (assumendo che abbiano risposto \u003cu\u003esinceramente\u003c/u\u003e) che almeno uno dei due ha estratto una pallina verde: ovvero l'urna è `UV`.\n\nPosso quindi applicare il seguente ragionamento:\n\n* se i due voti sono concordi, qualsiasi siano, il mio voto è ininfluente, perciò posso votare `UV` e l'esito non cambia.\n* se i due voti sono discordi, allora l'urna è `UV`, quindi il mio voto è essenziale per vincere. Mi conviene votare `UV` indipendentemente da ciò che pesco.\n\nA questo punto è facile convincersi, sempre sotto l'assunzione che gli altri votino in maniera sincera, che votare `UV` massimizza sempre la mia probabilità di vittoria.\n\nMi conviene votare in maniera **non sincera**.\n\n### Esempio Giuria - Unanimità\n\nConsideriamo la situazione in cui una giuria deve decidere se un imputato è innocente `I` o colpevole `C`.\nSupponiamo inoltre che la colpevolezza e l'innocenza dell'imputato siano *equiprobabili*, ovvero che \n$$\\mathcal{P}(I) = \\mathcal{P}(C) = \\frac12$$\nLa colpevolezza dell'imputato viene presa all'**unanimità**, ovvero **tutti** devono essere d'accordo per condannare l'inputato.\nNon si vuole avere nessun dubbio della sua colpevolezza, se anche solo un giudice vota `I` allora l'accusato viene dichiarato innocente, *oltre ogni ragionevole dubbio*.\n\nAncora una volta ogni giudice riceve un *segnale privato*:\n`i` suggerisce `I` e `c` suggerisce `C`, con probabilità di occorrenza\n$$\\begin{align\\*}\n\\\\mathcal{P}(i \\vert I) = q \u003e \\frac12\\\\\n\\\\mathcal{P}(c \\vert C) = q \u003e \\frac12\n\\\\end{align\\*}$$\n\nPerciò se $S$ è l'insieme dei voti dei giurati, non è sufficiente avere che $\\mathcal{P}(C \\vert S) \u003e 1/2$ per condannare l'imputato, sempre per evitare ogni dubbio.\n\nSempre immedesimandoci in un \"giocatore\" (un giurato), ci si chiede quando il mio voto è realmente influente nell'esito finale.\n\nSupponiamo di essere in una giuria di $k$ giurati, nella quale tutti (tranne me) votino in accordo al proprio segnale privato:\ntutti gli altri fanno una votazione sincera.\n\nCalcoliamo la probabilità che l'imputato sia colpevole sapendo che **solamente uno** abbia ricevuto un segnale d'innocenza `i`.\n$$\\begin{align\\*}\n\\\\mathcal{P}(C \\vert ic^{k-1}) \n\u0026= \\frac{ \\mathcal{P}(ic^{k-1} \\vert C) \\cdot \\mathcal{P}(C) }{ \\mathcal{P}(ic^{k-1} \\vert C) \\cdot \\mathcal{P}(C) + \\mathcal{P}(ic^{k-1} \\vert I) \\cdot \\mathcal{P}(I)}\\\\\n\\\\\n\u0026= \\frac{ (1-q)q^{k-1} \\cdot \\frac12 }{ (1-q)q^{k-1} \\cdot \\frac12 + q(1-q)^{k-1} \\cdot \\frac12 }\\\\\n\\\\\n\u0026= \\frac{ q^{k-2} }{ q^{k-2} + (1-q)^{k-2} } = \\frac{ 1 }{ 1 + \\left(\\frac{1-q}{q}\\right)^{k-2} }\n\\\\end{align\\*}$$\n\nAll'aumentare dei votanti avremo che\n$$\\lim\\_{k \\rightarrow \\infty} \\mathcal{P}(C \\vert ic^{k-1}) = \\lim\\_{k \\rightarrow \\infty} \\frac{ 1 }{ 1 + \\left(\\frac{1-q}{q}\\right)^{k-2} } = 1$$\nperchè dato che per ipotesi $q \u003e 1/2$ allora $\\frac{1-q}{q} \\\u003c 1$.\n\nAnche in questo caso posso dedurre una strategia che massimizza la probabilità di ottenere un risultato corretto:\n\n* Se fra gli altri giurati c'è qualcuno che è in favore dell'innocenza, che io voti per la *colpevolezza* o per l'*innocenza* non alter il verdetto.\n* Se invece gli altri giurati sono in favore della colpevolezza, allora è proprio dal mio voto che dipende il verdetto. Però abbiamo visto che anche se sono l'unico ad avere il segnale `i`, quasi sicuramente l'imputato è colpevole. Perciò conviene comunque che io voti `C` colpevole.\n\nAnche in questo esempio, assumendo che gli altri votino sinceramente, l'alternativa che massimizza la probabilità di successo è che voti `C` colpevole, a prescindere da quale sia il mio segnale privato (alla faccia di *\"oltre ogni ragionevole dubbio\"*...).\n\n---\n\n# Sistema di Voto Individuale\n\nFinora abbiamo visto sistemi di voto in cui ci sono solamente *due alternative*, nelle quali la decisione finale si prende per **maggioranza** oppure all'**unanimità** (per una delle due alternative).\nGeneralmente però è richiesto di scegliere una preferenza su *più alternative*, oppure specificare un **classifica** (o **ranking**) di preferenze.\n\nUn **sistema di voto** è un *insieme di regole utili per derivare una decisione collettiva a partire da un insieme di decisioni individuali*.\n\nIndichiamo con $A = \\lbrace a_1, a_2, ..., a_n \\rbrace$ l'insieme di\n$n$ *alternative possibili*, e con $V = \\lbrace v_1, v_2, ..., v_k \\rbrace$ l'insieme di $k$ *votanti*.\n\nPer semplicità alcune volte porremo $A \\equiv \\left\\[ n \\right\\]$ e $V \\equiv \\left\\[ k \\right\\]$.\n\nPer prima cosa definiamo il concetto di **voto** dei singoli votanti.\nCiascun votante $v_h \\in V$ può esprimere il suo voto in due modalità \u003cu\u003eequivalenti\u003c/u\u003e:\n\n* **Ranking (Graduatoria)** un **ranking** $r_h$ per un votante $v_h$ è una **sequenza ordinata** $\\langle a\\_{h1}, a\\_{h2}, ..., a\\_{hn} \\rangle \\in \\Pi(A)$ dove $\\Pi(A)$ è l'insieme di tutte le **permutazioni** delle alternative in $A$. Più precisamente gli elementi in $r_h$ sono ordinati in ordine decrescente di preferenza, ovvero $a\\_{h1}$ è il preferito di $v_h$, $a\\_{h2}$ è il secondo preferito, e così via...\n\n* **Relazione Binaria e Completa** una relazione $\u003e\\_h$ che deve essere\n  \n  * **Binaria:** di *arietà* 2, ovvero con soli due argomenti.\n  * **Completa:** definita per ogni coppia di elementi $a, a' \\in A$, $a \u003e\\_h a'$ oppure $a' \u003e\\_h a$.\n  * **Transitiva:** se $a \u003e\\_h a'$ ed $a' \u003e\\_h a''$ allora\n    $a \u003e\\_h a''$.\n    **Antisimmetrica:** $a \\not\u003e\\_h a$.\n\nCome già accennato le due forme possibili di espressione di un voto sono fra loro \u003cu\u003eequivalenti\u003c/u\u003e, ovvero è sempre possibile ricavare un'espressione di voto da un'altra.\n\nDerivare una relazione $\u003e*h$ da un ranking $r_h = \\langle a*{h1}, a\\_{h2}, ... , a\\_{hn} \\rangle$ è immediato: per ogni $i, j \\in \\left\\[ n \\right\\]$ tali che $j \u003e i$ rispetto a $r_h$, poniamo $a\\_{hi} \u003e*h a*{hj}$.\n\nIl viceversa è un po' più articolato.\nDato che $\u003e*h$ è completa e transitiva, certamente esiste un'alternativa $\\ell \\in \\left\\[ n \\right\\]$ tale \u003cu\u003eper ogni\u003c/u\u003e altra alternativa $j \\in \\left\\[ n \\right\\] \\setminus \\lbrace \\ell \\rbrace$, $a*{\\ell}$ è preferita più volte rispetto ad $a_j$, ovvero formalmente\n$$\\vert \\lbrace i \\in \\left\\[ n \\right\\] : a\\_{\\ell} \u003e\\_h a_i \\rbrace \\vert \u003e \\vert \\lbrace j \\in \\left\\[ n \\right\\] : a_j \u003e\\_h a_i \\rbrace \\vert$$\nA breve verrà dimostrata questa proprietà nel **[Lemma 1](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md#efe0e4)**.\n\nUna diretta e naturale conseguenza del **[Lemma 1](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md#efe0e4)** è ciò che verrà mostrato nel **[Lemma 2](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md#db164b)**, ovvero che certamente $j \\in \\left\\[ n \\right\\] \\setminus \\lbrace \\ell \\rbrace$, $a\\_{\\ell} \u003e\\_h a_j$ (dovrebbe essere immediato visualizzarlo).\n\nA questo punto individuato tale $\\ell$, poniamo $a\\_{h1} = a\\_{\\ell}$, ed iteriamo con lo stesso procedimento sul sottoinsieme $A \\setminus \\lbrace a\\_{\\ell} \\rbrace$ per individuare $a\\_{h2}$, e così via...\n\nDimostriamo ora le proprietà appena utilizzate.\n\n \u003e \n \u003e **Lemma 1:** se $\u003e*h$ è una relazione binaria completa e transitiva sull'inseme $A = \\lbrace a_1, a_2, ..., a_n \\rbrace$, allora esiste un $\\ell \\in \\left\\[ n \\right\\]$ tale che per ogni altro $j \\in \\left\\[ n \\right\\] \\setminus \\lbrace \\ell \\rbrace$ \n \u003e $$\\vert \\lbrace i \\in \\left\\[ n \\right\\] : a*{\\ell} \u003e\\_h a_i \\rbrace \\vert \u003e \\vert \\lbrace j \\in \\left\\[ n \\right\\] : a_j \u003e\\_h a_i \\rbrace \\vert$$\n\n^efe0e4\n\n \u003e \n \u003e **Proof:** per ogni $j \\in \\left\\[ n \\right\\]$ indichiamo con $p_j = \\vert \\lbrace j \\in \\left\\[ n \\right\\] : a_j \u003e\\_h a_i \\rbrace \\vert$ il numero di alternative che $a_j$ *\"batte\"* secondo il voto di $v_h$.\n \u003e \n \u003e Certamente esisterà un esiste un $\\ell \\in \\left\\[ n \\right\\]$ tale per ogni altro $j \\in \\left\\[ n \\right\\] \\setminus \\lbrace \\ell \\rbrace$\n \u003e $$p\\_{\\ell} = \\vert \\lbrace i \\in \\left\\[ n \\right\\] : a\\_{\\ell} \u003e\\_h a_i \\rbrace \\vert \\geq \\vert \\lbrace j \\in \\left\\[ n \\right\\] : a_j \u003e\\_h a_i \\rbrace \\vert = p_j$$\n \u003e in quanto $p_1, p_2, ..., p_n$ sono numeri, e quindi esiste un massimo.\n \u003e \n \u003e Supponiamo per assurdo che esiste un $m \\neq \\ell$ tale che $p\\_{\\ell} = p_m$.\n \u003e Poiché $\u003e*h$ è **completa** deve essere vero che o $a*{\\ell} \u003e\\_h a_m$ oppure $a_m \u003e*h a*{\\ell}$ (\u003cu\u003ema non entrambe\u003c/u\u003e).\n \u003e \n \u003e Se $a_m \u003e*h a*{\\ell}$ allora per **transitività** certamente è vero che $a_m$ \"batte\" sia $a\\_{\\ell}$ sia tutte le altre alternative battute da $a\\_{\\ell}$, ovvero che\n \u003e $$\\lbrace i \\in \\left\\[ n \\right\\] : a\\_{\\ell} \u003e*h a_i \\rbrace \\cup \\lbrace a*{\\ell} \\rbrace \\subseteq \\lbrace i \\in \\left\\[ n \\right\\] : a_m \u003e*h a_i \\rbrace$$\n \u003e Inoltre poiché $\u003e*h$ è **antisimmetrica**, avremo che $a*{\\ell} \\notin \\lbrace i \\in \\left\\[ n \\right\\] : a*{\\ell} \u003e*h a_i \\rbrace$.\n \u003e Perciò\n \u003e $$p_m \\geq p*{\\ell} + 1 \u003e p\\_{\\ell} = p_m$$\n \u003e Assurdo $p_m \u003e p_m$!\n \u003e \n \u003e Viceversa, se $a\\_{\\ell} \u003e a_m$ riapplicando lo stesso ragionamento otterremo che $p\\_{\\ell} \u003e*h p*{\\ell}$, assurdo!\n \u003e \n \u003e In conclusione il valore $\\ell$ con tali proprietà è unica $\\square$.\n\n \u003e \n \u003e **Lemma 2:** se $\u003e*h$ è una relazione binaria completa e transitiva sull'inseme $A = \\lbrace a_1, a_2, ..., a_n \\rbrace$, e sia $\\ell \\in \\left\\[ n \\right\\]$ tale che per ogni altro $j \\in \\left\\[ n \\right\\] \\setminus \\lbrace \\ell \\rbrace$\n \u003e $$\\vert \\lbrace i \\in \\left\\[ n \\right\\] : a*{\\ell} \u003e\\_h a_i \\rbrace \\vert \u003e \\vert \\lbrace j \\in \\left\\[ n \\right\\] : a_j \u003e*h a_i \\rbrace \\vert$$ allora $a*{\\ell} \u003e\\_h a_j$.\n\n^db164b\n\n \u003e \n \u003e **Proof:** diretta conesguenza della dimostrazione del [Lemma 1](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md#efe0e4) $\\square$.\n\nSiamo ora in grado di definire formalmente un **sistema di voto**.\n\nCome già accennato un sistema di voto è un *insieme di regole utili per derivare una decisione collettiva a partire da un insieme di decisioni individuali*.\n\nData l'equivalenza delle due modalità di voto per il momento assumiamo che i $k$ votanti esprimano il loro voto tramite **ranking**.\n\nUn **voto aggregato** per $n$ alternative e $k$ votanti è una *funzione*\n$$\\begin{align\\*}\nf\\_{n,k} : \\Pi(\\left\\[ n \\right\\])^k \u0026\\rightarrow \\Pi(\\left\\[ n \\right\\])\\\\\n\\\\\n\\\\begin{bmatrix}\nr_1\\\\\nr_2\\\\\n\\\\vdots \\\\\nr_k\n\\\\end{bmatrix}\u0026 \\mapsto r\n\\\\end{align\\*}$$\nche associa a $k$ ranking un nuovo ranking $r$\n$$f\\_{n,k}(r_1, r_2, ..., r_k) = r$$\n\nUn **sistema di voto** è un predicato $\\sigma$ che specifica, per ogni $k$-upla di ranking $(r_1, r_2, ..., r_k) \\in \\Pi(\\left\\[ n \\right\\])^k$ le regole che devono essere rispettate dal voto aggregato $f\\_{n,k}(r_1, r_2, ..., r_k)$.\n\nPerciò un ranking $r$ è un voto aggregato per i ranking $r_1, r_2, ..., r_k$ se e solo se $\\sigma(r_1, r_2, ..., r_k,r)$ è vero.\n\nCon un piccolo abuso di notazione, possiamo definire il voto aggregato sottoforma di relazioni binarie come $f\\_{n,k}(\u003e\\_1, \u003e\\_2, ..., \u003e\\_k) = \\succ$.\n\nAnalogamente la relazione bianria $\\succ$ è un voto aggregato per le relazioni $\u003e\\_1, \u003e\\_2, ..., \u003e\\_k$ se e solo se $\\sigma(\u003e\\_1, \u003e\\_2, ..., \u003e\\_k, \\succ)$ è vero.\n\n## Sistema di Voto a Maggioranza\n\nConsideriamo un insieme di voti $\u003e\\_1, \u003e\\_2, ..., \u003e\\_k$ espressi come relazioni binarie.\n\nIl **sistema di voto a maggioranza** è intuitivamente espresso dal seguente predicato $\\sigma_M$ \n$$\\begin{align\\*}\n\\\\sigma_M(\u003e\\_1, \u003e\\_2, ..., \u003e\\_k, \\succ) = \\forall i,j \\in \\left\\[ n \\right\\]\\\\\n\\\\\ni \\succ j \\iff \\vert \\lbrace h \\in \\left\\[ k \\right\\] : i \u003e\\_h j \\rbrace \\vert \u003e \\vert \\lbrace h \\in \\left\\[ k \\right\\] : j \u003e\\_h i \\rbrace \\vert\n\\\\end{align\\*}$$\nOvvero se il numero di votanti che preferiscono $i$ a $j$ è maggiore di quelli che preferiscono $j$ ad $i$: $i$ è preferito a $j$ dalla **maggioranza** dei votanti.\n\nQuesto sistema di voto è molto semplice e intuitivo, e funziona bene finché ci sono due sole alternative.\nQuando sono più di due però possono occorrere **incoerenze**.\n\nConsideriamo come esempio quello in cui tre amici `A`, `B` e `C` vanno in campeggio, e dato che hanno un budget limitato devono scegliere se comprare cioccolata 🍫, miele 🍯 o marmellata 🍒.\n\nLe rispettive graduatorie sono:\n\n* `A`: 🍫 $\u003e\\_A$ 🍒 $\u003e\\_A$ 🍯.\n* `B`: 🍒 $\u003e\\_B$ 🍯 $\u003e\\_B$ 🍫.\n* `C`: 🍯 $\u003e\\_C$ 🍫 $\u003e\\_C$ 🍒.\n\nTuttavia se proviamo a ricavare un voto aggregato $\\succ$ secondo il predicato $\\sigma_M$ otteremo una **contraddizione**.\n\nInffati\n\n* 🍫 è preferita a 🍒 due volte su tre $\\implies$ 🍫 $\\succ$ 🍒\n* 🍒 è preferita a 🍯 due volte su tre $\\implies$ 🍒 $\\succ$ 🍯\n* 🍯 è preferito a 🍫 due volte su tre $\\implies$ 🍯 $\\succ$ 🍫\n\nOvvero si ottiene che\n🍫 $\\succ$ 🍒 $\\succ$ 🍯 $\\succ$ 🍫\n\nAssurdo!\n\nTale relazione non è nemmeno transitiva, infatti anche se è vero che 🍫 $\\succ$ 🍒 e 🍒 $\\succ$ 🍯, non è vero che 🍫 $\\succ$ 🍯.\n\nTale contraddizione descrive il cosiddetto **Paradosso di Condorcet** che afferma\n\n \u003e \n \u003e *anche se le relazioni binarie individuali sono transitive, la relazione binaria collettiva ottenuta dalla loro aggregazione può non essere transitiva.*\n\n^d7f399\n\n## Sistema di Voto a Torneo\n\nAbbiamo visto che il voto a maggioranza soffre di problemi di coerenza quando ci sono più di due alternative da votare.\nPerò è molto stabile nel caso di sole due scelte, perciò può essere usato come punto di partenza per costruire un nuovo sistema di voto che non soffre del [paradosso di Condorcet](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md#d7f399).\n\nTale sistema è il cosiddetto sistema a **Torneo**.\nIn tale sistema si effettuano degli *\"scontri\"* tra coppie di alternaitve, e chi vince procede avanti nel torneo, iterando gli scontri finché non si sarà generata una classifica finale.\n\n![Esempio torneo.](ar-lesson13-img1.png)\nSe le $n$ alternative sono dispari, una di esse passerà direttamente ad una fase del torneo più avanzata, in modo da ottenere sempre scontri tra due sole alternative.\n\n![Torneo con 7 alternative. Quella viola passa direttamente al secondo scontro.](ar-lesson13-img2.png)\n\nSe i $k$ votanti sono dispari ci sarà sempre un vincitore.\nNel caso di $k$ pari possono accadere pareggi, in quel caso supponiamo di avere un metodo imparziale per rompere la simmetria e proclamare un vincitore, per esempio lanciando una moneta.\n\nImportante osservare che in un torneo non avvengono tutti gli scontri possibili, bensì \u003cu\u003esolamente quelli programmati\u003c/u\u003e da un'**agenda**.\nOvvero prima del torneo si pianificano i vari scontri che verranno fatti.\n\nÈ facile convincersi che **l'agenda può avere un ruolo determinante nel decretare il vincitore**.\n\nPer esempio consideriamo ancora l'esempio della cioccolata 🍫, miele 🍯 e marmellata 🍒.\nOgnuo propone una diversa sequenza di scontri:\n\n* `A` propone l'agenda secondo la quale il primo scontro è 🍒-🍯, e il vincitore si scontrerà con 🍫.\n* `B` propone l'agenda secondo la quale il primo scontro è 🍯-🍫, e il vincitore si scontrerà con 🍒.\n* `C` propone l'agenda secondo la quale il primo scontro è 🍫-🍒, e il vincitore si scontrerà con 🍯.\n\n![Gli esiti dei tornei secondo le tre diverse agende.](ar-lesson13-img3.png)\n\nCiascun amico ha proposto un'agenda che porta alla vittoria il proprio prodotto preferito!\n\nPurtroppo il sistema di voto a torneo è sensibile al cosiddetto **Strategic Agenda Setting**.\n\n[Part 2 →](14%20-%20Sistemi%20di%20voto%20-%20Part%202.md) \n","lastmodified":"2022-08-29T13:39:17.117868843+02:00","tags":null},"/AR/14-Sistemi-di-voto-Part-2":{"title":"","content":"\n# Sistemi di Voto Posizionali\n\nSupponiamo che i voti individuali siano espressi sotto forma di \u003cu\u003eranking\u003c/u\u003e $(r_1, ..., r_k) \\in \\Pi(\\left\\[ n \\right\\])^k$.\n\nUna classe diversa di sistemi di voto cerca di produrre un ranking di gruppo $r$ **direttamente** dalle classifiche individuali $r_1, ..., r_k$, piuttosto che costruire $r$ da confronti tra coppie di alternative.\n\nIn un sistema di voto **posizionale** a ciascun ranking $r_h$ viene assegnata una **funzione peso** $w_h$ la quale associa un valore numerico a ciascuna alternativa **dipendentemente** dalla sua posizione nel ranking $r_h$.\n\nTale funzione $w_h$ per essere sensata è tipicamente decrescente, ovvero se un'alternativa $a$ sta in una posizione bassa (tra i primi posti) rispetto a $r_h$ avrà un peso $w_h(a)$ alto, viceversa se $a$ sta verso gli ultimi posti allora $w_h(a)$ assumerà un valore più basso.\n\nUn esempio di funzione peso $w_h$ per il ranking $r_h = \\langle a\\_{h1}, ..., a\\_{hn} \\rangle$ è la seguente\n$$w_h(a\\_{hi}) = \\frac{1}{i} ;; \\forall i \\in \\left\\[ n \\right\\]$$\n\nUna volta associata una funzione peso ad ogni ranking si calcola il **peso collettivo** di un'alternativa $a$ semplicemente sommando i pesi dei singoli ranking, ovvero\n$$w(a) = \\sum\\_{h = 1}^{k} w_h(a)$$\nInfine le alternative vengono quindi ordinate in base al loro peso totale, e in base ad esse definito un ranking collettibo $r$.\n\nIl **Borda Count** è un particolare sistema di *voto posizionale* nel quale per ogni votante $h \\in \\left\\[ k \\right\\]$ la funzione di peso associata al ranking $r_h$ è definita come segue\n$$\\rho_h(a\\_{hi}) = n - i ;;; \\forall i \\in \\left\\[ n \\right\\]$$ ^b1a4d1\n\n## Problema dell ex aequo\n\nAnche nei sistemi posizionali si manigesta il *paradosso di Condorcet* sotto forma di **ex aequo** (pareggio).\n\nConsideriamo ancora una volta l'[esempio dei tre amici](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md#sistema-di-voto-a-maggioranza) che devono andare in campeggio.\nLe tre classifiche erano\n\n* `A`: $\\langle$🍫, 🍒, 🍯$\\rangle$.\n* `B`: $\\langle$🍒, 🍯, 🍫$\\rangle$.\n* `C`: $\\langle$🍯, 🍫, 🍒$\\rangle$.\n\nApplichiamo ora il Borda Count, ottendo le seguenti funzioni peso\n\n* $\\rho_A$(🍫) = 2; $\\rho_A$(🍒) = 1; $\\rho_A$(🍯) = 0\n* $\\rho_B$(🍒) = 2; $\\rho_B$(🍯) = 1; $\\rho_B$(🍫) = 0\n* $\\rho_C$(🍯) = 2; $\\rho_C$(🍫) = 1; $\\rho_C$(🍒) = 0\n\nAlla fine otteremo un pareggio tra i pesi finali\n$$\\rho(🍫) = \\rho(🍒) = \\rho(🍯) = 3$$\nPerciò è necessario supporre che se due alternative ricevono lo stesso peso totale, allora viene utilizzato un sistema di **spareggio** organizzato in anticipo per decidere quale di queste due alternative posizionare di fronte all'altra.\n\n## Rilevanza delle Alternative Irrilevanti\n\nConsideriamo una rassegna cinematografica, in cui una giuria composta da cinque critici `A`, `B`, `C`, `D`, `E` deve eleggere un vincitore tra i film *\"Via col Vento\"* (alternativa `VV`) e *\"Il Padrino\"* (alternativa `IP`).\n\nTre guidici su cinque ritengono che `VV` sia il film che debba vincere.\nLe classifiche riultano quindi essere\n\nGiudici   1° posto          2° posto\n\n---\n\n`A`       *Via col Vento*   *Il Padrino*\n`B`       *Il Padrino*      *Via col Vento*\n`C`       *Via col Vento*   *Il Padrino*\n`D`       *Il Padrino*      *Via col Vento*\n`E`       *Via col Vento*   *Il Padrino*\n\n: Classifiche dei 5 giudici.\n\nA questo punto gli organizzatori nella rassegna decidono di introdurre un novo film nella gara, *\"Pulp Fiction\"* (alternativa `PF`).\n\nTutta la giuria è d'accordo che `PF` non è all'altezza della competizione e che quindi non può vincere.ù\nTuttavia i player `B` e `D` (i due che preferiscono `IP` a `VV`) possono creare un ranking in modo tale da far vincere il loro preferito.\n\nInfatti ponendo `PF` al secondo posto nella loro classifica, e `VV` all'utlimo, possono compromettere il risultato finale.\n\nGiudici   1° posto          2° posto         3° posto\n\n---\n\n`A`       *Via col Vento*   *Il Padrino*     *Pulp Fiction*\n`B`       *Il Padrino*      *Pulp Fiction*   *Via col Vento*\n`C`       *Via col Vento*   *Il Padrino*     *Pulp Fiction*\n`D`       *Il Padrino*      *Pulp Fiction*   *Via col Vento*\n`E`       *Via col Vento*   *Il Padrino*     *Pulp Fiction*\n\n: Nuove classifiche.\n\nCon questa nuova graduatoria avremo i seguenti pesi collettivi\n$$\\begin{align\\*}\n\\\\rho(\\texttt{`Via col Vento''}) \u0026= 6\\\\ \\rho(\\texttt{`Il Padrino''}) \u0026= 7\\\\\n\\\\rho(\\texttt{\\``Pulp Fiction''}) \u0026= 2\n\\\\end{align\\*}$$\n\nIn pratica, classificando in maniera opportuna l'**alternativa irrilevante** (ovvero `PF`) si riesce a compromettere la graduatoria finale della competizione.\n\nQuesto è uno dei problemi principali di cui soffrono i sistemi di voto posizionali.\n\n---\n\n# Sistemi di Voto Affidabili\n\nFin ora abbiamo incontrato alcune tipologie di sistemi di voto, ognuna affetta da *\"patologie\"* (problematiche che lo rendono non del tutto affidabile).\nAlcune problematiche incontrate sono state\n\n* **Paradosso di Condorcet**: col sistema a maggioranza non risco sempre ad individuare una classifica finale coerente.\n* **Strategic Agenda Setting**: col sistema a torneo la graduatoria finale dipende dall'ordinamento iniziale delle alterantive.\n* **Alternative Irrilevanti**: nel sistema posizionale si possono classificare le alternative irrilevanti per condizionare la graduatoria finale.\n\nAd questo punto ha senso fare un passo indietro dai sistemi di voto specifici e porsi una domanda più generale:\n\n \u003e \n \u003e *esiste un sistema di voto che produca una classifica collettiva (per tre o più alternative) evitando tutte le \"patologie\" precedentemente descritte?*\n\no meglio ancora\n\n \u003e \n \u003e *riusciamo a definire un sistema di voto sempre **affidabile**?*\n\nPer quanto visto in precedenza, un paio di condizioni **minime** per avere l'affidabilità di un sistema di voto sono:\n\n* il voto finale deve rappresentare le scelte di tutti i votanti qualora tutti siano d'accordo su qualcosa.\n* non deve essere possibile sfruttare le alternative irrilevanti per modificare la graduatoria finale.\n\nPer quanto riguarda il paradosso di Condorcet, se esprimiamo la graduatoria finale in termini di ranking $r$ avremo sempre una classifica non ambigua (basta introdurre un metodo imparziale per lo spareggio).\n\nAnaliziamo ora in maniera più formale le due condizioni minime per ottenere un sistema di voto affidamile.\n\n## Principio di Paretro - Unanimità\n\nSia $\\sigma$ un *sistema di voto* con $n$ alternative e $k$ votanti.\nSiano i ranking $(r_1, ..., r_k) \\in \\Pi(\\left\\[ n \\right\\])^k$ dei $k$ partecipanti.\nIndichiamo con $r$ il **voto collettivo** ruspetto ai ranking $r_1, ..., r_k$, tali che $$\\sigma(r_1, ..., r_k, r) = \\texttt{True}$$\nIn fine, per ogni votante $h \\in \\left\\[ k \\right\\]$ indichiamo la funzione di peso [Borda count](14%20-%20Sistemi%20di%20voto%20-%20Part%202.md#b1a4d1) $\\rho_h$ rispetto a $r_h$, e la funzione\n$\\rho$ rispetto al voto collettivo $r$.\n\nIl principio dell'**Unanimità** (o **Principio di Paretro**) vuole che nel caso in cui un'alternativa `X` è preferita ad un'alternativa `Y`\nper **tutti** i votanti $h \\in \\left\\[ k \\right\\]$, allora anche nella graduatoria finale `X` deve essere preferito a `Y`.\n\nPiù formalmente\n$$\n\\\\forall i,j \\in \\left\\[ n \\right\\]\\\\\n\\\\left\\[\n\\\\forall h \\in \\left\\[ k \\right\\] \\rho_h(i) \u003e \\rho_h(j)\n\\\\implies \\rho(i) \u003e \\rho(j)\n\\\\right\\]$$\n\nD'ora in poi ci riferiremo al principio dell'unanimità con `U`.\n\n## Principio d'Indipendenza dalle Alternative Irrilevanti\n\nSia $\\sigma$ un *sistema di voto* con $n$ alternative e $k$ votanti.\n\nIl principio dell'**Indipendenza dalle Alternative Irrilevanti** si richiede che per ogni coppia di alternative `X`, `Y` il loro ordinamento\nnella graduatoria finale $r$ dipende **unicamente** dalle posizioni relative rispetto alle graduatorie individuali.\n\nIn poche parole, se in una graduatoria finale `X` è preferita ad `Y`, anche se introduciamo una nuova alternativa `Z`, il sistema deve produrre un nuovo ranking in cui `X` rimane ancora il preferito rispetto a `Y`.\n\nPiù formalmente\n$$\\forall i,j \\in \\left\\[ n \\right\\]\n\\\\forall (r_1, ..., r_k), (r'\\_1, ..., r'\\_k) \\in \\Pi(\\left\\[ n \\right\\])^k\\\\\n\\\\left\\[\n\\\\left( \\forall h \\in \\left\\[ k \\right\\] \\rho_h(i) \u003e \\rho_h(j) \\iff \\rho'\\_h(i) \u003e \\rho'\\_h(j) \\right)\\\\\n\\\\implies \\left( \\rho(i) \u003e \\rho(j) \\iff \\rho'(i) \u003e \\rho'(j) \\right)\n\\\\right\\]$$\ndove $\\rho'$ è il Borda count collettivo rispetto al ranking $(r'\\_1, ..., r'\\_k)$, in accordo col sistema di voto $\\sigma$.\n\nD'ora in poi ci riferiremo al principio dell'indipendenza dalle alternative irrilevanti con `IIA`.\n\n---\n\n# Il Teorema (di Impossibilità) di Arrow\n\nNel 1950, Kenneth Arrow mostrò dei risultati sul perché è così complicato trovare un sistema di voto affidabile che non fosse affetto dalle \"patologie\" descritte in precedenza.\nPiù precisamente nel suo **Teorema di Impossibilità** individua l'**unico** sistema di voto che riesce a soddisfare entrambi i principi `U` e `IIA`.\n\n \u003e \n \u003e **Teorema di Arrow**\n \u003e *If there are at least three alternatives, then any voting system that satisfies both `U` and `IIA` must correspond to dictatorship by one individual.*\n \u003e \n \u003e Più formalmente, se il sistema di voto $\\sigma$ soddisfa entrambe le caratteristiche `U` e `IIA`, allora per ogni insieme $\\left\\[ k \\right\\]$ di votanti esiste un votante $j \\in \\left\\[ k \\right\\]$ tale che, per ogni insieme $\\left\\[ n \\right\\]$ di $n \u003e 2$ alternative e per ogni $k$-upla di ranking $(r_1, ..., r_k) \\in \\Pi(\\left\\[ n \\right\\])^k$ su di esse, il \u003cu\u003evoto collettivo\u003c/u\u003e $r$ rispettivo ai singoli ranking $r_1, ..., r_k$ e derivato in accordo a $\\sigma$, corrisponde esattamente a $r = r_j$.\n \u003e \n \u003e In termini rigorosi\n \u003e $$\\forall \\left\\[ k \\right\\] \\subset \\mathbb{N} ;; \\exists j \\in \\left\\[ k \\right\\]\\\\\n \u003e \\\\left\\[\n \u003e \\\\forall \\left\\[ n \\right\\] \\subset \\mathbb{N} : n \u003e 2 ;; \\forall (r_1, ..., r_k) \\in \\Pi(\\left\\[ n \\right\\])^k ;\n \u003e \\\\sigma(r_1, ..., r_j, ..., r_k, r_j)\n \u003e \\\\right\\]$$\n\nIn sintesi ciò che vuole dire il teorema è che tale sistema di voto privo di \"patologie\" individua un singolo votante $j$ per il quale il voto finale collettivo $r$ corrisponde al voto $r_j$, **indipendentemente** da quali siano le $n$ alternative.\nIn altri termini ciò equivale a dire che $j$ decide per tutti quanti i votanti, perciò in sintesi l'unico sistema di voto che garantische `U` e `IIA` è la *\"dittatura\"*.\n\n## Dimostrazione de Teorema di Arrow\n\nPrima di procedere con la dimostrazione del teorema di Arrow è necessario introdurre alcuni concetti.\n\n* **Profilo** dati un insieme $\\left\\[ n \\right\\]$ di alternative e un insieme $\\left\\[ k \\right\\]$ di votanti, un **profilo** è una $k$-upla di ranking $P = \\langle r_1, ..., r_k \\rangle \\in \\Pi(\\left\\[ n \\right\\])^k$, ciascuno esprimente il voto dei singoli individui rispetto alle $n$ alternative.\n\n|\\\\|$a\\_{i1}$|$a\\_{i2}$|$a\\_{i3}$|$a\\_{i4}$|\n|-|--------|--------|--------|--------|\n|$r_1$|A|B|C|D|\n|$r_2$|B|A|C|D|\n|$r_3$|A|C|B|D|\n|$r_4$|D|C|B|A|\n|$r_5$|B|C|A|D|\n|$r_6$|A|D|C|B|\n\n````\n  : Esempio con 6 votanti e alternative `A`, `B`, `C` e `D`.\n````\n\n* **Alternativa Polarizzante** dati un insieme $\\left\\[ n \\right\\]$ di alternative e un insieme $\\left\\[ k \\right\\]$ di votanti e un profilo $P = \\langle r_1, ..., r_k \\rangle$, una **alternativa polarizzante** per $P$ è un'alternativa $x \\in \\left\\[ n \\right\\]$ tale che **per ogni** votante $h \\left\\[ k \\right\\]$ $$\\rho_h(x) = 0  ; \\lor ; \\rho_h(x) = n-1$$ovvero $x$ sta o al primo posto o all'ultimo nei diversi voti di $P$. ^f53418\n\n|\\\\|$a\\_{i1}$|$a\\_{i2}$|$a\\_{i3}$|$a\\_{i4}$|\n|-|--------|--------|--------|--------|\n|$r_1$|**A**|B|C|D|\n|$r_2$|B|D|C|**A**|\n|$r_3$|**A**|C|B|D|\n|$r_4$|**A**|C|D|B|\n|$r_5$|B|C|D|**A**|\n|$r_6$|**A**|D|C|B|\n\n````\n  : Profilo $P$ per il quale `A` è un\\'alternativa polarizzante.\n````\n\n### Schema della dimostrazione\n\nLa dimostrazione del teorema di Arrow è una dimostrazione costruttiva divisa di tre parti:\n\n* **Parte 1** Verrà dimostrato che se $x$ è un'alternativa polarizzante per un profilo $P$, allora avremo che o $\\rho(x) = 0$ oppure $\\rho(x) = n-1$, ovvero o $x$ è all'ultimo posto nel voto finale $r$ oppure è al primo.\n\n* **Parte 2** Definiamo una successione $P_1, P_2, ..., P_k$ di $k$ profili, dove in ciascuno dei quali una **stessa** alternativa $x$ è polarizzante. Tramite questi profili individuiamo un potenziale ditattore $j$.\n\n* **Parte 3** Dimostriamo che il dittatore potenziale $j$ è effettivamente il dittatore che cerchiamo per dimostrare il teorema.\n\n---\n\n### Parte 1\n\nSi vuole dimostrare che se $x$ è un'alternativa polarizzante per un profilo $P$, allora avremo che o $\\rho(x) = 0$ oppure $\\rho(x) = n-1$.\n\nSia $x$ un'alternativa polarizzante per $P$, e supponiamo per assurdo che nella funzione peso collettiva $0 \\\u003c \\rho(x) \\\u003c n-1$.\nSe questo è vero allora esisteranno altre due alternative $a,b \\in \\left\\[ n \\right\\]$ tali che $$\\rho(a) \\\u003c \\rho(x) \\\u003c \\rho(b)$$\n\n![](ar-lesson14-img1.png)\n\nA questo punto creaimo un nuovo profilo $P' = \\langle r'\\_1, ..., r'\\_k \\rangle$ nel senguente modo:\n\n* per ogni votante $i \\in \\left\\[ k \\right\\]$ tale che $\\rho_i(b) \\\u003c \\rho_i(a)$ poniamo il ranking $r'\\_i = r_i$.\n\n* per ogni votante $i \\in \\left\\[ k \\right\\]$ tale che $\\rho_i(b) \u003e \\rho_i(a)$, il ranking $r'\\_i$ è ottenuto da $r_i$ spostando $a$ direttamente accanto a $b$, in modo tale da ottenere $\\rho'\\_i(a) = \\rho'\\_i(b) + 1$.\n\n![](ar-lesson14-img2.png)\n\nPoiché $x$ non è stato coinvolto in nessuno spostamento, allora $x$ continua a rimanere un'alternativa polarizzante anche per $P'$.\nInfatti, per ogni $i \\in \\left\\[ k \\right\\]$ in $r'\\_i$ non sono cambiati gli ordini tra $x,a$ e $x,b$ rispetto a $r_i$. Infatti se in $r_i$ $x$ era al primo posto (o ultimo) in $r'\\_i$ continua a rimanere in tale posizione.\n\nInfine per come abbiamo costruito $P'$ avremo che $b$ sta **sempre** in una posizione inferiore rispetto ad $a$, ovvero $i \\in \\left\\[ k \\right\\]$ $\\rho'\\_i(b) \\\u003c \\rho'\\_i(a)$.\n\nPoiché in $P$ e $P'$ le posizioni di $a$ rispetto a $x$ non sono cambiate, per il principio `IIA` avremo che $$\\rho(a) \\\u003c \\rho(x) \\iff \\rho'(a) \\\u003c \\rho'(x)$$\nPer lo stesso motivo avremo che $$\\rho(x) \\\u003c \\rho(b) \\iff \\rho'(x) \\\u003c \\rho'(b)$$\n\nInfine, per come abbiamo costruito $P'$, sappiamo che per ogni votante $i$ avremo che $\\rho'\\_i(b) \\\u003c \\rho'\\_i(a)$.\nPerciò per principio di unanimità `U` deve essere necessariamente vero che $\\rho'(b) \\\u003c \\rho'(a)$.\n\nUnendo queste disuguaglianze otterremo un assurdo $$\\rho'(a) \\\u003c \\rho'(x) \\\u003c \\rho'(b) \\\u003c \\rho'(a) ;;;\\square$$\n\n---\n","lastmodified":"2022-08-29T13:39:16.973187651+02:00","tags":null},"/AR/15-Sistemi-di-voto-Part-3":{"title":"","content":"\n# Dimostrazione Teorema di Arrow\n\nRiassumendo, il teorema di Arrow ci diceva che **per ogni** insieme $\\left\\[ k \\right\\]$ di votanti esiste un $j \\in \\left\\[ k \\right\\]$ tale che **indipendentemente** dalle $n \u003e 2$ alternative avremo che l'unico sistema di voto che rispetta `U` e `IIA` condurrà ad un voto collettivo $r$ esattamente uguale al voto individuale $r_j$.\nIn altri termini, l'unico sistema di voto che rispetta sia `U` che `IIA` è la \"dittatura\".\n\nNella [lezione precedente](14%20-%20Sistemi%20di%20voto%20-%20Part%202.md) è stata dimostrata la prima delle tre parti della dimostrazione del teorema.\nIn questa prima fase è stato dimostrato che se un'alternatica $x$ è **polarizzante** per un profilo $P = \\langle r_1, ..., r_k \\rangle$ allora o $\\rho(x) = 0$ oppure\n$\\rho(x) = n-1$ (ovvero o $x$ si trova all'ultimo posto nel voto collettivo $r$, oppure all'utlimo).\n\n## Parte 2 dimostrazione\n\nDefiniamo una successione di $k+1$ profili $P^{(0)}, P^{(1)}, P^{(k)} \\in \\Pi(\\left\\[ n \\right\\])^k$, dove in ciascuno dei quali una stessa alternativa $x \\in \\left\\[ n \\right\\]$ è [polarizzante](14%20-%20Sistemi%20di%20voto%20-%20Part%202.md#f53418).\nTramite essi individueremo un *dittatore potenziale*.\n\n![](ar-lesson15-img1.png) ^49e899\n\nConsideriamo tali profili ordinati in modo tale che nel profilo $P^{(h)} = \\langle r^h_1, ..., r^h_k \\rangle$ l'alternativa $x$ è al primo posto nei primi $h$ ranking, ed ultima nei restainti (come in [figura](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#49e899)).\n\nPiù precisamente\n$$\\rho^{(h)}\\_i(x) = \\begin{cases}\nn-1 \u0026\\forall i \\leq h\\\\\n0   \u0026\\forall i \u003e h\n\\\\end{cases}$$\n\nÈ facile osservare che i due profili $P^{(h-1)}$ e $P^{(h)}$ differiscono l'uno dall'altro solo per il modo in cui l'$h$-esimo votante giudica l'alternativa $x$:\n\n* nel profilo $P^{(h-1)}$ il votante $h$ giudica $x$ **ultimo**, ovvero $\\rho^{(h-1)}\\_h(x) = 0$\n* nel profilo $P^{(h)}$ il votante $h$ giudica $x$ **primo**, ovvero $\\rho^{(h)}\\_h(x) = n-1$\n\n![](ar-lesson15-img2.png)\n\nDato che nel primo profilo tutti i votanti hanno $x$ in ultima posizione, mentre nell'ultimo profilo hanno tutti $x$ in prima posizione, avremo per **principio di unanimità** `U` che\n$$\\begin{align\\*}\n\\\\rho^{(0)}(x) \u0026= 0\\\\\n\\\\rho^{(k)}(x) \u0026= n-1\n\\\\end{align\\*}$$\n\nDato che dal profilo 0 al profilo $k$ l'alternativa $x$ passa da essere all'utlimo posto fino al primo, esisterà certamente un **primo** profilo $j \\in \\left\\[ k \\right\\]$ per il quale $x$ non è più all'ultimo posto.\nOvvero, per ogni $h \\\u003c j$ avremo che $\\rho^{(h)}(x) = 0$ mentre nel profilo $j$ avremo $\\rho^{(j)}(x) \u003e 0$.\n\nInoltre, per quanto visto nella [prima parte della dimostrazione](14%20-%20Sistemi%20di%20voto%20-%20Part%202.md#parte-1), dato che $x$ è polarizzante per $P^{(j)}$ avremo che o $\\rho^{(j)}(x) = 0$ o $\\rho^{(j)}(x) = n-1$.\nPerò visto che abbiamo definito $j$ in modo tale che $\\rho^{(j)}(x) \u003e 0$ allora necessariamente avremo che $\\rho^{(j)}(x) = n-1$.\n\nNotiamo che il votante $j$ ha un ruolo decisivo nel posizionare $x$ nella graduatoria finale del profilo $P^{(j)}$, perché lo fa passare da essere all'ultimo posto al primo.\nPerciò possiamo dire che il votante $j$ è il **dittatore potenziale**.\n\n---\n\n## Parte 3 dimostrazione\n\nIn questa ulitma parte dimostreremo che il dittatore potenziale $j$ trovato nella [seconda parte](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#parte-2-dimostrazione) è effettivamente il dittatore del sistema di voto affidabile che rispetta `U` e `IIA`.\n\nIl il profilo $Q = \\langle r^Q_1, ..., r^Q_k \\rangle$ con $k$ votanti su $n$ alternative.\nCome prima, per ogni votante $h \\in \\left\\[ k \\right\\]$ indichiamo con $\\rho^Q_h$ la funzione peso associata al ranking $r^Q_h$ del votante $h$. Infine indichiamo che $r^Q$ il voto collettivo finale (che soddisfa $\\sigma$ e con $\\rho^Q$ la funzione di peso collettiva associata a $r^Q$).\n\nVogliamo dismotrare che **qualunque sia** $Q$ allora $r^Q = r^Q_j$.\nPiù precisamente, **qualunque sia** $Q$, comunque si scelgano due alternative $y,z \\in \\left\\[ n \\right\\]$ allora\n$$\\rho^Q(y) \u003e \\rho^Q(z) \\iff \\rho^Q_j(y) \u003e \\rho^Q_j(z)$$\n\nTale affermazione verrà dimostrata in due sottofasi:\n\n1. dimostriamo che se $y \\neq x$ e $z \\neq x$ allora $\\rho^Q(y) \u003e \\rho^Q(z) \\iff \\rho^Q_j(y) \u003e \\rho^Q_j(z)$.\n1. dimostriamo che se $y \\neq x$ allora $\\rho^Q(y) \u003e \\rho^Q(x) \\iff \\rho^Q_j(y) \u003e \\rho^Q_j(x)$.\n\n### Sottofase 3.1\n\nSupponiamo di avere che $y \\neq x$ e $z \\neq x$, e senza perdita di generalità supponiamo che $\\rho^Q_j(y) \u003e \\rho^Q_j(z)$.\n\nA questo punto costruiamo a partire da $Q$ un nuovo profilo $T = \\langle r^T_1, ..., r^T_k \\rangle$ nella seguente maniera:\n\n* Per ogni votante $h \\leq j$ poniamo $x$ in testa alla graduatoria.\n* Per ogni votante $h \u003e j$ poniamo $x$ in ultima posizione della graduatoria.\n* Infine, considerando solamente il votante $j$, poniamo l'aternativa $y$ in testa la ranking $r^T_j$.\n\n![Transformazione dal profilo $Q$ al profilo $T$.](ar-lesson15-img3.png \"Q2T\") ^d3593a\n\nOsserviamo che il profilo appena costruito $T$ è molto simile al profilo $P^{(j)}$ trovato nella fase 2.\n\n![](ar-lesson15-img4.png)\n\nDalle parti 1 e 2 della dimostrazione sappiamo che $\\rho^{(j)}(x) = n-1$, perciò è vero che\n$\\rho^{(j)}(x) \u003e \\rho^{(j)}(z)$.\nInoltre poiché l'oride relativo tra $x$ e $z$ rimane invariato sia in $P^{(j)}$ sia in $T$, allora per il principio dell'indipendenza dalle alternative irrilevanti `IIA` avremo che $\\rho^{T}(x) \u003e \\rho^{T}(z)$.\n\nAnalogamente possiamo osservare che $T$ è molto simile anche al profilo $P^{(j-1)}$.\n\n![](ar-lesson15-img5.png)\n\nCome prima, dalla parte 2 della dimostrazione abbiamo trovato un $j$ in modo tale che $\\rho^{(j-1)}(x) = 0$, perciò avremo che $\\rho^{(j-1)}(x) \\\u003c \\rho^{(j-1)}(y)$.\nInoltre poiché l'oride relativo tra $x$ e $y$ rimane invariato sia in $P^{(j-1)}$ sia in $T$, allora per il principio dell'indipendenza dalle alternative irrilevanti `IIA` avremo che $\\rho^{T}(x) \\\u003c \\rho^{T}(y)$.\n\nOsserviamo ora la [figura ](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#d3593a).\nL'ordine relativo tra $y$ e $z$ rimane invariato sia in $Q$ che in $T$, perciò ancora una volta per il principio `IIA` avremo che $\\rho^Q(y) \u003e \\rho^Q(z)$.\n\nRicapitolando, siamo partiti dall'assunzione che $\\rho^Q_j(y) \u003e \\rho^Q_j(z)$, e costruendo il profilo $T$ abbiamo dimostrato che tale assunzione implica che $\\rho^Q(y) \u003e \\rho^Q(z)$.\nOvvero abbiamo mostrato che\n\n$$\\begin{equation}\n\\\\rho^Q_j(y) \u003e \\rho^Q_j(z) \\implies \\rho^Q(y) \u003e \\rho^Q(z)\n\\\\end{equation}$$\n\n^4afe65\n\nDato che $y$ e $z$ sono **variabili mute** (ovvero interscambiabili), possiamo dimostrare alla stessa meniera che\n\n$$\\begin{equation}\n\\\\rho^Q_j(y) \\\u003c \\rho^Q_j(z) \\implies \\rho^Q(y) \\\u003c \\rho^Q(z)\n\\\\end{equation}$$\n\n^cab5c8\n\nLe due euqaioni [(1)](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#4afe65) e [(2)](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#cab5c8) implicano l'ipotesi della corrente sottofase, ovvero\n$$\\left\\[ (1) \\land (2) \\right\\] \\implies \\left\\[ (y \\neq x \\land z \\neq x) \\implies (\\rho^Q(y) \u003e \\rho^Q(z) \\iff \\rho^Q_j(y) \u003e \\rho^Q_j(z)) \\right\\]$$\n\n### Sottofase 3.2\n\nIn questa sottofase si vuole dimostrare che se $y \\neq x$ allora $\\rho^Q(y) \u003e \\rho^Q(x) \\iff \\rho^Q_j(y) \u003e \\rho^Q_j(x)$.\n\nIniziamo con lìosserva che dato che ci sono **più di due alternative**, ovvero $n \u003e 2$, allora certamente esisterà un'altra alternativa $z \\neq y$ e $z \\neq x$.\n\nDeriviamo ora dai profili $P^{(0)}, P^{(1)}, ..., P^{(k)}$ una nuova sequenza di profili $T^{(0)}, T^{(1)}, ..., T^{(k)}$ spostando la posizione di $z$:\n\n* $T^{(0)}$ è ottenuta da $P^{(0)}$ semplicemente spostando $z$ in ultima posizione per tutti i ranking $r^{(0)}\\_1, ..., r^{(0)}\\_k$.\n* Per $h \u003e 0$, $T^{(h)}$ è ottenuta da $P^{(h)}$ spostando $z$ in prima posizione per tutti i ranking $i \\leq h$, e in ultima per tutti gli altri, ovvero $$\\rho^{T^{(h)}}\\_i(x) = \\begin{cases}\n  n-1 \u0026\\forall i \\leq h\\\\\n  0   \u0026\\forall i \u003e h\n  \\\\end{cases}$$\n\n![Sequenza di profili $T^{(0)}, T^{(1)}, ..., T^{(k)}$.](ar-lesson15-img6.png \"profiliT\")\n\nPer comodità, per ogni $h \\in \\lbrace 0 \\rbrace \\cup \\left\\[ k \\right\\]$ indichiamo con $t^h$ il ranking collettivo del profilo $T^{(h)}$, e con $\\rho^{T^{(h)}}$ la funzione di pesso ad esso associata.\n\nEsattamente come per i profili $P^{(0)}, P^{(1)}, ..., P^{(k)}$ (vedi [parte 2](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#parte-2-dimostrazione)), esiste un $\\ell \\in \\left\\[ k \\right\\]$ tale che $\\rho^{T^{(h)}}(z) = 0$ per ogni $h \\\u003c \\ell$, mentre $\\rho^{T^{(\\ell)}}(z) = n-1$.\n\nAncora una volta, esattamente come dimostrato nel [punto 3.1](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#sottofase-3-1), per ogni profilo $Q$, dato che $y \\neq z$ e dato che $x \\neq z$ allora $$\\rho^Q(y) \u003e \\rho^Q(x) \\iff \\rho^Q\\_{\\ell}(y) \u003e \\rho^Q\\_{\\ell}(x)$$ Per concludere la dimostrazione basta dimostrare che $\\ell = j$.\n\n#### Caso $\\ell \\\u003c j$\n\nDimostriamo che esiste almeno un profilo $P$ tale che $\\rho^P \\neq \\rho^{P}\\_{\\ell}$.\nRicordiamo che nel [punto 2](15%20-%20Sistemi%20di%20voto%20-%20Part%203.md#parte-2-dimostrazione) abbiamo scelto $j$ in modo tale che $\\rho^{(j-1)}(x) = 0$, ovver che $$\\rho^{(j-1)}(x) \\\u003c \\rho^{(j-1)}(y)$$\nMa per come è definita la sequenza $P^{(0)}, P^{(1)}, ..., P^{(k)}$ sappiamo che per ogni profilo $h$ e per ogni $i \\leq h$ abbiamo che $\\rho^{h}*i(x) = n-1$, perciò avremo che $\\rho^{(j-1)}*{\\ell}(x) = n-1$ dato che $\\ell \\\u003c j \\implies \\ell \\leq j-1$.\n\nPerciò avremo che nel ranking $\\ell$ del profilo profilo $P^{(j-1)}$ che $$\\rho^{(j-1)}*{\\ell}(x) \u003e \\rho^{(j-1)}*{\\ell}(y)$$\nQuindi certamente $\\rho^{(j-1)} \\neq \\rho^{(j-1)}\\_{\\ell}$.\n\n![](ar-lesson15-img7.png)\n\nQuesto stesso ragionamento si può applicare per ogni profilo minore di $j$, perciò per forza non può essere vero che $\\ell \\\u003c j$.\n\n#### Caso $\\ell \u003e j$\n\nPer come abbiamo scelto $j$ sappiamo che $\\rho^{(j)}(x) = n-1$ e che quindi $$\\rho^{(j)}(x) \u003e \\rho^{(j)}(y)$$\nPerò per come abbiamo definito la sequenza di profili $P^{(0)}, P^{(1)}, ..., P^{(k)}$, sappiamo che per ogni $i \u003e h$ abbiamo che $\\rho^{h}*i(x) = 0$.\nPerciò dato che $\\ell \u003e j$ allora $$\\rho^{(j)}*{\\ell}(x) \\\u003c \\rho^{(j)}\\_{\\ell}(y)$$ quindi non può essere vero che $\\ell \u003e j$.\n\nIn conclusione, se non è vero che $\\ell \\\u003c j$ e non è vero che $\\ell \u003e j$ deve necessariamente essere vero che $\\ell = j$ $\\square$.\n","lastmodified":"2022-08-29T13:39:16.958972574+02:00","tags":null},"/AR/16-Sistemi-di-voto-Part-4":{"title":"","content":"\n# Single-Peaked Preferences and the Median Voter Theorem\n\nIl [teorema di Arrow](14%20-%20Sistemi%20di%20voto%20-%20Part%202.md#il-teorema-di-impossibilita-di-arrow), come anche il [paradosso di Condorcet](13%20-%20Sistemi%20di%20voto%20-%20Part%201.md#d7f399), pongono una prospettiva non rassicurante sui sistemi di voto.\nTuttavia, un approccio comune di fronte a un risultato di impossibilità è quello di considerare alcuni **casi particolari**, i quali sono anche ragionevoli se applicati in un contesto reale, che consentano in qualche modo di \"aggirare\" i risultati negativi visti fin ora.\n\nUn punto di partenza è quello di osservare che c'è qualcosa di un po' *insolito* nel considerare ranking senza alcun vincolo.\nPer fare un esempio, consideriamo le alternative `X`, `Y`, `Z` e i votanti 1, 2, 3 con i seguenti ranking:\n\n1. $X \u003e\\_1 Y \u003e\\_1 Z$\n1. $Y \u003e\\_2 Z \u003e\\_2 X$\n1. $Z \u003e\\_3 X \u003e\\_3 Y$\n\nSupponiamo per esempio che le tre alternative indichino una quantità di investimento in denaro dove `X` rappresenta un investimento minimo, `Y` uno medio e `Z` uno alto.\nOvviamente la perdita in denaro derivata da un investimento è controbilanciata da un guadagno che segue la regola del *\"più spendi, più la qualità del ricavato è alta\"*.\n\nPer quanto riguarda la classifica del primo votante essa ha senso, in quanto egli si accontanta di spendere poco `X`, altrimenti una quantità media `Y`, e solo in estremis la quantità elevata `Z`.\n\nIl secondo votante segue anche una certa logica, ovvero quella del *\"spendo un po' di più\"*.\nInfatti preferisce pagare una quantità media `Y`, eventualmente pagare molto `Z`, e solo alla fine pagare poco `X`.\n\nQuello che non ha senso è la classifica del terzo votante. Infatti inizia col dire che preferisce pagare tanto `Z`, dopodichè preferisce pagare poco `X`, e in fine preferisce pagare una quantità media `Y`.\n\nIn altre parole, i primi due elettori hanno preferenze che possono essere spiegate dalla \"vicinanza\" a una utilità fissata.\nOgnuno di loro ha una quota **ideale** che vorrebbero invesitre, e valutano le alternative in base a quanto si avvicinano a questo ideale.\n\nLe preferenze del terzo elettore non possono essere spiegate in questo modo, infatti non esiste una quantità \"ideale\".\n\nOvviamente questo non vuol dire che una persona non possa mantenere queste preferenze.\nPer esempio, infatti, il terzo giocatore potrebbe applicare il ragionamento del\n\n \u003e \n \u003e *\"se non siamo disposti a investire abbastanza per farlo bene, non dovremmo spendere nulla\"*\n\nIn generale però avere delle preferenze così differenti tra di loro è meno usuale.\n\nUn altro esempio che rende meglio l'idea è una elezione di un politico.\nAssumiamo che `X` sia un candidato con orientamento a sinistra, `Z` un candidato con orientamento a destra e `Y` un candidato più neutro (\"centrale\").\nPer esempio per un elettore con preferenze a sinistra avrebbe senso presentare il seguente ranking $\\langle X, Y, Z \\rangle$, mentre per uno orientanto alla destra avrebbe senso il ranking $\\langle Z, Y, X \\rangle$.\nAnche il ranking $\\langle Y, Z, X \\rangle$ ha un senso, ovvero quello del\n\n \u003e \n \u003e *\"non ho un orientamento politico fortemente indirizzato a destra o sinistra perciò voto `Y`, però se proprio devo scegliere un'alternativa scelgo la destra con `Z`\"*\n\nCiò che non avrebbe porprio senso sarebbe il rankin $\\langle Z, X, Y \\rangle$, in quanto non ha molto senso che una persona di destra abbia come seconda scelta un candidato di sinistra (e viceversa).\n\n## Single-Peaked Preferences\n\nConsideriamo quindi insiemi di alternative che corrispondono a quantità numeriche, o più in generale che abbiano un ordinamento lineare totale.\n\nÈ ragionevole presumere che le preferenze individuali tendano ad assomigliare a quelle dei votanti dell'esempio precedente:\nognuno ha una particolare alternativa **ideale** nella gamma di alternative, e valutano le alternative in base alla loro **vicinanza** a questa alternativa ideale.\n\nPerciò formalmente poniamoci in un contesto con alternative **totalmente ordinate** $$A \\equiv \\lbrace a_1, ..., a_n | \\forall i=1,...,n-1 \\left\\[ a_i \\\u003c a\\_{i+1} \\right\\] \\rbrace$$\nDato un votante $h \\in \\left\\[ k \\right\\]$, diremo che il suo ranking $r_h = \\langle a\\_{h1}, a\\_{h2}, ..., a\\_{hn} \\rangle$ è **single peacked** se \u003cu\u003ecomunque\u003c/u\u003e si scelgano tre alternative $a_i \\\u003c a_j \\\u003c a\\_{\\ell}$ **non** avremo che $\\rho_h(a_j) \\\u003c \\rho_h(a_i)$ e $\\rho_h(a_j) \\\u003c \\rho_h(a\\_{\\ell})$.\n\nIn termini formali\n$$\\forall a_i, a_j, a\\_{\\ell} \\in A : a_i \\\u003c a_j \\\u003c a\\_{\\ell} \\lnot\\left\\[ \\rho_h(a_j) \\\u003c \\rho_h(a_i) \\land \\rho_h(a_j) \\\u003c \\rho_h(a\\_{\\ell}) \\right\\]$$\nPer fare chiarezza consideriamo ciascuna funzione $\\rho_h$ come una funzione su domini ordinati, allora $\\rho_h$ non ha **minimi locali relativi**.\n\n![Tre ranking *single picked*.|500](ar-lesson16-img1.png \"single-picked\") ^3653e9\n\nA questo punto supponiamo, senza perdita di generalità[^1], che per ogni votante $h \\in \\left\\[ k \\right\\]$, il *\"picco\"* (o *alternativa ideale*) del votante $h$ **non preceda** il picco del votante $h+1$.\nOvvero, sia $P = \\langle r_1, ..., r_k \\rangle$ un profilo composto da soli ranking *single picked*.\nPer ogni votante $h \\in \\left\\[ k \\right\\]$ indichiamo con $M_h$ l'alternativa **preferita** del votante $h$, ovvero $$M_h \\in A ; : ; \\rho_h(M_h) = n-1$$\nAllora i votanti sono ordinati in modo tale che $$M_1 \\leq M_2 \\leq ... \\leq M_k$$\nPer esempio in [figura](16%20-%20Sistemi%20di%20voto%20-%20Part%204.md#3653e9) avremo che il votante verde è il primo votante, il rosso è il secondo e quello bul è l'ultimo.\n\n## Teorema del Votante Mediano\n\nNel caso in cui le alternative compongono un insieme *totalmente ordinato* e i ranking di tutti i votanti sono *single peacked* è possibile utilizzare il sistema di voto a **maggioranza** con la certezza di non incorrere nel paradosso di Condorcet.\n\n \u003e \n \u003e **Teorema del Votante Mediano**\n \u003e Sia $A \\equiv \\lbrace a_1, a_2, ..., a_n \\rbrace$ un insieme di alternative **totalmente ordinate** tali che $a_1 \\leq a_2 \\leq ... \\leq a_n$, e sia $P = \\langle r_1, ..., r\\_{2k-1} \\rangle$ un profilo di $2k-1$ **ranking single peacked**, ovvero tale che $$M_1 \\leq M_2 \\leq ... \\leq M\\_{2k-1}$$ \n \u003e Allora per ogni alternativa $y \\in A \\setminus \\lbrace M_k \\rbrace$ avremo che $$\\vert \\lbrace h : \\rho_h(M_k) \u003e \\rho_h(y) \\rbrace \\vert \u003e \\vert \\lbrace h : \\rho_h(y) \u003e \\rho_h(M_k) \\rbrace \\vert$$\n\nIn termini più semplici il teorema ci dice che, sotto le sue ipotesi, esiste sempre un'alternativa preferita dalla **maggiorparte** dei votanti, ed essa corrisponde esattamente al **picco** del votante che si trova in posizione centrale rispetto all'ordinamento $M_1 \\leq M_2 \\leq ... \\leq M\\_{2k-1}$.\n\nÈ facile osservare che tale alternativa $M_k$ corrisponde alla prima in classifica (vedi [dimostrazionte](16%20-%20Sistemi%20di%20voto%20-%20Part%204.md#dimostrazione-teorema-del-votante-mediano)).\n\nA questo punto rimuovendo l'alternativa $M_k$, i $2k-1$ ranking continuano a rimanere *single peacked*, perciò si può pensare di riapplicare lo stesso ragionamento per trovare il secondo classificato, poi il terzo, e così via...\n\n**\\[VEDI ESEMPIO SLIDES 61-65\\]**\n\n### Dimostrazione Teorema del Votante Mediano\n\nSia $M_k = a_m$ l'alternativa preferita del votante mediano $k$, ovvero tale che $\\rho_k(a_m) = n-1$.\nConsideriamo ora l'alternativa $y = a_t \\neq a_m$.\n\nAbbiamo due casi\n\n#### Caso $t \u003e m$\n\nDato che le alternative sono **totalmente ordinate** avremo che se $t \u003e m$ allora $a_t \u003e a_m$.\nInoltre, per come abbiamo ordinato i votanti, per ogni votante $h \\geq k$ avremo che $$M_h \\leq M_k = a_m \\\u003c a_t$$\nInfine, dato che i ranking sono tutti **single peacked**, avremo che $$\\rho_h(M_h) \\geq \\rho_h(a_m) \u003e \\rho_h(a_t)$$\nOvvero tutti i votanti $h$ che **precedono** $k$ preferiscono $a_m$ ad $a_t$.\n\n![Il rankign $k$ è quello rosso, il ranging $h$ è quello blu, $m=4,t=6$.|500](ar-lesson16-img3.png)\n\nPerciò i votanti che preferiscono invece $a_t$ ad $a_m$ hanno un indice $h \u003e k$ (non è detto che siano tutti quelli $h \u003e k$).\n\nIn conclusione abbiamo almeno $k$ individui che preferiscono $a_m$ ad $a_t$ e al più $k-1$ che viceversa preferiscono $a_t$ ad $a_m$.\nOvvero **la maggio parte** preferisce $a_m$ ad $a_t$ se $t \u003e m$.\n\n#### Caso $t \\\u003c m$\n\nDimostrazione del tutto simmetrica al caso precedente.\nDato che le alternative sono **totalmente ordinate** avremo che se $t \\\u003c m$ allora $a_t \\\u003c a_m$.\nInoltre, per come abbiamo ordinato i votanti, per ogni votante $h \\geq k$ avremo che $$M_h \\geq M_k = a_m \u003e a_t$$\nInfine, dato che i ranking sono tutti **single peacked**, avremo che $$\\rho_h(M_h) \\geq \\rho_h(a_m) \u003e \\rho_h(a_t)$$\nOvvero tutti i votanti $h$ che **succedono** $k$ preferiscono $a_m$ ad $a_t$.\n\n![Il rankign $k$ è quello rosso, il ranging $h$ è quello verde, $m=4,t=2$.|500](ar-lesson16-img4.png)\n\nPerciò i votanti che preferiscono invece $a_t$ ad $a_m$ hanno un indice $h \\\u003c k$ (non è detto che siano tutti quelli $h \\\u003c k$).\n\nIn conclusione abbiamo almeno $k$ individui che preferiscono $a_m$ ad $a_t$ e al più $k-1$ che viceversa preferiscono $a_t$ ad $a_m$.\nOvvero **la maggio parte** preferisce $a_m$ ad $a_t$ se $t \\\u003c m$.\n\nApplicando questo ragionamento per ogni $y \\in A \\setminus \\lbrace a_m \\rbrace$ avremo che la maggior parte dei votatni preferisce $a_m = M_k$ $\\square$.\n\n---\n\n[^1]: A meno di un riordinamento dei votanti.\n","lastmodified":"2022-08-29T13:39:16.964491499+02:00","tags":null},"/AR/17-Web-Search-Part-1":{"title":"","content":"\n# World Wide Web\n\nSe stai leggendo questi appunti certamente hai usato (e sai usare) il **Web**.\n\nIl Web è un'appicazione sviluppata da *[Tim Berners-Lee](https://it.wikipedia.org/wiki/Tim_Berners-Lee)* nel periodo 1989-1991 per consentire alle persone di condividere informazioni tramite internet.\n\nL'architettura del web è di tipo **client-server** e il suo funzionamento può essere descritto in due principi:\n\n* delle informazioni sono salvate su delle macchine **server** e resi disponibili tramite *internet* sotto forma di **pagine web**.\n* un'applicazione **client** (per esempio un *browser*) richiede tali pagine Web pubblicamente accessibili.\n\nQuesta in sintesi è la **struttura fisica** del web.\n\nCiò che è interessante è invece l'**organizzazione logica** delle pagine web.\nLe pagine web possono **referenziare** in maniera \u003cu\u003ediretta\u003c/u\u003e altre pagine web, tramite dei **riferimenti** o **link**.\nPerciò possiamo pensare al web come un grafo diretto in cui i nodi sono le pagine web, e gli archi sono i riferimenti tra una pagina e un'altra.\nPer questo motivo una pagina web viene anche detta **ipertesto**.\n\n## Precursori dell'ipertesto\n\nUn primo precursore *intelletuale* del concetto di ipertesto è il concetto di **reference**.\nNegli articoli o nei libri, quando si necessità indirizzare a informazioni supplementari o semplicemente citare il proprietario intelletuale di una informazione, si fanno dei **riferimenti** ad altri libri o articoli.\nAnche in questo caso si crea un grafo diretto i cui nodi sono i libri o gli articoli e gli archi sono i riferimenti.\n\nLa differenza sostanziale però con l'ipertesto è la linea temporale nella quale si fanno i riferimenti.\nSe un libro `X` fa una citazione a un articolo `Y` vuol dire che `Y` è stato scritto e pubblicato prima di `X`, perciò non ci potranno essere riferimenti ad `X` nell'articolo `Y`.\n\nInvece nel rete del Web abbiamo degli archi bidirezionali, ovvero capita spesso di trovare due pagine che si referenziano reciprocamente.\n\nUn altro precursore dell'ipertesto sono le cosidette **crossing-references**, o **riferimenti incrociati**.\nTale tipo di organizzazione la troviamo per esempio in una enciclopedia, e consente di collegare argomenti differenti attraverso una catena di collegamenti semantici o riferimenti tra altri arogmenti.\n\n![Cross-references.](ar-lesson17-img1.png \"cross-references\") ^b6ec61\n\nPer esempio la [figura](17%20-%20Web%20Search%20-%20Part%201.md#b6ec61) mostra come tramite riferimenti incrociati di *Wikipedia* possiamo connettere gli Equilibri di Nash con la Nasa.\n\n### MEMEX\n\nVannevar Bush nel suo articolo *\"As we may think\"* del 1945 cercò di immaginare come le moderne tecnologie di comunizaione emergenti all'epoca avrebbero influenzato il mondo, grazie alle rivoluzionarie tecniche di **archiviazione**, **scambio** e **accesso** di informazioni.\n\nIn particolare Bush osservò che i metodi tradizionali per archiviare le informazioni in un libro, in una biblioteca o nella memoria di un computer erano altamente **lineari**.\nBasta pensare a un dizionario enciclopedico in cui tutti gli argomenti sono ordinati uno dopo l'altro.\n\nD'altra parte la mente umana struttura e accede alla propria esperienza mostrando quella che potrebbe essere definita una **memoria associativa**, ovvero è strutturata in una **rete semantica** di concetti.\nTu pensi a una cosa, te ne ricorda un'altra tramite una *connessione*, dopodiché ti viene un intuizione che ti porta ad un terzo pensiero, e così via...\n\nBush ha quindi immaginato un sistema che cercava di imitare questo stile di memoriazione **associativa**, il **MEMEX**, ovvero una versioni digitalizzate di tutta la conoscenza umana collegate da collegamenti associativi.\nInfatti Bush fu esplicitamente citato da Tim Berners Lee quando progettò il Web.\n\n## Web 2.0\n\nInizialmente il Web era costituito da una collezione di pagine **statiche** al cui interno erano (eventualmente) presenti degli\n*hyperlink* ad altre pagine.\nTali *hyperlink* sono detti **navigazionali** in quanto servono appunto per \"navigare\" nel Web, esattamente come noi navighiamo nella nostra conoscienza, *implementando* così la **memoria associativa**.\n\nCol tempo però il Web si è evoluto, passando da pagine totalmente statiche a pagine che consentono di effettuare delle **azioni**, come per esempio sottomettere una richiesta a un server oppure effettuare dei pagamenti.\nI link che consentono di effettuare tali azioni sono detti appunto **transazionali**.\n\nAltre evoluzioni sono per esempio l'avvento dei servizi, come per esempio:\n\n* la creazione e mantenimento di contenuti in maniera condivisa con *Wikipedia*.\n* lo scambio di messaggio con i servizi di *web-mailing*.\n* reti che connettono individui anziché documenti con i *social-media*.\n* reti che connettono video con *YouTube*.\n\nCon tali evoluzioni si indica il cosidetto **Web 2.0**.\n\n## Il Grafo diretto del Web\n\nCome abbiamo già accennatto il Web può essere visto come un grafo diretto, in cui i nodi sono le pagine e gli archi sono gli hyperlink tra esse.\nUna osservazione abbastanza intuitiva che si può fare è quella che un pagina web conosce solamente le pagine a cui punta, ovvero i\ncosidetti **archi uscenti**, e non le pagine da cui è puntata, ovvero gli **archi entranti**.\n\nIn uno studio del 2000 si osservò che il grafo del web, composto da milioni di nodi, ha una forma a **bow-tie**, ovvero a **fiocco**.\nAl centro è presente una **componente fortemente connessa** (che indicheremo con `SCC`, *Strongly Connected Component*) composta dalla maggior parte dei nodi.\nIn tale componente, per ogni pagina web `X` della componente è possibile trovare una serie di link che collegano `X` verso qualsiasi altra pagina in `SCC`, e viceversa da qualsiasi altra pagina è possibile navigare e raggiungere `X`.\n\nDopodiché si osservò la presenza di altre due componenti che formavano una sorta di *\"flusso\"* in entrata e uscita da `SCC`.\nLe componenti sono:\n\n* **IN**: composta dai nodi dai quali navigando è possibile raggiungere `SCC`, ma non raggiungibili in alcun modo da da `SCC`. Questa componente rappresenta quindi il flusso in entrata in `SCC`.\n* **OUT**: compsta dai nodi raggiungibili da `SCC` tramite una navigazione ma che a loro volta non possono raggiugere `SCC`. Questa componente rappresenta quindi il flusso in uscita in `SCC`.\n\nAltre componenti osservate nel grafo del web sono:\n\n* **Tendrils**: o *\"tentacoli\"* è una componente composta da:\n  * nodi che sono raggiungibili dai nodi presenti nella componente `IN` ma dai quali non si può raggiungere `SCC`.\n  * nodi attraverso i quali si può raggiungere la componente `OUT` ma i quali non sono raggiungibili dai nodi in `SCC`.\n* **Tubi**: composto dai nodi che creano un flusso che collegga la componente `IN` alla componente `OUT` senza quindi mai passarre attraverso `SCC`.\n* **Componenti disconnesse**: una serie di nodi disconnessi dalla struttura a fiocco.\n\n![Una immagine semantica che rappresenta la struttura a fiocco del Web.|600](ar-lesson17-img2.png)\n\n---\n\n# Link Analysis and Web Search\n\n## Il problema della ricerca\n\nIl problema di classificare e ricercare documenti è un problema antico.\n\nPrima dell'avvento del Web, la difficoltà nel ricercare documenti era sostanzialmente dovuta alla scarsità di questi ultimi.\nInfatti, un tempo bisognava raggiungere fisicamente una biblioteca, libreria o archivio per avere accesso a libri, articoli o documenti, e inoltre non ce n'erano a disposizione una grande quantità.\nTuttavia c'era un vantaggio, i documenti in generale erano catalogati in categorie, perciò a chi interessava avere informazioni su un determinato argomento bastava recarsi nel luogo in cui erano raccolti i documenti relativi all'argomento interessato.\nPer esempio, a un avvocato che necessita delle schede penali di alcune persone basta andare in un archivio di un tribunale.\nOppure se ti interessa trovare un nuovo romanzo da leggere, basta andare in libreria nella sezione \"Romanzi\" e troverai una raccolta di libri inerenti al genere che ti interessa.\n\nIl Web ha letteralmente capovolto i ruoli.\nAdesso *chiunque* ha acesso a una infinità di documenti in letteralmente **pochissimi istanti**.\nIl problema principale invece è appunto questa **sovrabbondanza** di documenti, i quali purtroppo non sono catalogati e raggruppati in categorie.\n\nPurtroppo proprio per questa eterogeneità dei documenti, non è possibile effettuare una **ricerca specializzata** per parole chiave.\nOltre al fatto che il numero di parole chiave è **potenzialmente illimitato**, una parola assume differenti significati.\nInfatti per esempio la parola \"albero\" in teoria dei grafi è un grafo particolare, mentre in botanica è un tipo di pianta, oppure ancora può poter significare un albero genealogico.\n\nSi vuole quindi definire uno strumento di **web search** che consenta di effettuare una ricerca catalogando in base a delle parole chiave e\nscartando tutte le pagine non coerenti.\nQuesta però non è una condizione sufficiente affinché uno strumento di web search risulti utile.\nInfatti, come risultato di una ricerca, potrebbe essere restituito un insieme potenzialmente immenso di pagine inerenti alle parole chiave.\nPerciò è necessario che tale strumento in qualche modo **sfoltisca** le pagine meno *rilevanti*, restituendo così un inseme abbastanza piccolo da essere umanamente visitato, e possibilmente **ordinando** queste pagine in un ordine di rilevanza, ovvero effettuando un **ranking** delle pagine restituite.\n\n## Link Analysis\n\nPurtroppo il contenuto interno di una pagina non consente da solo di quantificarne con precisione la sua rilevanza rispetto alla ricerca in corso.\n\nUn primo strumento utile che consente invece di capire meglio la rilevanza di una pagina sono gli hyperlink.\nConsideriamo prima un esempio:\n\n \u003e \n \u003e Staimo studiando un articolo utile per fare una tesi.\n \u003e Per capire meglio l'argomento un solo articolo non basta, perciò decidiamo di attingere dalla bibliografia dell'articolo.\n \u003e Purtroppo notiamo che sono presenti svariate decine di citazioni ad altri articoli.\n \u003e Non potendo leggerli tutti quanti, è sensato considerare gli articoli che più hanno citazioni in generale.\n\nPrendendo quindi come base questo esempio, dopo aver escluso tutte quelle pagine **non inerenti** alla nostra ricerca, possiamo ordinarle in ordine **non crescente** di numero di referimenti.\nPiù precisamente, mettiamo tra i primi risultati della ricerca tutte quelle pagine che all'interno del sottoinsieme di pagine inerenti alla ricerca sono maggiormente **puntate** da hyperlink.\n\nOvvero la rilevanza di una pagina è calcolata **analizzando i link** che la coinvolgono.\n\n[continua →](18%20-%20Web%20Search%20-%20Part%202.md)\n","lastmodified":"2022-08-29T13:39:16.888349513+02:00","tags":null},"/AR/18-Web-Search-Part-2":{"title":"","content":"\n# Link Analysis and Web Search\n\n## HITS: Hubs and Authorities\n\nRicapitolando, una volta individuato un sottoinsieme di pagine inerenti alla nostra ricerca, consideriamo maggiormente rilevanti quelle pagine che sono molto puntate (o **indicizzate**) all'interno dell'insieme.\n\nPurtroppo però potrebbe capitare che una pagina venga puntata da tantissime pagine che in realtà sono molto poco rilevanti ai fini della ricerca.\nOppure ancora, un utente malevolo a scopi egoistici potrebbe creare tante pagine fittizie che puntano alle sue pagine per avere più rilevanza.\nPerciò è utile porsi il seguente questio:\n\n \u003e \n \u003e *quando e quanto una pagina è **autorevole** nel conferire rilevanza ad un'altra pagina che punta?*\n\nL'algoritmo **Hyperlink-Induced Topic Search** (o **HITS**, noto anche come **Hubs \u0026 Authorities**) proposto da [Jon Kleinberg](https://it.wikipedia.org/wiki/Jon_Kleinberg) consente di valutare la rilevanza delle pagine in funzione dei link che la puntano.\n\nIniziamo con l'associare ad ogni pagina due **indici**:\n\n* un indice di **autorità** che esprime la **rilevanza** della pagina ai fini della ricerca.\n* un indice di **hub** che invece esprime l'attitudine della pagina a **conferire autorità** alle pagine alle quali punta.\n\nPer ogni pagina $i$ della rete indichiamo con $a_i$ il suo valore di **autorità**, come il numero di pagine (nell'insieme di pagine attinenti alla ricerca) che puntano ad $i$.\n$$a_i = \\vert { j : j \\mbox{ è attinente alla ricerca} \\land j \\rightarrow i } \\vert$$\nCon $j \\rightarrow i$ stiamo ad indicare che la pagina $j$ punta alla pagina $i$.\n\nAssumiamo che a fronte di una ricerca otteniamo un sottoinsieme di $n$ pagine, indichiamo con $M$ la **matrice di adiacenza** del sottografo indotto dalle $n$ pagine inerenti alla ricerca.\n$$M\\left\\[i,j \\right\\] = \\begin{cases}\n1 \u0026\\mbox{se } i \\rightarrow j\\\\\n0 \u0026\\mbox{altrimenti}\n\\\\end{cases};;\n\\\\forall 1 \\leq i \\\u003c j \\leq n$$\nDefinendo in questa maniera $M$ avremo che $$a_i = \\sum\\_{j = 1}^{n} M\\left\\[j,i \\right\\]$$\n\nIndichiamo invece con $h_i$ l'indice di hub di una pagina $i$.\nTale indice potremmo definirlo come il numero di pagine (sempre all'interno del sottoinsieme di nodi inerenti alla ricerca) alle quali $i$ punta.\nOvvero\n\n$$\\begin{align\\*}\nh_i \u0026= \\vert { j : j \\mbox{ è attinente alla ricerca} \\land j \\leftarrow i } \\vert\\\\\nh_i \u0026= \\sum\\_{j = 1}^{n} M\\left\\[i,j \\right\\]\n\\\\end{align\\*}$$\n\nPartiamo con l'osservare che possiamo *raffinare* i due indici appena definiti tramite le seguenti idee:\n\n* il valore di autorità di una pagina $i$ dovrebbe essere tanto più eleveto quanto più sono **autorevoli** le pagine $j$ che la puntano.\n* simmetricamente, il valore di hub di una pagina $i$ dovrebbe essere tanto più elevato quanto più è elevata la **rilevanza** delle pagine $j$ a cui punta.\n\nSe in qualche modo ci venisse suggerito un valore di hub iniziale $h^{(0)}\\_i$ potremmo raffinare il valore $a_i$ visto in precedenza nella seguente maniera $$a^{(1)}*i = \\sum*{j = 1}^{n} M\\left\\[j,i \\right\\] \\cdot h^{(0)}\\_j$$\nOvvero l'autorità $a^{(1)}\\_i$ è influenzata dall'autorevolezza delle $j$ che la puntano.\n\nDato che quindi l'indice di autorità è modificato, possiamo raffinare anche $h^{(0)}\\_i$ alla stessa maniera $$h^{(1)}*i = \\sum*{j = 1}^{n} M\\left\\[i,j \\right\\] \\cdot a^{(1)}\\_j$$\n\nPossiamo quindi applicare questo **metodo iterativo** per raffinare al meglio gli indici di autorità e di hub\n\n$$\\begin{align\\*}\na^{(k+1)}*i \u0026= \\sum*{j = 1}^{n} M\\left\\[j,i \\right\\] \\cdot h^{(k)}\\_j\\\\\nh^{(k+1)}*i \u0026= \\sum*{j = 1}^{n} M\\left\\[i,j \\right\\] \\cdot a^{(k+1)}\\_j\n\\\\end{align\\*}$$\n\noppure in forma compatta\n\n$$\\begin{align\\*}\na^{(k+1)}\\_i \u0026= M^T h^{(k)}\\\\\nh^{(k+1)}\\_i \u0026= M a^{(k+1)}\n\\\\end{align\\*}$$\n\ne ponendo (in maniera del tutto convenzionale) $h^{(0)} = \\underline{1}$.\n\nCiò che vogliamo è ottenere ad ongi iterazione che i valori di autorità e di hub descrivano **meglio rispetto all'iterazione precedente** la rilevanza di una pagina nella ricerca.\nCiò che cerchiamo è quindi una sorta di \"convergenza\" ai valori reali di autorità e di hub.\n\nInnanzitutto non possiamo parlare di convergenza vera e propria in quanto ogni volta sommiamo valori non negativi.\nPerciò considereremo una convergenza in presenza di una **opportuna normalizzazione**.\n\nPoi, per ottenere convergenza, è necessario che ad ogni iterazione si ottiene un risultato sempre migliore rispetto a quella precedente.\nPerciò non vogliamo che accada una situazione del tipo $$\\exists i,j : a^{(k)}\\_i \u003e a^{(k)}\\_j, ;; a^{(k+1)}\\_i \\\u003c a^{(k+1)}\\_j, ;; a^{(k+2)}\\_i \u003e a^{(k+2)}\\_j, ;; ...$$\n\n \u003e \n \u003e **THM**\n \u003e Comunque si scelga un vettore iniziale $h^{(0)}$ con valori **positivi**, esiste un valore $c \\in \\mathbb{R}^+$ e un vettore $z \\in \\mathbb{R}^n$ **non nullo** tali che $$\\lim\\_{k \\rightarrow \\infty} \\frac{h^{(k)}}{c^k} = z$$ Analogamente per $a^{(k)}$.\n\n \u003e \n \u003e **Proof**: per definizione di $a^{(1)}$ abbiamo che $$\n \u003e h^{(1)} = M a^{(1)} = MM^T h^{(0)}\n \u003e $$ Perciò \"srotolando\" la formula che definisce $h^{(k)}$ avremo che\n \u003e \n \u003e ````{=latex}\n \u003e \\begin{align*}\n \u003e   h^{(2)} \u0026= M a^{(2)} = MM^T h^{(1)} = (MM^T)(MM^T) h^{(0)} = (MM^{T})^2 h^{(0)}\\\\\n \u003e   h^{(3)} \u0026= M a^{(3)} = MM^T h^{(2)} = (MM^T)(MM^T)^2 h^{(0)} = (MM^{T})^3 h^{(0)}\\\\\n \u003e   \u0026\\vdots\\\\\n \u003e   h^{(k)} \u0026= M a^{(k)} = MM^T h^{(k-1)} = (MM^{T})^k h^{(0)}\n \u003e \\end{align*}\n \u003e ````\n \u003e \n \u003e Dato che nella matrice di adiacenza ogni elemento appartiene a\n \u003e ${ 0,1 }$, allora per il teorema `C` avremo che la matrice $MM^T$ è\n \u003e una matrice **simmetrica**, **semidefinita positiva**. Inoltre dato\n \u003e che i suoi valori sono tutti non negativi, allora $MM^T$ è **non\n \u003e nulla**.  \n \u003e Dato che siamo nelle ipotesi del teorema `A`, avremo che la matrice\n \u003e $MM^T$ ha $n$ autovettori reali $z_1, ..., z_n \\in \\mathbb{R}^n$\n \u003e distinti, i quali formano una **base ortonormale** per\n \u003e $\\mathbb{R}^n$.  \n \u003e Per il teorema `B` sappiamo che ogni autovettore $z_i$ di $MM^T$ ha un\n \u003e relativo autovalore **reale non negativo** $c_i \\in \\mathbb{R}$. Senza\n \u003e perdita di generalità assumiamo che gli autovettori siano ordinati in\n \u003e modo tale che i relativi autovalori rispettino il seguente oridine $$\n \u003e c_1 \\geq c_2 \\geq ... \\geq c_n\n \u003e $$ Sempre per il teorema `B` sappiamo che esiste almeno un autovalore\n \u003e \\[strettamente positivo\\]{.underline}, perciò certamente avremo che\n \u003e $c_1 \u003e 0$.  \n \u003e Dato che gli autovettori $z_1, ..., z_n$ formano una base di\n \u003e $\\mathbb{R}^n$ allora possiamo scrivere $h^{(0)}$ come una\n \u003e **combinazione lineare** di questi ultimi, del tipo $$\n \u003e h^{(0)} = \\sum\\_{i=1}^{n} q_i z_i\n \u003e $$ e dunque\n \u003e \n \u003e ````{=latex}\n \u003e \\begin{align*}\n \u003e   h^{(k)} \u0026= (MM^{T})^k h^{(0)} = (MM^{T})^k \\sum_{i=1}^{n} q_i z_i\\\\\n \u003e   \u0026= (MM^{T})^{k-1} \\sum_{i=1}^{n} q_i (MM^{T}) z_i\\\\\n \u003e   (\\textit{per def. di autovettore})\u0026= (MM^{T})^{k-1} \\sum_{i=1}^{n} q_i (c_i z_i)\\\\\n \u003e   \u0026= (MM^{T})^{k-2} \\sum_{i=1}^{n} q_i c_i(MM^{T}) z_i = (MM^{T})^{k-2} \\sum_{i=1}^{n} q_i c_i^2 z_i\\\\\n \u003e   \u0026\\vdots\\\\\n \u003e   \u0026= \\sum_{i=1}^{n} q_i c_i^k z_i\n \u003e \\end{align*}\n \u003e ````\n \u003e \n \u003e Ovvero abbiamo ottenuto che $$\n \u003e h^{(k)} = \\sum\\_{i=1}^{n} q_i c_i^k z_i\n \u003e $$ Ora \\[normaliziamo\\]{.underline} dividendo ambi i membri per $c_1^k$,\n \u003e ovvero per l'autovalore massimo. $$\n \u003e \\\\frac{h^{(k)}}{c_1^k} = \\sum\\_{i=1}^{n} q_i \\left( \\frac{c_i}{c_1} \\right)^k z_i\n \u003e $$\n \u003e \n \u003e Individuiamo ora il primo indice $\\ell \\leq n$ tale che\n \u003e $c\\_{\\ell} \u003e c\\_{\\ell + 1}$, ovvero tale che $$\n \u003e c_1 = c_2 = ... = c\\_{\\ell} \u003e c\\_{\\ell + 1} \\geq ... \\geq c_n\n \u003e $$ Allora per ogni $i \\leq \\ell$ avremo che\n \u003e $\\left( \\frac{c_i}{c_1} \\right)^k = 1$, perciò\n \u003e \n \u003e ````{=latex}\n \u003e \\begin{align*}\n \u003e   \\lim_{k \\rightarrow \\infty} \\frac{h^{(k)}}{c_1^k} \u0026= \\lim_{k \\rightarrow \\infty} \\sum_{i=1}^{n} q_i \\left( \\frac{c_i}{c_1} \\right)^k z_i\\\\\n \u003e   \u0026= \\lim_{k \\rightarrow \\infty} (q_1z_1 + q_2z_2 + ... + q_{\\ell}z_{\\ell} + \\\\\n \u003e   \u0026+ q_{\\ell + 1} \\left( \\frac{c_{\\ell + 1}}{c_1} \\right)^k z_{\\ell + 1} + ... +  q_n \\left( \\frac{c_n}{c_1} \\right)^k z_n)\\\\\n \u003e   \u0026= q_1z_1 + q_2z_2 + ... + q_{\\ell}z_{\\ell}\n \u003e \\end{align*}\n \u003e ````\n \u003e \n \u003e Dimostriamo il teorema \\[solamente\\]{.underline} nel caso in cui\n \u003e $\\ell = 1$, ovvero quando $$\n \u003e \\\\lim\\_{k \\rightarrow \\infty} \\frac{h^{(k)}}{c_1^k} = \\lim\\_{k \\rightarrow \\infty} \\frac{(MM^T)^k h^{(0)}}{c_1^k} = q_1z_1\n \u003e $$ Per concludere la dimostrazione del teorema basti dimostrare che,\n \u003e comunque si scelga $h^{(0)}$ a coordinate \\[positivie\\]{.underline},\n \u003e avremo che $q_1 \\neq 0$.  \n \u003e Infatti, sappiamo che $z_1$ è un vettore **reale** e **non nullo** in\n \u003e quanto è un elemento di una \\[base ortonormale\\]{.underline} di\n \u003e $\\mathbb{R}^n$. Se fosse nullo, avremo che $z_1$ non sarebbe normale,\n \u003e ovvero $$\n \u003e z_1 = \\underline{0} \\implies z_1 \\cdot z_1 = \\underline{0} \\cdot \\underline{0} = 0 \\neq 1\n \u003e $$\n \u003e \n \u003e Osserviamo inoltre che la base è ortonormale allora\n \u003e $q_1 = h^{(0)}z_1$, infatti\n \u003e \n \u003e ````{=latex}\n \u003e \\begin{align*}\n \u003e   h^{(0)}z_1 \u0026= \\left(\\sum_{i = 1}^{n} q_i z_i \\right) \\cdot z_1\\\\\n \u003e   \u0026= \\sum_{i = 1}^{n} q_i (z_i \\cdot z_1)\\\\\n \u003e   \u0026= q_1 \\cdot \\underbrace{(z_1 \\cdot z_1)}_{1} + q_2 \\cdot \\underbrace{(z_2 \\cdot z_1)}_{0} + ... + q_n \\cdot \\underbrace{(z_n \\cdot z_1)}_{0} = q_1\n \u003e \\end{align*}\n \u003e ````\n \u003e \n \u003e Perciò $q_1 \\neq 0$ se e solo se $h^{(0)}z_1 \\neq 0$. Dimostriamo\n \u003e quindi che comunque scegliamo $h^{(0)}$ a coordinate positive\n \u003e $h^{(0)}z_1 \\neq 0$.\n \u003e \n \u003e Parte 1\n \u003e \n \u003e :   Innanzitutto dimostriamo che esiste un vettore\n \u003e $y \\in \\mathbb{R}^n$ a coordinate positive tale che\n \u003e $y z_1 \\neq 0$. Supponiamo per assurdo che \\[ogni\\]{.underline}\n \u003e vettore $x \\in \\mathbb{R}^n$ a coordinate positive vale che\n \u003e $x z_1 = 0$. Scegliamo ora un qualsiasi vettore $y$ a coordinate\n \u003e positive $y_i \u003e 0$ per ogni $i = 1,...,n$. Per ogni\n \u003e $\\ell = 1,...,n$ indichiamo il vettore $y^{\\left\\[ \\ell \\right\\]}$\n \u003e nel segiente modo $$\n \u003e y^{\\left\\[ \\ell \\right\\]} = \\begin{cases}\n \u003e y_i \u0026\\mbox{se } i \\neq \\ell\\\\\n \u003e y_i + 1 \u0026\\mbox{se } i = \\ell\\\\\n \u003e \\\\end{cases}\n \u003e $$ Per esempio $$\n \u003e y^{\\left\\[ 3 \\right\\]} = (y_1, y_2, y_3+1, y_4, ..., y_n)\n \u003e $$ Dato che stiamo assumendo che per ogni vettore $x$ a\n \u003e coordinate positive $x z_1 = 0$, allora il seguente sistema è\n \u003e soddisfatto\n \u003e \n \u003e ````\n \u003e ```{=latex}\n \u003e \\begin{cases}\n \u003e    y \\cdot z_1 \u0026= 0\\\\\n \u003e    y^{\\left[ \\ell \\right]} \\cdot z_1 \u0026= 0\n \u003e \\end{cases}\n \u003e ```\n \u003e per ogni $\\ell = 1, ..., n$.\\\n \u003e Andando a risolvere il sistema avremo che\n \u003e \n \u003e ```{=latex}\n \u003e \\begin{cases}\n \u003e    y_1 \\cdot z_{11} +  y_2 \\cdot z_{12} + ... +  y_{\\ell} \\cdot z_{1\\ell} + ... +  y_n \\cdot z_{1n} \u0026= 0\\\\\n \u003e    (y_1 + 1) \\cdot z_{11} +  y_2 \\cdot z_{12} + ... +  y_{\\ell} \\cdot z_{1\\ell} + ... +  y_n \\cdot z_{1n} \u0026= 0\\\\\n \u003e    y_1 \\cdot z_{11} +  (y_2 + 1) \\cdot z_{12} + ... +  y_{\\ell} \\cdot z_{1\\ell} + ... +  y_n \\cdot z_{1n} \u0026= 0\\\\\n \u003e    \\vdots\\\\\n \u003e    y_1 \\cdot z_{11} +  y_2 \\cdot z_{12} + ... +  (y_{\\ell} + 1) \\cdot z_{1\\ell} + ... +  y_n \\cdot z_{1n} \u0026= 0\\\\\n \u003e    \\vdots\\\\\n \u003e    y_1 \\cdot z_{11} +  y_2 \\cdot z_{12} + ... +  y_{\\ell} \\cdot z_{1\\ell} + ... +  (y_n + 1) \\cdot z_{1n} \u0026= 0\n \u003e \\end{cases}\n \u003e ```\n \u003e \\\n \u003e \\\\begin{cases} \u0026y~1~ ċ z~11~ + \u0026y~2~ ċ z~12~ + ... + \u0026y~ℓ~ ċ\n \u003e z~1ℓ~ + ... + \u0026y~n~ ċ z~1n~ \u0026= 0\\\n \u003e \u0026z~11~ \u0026\u0026\u0026\u0026= 0\\\n \u003e \u0026\u0026z~12~ \u0026\u0026\u0026= 0\\\n \u003e \u0026\u0026⋮\u0026\u0026\u0026\\\n \u003e \u0026\u0026\u0026z~1ℓ~ \u0026\u0026= 0\\\n \u003e \u0026\u0026⋮\u0026\u0026\u0026\\\n \u003e \u0026\u0026\u0026\u0026z~1n~ \u0026= 0 \\\\end{cases}\n \u003e \n \u003e Ovvero in poche parole, per ogni vettore $x$ a cooridnate positive\n \u003e $x z_1 = 0$ se e soltanto se $z_1 = \\underline{0}$. Ma da prima\n \u003e sappiamo che $z_1 \\neq 0$, perciò deve necessariamente essere vero\n \u003e che esiste un vettore $y$ a coordinate positive tale che\n \u003e $y z_1 \\neq 0$.\n \u003e ````\n \u003e \n \u003e Parte 2\n \u003e \n \u003e :   In conclusione si vuole dimostrare che per ogni vettore $y$ a\n \u003e coordinate positive vale che $y z_1 \\neq 0$, quindi questo vale\n \u003e anche per $h^{(0)}z_1$ dato che $h^{(0)}$ è un vettore a\n \u003e coordinate positive.  \n \u003e Dalla parte precedente sappiamo che esiste almeno un vettore $y$ a\n \u003e coordinate positive tale che $y z_1 \\neq 0$. Scriviamo $y$ come\n \u003e combinazione lineare della base ortonormale composta dagli\n \u003e autovettori di $MM^T$. $$\n \u003e y = p_1z_1 + p_2z_2 + ... + p_nz_n\n \u003e $$\n \u003e \n \u003e ````\n \u003e Come già visto prima avremo che l\\'esressione\n \u003e $\\frac{(MM^T)^k y}{c_1^k}$ [converge]{.underline} a $p_1z_1$.\n \u003e Inoltre dato che $\\frac{(MM^T)^k y}{c_1^k}$ contiene solo\n \u003e coordinate [non negative]{.underline} avremo che anche $p_1z_1$\n \u003e avrà coordinate [non negative]{.underline}.\\\n \u003e Poiché sappiamo che $y z_1 \\neq 0$ e che $p_1 = y z_1$, allora\n \u003e $p_1 z_1$ avrà almeno una coordinata [strettamente\n \u003e positiva]{.underline}. Ovvero $z_1$ ha tutte coordinate non\n \u003e negative ($\\geq 0$) e almeno un positiva ($\u003e 0$).\n \u003e \n \u003e Consideriamo ora un qualsiasi altro vettore $x \\neq y$ a\n \u003e coordinate positive. Abbiamo che $$\n \u003e  x \\cdot z_1 = x_1z_{11} + x_2z_{12} + ... + x_nz_{1n} \\neq 0\n \u003e  $$ L\\'ultima uguaglianza è vera perché $x$ ha tutte coordinate\n \u003e positive mentre abbiamo dimostrato prima che $z_1$ ne\n \u003e [almeno]{.underline} una positiva $\\square$.\n \u003e ````\n\n## Considerazioni\n\nNel teorema precedente abbiamo dimostrato che la quantità\n$\\frac{h^{(k)}}{c_1^k}$ tende ad un vettore $z$ non nullo. L'abbiamo\ndimostrato solamente nel caso $c_1 \u003e c_2$, però con tecniche analoghe si\npuò dimostrare in qualsiasi caso generale.  \nIn poche parole, il precedente teorema ci dice che, nel caso in cui\n$c_1 \u003e c_2$, qualunque sia il vettore di hub iniziale $h^{(0)}$ purché a\ncoordinate **positive**, avremo che $\\frac{h^{(k)}}{c_1^k}$ convergerà\nal vettore $q_1 z_1$, dove $q_1 = h^{(0)}z_1$. Ciò significa che\ncomunque scegliamo un vettore di hub iniziale, esso convergerà ad un\naltro vettore **parallelo** all'autovettore $z_1$. Perciò la\nconvergenza del vettore di hub dipende \\[solamente\\]{.underline} dalla\nmatrice $M$.  \nRicapitolando, l'algoritmo `HITS` valuta la rilevanza di una pagina\npresente nel sottoinsieme di pagine inrenti alla ricerca rispetto a due\n\\[ruoli\\]{.underline}:\n\n* rispetto al ruolo di **autorità** che indica la rilevanza della\n  pagina rispetto alla ricerca, e tale quantità è determinata mediante\n  lo studio degli link **entranti** nella pagina.\n* rispetto al ruolo di **hub** che indica quanta rilevanza da tale\n  pagina alle pagine che essa punta, e tale quantità è invece\n  derminata mediante lo studio dei suo link **uscenti**.\n\nCiò significa che si può incorrere in situazioni in cui una pagina poco\nrilevante ai fini di una ricerca conferisca invece rilevanza ad altre\npagine.  \nIn poche parole l'intuizione alla base di *Hubs \u0026 Authorities* si basa\nsull'idea che le pagine svolgano molteplici ruoli nella rete e, in\nparticolare, che le pagine possano svolgere un potente ruolo di\n**approvazione** senza che esse siano fortemente sostenute. Perciò\nl'algotimo `HITS` se presta bene a modellare tutte quelle situazioni in\ncui le pagine sono naturalmente partizionate in due sottoinsiemi\n**semanticamente** distinti. Per esempio quando ricerchiamo degli\noggetti da comprare, le pagine dei rivenditori non si puntano a vincenda\nin quanto sono concorrenti: se si puntano allora si stanno dando\nrilevanza al concorrente. Viceversa, alcuni siti come eBay puntano ad\naltri rivenditori.\n\n---\n\n# Appendice\n\n## Autovalori e Autovettori\n\nData una matrice $A \\in \\mathbb{C}^{n \\times n}$, un vettore\n$x \\in \\mathbb{C}^n$ tale che $x \\neq \\overline{0}$ e un valore\n$\\lambda \\in \\mathbb{C}$, diremo che essi sono rispettivamente un\n**autovettore** e relativo **autovalore** della matrice $A$ se $$\nAx = \\lambda x\n$$ ovvero se $$\n(A - \\lambda I)x = 0\n$$\n\n## Base\n\nUna base per uno spazio vettoriale $\\mathbb{R}^n$ è un inseme di $n$\nvettori $z_1, ..., z_n \\in \\mathbb{R}^n$ tali che ogni altro vettore\n$x \\in \\mathbb{R}^n$ può essere espresso come una **combinazione\nlineare** della base, ovver $$\n\\\\forall x \\in \\mathbb{R}^n \\exists p \\in \\mathbb{R}^n : x = \\sum\\_{i = 1}^{n} p_i \\cdot z_i\n$$\n\n## Vettore Normale\n\nDato un vettore $z \\in \\mathbb{R}^n$ esso si dice **normale** se $$\nz \\cdot z = z_1^2 + z_2^2 + ... + z_n^2 = 1\n$$\n\n## Vettore Ortogonale\n\nDati due vettori $z_i,z_j \\in \\mathbb{R}^n$ essi si dice **ortogonali**\nse $$\nz_i \\cdot z_j = z\\_{i1}z\\_{j1} +  z\\_{i2}z\\_{j2} + ... +  z\\_{in}z\\_{jn} = 0\n$$\n\n## Base Ortonormale\n\nData una base $z = (z_1, ..., z_n) \\in \\mathbb{R}^{n \\times n}$ essa è\ndetta **ortonormale** se tutti i vettori sono normali e reciprocamente\nortogonali, ovvero se\n\n````{=latex}\n\\begin{align*}\n     \\forall i = 1, ..., n \u0026: z_i \\cdot z_i = z_{i1}^2 + z_{i2}^2 + ... + z_{in}^2 = 1\\\\\n     \\forall i \\neq j \u0026: z_i \\cdot z_j = z_{i1}z_{j1} +  z_{i2}z_{j2} + ... +  z_{in}z_{jn} = 0\n\\end{align*}\n````\n\n## Matrice Semidefinita Positiva\n\nUna matrice $A$ $n \\times n$ è detta **semidefinita positiva** se $$\n\\\\forall x \\in \\mathbb{R}^n : x^T A x \\geq 0\n$$\n\n## Teorema `A`\n\nSe $A$ è una matrice a valori \\[tutti reali\\]{.underline} e\n\\[simmetrica\\]{.underline}, ovvero $A = A^T$, allora $A$ avrà $n$\nautovalori ed $n$ autovettori reali e distinti, e inoltre tali\nautovalori formano una **base ortonormale** per $\\mathbb{R}^n$.\n\n## Teorema `B`\n\nSe $A$ è una matrice \\[semidefinita positiva\\]{.underline} allora:\n\n1. gli autovalori di $A$ sono \\[non negativi\\]{.underline}.\n1. se $A$ è non nulla, ovvero $A \\neq \\underline{0}$, allora $A$ avrà\n   almeno un autovalore $\\lambda \u003e 0$ \\[strettamente\n   positivo\\]{.underline}.\n\n## Teorema `C`\n\nSe $A$ ha solamente elementi \\[reali\\]{.underline}, allora $AA^T$ è un\nmatrice **simmetrica** e **semidefinita positiva**.\n\n---\n","lastmodified":"2022-08-29T13:39:16.950624594+02:00","tags":null},"/AR/19":{"title":"","content":"\n# PageRank\n\nMentre con l'algoritmo [HITS](./18.html) la rilevanza di una pagina\ndipende da quante pagine è putanta e a quante punta, esistono contesti\nin cui la rilevanza non dipende dal numero bensì dalla **qualità** dei\nlink. Ovvero ci sono situazioni in cui l'approvazione è vista come un\npassaggio diretto da una pagina importante ad un'altra. Per esempio, se\nun articolo `X` molto importante cita un articolo `Y`, allora `Y`\nprenderà rilevanza. Simmetricamente, se `X` cita molti articoli\nimportanti allora probabilmente il suo contenuto sarà rilevante per la\nricerca.  \nQuesto concetto è quello su cui si basa l'algoritmo **PageRank** per\ndeterminare la rilevanza delle pagine rispetto a una ricerca. Tale\nmodello prende il nome da [Larry\nPage](https://it.wikipedia.org/wiki/Larry_Page), fondatore di Google da\ncui il nome.  \nTale algoritmo è ancora una volta un metodo iterativo, basato però\nsull'analisi dei soli \\[link entranti\\]{.underline} in una pagina. Ovvero\nsolamente i link che puntano ad una pagina `X` saranno utili per\ndefinirne la sua rilevanza.  \nTale algoritmo parte dall'assunzione che nella porzione di rete\nattinente alla ricerca sia presente una unità di **flusso** inizialmente\ndistribuita in maniera equa fra tutti i nodi, ovvero se ci sono $n$\nallora inizialmente ognino possiede frazione $1/n$ di flusso.  \nIn maniera intutitva, durante le iterazioni dell'algoritmo, ogni nodo\nredistribuisce la propria frazione di flusso alle pagine che punta. Alla\nfine, dopo un certo numero di iterazioni, la pagina che avrà una\nfrazione più alta sarà quella più rilevante per la ricerca.  \nFormalmente indichiamo con $$\nf^{(0)}\\_i = \\frac{1}{n}\n$$ la quantità \\[iniziale\\]{.underline} di flusso del nodo $i$-esimo,\nper $i=1,...,n$.  \nAd ogni passo, ogni nodo redistribuisce la propria quantità di flusso\nlungo i suoi archi uscenti in maniera **uniforme**. Perciò avremo che $$\nf^{(k+1)}*i = \\sum*{1 \\leq j \\leq n :\\\\j \\rightarrow i} \\frac{f^{(k)}\\_j}{d^{(out)}\\_j}\n$$ dove $d^{(out)}\\_j$ indica il \\[grado uscente\\]{.underline} di $j$,\novvero il numero di nodi puntati da $j$ all'interno del sottografo\nindotto dalle sole pagine inerenti alla ricerca.  \nPer notazione indichiamo con $f^{(k)} = (f^{(k)}\\_1, ..., f^{(k)}\\_n)$ il\nvettore delle quantità di flusso degli $n$ al tempo $k$.\n\n \u003e \n \u003e Se il sottografo indotto dalle pagine attinenti alla ricerca è\n \u003e \\[fortemente connesso\\]{.underline} allora esiste ed è unico il limite\n \u003e $$\n \u003e \\\\lim\\_{k \\rightarrow \\infty} f^{(k)} = f^\\*\n \u003e $$\n\nSotto l'assunzione di connessione forte, è facile osservare che la\nquantità di flusso globale rimane sempre 1.  \nPossiamo quindi pensare al limite $f^*$ come una **configurazione di\nequilibrio** in cui $$\nf^**i = \\sum*{1 \\leq j \\leq n :\\\\j \\rightarrow i} \\frac{f^\\*\\_j}{d^{(out)}\\_j} ;;; \\forall i=1,...,n\n$$\n\n![Configurazione di equilibrio $f^\\*$ (porvare per\ncredere).](../images/ar-lesson19-img1.png){width=\"100%\"\nstyle=\"max-width: 500px;\"}\n\nOvviamente la condizione che il grafo sia fortemente connesso è\n**necessaria** per il correto funzionamento, in quanto se non fosse\nfortemente connesso tutto il flusso andrebbe a finire tutto in\n\\[componenti pozzo\\]{.underline}.  \nPerciò è necessario modificare opportunamente il PageRank per evitare\ntutto il flusso si accumuli in componenti pozzo. Una versione modificata\nè il noto **Scaled PageRank** nel quale ogni pagina\n\\[preserva\\]{.underline} un propria porzione di flusso per evitare che\ntutto si accumuli nei *\"vicoli ciechi\"*.  \nPiù precisamente, fissato un parametro $s \\in \\left\\[ 0,1 \\right\\]$, e ad\nogni iterazione:\n\n* una frazione $s$ del flusso di ogni nodo viene redistribuito\n  uniformemente sugli archi uscenti come nel PageRank calssico.\n* mentre la frazione rimanente $(1-s)$ di ciascun nodo viene\n  ridistribuita sul tutto il grafo in maniera uniforme.\n\nPercò, dato che il flusso globale di tutta la sottorete è sempre 1,\navremo che ad ogni iterazione ogni nodo riceverà una quantità di flusso\ndi \\[almeno\\]{.underline} $(1-s)/n$.  \nPer distiguere, indichiamo con $r^{(k)}\\_i$ la quantità di flusso\nposseduta dal nodo $i$ all'iterazione $k$ nello Scaled Page Rank.\nD'ora in avanti ci riferiremo ad esso con il termine di **rank**, e non\npiù di flusso.  \nLa formula ricorsiva per calcolare il rank di un nodo al tempo $k+1$ è\n\n````{=latex}\n\\begin{equation}\n  r^{(k+1)}_i = \\Big( \\sum_{1 \\leq j \\leq n :\\\\j \\rightarrow i} s \\cdot \\frac{r^{(k)}_j}{d^{(out)}_j} \\Big) + \\frac{1-s}{n}\n\\end{equation}\n````\n\nDato un vettore di ranking\n$r^{(k)} = (r^{(k)}\\_1, r^{(k)}\\_2, ..., r^{(k)}\\_n)$ la tempo $k$,\ndifiniamo con $N$ la matrice $n \\times n$ che descirve il processo\niterativo, ovvero tale che $$\nr^{(k+1)} = N r^{(k)}\n$$\n\nPer definizione la matrice $N$ è definita come segue $$\nN \\[ i,j \\] = \\begin{cases}\n\\\\frac{s}{d^{(out)}\\_j} + \\frac{1-s}{n} \u0026\\mbox{se } j \\rightarrow i\\\\\n\\\\frac{1-s}{n} \u0026\\mbox{altrimenti}\n\\\\end{cases} ;; \\forall 1 \\leq i,j \\leq n\n$$ Infatti avremo che il ranking $i$-esimo di $r^{(k+1)}$ sarà\n\n````{=latex}\n\\begin{align*}\n    r^{(k+1)} = \\sum_{j = 1}^{n} N [ i,j ] r^{(k)}_j \u0026= \\bigg( \\sum_{1 \\leq j \\leq n :\\\\ j \\rightarrow i} \\Big( \\frac{s}{d^{(out)}_j} + \\frac{1-s}{n} \\Big) r^{(k)}_j \\bigg) + \\bigg( \\sum_{1 \\leq j \\leq n :\\\\ j \\not\\to i} \\frac{1-s}{n}r^{(k)}_j \\bigg)\\\\\n    \u0026= \\bigg( \\sum_{1 \\leq j \\leq n :\\\\ j \\rightarrow i} \\frac{s}{d^{(out)}_j}r^{(k)}_j \\bigg) + \\bigg( \\sum_{j = 1}^{n} \\frac{1-s}{n}r^{(k)}_j \\bigg)\\\\\n    \u0026= \\bigg( \\sum_{1 \\leq j \\leq n :\\\\ j \\rightarrow i} \\frac{s}{d^{(out)}_j}r^{(k)}_j \\bigg) + \\frac{1-s}{n}\\underbrace{\\bigg( \\sum_{j = 1}^{n} r^{(k)}_j \\bigg)}_{\\scriptsize{\\mbox{tutto il flusso}}}\\\\\n    \u0026= \\bigg( \\sum_{1 \\leq j \\leq n :\\\\ j \\rightarrow i} \\frac{s}{d^{(out)}_j}r^{(k)}_j \\bigg) + \\frac{1-s}{n}\n\\end{align*}\n````\n\novvero la definizione data nell'eq. (1).  \nAnche in questo caso possiamo pensare al vettore $r^*$ che definisce una\n**configurazione di equilibrio**, ovvero tale che $$\nr^* = Nr^\\*\n$$\n\nOsserviamo che $r^\\*$ (se esiste) è un autovettore di $N$ con le seguenti\nproprietà:\n\n* il rispettivo autovalore è $\\lambda = 1$.\n* la somma degli elementi di $r^\\*$ è pari a 1.\n* ha tutti elementi \\[non negativi\\]{.underline}.\n* possibilmente che $r^\\*$ è l' \\[unico\\]{.underline} autovettore con\n  tali prorpietà (così da avere un unico punto di convergenza).\n\nMa chi ci assicura che tale autovettore (con relativo autovalore)\nesista?\n\n \u003e \n \u003e \\*Teorema di Perron\\*  \n \u003e Sia $A$ un matrice $n \\times n$ con valori \\[reali\n \u003e positivi\\]{.underline}, allora\n \u003e \n \u003e * $A$ ha un autovalore $c \\in \\mathbb{R}^+$ tale che\n \u003e   $c \u003e \\vert c' \\vert$ per ogni altro autovalore $c'$ di $A$.\n \u003e * l'autovettore di $A$ corrispondente a $c$ è \\[unico\\]{.underline}\n \u003e   ed ha elementi \\[reali positivi\\]{.underline} la cui somma è pari\n \u003e   a 1.\n\nLa nostra matrice $N$ rispetta tali condizioni, perciò possiamo\napplicare il teorema di *Perron* e dire che esiste una coppia\nautovalore-autovettore $(r^*, c)$ che rispetta le porprietà. Se\npotessimo anche essere certi $c = 1$ potremmo concludere che\n$r^* = N r^\\*$.  \nPer fortuna esiste un teorema che ci viene in salvo.\n\n \u003e \n \u003e \\*Teorema\\*  \n \u003e Sia $A$ una matrice stocastica, ovvero una matrice\n \u003e \\[quadrata\\]{.underline} $n \\times n$ la cui somma degli elementi su\n \u003e ciascuna riga (o colonna) è pari a 1. Allora $A$ ha un autovalore\n \u003e $\\lambda$ tale che $\\lambda = 1$ e $\\lambda$ è l'autovalore di\n \u003e \\[modulo massimo\\]{.underline}.\n\nOsserviamo che $N$ è una matrice stocastica per colonne. Infatti, poiché\nè vero che fissato un nodo $j$ avremo che $$\n\\\\sum\\_{1 \\leq i \\leq n :\\\\ j \\to i} \\frac{1}{d^{(out)}\\_j}\n$$ (convincersi di questo prima di proseguire) allora\n\n````{=latex}\n\\begin{align*}\n    \\sum_{1 \\leq i \\leq n} N [ i,j ] \u0026= \\Big( \\sum_{1 \\leq i \\leq n :\\\\ j \\to i} \\frac{s}{d^{(out)}_j} + \\frac{1 - s}{n} \\Big) + \\Big( \\sum_{1 \\leq i \\leq n :\\\\ j \\not\\to i} \\frac{1 - s}{n} \\Big)\\\\\n    \u0026= \\Big( \\sum_{1 \\leq i \\leq n :\\\\ j \\to i} \\frac{s}{d^{(out)}_j} \\Big) + \\Big( \\sum_{1 \\leq i \\leq n} \\frac{1 - s}{n} \\Big)\\\\\n    \u0026= s + (1-s) = 1\n\\end{align*}\n````\n\nIn conclusione per il teorema di *Perron* e per quello sulle matrici\nstocastiche averemo che l'algoritmo Scaled PageRank converge ad un\n**punto fisso** $r^\\* = Nr^\\*$.\n\n \u003e \n \u003e \\*Esempio Matrice Stocastica\\*  \n \u003e $$N = \\left \\[\n \u003e \\\\begin{array}{ccc}\n \u003e \\\\frac{1-s}{3} \u0026 \\frac{s}{2} + \\frac{1-s}{3} \u0026 s +\\frac{1-s}{3}\\\\\n \u003e s + \\frac{1-s}{3} \u0026 \\frac{1-s}{3} \u0026 \\frac{1-s}{3}\\\\\n \u003e \\\\frac{1-s}{3} \u0026 \\frac{s}{2} + \\frac{1-s}{3} \u0026 \\frac{1-s}{3}\n \u003e \\\\end{array}\n \u003e \\\\right \\]$$\n \u003e \n \u003e ![Sottografo indotto dalle pagine inerenti alla\n \u003e ricerca](../images/ar-lesson19-img2.png){width=\"100%\"\n \u003e style=\"max-width: 250px;\"}\n\n# PageRank e Random Walk\n\nAbbiamo visto concettualmente che l'idea dietro al PageRank è quella di\navere una sorta di fluido che *\"scorre\"* tra le pagine individuate\nessere inerenti alla ricerca.  \nEsiste una relazione tra questo concetto di fluido e le cosidette\n**Random Walk**, o **percorso aleatorio**. Una Random Walk funziona\nnella seguente maniera:\n\n* dato un grafo $G$ scegliamo \\[uniformemente a caso\\]{.underline} un\n  nodo $u$ da cui iniziare il percorso.\n* al passo successivo passiamo da $u$ ad uno dei suoi vicini in\n  maniera del tutto \\[uniforme\\]{.underline}.\n* e così via...\n\nCerchiamo di calcolare la probabilità di trovarsi su di un dato nodo $i$\ndopo una random walk lunga $k$ passi. Più formalmente, per ogni\n$i \\in V$ indichiamo con $w^{(k)}\\_i$ la v.a. binaria che:\n\n* vale 1 se dopo $k$ passi del random walk ci troviamo esattamente sul\n  nodo 1.\n* 0 altrimenti.\n\nScegliendo il primo noto della random walk in maniera uniforme avremo\nche $$\n\\\\mathcal{P}(w^{(0)}\\_i = 1) = \\frac{1}{n} = f^{(0)}\\_i\n$$\n\nAl tempo $k = 1$ avremo invece che la probabilità che il cammino\naleatoria finisca sul nodo $i$ è pari alla probabilità che un suo vicino\n$j$ sia il nodo iniziale del cammino, moltiplicata per la probabilità\nche $j$ si passi esattamente ad $i$.\n\n````{=latex}\n\\begin{align*}\n    \\mathcal{P}(w^{(1)}_i = 1) \u0026= \\sum_{j \\in V:\\\\ j \\to i} \\left( \\mathcal{P}(w^{(0)}_j = 1) \\cdot \\frac{1}{d^{(out)}_j} \\right)\\\\\n    \\sum_{j \\in V:\\\\ j \\to i} \\frac{f^{(0)}_j}{d^{(out)}_j} = f^{(1)}_i\n\\end{align*}\n````\n\nIn maniera induttiva per ogni $k \u003e 0$\n\n````{=latex}\n\\begin{align*}\n    \\mathcal{P}(w^{(k+1)}_i = 1) \u0026= \\sum_{j \\in V:\\\\ j \\to i} \\left( \\mathcal{P}(w^{(k)}_j = 1) \\cdot \\frac{1}{d^{(out)}_j} \\right)\\\\\n    \\sum_{j \\in V:\\\\ j \\to i} \\frac{f^{(k)}_j}{d^{(out)}_j} = f^{(k+1)}_i\n\\end{align*}\n````\n\nOvvero la quantità di flusso del nodo $i$ dopo $k$ iterazioni e pari\nalla probabilità di finire esattamente sul nodo $i$ dopo $k$ passi del\nrandom walk.  \nConsideriamo una versione \"scalata\" del random walk per lo *Scaled\nPageRank*. Le regole di questa versione di random walk sono:\n\n* fissare un parametro $s \\in \\[ 0,1 \\]$.\n* scegliere \\[uniformemente a caso\\]{.underline} un nodo iniziale $u$ da\n  cui partire.\n* da $u$:\n  * con probabilità $s$ proseguiamo la random walk, ovvero scegliamo\n    \\[uniformemente a caso\\]{.underline} un suo vicino su cui\n    avviarci.\n  * con probabilità $1 - s$ rincominciamo la random walk, ovvero\n    scegliamo \\[uniformemente a caso\\]{.underline} un altro nodo del\n    grafo da cui iniziare.\n* e così via...\n\nPper ogni nodo $i \\in V$ indichiamo con $\\omega^{(k)}\\_i$ la v.a. binaria\nche:\n\n* vale 1 se dopo $k$ passi del random walk ci troviamo esattamente sul\n  nodo 1.\n* 0 altrimenti.\n\nCome prima abbiamo che $$\n\\\\mathcal{P}(\\omega^{(0)}\\_i = 1) = \\frac{1}{n} = r^{(0)}\\_i\n$$ per $k = 1$\n\n````{=latex}\n\\begin{align*}\n    \\mathcal{P}(\\omega^{(1)}_i = 1) \u0026= s \\cdot \\Big( \\sum_{j \\in V:\\\\ j \\to i} \\mathcal{P}(\\omega^{(0)}_j = 1) \\cdot \\frac{1}{d^{(out)}_j} \\Big) + (1-s) \\cdot \\frac{1}{n}\\\\\n    \u0026= \\sum_{j \\in V:\\\\ j \\to i} \\Big( s \\cdot \\frac{r^{(0)}_j}{d^{(out)}_j} \\Big) + \\frac{1 - s}{n}\\\\\n    \u0026= r^{(1)}_i\n\\end{align*}\n````\n\ne quindi più in generale\n\n````{=latex}\n\\begin{align*}\n    \\mathcal{P}(\\omega^{(k+1)}_i = 1) \u0026= s \\cdot \\Big( \\sum_{j \\in V:\\\\ j \\to i} \\mathcal{P}(\\omega^{(k)}_j = 1) \\cdot \\frac{1}{d^{(out)}_j} \\Big) + (1-s) \\cdot \\frac{1}{n}\\\\\n    \u0026= \\sum_{j \\in V:\\\\ j \\to i} \\Big( s \\cdot \\frac{r^{(k)}_j}{d^{(out)}_j} \\Big) + \\frac{1 - s}{n}\\\\\n    \u0026= r^{(k+1)}_i\n\\end{align*}\n````\n\nOvvero lo scaled rank di una pagina $i$ dopo $k$ iterazioni\ndell'algoritmo *Scaled PageRank* equivale alla probabilità di trovarsi\nesattamente sul nodo $i$ dopo $k$ passi di questo scaled random walk.\n\n# Modern Web Search\n\nL'enorme crescita del Web, in termini di numero di pagine e numero di\nargomenti trattati, ha richiesto col tempo di raffinare le vecchie\ntecniche di link analysis e web search. Una tecnica è quella di\nanalizzare i link combinando il **contenuto** delle pagine, come per\nesempio usando gli **anchor text**, ovvero delle parole chiave che\ndescrivono in qualche maniera il contenuto di un link. Oppure ancora\nconsiderando con quale frequenza o quante volte una pagina viene\neffettivamente aperta.  \nSpesso ci sono anche motivi commerciali per cercare di apparire primi\nnei ranking di una ricerca. Infatti è nata una vera e propria industria\ndietro le tecniche di ranking. Da una parte ci sono i web designer che\ncercano di comprendere gli algoritmi di ranking usati dai motori di\nricerca, e cercano un modo per poterli sfruttare a loro vantaggio.\nD'altra parte ci sono i progettisti di motori di ricerca che vengono\nindotti nel cercare di modificare è migliorare i propri algoritmi di\nranking. Ecco perché gli algoritmi di ranking effettivi vengono spesso\ntenuti segreti.\n\n---\n","lastmodified":"2022-08-29T13:39:16.80841043+02:00","tags":null},"/AR/2-Power-Law":{"title":"","content":"\n\n \u003e \n \u003e In questa pagina sono riportati gli appunti delle lezioni 2 e 3, essendo tali lezioni strettamente correllate.\n\n# Power Law\n\nNella [lezione 1](1%20-%20Erdos-Renyi%20Random%20Graph.md) si è visto che in un *Erdős-Rény random graph* il numero di nodi che hanno grado esattamente $k$ decresce *esponenzialmente* in $k$.\nPer comprendere meglio il perché di questo andamento è necessario enunciare (quantomeno in maniera informale e intuitiva) il [teorema del limite centrale](https://en.wikipedia.org/wiki/Central_limit_theorem).\n\n \u003e \n \u003e **Teorema del limite centrale**\n \u003e Siano $X_1, X_2, ..., X_n$ una sequenza di $n$ variabili aleatorie **indipendenti** e **identicamente distribuite**, con *valore atteso* $\\mu$ e *varianza* $\\sigma^2 \\\u003c \\infty$.\n \u003e Consideriamo la semplice media aritmetica \n \u003e $$\\overline{X}*n \\equiv \\frac{ X_1 + X_2 + ... + X_n }{n}$$ovviamente con valore atteso che tende a $\\mu$ per $n \\rightarrow \\infty$.\n \u003e Il teorema dice che\n \u003e $$\\lim*{n \\rightarrow \\infty} \\sqrt{n} \\left( \\overline{X}\\_n - \\mu \\right) = \\mathcal{N}(0, \\sigma^2)$$\n \u003e In termini più intuitivi si può interpretare questo enunciato come segue: la somma di *tante* variabili aleatorie indipendenti e identicamente distribuite si distribuisce come una [distribuzione normale](https://en.wikipedia.org/wiki/Normal_distribution) intorno al valore atteso.\n \u003e \n \u003e ## ![Esempio distribuzione Normale|400](ar-lesson02-img1.png)\n\nQuesto teorema è utile a comprendere il fenomeno interessato in quanto il numero di nodi di grado $k$ in un *Erdős-Rény random graph* è proprio una **somma** di v.a. *i.i.d.*[^1], in quanto ogni arco è aggiunto in maniera totalmente indipendete ed equamente distribuita rispetto agli archi.\n\nNella realtà però si sono osservati fenomeni **sostanzialmente** differenti.\n\nConsideriamo il grafo di informazioni del *web*: possiamo modellarlo tramite un grafo **diretto** dove ogni nodo rappresenta un pagina, ed esiste un arco diretto $(a,b)$ se nella pagine $a$ c'è un iper-link alla pagina $b$.\n\nIn uno studio fatto[^2] si è osservato che la frazione di nodi con *grado entrante* $k$ decresce come $k^{-c}$ (per qualche costante\n$c \u003e 0$), e non come $k^{-k}$.\n\nUna funzione che decresce in questa maniera, ovvero come l'*inverso di un polinomio*, è detta **power law**. Un'altra definizione più formale è la seguente:\n\n \u003e \n \u003e **def. Power Law:** siano le costanti $C \u003e 0$ ed $\\alpha \u003e 1$. Una **legge di potenza** (o **power law**) è una funzione prporzionale a $C x^{-\\alpha}$.\n\nIl fatto che in una rete reale (come il web) il numero di nodi di grado alto decresca decisamente **molto** più lentamente rispetto a quanto ci si aspetta nel modello *Erdős-Rény*, implica che non è del tutto appropriato considerare l'esistenza di un arco *indipendente* rispetto agli altri.\n\n## Riconoscere una power law\n\nNon è sempre scontato il riconoscere a vista una funzione power law rispetto a una funzione che decresce esponenzialmente.\nPer fare ciò è necessario considerare un grafico di tipo **log-log**, ovvero dove i *tick*[^3] degli assi crescono esponenzialmente.\n\nAll'atto pratico, invece di considerare la funzione $y = f(x)$, verrà mostrata la funzione $\\log{(y)} = \\log{\\left( f(x) \\right)}$.\n\n![Esempio di scala *lineare* (a sinistra) e scala *log-log* (a destra)|600](ar-lesson02-img2.png)\n\nCome si può notare nell'immagine precedente, è difficile stabilire ad occhio quale delle due funzioni è power law. Invece, con la scala *log-log*, la funzione power law assume un andamento lineare.\nQuesto perché $\\log{(y)} \\approx -c \\log{(k)}$.\n\n---\n\n# Fenomeno *rich-get-richer*\n\nUno dei fenomi più noti nelle reti è il cosidetto fenomeno *rich-get-richer*.\nUn esempio reale che spiega questo fenomeno è il seguente:\n\n \u003e \n \u003e In questo momento sto scrivendo queste note riguardo la scorsa lezione della professoressa Di Ianni.\n \u003e A un certo punto ho citato il teorema del limite centrale, mettendo un hyper-link alla relativa pagina wikipedia.\n \u003e Il teorema del limite centrale è un teorema che fa parte della \"letteratura classica\" del calcolo delle probabilità, perciò su internet si possono trovare **milioni** di pagine che lo descrivono.\n \u003e Già solo cercando col motore di ricerca di google la parola `central limit theorem` vengono riportati più di 33 milioni di pagine inerenti.\n \u003e Allora perché ho scelto proprio la pagina di wikipedia, piuttosto che l'ultima delle 33 milioni indicizzate da google?\n \u003e Semplice, ho puntato alla pagina che risultasse \"più autorevole\", ovvero quella che so essere più indicizzata rispetto all'ultima povera pagina delle 33 milioni.\n\nPerciò, se consideriamo il grado entrante di una pagina web come il numero di hyper-link che la puntano, avremo che sulla base del precedente ragionamento, il grado della pagina del teorema del limite centrale di wikipedia tenderà sempre di più a crescere rispetto all'ultima pagina[^4] indicizzata da google.\n\nTutto questo implica che nel grafo del web l'esistenza di un arco **dipende** dall'esistenza di altri archi.\n\nUn altro esempio concreto del fenomeno *rich-get-richer* avviene nelle reti sociali di un social network: se una persona è famosa ed ha molti follower tenderà a diventare sempre più popolare.\n\n## Un modello per *rich-get-richer*\n\nSi vuole descrivere un modello secodno il quale la scelta di un nuovo arco da aggiungere si basa sull'esistenza degli archi già presenti, in modo tale che gli individui tendano a \"copiare\" il comportamento degli altri.\nVerrà proposto un **processo incrementale** di creazione di una rete che rispecchia le seguenti proprietà, simile alla creazione del web:\n\n1. i nodi vengono generati in sequenza\n1. ogni volta che viene inserito un nuovo nodo si decide quali archi inserire sulla base di quelli già presenti\n\n### Procedura per la generazione\n\nFissata una probabilità $p \\in \\left\\[ 0,1 \\right\\]$, vengono eseguite le seguenti operazioni in maniera sequenziale:\n\n1. Al tempo $t=1$ viene inserito il solo nodo $1$.\n1. Al tempo $t=2$ viene inserito il nodo $2$ e l'arco diretto $(2,1)$.\n1. Al generico passo $t = i \u003e 2$ viene inserito il nodo $i$, scelto *u.a.r.*[^5] un nodo $j \\in \\left\\[ i-1 \\right\\]$ tra quelli già esistenti, e\n   * con probabilità $p$ viene inserito l'arco diretto $(i,j)$\n   * con probabilità $1-p$ viene inserito l'arco $(i,k)$, dove $k$ è l'estremo dell'arco $(j,k)$ (ovvero il nodo puntato da $j$)\n\n \u003e \n \u003e **n.b.** se dovesse capitare di scegliere il nodo $j=1$, esso viene considerato essere *autoreferenziato*, ovvere si considera la presenza dell'arco $(1,1)$ (per questioni di consistenza del processo).\n\nIntuitivamente questo processo genera un grafo che cattura il fenomeno *rich-get-richer*: è molto più probabile che un nuovo arco inserito punti a un nodo con grado entrante alto.\nSi osservi inoltre che ogni nodo ha *esattamente* un arco uscente.\n\n### Verifica correttezza\n\nBisogna ora da verificare che il modello precedentemente descritto rispetti una *power-law*: ovvero se il numero di nodi con grado $k$ decresce come l'inversa di un polinomio in $k$.\n\nPer prima cosa definiamo la v.a. binaria $\\delta\\_{i,j}$ che vale 1 se esiste l'arco $(i,j)$, 0 altrimenti $$\n\\\\delta\\_{i,j} = \\begin{cases}\n1 \u0026\\mbox{se } (i,j) \\in E\\\\\n0 \u0026\\mbox{altrimenti}\n\\\\end{cases}\n;;; \\forall i \u003e j\n$$\nPerciò la probabilità che esista un arco diretto $(i,j)$ può essere calcolata come segue\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\delta\\_{i,j} = 1)\n\u0026= p \\cdot \\mathcal{P}\\left( \\mbox{viene scleto } j \\right) + (1-p) \\cdot \\mathcal{P}\\left( \\mbox{scelgo un nodo } h : \\delta\\_{h,j} = 1 \\right)\\\\\n\u0026= \\frac{p}{i-1} + (1-p)\\mathcal{P} \\Big( \\bigcup\\_{h \\\u003c i : (h,j) \\in E} \\mbox{viene scleto } h \\Big)\\\\\n\\\\textbf{(1)}\u0026= \\frac{p}{i-1} + (1-p)\\sum\\_{h \\\u003c i : (h,j) \\in E} \\mathcal{P} \\left( \\mbox{viene scleto } h \\right)\\\\\n\\\\textbf{(2)}\u0026= \\frac{p}{i-1} + \\frac{(1-p)}{i-1} \\sum\\_{h \\\u003c i : (h,j) \\in E} 1\\\\\n\u0026= \\frac{p}{i-1} + \\frac{(1-p)}{i-1} \\sum\\_{1 \\leq h \\\u003c i} \\delta\\_{h,j} \n\\\\end{align\\*}\n$$\n\ndove:\n\n* **(1)** la probabilità dell'unione di eventi *disgiunti* è pari alla somma delle loro probabilità.\n* **(2)** la probabilità di scegliere un nodo $h \\\u003c i$ è equamente distribuita come $\\frac{1}{i-1}$.\n\nFacciamo una considerazione: dato che ogni nodo $i \u003e 2$ ha esattamente un arco uscente, deve essere necessariamente vero che $$\n\\\\mathcal{P}(\\exists j \\\u003c i : (i,j) \\in E ) = 1\n$$ Infatti $$\n\\\\mathcal{P}(\\exists j \\\u003c i : (i,j) \\in E ) = \\sum\\_{1 \\leq j \\\u003c i} \\mathcal{P}( (i,j) \\in E )\n$$ Questo si può dimostrare per induzione su $i$:\n\n* per $i = 2$ avremo che $$\n  \\\\sum\\_{1 \\leq j \\\u003c 2} \\mathcal{P}( (2,j) \\in E ) = \\mathcal{P}( (2,1) \\in E ) = 1\n  $$ e questo è vero **per costruzione**.\n* supponiamo sia vero per $i \\leq k - 1$, per $i = k$ avremo che\n\n$$\n\\\\begin{align\\*}\n\\\\sum\\_{1 \\leq j \\\u003c i} \\mathcal{P}( (i,j) \\in E )\n\u0026= \\sum\\_{1 \\leq j \\\u003c i} \\left\\[ \\frac{p}{i-1} + \\frac{(1-p)}{i-1} \\sum\\_{1 \\leq h \\\u003c i} \\delta\\_{h,j}  \\right\\]\\\\ \n\u0026= \\sum\\_{1 \\leq j \\\u003c i} \\frac{p}{i-1} + \\sum\\_{1 \\leq j \\\u003c i} \\Big( \\frac{(1-p)}{i-1} \\sum\\_{1 \\leq h \\\u003c i} \\delta\\_{h,j} \\Big) ;;; \\mbox{spezzo la serie}\\\\\n\u0026= \\frac{(i-1)p}{i-1} + \\frac{(1-p)}{i-1} \\sum\\_{1 \\leq j \\\u003c i} \\sum\\_{1 \\leq h \\\u003c i} \\delta\\_{h,j}\\\\\n\u0026= p + \\frac{(1-p)}{i-1} \\sum\\_{1 \\leq h \\\u003c i} \\underbrace{ \\sum\\_{1 \\leq j \\\u003c i} \\delta\\_{h,j} }*{h \\scriptsize{\\mbox{ ha 1 solo arco uscente}}} ;;; \\mbox{inverto le due serie}\\\\\n\u0026= p + \\frac{(1-p)}{i-1} \\sum*{1 \\leq h \\\u003c i} 1\\\\\n\u0026= p + \\frac{(1-p)}{i-1}(i-1)\\\\\n\u0026= p + (1 - p) = 1\n\\\\end{align\\*}\n$$\n\nSiamo ora pronti a verificare la reale presenza di una *power law*.\nQuesto procedimento avverrà in 4 fase:\n\n1. Definizione di una legge aleatoria che esprima la variazione del grado (entrante) di un nodo nel tempo.\n1. Approssimazione **deterministica** e **continua** della legge.\n1. Risoluzione di una *equazione differenziale* che calcola il valore di tale approssimazione.\n1. Individuazione di una *power law*.\n\n#### 1 - Legge aleatoria\n\nSia la *v.a. discreta* $D_j(t)$ che esprima il grado entrante del nodo $j$ al tempo $t$ del processo di generazione del grafo.\nSi osservi che $D_j(t)$ è difinita **solamente** per $t \\geq j$, e che $D_j(j) = 0$ per ogni $j$ (per costruzione).\n\nRitornando alla variazione del grado entrante nel tempo, possiamo dire che dal tempo $t$ al tempo $t+1$ esso potrà essere aumentato di **al più** una unità.\nPerciò possiamo esprimere la variazione nel tempo del grado entrante del nodo $j$ come la differenza $D_j(t+1) - D_j(t)$.\n\nPossiamo quindi calcolare la probabilità che il grado del nodo $j$ aumenti di 1 come\n\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(D_j(t+1) - D_j(t) = 1) \u0026= \\mathcal{P}(\\delta\\_{t+1, j} = 1)\\\\\n\u0026= \\frac{p}{(t+1)-1} + \\frac{(1-p)}{(t+1)-1} \\sum\\_{1 \\leq h \\\u003c (t+1)} \\delta\\_{h,j}\\\\\n\u0026= \\frac{p}{t} + \\frac{(1-p)}{t}D_j(t)\n\\\\end{align\\*}\n$$\n\n#### 2 - Approssimazione deterministica e continua\n\nStabilita la legge $\\mathcal{P}(D_j(t+1) - D_j(t) = 1) = \\frac{p}{t} + \\frac{(1-p)}{t}D_j(t)$, la si vuole approssimare.\nQuesto perché generalmente le leggi *discrete* e *probabilistiche* sono troppo complesse da analizzare.\n\nPer prima cosa si può rimuovere il fattore aleatorio e renderla deterministica con la seguente approssimazione\n\n$$\n\\\\begin{cases}\nX_j(j) = 0\\\\\n\\\\\nX_j(t+1) - X_j(t) = \\frac{p}{t} + \\frac{(1-p)}{t}X_j(t)\n\\\\end{cases}\n$$  \n$\\forall t \\geq j$.\n\nLa seconda approssimazione da fare è passare dal *discreto* al *continuo*\n\n$$\n\\\\begin{cases}\nx_j(j) = 0\\\\\n\\\\\n\\\\frac{d}{dt}x_j(t) = \\frac{p}{t} + \\frac{(1-p)}{t}x_j(t)\n\\\\end{cases}\n$$  \nNon è detto che questa approssimazione si avvicini alla legge reale.\nNotare in fine che la seconda equazione del sistema è una *equazione differenziale*[^6].\n\n#### 3 - Risoluzione equazione differenziale\n\nSi vuole risolvere la seguente eq. differenziale $\\frac{d}{dt}x_j(t) = \\frac{p}{t} + \\frac{(1-p)}{t}x_j(t)$.\nPer prima cosa si può raccogliere il fattore $1/t$\n$$ \\frac{d}{dt}x_j(t) = \\frac{1}{t} \\left\\[ p + (1-p)x_j(t) \\right\\] $$\ne poi dividendo entrambi i membri per $\\left\\[ p + (1-p)x_j(t) \\right\\]$\n$$ \\frac{1}{p + (1-p)x_j(t)}  \\frac{d}{dt}x_j(t) = \\frac{1}{t} $$\n\nA questo punto si può procedere integrando in $dt$ $$\n\\\\int \\frac{1}{p + (1-p)x_j(t)}  \\frac{d x_j(t)}{dt} , dt = \\int \\frac{dt}{t}\\\\\n\\\\\n\\\\int \\frac{d x_j(t)}{p + (1-p)x_j(t)} = \\int \\frac{dt}{t}\n$$\nMoltiplichiamo entrambi i membri per $(1-p)$\n$$ \\int \\frac{(1-p) d x_j(t)}{p + (1-p)x_j(t)} = (1-p) \\int \\frac{dt}{t} $$\nPoniamo poi $y = p + (1-p)x_j(t)$. La derivata di $y$ sarà\n$$ y' = \\frac{dy}{dx_j(t)} = (1-p)$$\novvero il numeratore della frazione nel primo integrale.\n$$\\int \\frac{y'}{y} , dx_j(t) = (1-p) \\int \\frac{dt}{t}$$\nIl quale si può semplificare come\n$$\\int \\frac{y'}{y} , dx_j(t) =  \\int \\frac{\\frac{dy}{dx_j(t)}}{y} , dx_j(t) = \\int \\frac{dy}{y}$$\n\nAdesso che è rimasto solo il fattore $y$ al primo membro, risostituiamo col valore origianle\n$$\\int \\frac{dy}{y} = \\int \\frac{d \\left\\[p + (1-p) x_j(t) \\right\\]}{p + (1-p)x_j(t)} = (1-p) \\int \\frac{dt}{t}$$ A questo punto è facile integrare, ottenendo che\n$$\\ln{\\left( p + (1-p) x_j(t) \\right)} = (1-p) \\ln{(t)} + c$$\nDa cui poi elevando a potenza\n$$p + (1-p) x_j(t) = t^{1-p} \\cdot e^c = C \\cdot t^{1-p}$$\n\nPer calcolare la costante $C$ basta considerare la condizione iniziale per cui $x_j(j) = 0$, ottenendo che\n$$p = C \\cdot j^{1-p} \\implies C = \\frac{p}{ j^{(1-p)} }$$\n\nConcludendo che\n$$\n\\\\begin{align\\*}\np + (1-p) x_j(t) \u0026= C \\cdot t^{1-p}\\\\\np + (1-p) x_j(t) \u0026= t^{1-p} \\cdot e^c = \\frac{p}{ j^{(1-p)} } \\cdot t^{1-p} = p \\left( \\frac{t}{j}  \\right)^{1-p}\\\\\n(1-p) x_j(t) \u0026= p \\left\\[ \\left( \\frac{t}{j} \\right)^{1-p} - 1 \\right\\]\\\\\nx_j(t) \u0026= \\frac{p}{1-p} \\left\\[ \\left( \\frac{t}{j}  \\right)^{1-p} - 1 \\right\\]\n\\\\end{align\\*}\n$$\n\n#### 4 - Individuazione Power Law\n\nDati quindi dei valori di $k$ e $t$, cerchiamo di calcolare quanto vale la frazione di nodi che al tempo $t$ ha esattamente grado entrante $k$.\nPer fare ciò iniziamo col definire l'insieme $A_t(k) = \\lbrace j \\leq t : x_j(t) \\geq k \\rbrace$, ovvero l'insieme dei nodi che hanno grado entrante **almeno** $k$ (secondo la nostra approssimazione continua e deterministica).\n\nPerciò la frazione dei nodi con grado $k$ sarà la differenza tra il numero di nodi con grado \u003cu\u003ealmeno\u003c/u\u003e $k$ e il numero di nodi con grado \u003cu\u003ealmeno\u003c/u\u003e $k+1$, fratto il numero di nodi inseriti fino al tempo $t$ (che ovviamente equivale a $t$).\n$$\\frac{1}{t} | A_t(k) - A_t(k+1) | = \\frac{1}{t} \\left( |A_t(k)| + |A_t(k+1)| \\right)$$\n\nPer definizione quindi un nodo $j$ appartiene all'insieme $A_t(k)$ se e solo se $j \\leq t$ e $x_j(t) \\leq k$.\nMa sappiamo dalla precedente eq. differenziale che $x_j(t) = \\frac{p}{1-p} \\left\\[ \\left( \\frac{t}{j}  \\right)^{1-p} - 1 \\right\\]$, perciò $x_j(t) \\geq k$ se e solo se $\\frac{p}{1-p} \\left\\[ \\left( \\frac{t}{j} \\right)^{1-p} - 1 \\right\\] \\geq k$.\n\nRisolvendo questa disequazione per trovere i valori di $j$ che rispettano la disuguaglianza\n$$\n\\\\begin{align\\*}\n\\\\frac{p}{1-p} \\left\\[ \\left( \\frac{t}{j}  \\right)^{1-p} - 1 \\right\\] \u0026\\geq k\\\\\n\\\\left( \\frac{t}{j}  \\right)^{1-p} - 1 \u0026\\geq k\\frac{1-p}{p}\\\\\n\\\\left( \\frac{t}{j}  \\right)^{1-p} \u0026\\geq k\\frac{1-p}{p} + 1\\\\\n\\\\frac{t}{j} \u0026\\geq \\left\\[ k\\frac{1-p}{p} + 1 \\right\\]^{ \\frac{1}{1-p} }\\\\\nj \u0026\\leq t \\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} }\n\\\\end{align\\*}\n$$\n\nSi osservi che poichè $k \\frac{1-p}{p} + 1$ è maggiore di 1 e l'esponente $- \\frac{1}{1-p}$ è minore di 0, è vero che\n$$\\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} } \\leq 1 \\implies t \\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} } \\leq t$$\nRiformulando l'affermazione di prima, il nodo $j$ appartiene all'insieme $A_t(k)$ se e soltanto se $j \\leq t \\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} }$.\n\nPerciò possiamo riformulare anche la definizione dell'insieme $A_t(k)$ come\n$$A_t(k) := \\bigg{ j \\leq t \\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} }  \\bigg} $$\nil quale avrà cardinalità esattamente\n$$|A_t(k)| =  t \\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} }$$\nPer comodità definiamo la funzione $F(k) = \\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} }$.\n\nPerciò la quantità che vogliamo calcolare al possiamo riscrivere come\n$$\\frac{1}{t} \\left( |A_t(k)| + |A_t(k+1)| \\right) = F(k) - F(k+1) = f(k)$$\n\nA questo punto possiamo *approssimare* $f(k)$ come la derivata $-\\frac{d}{dk}F(k)$.\nSe il segno \"`-`\" confonde, con la seguente equazione apparirà più chiaro\n$$\nF(k) - F(k+1)\n= \\frac{(-1)}{(-1)} \\left( F(k) - F(k+1) \\right)\n= - \\left( - \\frac{ F(k) - F(k+1) }{1} \\right)\n= - \\left( \\frac{ F(k+1) - F(k) }{1} \\right)\n\\\\approx -\\frac{d}{dk}F(k)\n$$\n\nAssodata questa approssimazione, si può procedere derivando[^7] in $k$.\n\n$$\n\\\\begin{align\\*}\nf(k) \u0026\\approx -\\frac{d}{dk} F(k)\\\\\n\u0026= - \\left( \\frac{1}{1 - p} \\right)\n\\\\cdot \\left( \\frac{1-p}{p} \\right)\n\\\\cdot \\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\frac{1}{1-p} - 1 }\\\\\n\u0026= \\frac{1}{p} \\cdot\n\\\\left\\[ k \\frac{1-p}{p} + 1 \\right\\]^{ - \\left( 1 + \\frac{1}{1-p} \\right) }\n\\\\end{align\\*}\n$$\n\nTale funzione è l'inversa di un polinomio in $k$ con esponente massimo $\\left( 1 + \\frac{1}{1-p} \\right)$, e in quanto tale è una *power-law*.\n\n---\n\n### Osservazioni sull'analisi\n\nIn realtà l'approssimazione continua e deterministica fatta per analizzare la correttezza della procedura di generazione del modello potrebbe discostarsi molto dal valore effettivo, ovvero quello descritto in maniera discreta e probabilistica.\n\nIn realtà è stato dimostrato[^8] che *w.h.p.*[^9] nel modello di rete per *rich-get-richer* proposto, la frazione di nodi con grado $k$ è proporzionale a $k^{- \\left(1 + \\frac{1}{1-p} \\right)}$.\n\n---\n\n# Impredicibilità della popolarità\n\nDa come è stato definito il modello per *rich-get-richer* in precedenza, viene subito da pensare che la distribuzione dei gradi dipende *fortemente* dalla fase iniziale del processo di generazione.\n\nC'è un esperimento di [Salganik-Dodds-Watts](https://www.princeton.edu/~mjs3/salganik_dodds_watts06_full.pdf) del 2006 che mostra quanto è importante e instabile la fase iniziale.\n\n \u003e \n \u003e Venne creato un sito era possibile ascoltare e scaricare delle canzoni tra circa 50 proposte. C'erano inoltre 8 playlist, ognunga delle quali contente tutte le canzoni del sito.\n \u003e Per ogni playlist, veniva mostrato un *contatore dei download* delle canzoni internamente alla playlist: se la canzone `X` veniva scaricata dalla playlist `A`, quel download veniva contato e riportato solo per `A`, e non per un'altra playlist `B`.\n \u003e Quando chiunque entrava nel sito, veniva riportato automaticamente a una playlist totalmente a caso.\n \u003e \n \u003e Ovviamente, più una canzone aveva l'indice di download alto, più veniva ascoltata e scaricata, in quantola gente è influenzata dal parere della massa.\n \u003e Interessante invece osservare come si sono evoluti i contatori di download nel tempo.\n \u003e Dato che inizialmente erano tutti posti a 0, e dato che le persone venivano rendirizzate alle playlist \u003cu\u003etotalmente a caso\u003c/u\u003e, si potrebbe pensare che col tempo più o meno tutte le playlist avessero una stessa classifica dei download.\n \u003e In realtà ogni palylist aveva un classifica totalmente differente.\n \u003e \n \u003e Questo è dovuto al fatto che la popolarità di una canzone in una playlist piuttosto che in un altra dipendeva da come si evolvevano le fasi iniziali.\n\nCiò che mostra questo esperimento è che **il processo che conduce alla popolarità è fortemente sensibile alle condizioni iniziali**.\nPerciò si potrebbe inizialmente sfruttare il **feedback** per cercare di influenzare la popolarità di una entità della rete.\n\n---\n\n# La lunga coda\n\nLa distribuzione della popolarità dei nodi di una rete può avere importanti effetti su attività commerciali. Per esempio consideriamo un sito di vendita di libri online.\nIl gestore del sito potrebbe chiedersi:\n\n \u003e \n \u003e *è più conveniente vendere \u003cu\u003etante copie di un pochi libri molto popolari\u003c/u\u003e, oppure è meglio vendere \u003cu\u003epoche copie ma di tantissimi libri poco popolari\u003c/u\u003e?*\n\nAnche in questo caso ci stiamo interessando alla popolarità, però non vogliamo sapere quanti nodi hanno grado $k$ (ovvero sono popolari) bensì vogliamo sapere se il volume di affare di tanti libri poco popolari è paragonabile a quello di pochi libri molto popolari.\n\nCome prima cosa enumeriamo i libri a disposizione in un ordine \u003cu\u003enon crescente\u003c/u\u003e di popolarità.\nOvvero, siano i libri ${ 1, ..., n }$ disponibili nel magazzino online, assumiamo che essi sono ordinati in modo tale che la popolarità (o grado entrante) $\\delta(i)$ del libro $i$ è \u003cu\u003enon maggiore\u003c/u\u003e di quella di $i+1$.\n$$\\delta(1) \\geq \\delta(2) \\geq ... \\geq \\delta(n)$$\n\n![\\|500](ar-lesson02-img3.png)\n\nA questo punto, assumiamo che il numero di nodi avente una certa popolarità \u003cu\u003eaumenti\u003c/u\u003e al diminurie della popolairtà.\nOvvero il numero di nodi con popolarità 100 sarà \u003cu\u003eminore\u003c/u\u003e di quelli con popolarità 99, che a sua volta sarà pià piccolo di quelli con popolairtà 98, ecc...\n\nSotto questa assunzione possiamo **raggrupare** i nodi con la stessa popolarità in un unico punto nel grafico, ottenendo così il seguente\n\n![\\|500](ar-lesson02-img4.png \"grafico1\")\n\nOsserviamo che invertendo gli assi, otteniamo nuovamente il grafico che ci dice il numero di nodi che hanno un determinato grado entrante (ovvero ciò che abbiamo analizzato in queste lezioni).\n\n![Grafico con assi invertite.|500](ar-lesson02-img5.png) ^f14a83\n\nIndichiamo formalmente con $\\#(k) = n$ la funzione che data la popolarità $k$ ci dice il numero di libri $n$ con tale probabilità, come quello mostrato in figura [grafico](2%20-%20Power%20Law.md#f14a83).\n\nQuello che interessa a noi è identificare la funzione che descrive il grafico [fig:grafico1](fig:grafico1), ovvero la funzione $\\#^-1(n) = k$ che dato un numero di libri $n$ aventi la stessa popolarità ci dice la loro popolarità esatta $k$.\nSempre ammettendo che la funzione $\\#(\\cdot)$ sia \u003cu\u003einvertibile\u003c/u\u003e.\n\nÈ possibile dimostrare che se la funzione $f(\\cdot)$ che esprime **la frazione** di libri (nodi) che hanno popolarità (grado entrante) $k$ è una **PowerLaw**, allora anche la funzione $\\#(\\cdot)$ (che invece esprime il numero esatto, e non una frazione) è una **PowerLaw**.\nOvvero\n$$n = \\#(k) \\approx k^{-c}$$\nper qualche $c \u003e 0$.\n\nDa essa è poi facile ricavarne l'inversa\n$$k = \\#^-1(n) \\approx n^{-1/c}$$\n\nSe quindi $k \\approx n^{-1/c}$, dove $k$ è un livello di popolarità ed $n$ è il numero di nodi con tale popolarità, possiamo osservare graficamente che $k$ decresce **mooolto** lentamente.\n\n![\\|500](ar-lesson02-img6.png \"grafico3\")\n\nCome possiamo vedere dalla Figura [fig:grafico3](fig:grafico3), la popolarità $k$ al crescere del numero dei libri decresce molto lentamente.\nSi crea appunto una **lunga coda**.\n\nDato che in genere il **volume di affari** ricavabile dalla vendita di un gruppo di prodotti è proporzionale alla loro popolairtà, l'area di quelli poco popolari, ovvero l'area sotto la **lunga coda**, è \u003cu\u003etutt'altro che trascurabile\u003c/u\u003e.\n\n## Gli effeti del Web-Search\n\nCi chiediamo ora se l'utilizzo dei motori di ricerca su internet hanno un impatto su fenomeno del *rich-get-richer*.\n\nDa una parte il fenomeno è **amplificato**, in quanto i motori di ricerca tendono a proproti come primi risultati le pagine più \"famose\" (inerentemente alla tua ricerca).\n\nD'altra parte l'effetto è **mitigato**, in quanto la ricerca è soggetta a una \"scrematura\" delle pagine in base alle parole usate per\nla ricerca.\nInfatti l'utilizzo di parole inusuali possono poartare come risultato della ricerca pagine che non sono \"famose\".\n\nPer quello visto prima, un venditore è interessato a promuovere i suoi prodotti \"di nicchia\" (quelli meno popolari), appunto per cercare di ricavare il guadagno dalla lunga coda.\n\nPer questo motivo i venditori online cercano sempre di rendirizzare gli utenti verso i prodotti \"in coda\", per esempio tramite l'utilizzo del cosidetto **recommendation system** i quali invitano gli utenti a visitare le pagine meno popolari.\n\nIn poche parole gli strumenti di web-search sono un esempio di utilizzo degli **effetti feedback**, i quali a volte amplificano l'effetto rich-get-richer, mentre altre volte lo mitigano.\n\n---\n\n[^1]: *i.i.d.* sta per *indipendenti e identicamente distribuite*.\n\n[^2]: \\[Broder et al., 2000\\]\n\n[^3]: per *tick* si intende gli indici del grafico che vengono segnati sugli assi. Generalmente si è abituati a vedere dei tick che crescono in maniera lineare $\\[0, 1, 2, ...\\]$, però spesso è necessario visualizzare l'asse secodno una scala differete, per esempio che cresce in maniera quadratica $\\[0, 1, 4, 9, 16, ...\\]$.\n\n[^4]: magari quell'ultima pagina delle 33 milioni è la migliore di tutte, ma probabilmente non lo saprò mai finché non salirà tra le prime 5 o 6 indicizzate (è difficile che io vada oltre).\n\n[^5]: *u.r.a.* sta per uniformemente a caso\n\n[^6]: una *eq. differenziale* è una equazione che lega una funzione alla sua derivata, del tipo $f'(x) = a \\cdot f(x) + b$\n\n[^7]: si ricordi che la derivata di una funzione del tipo $y = \\left\\[ h(x) \\right\\]^n$ è pari a\n$y' = n \\cdot \\left\\[ h(x) \\right\\]^{n-1} \\cdot h'(x)$.\n\n[^8]: \\[Bollobas, Riordan - 2005\\]\n\n[^9]: *with high probability*, ovvero con probabilità *almeno* $1 - \\left( \\frac{1}{n} \\right)^{\\Omega(1)}$\n","lastmodified":"2022-08-29T13:39:16.803643445+02:00","tags":null},"/AR/4-Grafi-geometrici-aleatori":{"title":"","content":"\n# Grafi geometrici aleatori e reti wireless\n\nI modelli fin'ora visti ([Erdős-Rényi](1%20-%20Erdos-Renyi%20Random%20Graph.md#il-modello-erdos-renyi) e [rich-get-richer](2%20-%20Power%20Law.md#un-modello-per-rich-get-richer)) sono tutti modelli di tipo *virtuale*, ovvero descrivono le *connessioni logiche* tra i nodi, trascurando del tutto l'implementazione fisica della rete.\n\nSpesso però si necessita di modellare reti che debbano essere poi **implementate fisicamente**.\nQuando si affronta un problema reale bisogna sempre considerare due fattori:\n\n1. la **fattibilità**\n1. le **risorse necessarie**\n\nInfatti, non basta sapere che è fisicamente possibile costruire una rete che è stata precedentemente modellizzata, ma bisogna sempre tener conto del costo in termine di risorse.\nSupponendo che non si disponga di risorse infite, quello che generalmente si desidera è sempre **minimizzare i costi**.\n\nIn ogni caso, quando bisogna implementare una rete fisica, bisogna sempre considerare la **struttura geometrica** che dovrà avere e lo **spazio** in cui dovrà essere costruita.\n\n## Grafo Geometrico\n\nSiano uno **spazio metrico** $(\\mathbb{R}^d, \\Vert \\cdot \\Vert )$ di dimensione $d \\geq 1$, e una costante $r \u003e 0$ detto **raggio**.\nUn **grafo geometrico** $G$ è composto dai seguenti insiemi:\n\n1. $V \\subseteq \\mathbb{R}^d$\n1. $E := \\lbrace (a,b) \\in V^2 : \\Vert a-b \\Vert \\leq r \\rbrace$\n\nLa maggior parte delle volte ci si trova a considerare uno spazio bidimensionale $\\mathbb{R}^2$, con *norma euclidea* e raggio unitario $r = 1$.\nIn questo caso esiste un arco tra due nodi $a,b$ solo se $\\sqrt{(x_1 - x_b)^2 + (y_1 - y_b)^2} \\leq 1$.\nQuesto modello è anche noto come **unique disk graph**.\n\n## Grafo Geometrico Aleatorio\n\nSiano due costanti $n \\in \\mathbb{N}$ ed $0 \\\u003c r \\leq \\sqrt{2}$.\nUn **grafo geometrico aleatorio** $G(n,r)$ è un particolare tipo di grafo aleatorio in cui vengono scelti $n$ nodi *u.a.r.* nell'insieme $\\left\\[ 0,1 \\right\\] \\times \\left\\[ 0,1 \\right\\]$.\n\nNotare che per $r \\rightarrow 0$ il grafo diventa sempre più sparso, mentre per $r = \\sqrt{2}$ il grafo risultate sarà *completo*[^1].\nL'ultima affermazione è vera perché scegliendo i nodi in quadrato di lato 1, due nodi possono essere distanti \u003cu\u003eal più\u003c/u\u003e $\\sqrt{2}$, ovvero la lunghezza della diagonale di una quadrato.\n\n`*inserire immagine*`\n\nQuesto particolare modello può avere numerosi riscontri pratici.\nPer esempio consideriamo una situazione in cui si hanno a disposizione $n$ sensori ambientali per l'acquisizione di dati utili allo studio di fenomi atmosferici, e di doverli disporre in una vasta area di 10 $km^2$.\n\nPrima di spargere i sensori è possibile impostare un raggio $r$ di trasmissione, utile ai sensori per scambiarsi informazioni.\nOvviamente maggiore è il raggio di trasmissione $r$, maggiore sarà il cunsumo di batteria dei sensori.\n\nQuesti sensori inoltre verranno rilasciati nell'ambiente in maniera casuale lanciandoli da un aereo che sorvolerà l'area.\n\nSi vuole quindi trovare il più piccolo valore di $r$ in relazione ad $n$ (che d'ora in poi chiameremo $r(n)$) tale che con **buona probabilità**[^2] la rete di sonsori $G(n, r(n))$ risulti connessa, usando così meno batteria possibile.\n\n## Reti Wireless ad-hoc\n\nQuello precedentemente descritto è un caso di **reti wireless ad-hoc**.\nIn questo contesto si considera un insieme di $n$ dispositivi (calcolatori, sensori, ecc...) dislocati in una data area, e ognuno dei quali dotato un trasmettitore wireless con un fissato **raggio di trasmissione**.\n\nCome prima, più è ampio il raggio di trasmissione maggiore sarà il consumo di batteria del dispositivo.\nOngi dispositivo $x$ può trasmettere i messaggi solamente ai dispositivi situati \u003cu\u003eentro\u003c/u\u003e il suo raggio di trasmissione $r_x$.\n\nNotare che non è detto che se un dispositivo $y$ è dentro il raggio di $x$, necessariamente $y$ sia in grado di trasmettere ad $x$.\n\nSi può quindi modellare questo tipo di rete con un **grafo di comunicazione** (**diretto**) dove l'insieme dei nodi corrisponde a quello dei dispositivi, mentre esiste l'arco diretto $(x,y)$ se e solo se $\\Vert x - y \\Vert \\leq r_x$.\n\n![Esempio di rete wireless|250px](ar-lesson04-img1.png)\n\n![Grafo delle comunicazioni associato|350](ar-lesson04-img2.png)\n\nIn questo modello è possibile anche mandare messaggi a nodi non direttamente connessi, a patto che siano nelle relative componenti connesse.\nPer esempio, se il nodo $v_1$ volesse mandare un messagio al nodo $v_4$ potrebbe farlo tramite il *cammino* $\\langle (v_1,v_2), (v_2,v_3), (v_3,v_4) \\rangle$.\n\nNotare però che queste comunicazioni **multi-hop** non sono simmetriche, in quanto nel grafo delle comunicazioni non esiste alcun cammino diretto che parte da $v_4$ e termina in $v_1$.\n\nPerciò se si vuole che ogni nodo sia in grado di comunicare con tutti gli altri è necessario che i raggi trasmissione siano scelti in modo tale che il grafo delle comunicazioni sia **fortemente connesso**[^3].\nBanalmente questo si può ottenere ponendo il raggio di ogni nodo pari alla distanza con il nodo ad esso più lontano, ovvero\n$$r_v = \\max\\_{x \\in V \\setminus \\lbrace v \\rbrace}{\\lbrace \\Vert v - x \\Vert \\rbrace}$$\n\nQuesto approccio potrebbe risultare però parecchio dispendioso in termini di utilizzo di batteria dei dispositivi.\nSarebbe preferibile scegliere dei raggi di trasmissione tali che minimizzino il più possibile lo spreco di batteria.\n\nPossiamo modellizzare questo problema come nell'esempio della precedente sezione, ovvero assumendo che tutti i nodi abbiano uno stesso raggio di trasmissione $r$, e senza perdere di generalità che la regione in cui distribuire i nodi sia un quadrato normalizzato\n$Q \\equiv \\left\\[ 0,1 \\right\\]^2$.\n\nOvviamente $r$ deve essere una funzione di $n$, in quanto se $r$ fosse fissato la densità del grafo geometrico aleatorio risultante dipnderebbe da $n$.\n\nInvece si vuole che al variare di $n$ il grafo $G(n,r(n))$ sia sempre fortemente connesso (con buona probabilità).\n\nOsservare che se $r$ è uguale per tutti i nodi allora non ha senso parlare di grafo diretto, in quanto se un nodo $x$ riesce a trasmettere direttamente a un nodo $y$ allora anche $y$ può trasmettere in modo diretto a $x$.\n\nFormalmente la domanda alla quale si vuole dare una risposta è:\n\n \u003e \n \u003e dati $n$ punti distribuiti uniformemente a caso nel quadrato unitario $Q$, calcolare il valore \u003cu\u003eminimo\u003c/u\u003e di $r(n)$ tale che $G(n, r(n))$ risulti connesso con buona probabilità.\n\n---\n\n## Connettività di $G(n, r(n))$\n\nIn questa sezione verrà dimostrato la seguente affermazione:\n\n \u003e \n \u003e Sia $r^{\\star}(n)$ il minimo valore di $r(n)$ tale che garantisce con ragionevole probabilità la connettività di $G(n,r(n))$.\n \u003e Allora $r^{\\star}(n) \\in \\Theta\\left( \\sqrt{\\frac{\\ln{n}}{n}} \\right)$.\n\nPer dimostrare la precedente affermazione è necessario dimostrare due teoremi che mostrano rispettivamente una limitazione **superiore** ed una **inferiore** per il minimo raggio di trasmissione $r^{\\star}(n)$.\n\n### Teorema 1 - delimitazione superiore\n\n#### Enunciato\n\nEsiste una costante $\\gamma_1 \u003e 0$ tale che se $r(n) \\geq \\gamma_1\\left( \\sqrt{\\frac{\\ln{n}}{n}} \\right)$, allora $G(n, r(n))$ è connesso con alta probabilità[^4].\n\n#### Proof\n\nDefiniamo una quantità $k(n)$ (dipendente da $n$), e partizioniamo il quadrato unitario $Q$ in $\\left(k(n)\\right)^2$ celle ciascuna di lato $\\frac{1}{k(n)}$.\n\nPoniamo $r(n)$ pari alla lunghezza della diagonale di un rettangolo composto da due celle adiacenti, ovvero\n$$r(n) = \\sqrt{\\left(\\frac{1}{k(n)}\\right)^2 + \\left(\\frac{2}{k(n)}\\right)^2} = \\frac{\\sqrt{5}}{k(n)}$$\n\n![Immagine esplicativa|350](ar-lesson04-img3.png)\n\nIn questa maniera, ciascun nodo sarà certamente collegato a \u003cu\u003etutti\u003c/u\u003e i nodi nelle celle adiacenti alla sua.\n\n![\\|350](ar-lesson04-img4.png)\n\nSe *con alta probabilità* ciascuna cella ha \u003cu\u003ealmeno\u003c/u\u003e un nodo allora è anche vero che con alta probabilità $G(n,r(n))$ è connesso.\n\nDimostriamo quindi che è possibile scegliere un $k(n)$ tale che *w.h.p.* nessuna cella di $Q$ è vuota.\n\nPer calcolare questa probabilità è più semplice partire dal calcolo dell'**evento complementare**, ovvero calcolare la probabilità dell'evento che esiste \u003cu\u003ealmeno\u003c/u\u003e una cella vuota.\n\nSia $C$ una cella: iniziamo col calcolare una *delimitazione superiore* alla probabilità che essa sia vuota $\\mathcal{P}(C = \\emptyset)$.\n\nL'evento \"$C = \\emptyset$\" può essere espresso come l'instersezione degli eventi $\\lbrace i \\not\\in C \\rbrace\\_{i \\in \\left\\[ n \\right\\]}$,\novvero\n$$\\mathcal{P}(C = \\emptyset) = \\mathcal{P}\\left( \\bigcap\\_{1 \\leq i \\leq n} i \\not\\in C \\right)$$\nDato che ogni nodo è posizionato in maniera totalmente indipendente dagli altri, e dato che la probabilità dell'intersezione di eventi indipendenti è pari al prodotto dei singoli, è vero che\n$$\\mathcal{P}\\left( \\bigcap\\_{1 \\leq i \\leq n} i \\not\\in C \\right) = \\prod\\_{1 \\leq i \\leq n} \\mathcal{P}\\left( i \\not\\in C \\right)$$\n\nNon resta che calcolare la probabilità $\\mathcal{P}\\left( i \\not\\in C \\right)$ che un nodo $i$ non \"cada\" nella cella $C$. Osserviamo che la probabilità dell'evento complementare, ovvero la probabilità dell'evento che $i$ cada in $C$ può essere ricavata semplicemente con la regola *\"casi favorevoli fratto casi possibili\"*, che in questo caso si traduce come *\"area di $C$ fratto area di $Q$\"*, ovvero\n$$\\mathcal{P}\\left( i \\in C \\right) = \\frac{|C|}{|Q|} = \\frac{1}{(k(n))^2}$$\nDi conseguenza\n$$\\mathcal{P}\\left( i \\not\\in C \\right) = 1 - \\mathcal{P}\\left( i \\in C \\right) = 1 - \\frac{1}{(k(n))^2}$$\nPerciò\n$$\\mathcal{P}(C = \\emptyset) = \\mathcal{P}\\left( \\bigcap\\_{1 \\leq i \\leq n} i \\not\\in C \\right) = \\prod\\_{1 \\leq i \\leq n} \\mathcal{P}\\left( i \\not\\in C \\right) = \\left(  1 - \\frac{1}{(k(n))^2} \\right)^n$$\n\nCalcolata la probabilità che la cella $C$ sia vuota, si vuole ora calcolare la probabilità dell'evento che esista \u003cu\u003ealmeno\u003c/u\u003e una cella vuota, ovvero\n$$\\mathcal{P}(\\exists C : C = \\emptyset) = \\mathcal{P}(\\bigcup\\_{C \\in Q} \\lbrace C = \\emptyset \\rbrace )$$\nRimarcando il concetto di **Union Bound** che dice che la probabilità dell'unione di eventi è minore o uguale della somma delle loro probabilità possiamo dare la seguente delimitazione superiore\n$$\\mathcal{P}(\\exists C : C = \\emptyset) \\leq \\sum\\_{C \\in Q} \\mathcal{P}(C = \\emptyset ) = (k(n))^2 \\left(  1 - \\frac{1}{(k(n))^2} \\right)^n$$\n\nRicordando che $r(n) = \\frac{\\sqrt{5}}{k(n)}$, possiamo sostituire $k(n)$ con $\\frac{\\sqrt{5}}{r(n)}$, ottenendo\n$$\\mathcal{P}(\\exists C : C = \\emptyset) \\leq \\frac{5}{(r(n))^2} \\left(  1 - \\frac{(r(n))^2}{5} \\right)^n$$\n\nA questo punto poniamo $r(n) = \\gamma_1\\left( \\sqrt{\\frac{\\ln{n}}{n}} \\right)$, ottenendo che\n$$\\mathcal{P}(\\exists C : C = \\emptyset) \\leq \\frac{5n}{\\gamma^2_1 \\ln{n}} \\left(  1 - \\frac{\\gamma^2_1 \\ln{n}}{5n} \\right)^n$$\n\nPrima di procedere (e concludere) con la dimostrazione della delimitazione superiore è necessario enunciare e dimostrare un *lemma\ntecnico*\n\n \u003e \n \u003e **Lemma:** $\\forall x \\in \\mathbb{R}$ vale la disuguaglianza $1 - x \\leq e^{-x}$.\n \u003e Inoltre se $x \\neq 0$ allora la disuguaglianza è\n \u003e stretta, ovvero $1 - x \\\u003c e^{-x}$.\n\n \u003e \n \u003e **Proof:** Sia la funzione $G(x) = 1 - x - e^{-x}$. Calcoliamo la derivata prima di $G$, ovvero $G'(x) = e^{-x} - 1$.\n \u003e Studiando il segno di $G'$ si nota che\n \u003e $$e^{-x} - 1 \\geq 0 \\implies e^{-x} \\geq 1 \\implies e^{-x} \\geq e^0$$\n \u003e ovvero che $G'(x) \\geq 0$ per $x \\leq 0$.\n \u003e \n \u003e Inoltre poiché $G'$ si annulla solamente per $x=0$, allora possiamo affermare che $x=0$ è il punto di massimo globale di $G$.\n \u003e \n \u003e Infine, dato che $G(0) = 0$ (e questo è il punto di massimo), possiamo affermare che $1-x \\leq e^{-x}$ per ogni $x \\in \\mathbb{R}$.\n \u003e $$G(x) \\leq G(0) \\implies 1 - x - e^{-x} \\leq 0 \\implies 1 - x \\leq e^{-x}$$\n \u003e $\\square$\n\nIn virtù del precedente Lemma, poniamo $x = \\frac{\\gamma^2_1 \\ln{n}}{5n}$, e dato che $\\frac{\\gamma^2_1 \\ln{n}}{5n} \\neq 0$, avremo che $$1 - \\frac{\\gamma^2_1 \\ln{n}}{5n} \\\u003c e^{-\\frac{\\gamma^2_1 \\ln{n}}{5n}}$$\nA questo punto non resta che eseguire qualche passaggio algebrico\n\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\exists C : C = \\emptyset)\n\u0026\\leq \\frac{5n}{\\gamma^2_1 \\ln{n}} \\left(  1 - \\frac{\\gamma^2_1 \\ln{n}}{5n} \\right)^n\\\\\n\u0026\\\u003c \\frac{5n}{\\gamma^2_1 \\ln{n}} \\left( e^{-\\frac{\\gamma^2_1 \\ln{n}}{5n}} \\right)^n\\\\\n\u0026= \\frac{5n}{\\gamma^2_1 \\ln{n}} e^{-\\frac{\\gamma^2_1 \\ln{n}}{5}}\\\\\n\u0026= \\frac{5n}{\\gamma^2_1 \\ln{n}} n^{-\\frac{\\gamma^2_1}{5}}\\\\\n\u0026\\\u003c \\frac{5n}{\\gamma^2_1} n^{-\\frac{\\gamma^2_1}{5}}\\\\\n\u0026= \\frac{5}{\\gamma^2_1} n^{1-\\frac{\\gamma^2_1}{5}}\n\\\\end{align\\*}\n$$\n\nOsserviamo ora che l'esponente $1-\\frac{\\gamma^2_1}{5} \\\u003c 0$ per $\\gamma_1 \u003e \\sqrt{5}$.\n\nIn conclusione, scegliendo un qualsiasi $\\gamma_1 \u003e \\sqrt{5}$ e ponendo $b = \\frac{5}{\\gamma^2_1}$ e $c = - \\left( 1-\\frac{\\gamma^2_1}{5} \\right) = \\frac{\\gamma^2_1}{5} - 1$, avremo che la probabilità che esista almeno una cella vuota è\n$$\\mathcal{P}(\\exists C : C = \\emptyset) \\\u003c \\frac{b}{n^c} \\in \\left( \\frac{1}{n} \\right)^{\\Omega(1)}$$\ne che quindi con alta probabilità non ci sono celle vuote\n$$\\mathcal{P}\\left( \\forall C \\subseteq Q ; \\exists x \\in V : x \\in Q \\right) \u003e 1 - \\left( \\frac{1}{n} \\right)^{\\Omega(1)}$$ $\\square$.\n\n---\n\n### Teorema 2 - delimitazione inferiore\n\n#### Enunciato\n\nPer ogni costante $c\u003e0$, $$\nr(n) \\leq \\sqrt{ \\frac{\\ln{(n)} + c}{n \\pi} }\n\\\\implies\n\\\\lim\\_{n \\rightarrow \\infty} \\mathcal{P}\\Big( G(n,r(n)) \\mbox{ non è connesso} \\Big) \u003e 0\n$$\n\nPer brevità, d'ora in poi si farà riferimento a $G(n,r(n))$ con $G$, e a $r(n)$ con $r$.\n\n#### Proof\n\nSi vuole dare una delimitazione inferiore alla probabilità che $G(n,r(n))$ **non** sia connesso.\n\nPer iniziare definiamo le seguenti famiglie di eventi:\n\n* $\\mathcal{E}\\_{\\geq 1}$ = $G$ contiene **almeno** un nodo isolato.\n* $\\mathcal{E}\\_{i_1,i_2,...,i_h}$ = i nodi $i_1,i_2,...,i_h \\in \\left\\[ n \\right\\]$ sono **tutti** isolati in $G$.\n* $\\mathcal{E}\\_{i!}$ = $i \\in \\left\\[ n \\right\\]$ è l'**unico** nodo isolato in $G$.\n\nFacciamo le seguenti osservazioni:\n\n \u003e \n \u003e **OSS. 1:** se $G$ contiene almeno un nodo isolato allora certamente $G$ è disconnesso.\n \u003e In termini logici possiamo scrivere come $\\mathcal{E}*{\\geq 1} \\implies G \\mbox{ disconnesso}$.\n \u003e In termini insiemistici invece l'implicazione si può tradurre come operatore di *sottoinsieme*, ovvero $\\mathcal{E}*{\\geq 1} \\subseteq G \\mbox{ disconnesso}$.\n \u003e Perciò avremo che $\\mathcal{P}\\Big(G \\mbox{ disconnesso}\\Big) \\geq \\mathcal{P}(\\mathcal{E}\\_{\\geq 1})$.\n\n^5ba4a6\n\n \u003e \n \u003e **OSS. 2:** se il nodo 1 è l'unico isolato, oppure se il nodo 2 è l'unico isolato, oppure ..., oppure il nodo $n$ è l'unico isolato allora certamente deve essere vero che $G$ ha *almeno* un nodo isolato.\n \u003e \n \u003e Perciò come per la precedente osservazione avremo che\n \u003e $$\\bigcup\\_{i \\in \\left\\[ n \\right\\]} \\mathcal{E}*{i!} \\subseteq \\mathcal{E}*{\\geq 1}$$\n \u003e e quindi in termini probabilistici\n \u003e $$\\mathcal{P}\\left( \\mathcal{E}*{\\geq 1} \\right) \\geq \\mathcal{P}\\left( \\bigcup*{i \\in \\left\\[ n \\right\\]} \\mathcal{E}\\_{i!} \\right)$$\n\n^b169ab\n\n \u003e \n \u003e **OSS. 3:** dato che $\\mathcal{E}*{1!}, \\mathcal{E}*{2!}, ..., \\mathcal{E}*{n!}$ sono tutti eventi **disgiunti** (ovvero ne può capitare solo uno tra tutti) allora avremo che\n \u003e $$\\mathcal{P}\\left( \\bigcup*{i \\in \\left\\[ n \\right\\]} \\mathcal{E}*{i!} \\right) = \\sum*{i \\in \\left\\[ n \\right\\]} \\mathcal{P}\\left( \\mathcal{E}\\_{i!} \\right)$$\n\n^b9f0cc\n\nDalle osservazioni [(1)](4%20-%20Grafi%20geometrici%20aleatori.md#5ba4a6), [(2)](4%20-%20Grafi%20geometrici%20aleatori.md#b169ab) e [(3)](4%20-%20Grafi%20geometrici%20aleatori.md#b9f0cc) possiamo dare una prima delimitazione inferiore\nalla probabilità che $G$ non sia connesso\n$$\\mathcal{P}\\Big(G \\mbox{ disconnesso}\\Big) \\geq \\sum\\_{i \\in \\left\\[ n \\right\\]} \\mathcal{P}\\left( \\mathcal{E}*{i!} \\right)$$\nA questo punto non resta che calcolare $\\mathcal{P}\\left( \\mathcal{E}*{i!} \\right)$.\n\nIn realtà non è propriamente semplice calcolare questa probabilità in menira diretta, perciò anche in questo caso cercheremo di *minorarla*[^5].\n\nNotiamo che $i$ è l'**unico** nodo isolato in $G$ se e solo se si verificano i seguenti eventi:\n\n1. $i$ è un nodo isolato in $G$\n1. comunque scegliamo un altro nodo $j$, avremo che $i$ e $j$ *non* sono enrambi isolati in $G$, ovvero\n   $$\\mathcal{E}*{i!} \\equiv\n   \\\\mathcal{E}*{i} \\bigcap\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\overline{\\mathcal{E}*{i,j}} \\equiv\n   \\\\mathcal{E}*{i} \\setminus \\left( \\bigcup\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\mathcal{E}\\_{i,j} \\right)$$\n   dove l'ultima uguaglianza è data dalla *legge di De Morgan*[^6].\n\nDa cui otteniamo la seguente minorazione\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}\\left( \\mathcal{E}*{i!} \\right)\n\u0026= \\mathcal{P}\\left( \\mathcal{E}*{i} \\setminus \\bigcup\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\mathcal{E}*{i,j} \\right)\\\\\n\u0026\\geq \\mathcal{P}\\left( \\mathcal{E}*{i} \\right) - \\mathcal{P}\\left( \\bigcup\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\mathcal{E}*{i,j} \\right)\\\\\n\u0026\\geq \\mathcal{P}\\left( \\mathcal{E}*{i} \\right) - \\sum\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\mathcal{P}\\left( \\mathcal{E}\\_{i,j} \\right)\n\\\\end{align\\*}\n$$\n\nPer calcolare quest'ultima probabilità dobbiamo ancora una volta ricavare delle limitazioni.\nPiù precisamente, se si vuole minorare, dobbiamo:\n\n1. trovare una **minorazione** per $\\mathcal{P}\\left( \\mathcal{E}\\_{i} \\right)$\n1. trovare una **maggiorazione** per $\\sum\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\mathcal{P}\\left( \\mathcal{E}\\_{i,j} \\right)$\n\n##### Minorazione per $\\mathcal{P}\\left( \\mathcal{E}\\_{i} \\right)$\n\nSia $t_i$ il *punto* di $Q$ in cui si trova il nodo $i$, e sia $C_r(t_i)$ la circonferenza di raggio $r$ centrata in $t_i$.\nL'evento $\\mathcal{E}\\_i$ si verifica solo se per ogni nodo $j \\neq i$ è vero che $j \\not\\in C_r(t_i)$.\n\nQuindi fissati $j$ e $t_i$ avremo che\n$$\\mathcal{P}\\left( j \\not\\in C_r(t_i) \\right) = \\frac{|Q - C_r(t_i)|}{|Q|} \\geq \\frac{|Q| - |C_r(t_i)|}{|Q|} = 1 - \\pi r^2$$\nIl *maggiore o uguale* è dato perché la circonferenza $C_r(t_i)$ potrebbe essere posizionata ai bordi, e quindi non rientrare in $Q$.\n\nPerciò, **fissato** un $t_i$ avremo che\n$$\\mathcal{P}\\left(j \\not\\in C_r(t_i) ; \\forall j \\neq i \\right) \\geq \\left( 1 - \\pi r^2 \\right)^{n-1}$$\nLa precedente probabilità è relativa a un dato $t_i$ fissato.\nCiò che serve a noi però è dare una stima per un qualsiasi $i$.\nPerò, visto che $t_i$ è scelto uniformemente a caso in un intervallo **continuo**, allora la funzione di densità della scelta u.a.r. in $Q$ sarà $f(t) = \\frac{1}{|Q|} = 1$.\n\nPerciò la delimitazione inferiore che cerchiamo è\n\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\mathcal{E}*i)\n\u0026\\geq \\int*{t_i \\in Q} f(t_i) \\left( 1 - \\pi r^2 \\right)^{n-1} ,dt_i\\\\\n\u0026= \\left( 1 - \\pi r^2 \\right)^{n-1} \\int\\_{t_i \\in Q} ,dt_i\\\\\n\u0026= \\left( 1 - \\pi r^2 \\right)^{n-1} \\cdot |Q|\\\\\n\u0026= \\left( 1 - \\pi r^2 \\right)^{n-1}\n\\\\end{align\\*}\n$$\n\n##### Maggiorazione per $\\sum\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\mathcal{P}\\left( \\mathcal{E}\\_{i,j} \\right)$\n\nBanalmente per maggiorare $\\sum\\_{j \\in \\left\\[ n \\right\\] \\setminus \\lbrace i \\rbrace} \\mathcal{P}\\left( \\mathcal{E}*{i,j} \\right)$ conviene maggiorare i singoli $\\mathcal{P}\\left( \\mathcal{E}*{i,j} \\right)$. \n\nOsserviamo quindi che l'evento $\\mathcal{E}\\_{i,j}$ occore se e solo se **fissato** un $t_i$ occorono le seguenti eventi:\n\n1. $j \\not\\in C_r(t_i)$\n1. $h \\not\\in C_r(t_i) \\cup C_r(t_j)$ $\\forall h \\in \\left\\[ n \\right\\] \\setminus \\lbrace i,j \\rbrace$\n\nPer calcolare $\\mathcal{P}\\left( \\mathcal{E}\\_{i,j} \\right)$ consideriamo la seguente immagine\n\n![\\|400](ar-lesson04-img5.png)\n\nCertamente finché $j$ si trova al di fuori del cerchio *rosso* ($C_r(t_i)$) allora $i,j$ non saranno direttamente connessi.\n\nA questo punto possono accadere due situazioni:\n\n1. $j$ si trova fuori dal cerchio $C\\_{2r}(t_i)$, e quindi l'area di $C_r(t_i) \\cup C_r(t_j)$ sarà esattamente la somma delle due aree, ovvero\n   $$|C_r(t_i) \\cup C_r(t_j)| = |C_r(t_i)| + |C_r(t_j)|$$\n   \n   ![\\|400](ar-lesson04-img6.png)\n\n1. $j$ si trova nell'anello *blu*, ovvero in $C\\_{2r}(t_i) \\setminus C_r(t_i)$, e quindi l'area di $C_r(t_i) \\cup C_r(t_j)$ è **minore o uguale** della somma delle aree $|C_r(t_i)|$ e $|C_r(t_j)|$, ovvero\n   $$|C_r(t_i) \\cup C_r(t_j)| = |C_r(t_i)| + |C_r(t_j)| - |C_r(t_i) \\cap C_r(t_j)| \\leq |C_r(t_i)| + |C_r(t_j)|$$\n   \n   ![\\|400](ar-lesson04-img7.png)\n\nCertamente si sta semplificando il tutto non considerando i casi in cui le circonferenze escano dai bori, però la limitazione non cambia.\n\nA questo punto possiamo riscrivere l'evento $\\mathcal{E}\\_{i,j}$ come l'unione di due eventi *mutuamente esclusivi*[^7]:\n\n* $\\mathcal{E}^1\\_{i,j} \\equiv t_j \\not\\in C\\_{2r}(t_i) \\land \\forall h \\in \\left\\[ n \\right\\] \\setminus \\lbrace i,j \\rbrace \\Big\\[ h \\not\\in C_r(t_i) \\cup C_r(t_j) \\Big\\]$\n* $\\mathcal{E}^2\\_{i,j} \\equiv t_j \\in C\\_{2r}(t_i) \\setminus C_r(t_i)  \\land \\forall h \\in \\left\\[ n \\right\\] \\setminus \\lbrace i,j \\rbrace \\Big\\[ h \\not\\in C_r(t_i) \\cup C_r(t_j) \\Big\\]$\n\nDato che i due eventi sono disgiunti possiamo dire che\n$$\\mathcal{P}(\\mathcal{E}*{i,j}) = \\mathcal{P}(\\mathcal{E}^1*{i,j} \\cup \\mathcal{E}^2\\_{i,j}) = \\mathcal{P}(\\mathcal{E}^1\\_{i,j}) + \\mathcal{P}(\\mathcal{E}^2\\_{i,j})$$\n\nCalcoliamo quindi le due probabilità.\nPer quanto riguarda $\\mathcal{P}(\\mathcal{E}^1\\_{i,j})$ è abbastanza semplice, in quanto la probabilità che un singolo $h$ **non** appartenga all'area $C_r(t_i) \\cup C_r(t_j)$ è pari all'area di $Q$ meno l'area dei due cerchi $C_r(t_i)$ e $C_r(t_j)$.\n$$\\mathcal{P}(\\mathcal{E}^1\\_{i,j}) = |Q| - |C_r(t_i) \\cup C_r(t_j)| =  |Q| - |C_r(t_i)| - |C_r(t_j)| = 1 - 2\\pi r^2$$Perciò, dato che ogni nodo viene collocato in $Q$ in maniera del tutto **indipendente** dagli altri nodi, possiamo affermare che fissati $t_i$ e $t_j$\n$$\n\\\\mathcal{P}\\left(\\bigcap\\_{h \\neq i,j} h \\not\\in C_r(t_i) \\cup  C_r(t_i) \\right)\n= \\prod\\_{h \\neq i,j} \\mathcal{P}\\left(h \\not\\in C_r(t_i) \\cup  C_r(t_i) \\right)\n= \\left( 1 - 2\\pi r^2 \\right)^{n-2}\n$$\nFissando un $t_i$, avremo che al variare di $t_j$ al di fuori della circonferenza *blu* $C\\_{2r}(t_i)$, la probabilità che tutti gli altri nodi $h \\neq i, j$ *\"cadano\"* al di fuori delle rispettive circonferenze sarà pari a\n$$\\int\\_{t_j \\in Q \\setminus C\\_{2r}(t_i)} f(t_j)\\left( 1 - 2\\pi r^2 \\right)^{n-2} ,dt_j$$\nInfine, calcolando tale probabilità al variare anche di $t_i$, risulterà che\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\mathcal{E}^1\\_{i,j})\n\u0026= \\mathcal{P}\\left( t_j \\not\\in C\\_{2r}(t_i) \\land \\forall h \\in \\left\\[ n \\right\\] \\setminus \\lbrace i,j \\rbrace \\Big\\[ h \\not\\in C_r(t_i) \\cup C_r(t_j) \\Big\\] \\right)\\\\\n\u0026= \\int\\_{t_i \\in Q} f(t_i) \\int\\_{t_j \\in Q \\setminus C\\_{2r}(t_i)} f(t_j)\\left( 1 - 2\\pi r^2 \\right)^{n-2} ,dt_j ,dt_i\\\\\n\u0026= \\int\\_{t_i \\in Q} \\int\\_{t_j \\in Q \\setminus C\\_{2r}(t_i)} \\left( 1 - 2\\pi r^2 \\right)^{n-2} ,dt_j ,dt_i\\\\\n\u0026= \\int\\_{t_i \\in Q} \\left( 1 - 4\\pi r^2 \\right) \\left( 1 - 2\\pi r^2 \\right)^{n-2} ,dt_i\\\\\n\u0026= \\left( 1 - 4\\pi r^2 \\right) \\left( 1 - 2\\pi r^2 \\right)^{n-2}\n\\\\end{align\\*}\n$$\n\nDove $f(t_i) = \\frac{1}{|Q|} = 1$ ricordiamo essere la funzione di densità riguardo la scelta di un punto uniformemente a caso in $Q$.\n\nInvece la quantità $\\left( 1 - 4\\pi r^2 \\right)$ è il risultato dell'integrale $\\int\\_{t_j \\in Q \\setminus C\\_{2r}(t_i)} ,dt\\_{j}$, ovvero l'area di $Q$ meno l'area del cerchio $C\\_{2r}(t_i)$.\n\nPiù articolato è invece il calcolo di $\\mathcal{P}(\\mathcal{E}^2\\_{i,j})$.\nOsserviamo che, fissato un $t_i$, la probobailità che un nodo $h \\neq i,j$ finisca *fuori* dall'area $|C_r(t_i) \\cup C_r(t_j)|$ dipende da come è posizionato $t_j$ nell'anello *blu* $C\\_{2r}(t_i) \\setminus C_r(t_i)$.\n\n![\\|400](ar-lesson04-img7.png)\n\nPiù precisamente, la probabilità che $h$ non finisca in $C_r(t_i) \\cup C_r(t_j)$ è pari ad $1 - |C_r(t_i) \\cup C_r(t_j)|$.\nA questo l'area di $|C_r(t_i) \\cup C_r(t_j)|$ sarà\n$$\n\\\\begin{align\\*}\n\\|C_r(t_i) \\cup C_r(t_j)|\n\u0026= |C_r(t_i)| + |C_r(t_j)| - |C_r(t_i) \\cap C_r(t_j)|\\\\\n\u0026= 2\\pi r^2 - |C_r(t_i) \\cap C_r(t_j)|\n\\\\end{align\\*}\n$$\n\nNotare che ai fini della dimostrazione vogliamo che quest'ultima quantità sia *minima*, e questo accade quando l'area dell'intersezione $|C_r(t_i) \\cap C_r(t_j)|$ è *massima*.\n\nGeometricamente si può intuire che questo accade quando $t_j$ risiede esattamente sul perimetro del cerchio $C_r(t_i)$.\n\n![\\|400](ar-lesson04-img8.png)\n\nPer calcolare tale area consideriamo la seguente immagine\n\n![Intersezione tra $C_r(t_i)$ e $C_r(t_j)$.|400](ar-lesson04-img9.png)\n\nPer calcolare l'intersezione tra $C_r(t_i)$ e $C_r(t_j)$ basta calcolare l'area *verde* in figura e moltiplicarla per 2.\n\nNotare che i triangoli $\\overset{\\triangle}{t_i B t_j}$ e $\\overset{\\triangle}{t_i A t_j}$ sono triangoli **equilateri** di lato $r$, e di conseguenza con angoli di 60°.\nPerciò l'agolo di $\\widehat{A t_j B}$ sarà $\\theta = 120° = \\frac{2\\pi}{3}$.\nLa lunghezza dell'arco $AB$ è invece pari a $L = \\theta r = \\frac{2\\pi}{3} r$.\n\n![Formula lunghezza di un arco di circonferenza|400](ar-lesson04-img10.png)\n\nInvece, l'area dello spicchio formato dall'area *verde* e dall'area *gialla* può essere calcolato con la formula $\\frac{L \\times r}{2}$.\n\n![In viola l'area $L \\times r$.|250](ar-lesson04-img11.png)\n\nIn fine bisogna sottrarre l'area del triangolo *giallo*.\n\nPer fare ciò bisogna calolcare la lungezza del segmento $\\overline{CB}$, e questo si può fare semplicemente col *teorema di Pitagora*\n\n$$\n\\\\begin{align\\*}\n\\\\overline{CB}\n\u0026= \\sqrt{ \\overline{t_i B}^2 - \\overline{t_i C}^2 }\\\\\n\u0026= \\sqrt{ r^2 - \\left(\\frac{r}{2}\\right)^2 }\\\\\n\u0026= \\sqrt{ r^2 \\left( 1 - \\frac{1}{4} \\right) }\\\\\n\u0026= \\sqrt{ r^2 \\left( 1 - \\frac{1}{4} \\right) }\\\\\n\u0026= \\sqrt{ \\frac{3}{4}r^2}\\\\\n\u0026= \\frac{\\sqrt{3}}{2}r \n\\\\end{align\\*}\n$$\n\nPerciò l'area del triangolo giallo sarà\n$$2\\overline{CB} \\times \\frac{r}{2} \\times \\frac{1}{2} = \\frac{\\sqrt{3}}{4}r^2$$\n\nIn conclusione l'area dell'intersezione $C_r(t_i) \\cap C_r(t_j)$ sarà pari a\n$$\n\\\\begin{align\\*}\n\\|C_r(t_i) \\cap C_r(t_j)|\n\u0026= 2 \\times \\left( \\frac{L \\times r}{2} - \\frac{\\sqrt{3}}{4}r^2 \\right)\\\\\n\u0026= 2 \\times \\left( \\frac{\\frac{2\\pi}{3} r \\times r}{2} - \\frac{\\sqrt{3}}{4}r^2 \\right)\\\\\n\u0026= \\frac{2\\pi}{3}r^2 - \\frac{\\sqrt{3}}{2}r^2\\\\\n\u0026= 2r^2 \\left( \\frac{\\pi}{3} - \\frac{\\sqrt{3}}{4} \\right)\n\\\\end{align\\*}\n$$\nRitornando quindi alla formula da massimizzare\n$$\n\\\\begin{align\\*}\n\\|C_r(t_i) \\cup C_r(t_j)|\n\u0026= 2\\pi r^2 - |C_r(t_i) \\cap C_r(t_j)|\\\\\n\u0026\\geq 2\\pi r^2 - 2r^2 \\left( \\frac{\\pi}{3} - \\frac{\\sqrt{3}}{4} \\right)\\\\\n\u0026= 2\\pi r^2 - \\frac{2}{3}\\pi r^2 + \\frac{\\sqrt{3}}{2}r^2\\\\\n\u0026= \\frac{4}{3}\\pi r^2 + \\frac{\\pi}{\\pi} \\cdot \\frac{\\sqrt{3}}{2}r^2\\\\\n\u0026= \\pi r^2 \\left(\\frac{4}{3} +  \\frac{\\sqrt{3}}{2 \\pi}\\right)\\\\\n\u0026\u003e \\frac{8}{5}\\pi r^2\n\\\\end{align\\*}\n$$\n\nIn conclusione, fissati $t_i$ e $t_j$ come descritto dall'evento $\\mathcal{E}^2\\_{i,j}$, la probabilità che un nodo $h$ finisca al di fuori di $C_r(t_i) \\cup C_r(t_j)$ sarà $\\\u003c 1 - \\frac{8}{5}\\pi r^2$.\n\nSe estendiamo questa probabilità a tutti i nodi $h \\neq i,j$ essa sarà $\\\u003c \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2}$.\n\nGeneralizzando, fissato un $t_i$, la probabilità che scegliendo un $t_j \\in C\\_{2r}(t_i) \\setminus C_r(t_i)$ tutti i restanti nodi non *\"finiscano\"* in $C_r(t_i) \\cup C_r(t_j)$ sarà **minore** di\n$$\\int\\_{t_j \\in C\\_{2r}(t_i) \\setminus C_r(t_i)} f(t_j) \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2} ,dt_j$$\n\nInfine generalizzando anche per $t_i$ avremo che\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\mathcal{E}^2\\_{i,j})\n\u0026\\\u003c \\int\\_{t_i \\in Q} f(t_i)  \\int\\_{t_j \\in C\\_{2r}(t_i) \\setminus C_r(t_i)} f(t_j) \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2} ,dt_j ,dt_i\\\\\n\u0026= \\int\\_{t_i \\in Q} \\int\\_{t_j \\in C\\_{2r}(t_i) \\setminus C_r(t_i)}\\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2} ,dt_j ,dt_i\\\\\n\u0026= \\int\\_{t_i \\in Q} |C\\_{2r}(t_i) \\setminus C_r(t_i)| \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2} ,dt_i\\\\\n\u0026\\overset{?}{=} \\int\\_{t_i \\in Q} \\left( 4\\pi r^2 - \\pi r^2  \\right) \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2} ,dt_i\\\\\n\u0026= |Q| \\cdot 3\\pi r^2 \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2}\n= 3\\pi r^2 \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2}\n\\\\end{align\\*}\n$$\n\nFinalmente, trovate delle maggiorazioni alle probabilità di $\\mathcal{E}^1\\_{i,j}$ e $\\mathcal{E}^2\\_{i,j}$ possiamo maggiorare anche la probabilità di $\\mathcal{E}*{i,j}$\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\mathcal{E}*{i,j})\n\u0026= \\mathcal{P}(\\mathcal{E}^1\\_{i,j}) + \\mathcal{P}(\\mathcal{E}^2\\_{i,j})\\\\\n\u0026\\\u003c \\left( 1 - 4\\pi r^2 \\right) \\left( 1 - 2\\pi r^2 \\right)^{n-2} + 3\\pi r^2 \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2}\\\\\n\u0026\\\u003c \\left( 1 - 2\\pi r^2 \\right)^{n-2} + 3\\pi r^2 \\left(1 - \\frac{8}{5}\\pi r^2\\right)^{n-2}\n\\\\end{align\\*}\n$$\n\nSostituendo $r$ con $\\sqrt{ \\frac{\\ln{(n)} + c}{n\\pi} }$ otterremo\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\mathcal{E}\\_{i,j})\n\u0026\\\u003c \\left( 1 - 2\\frac{\\ln{(n)} + c}{n} \\right)^{n-2} + 3\\frac{\\ln{(n)} + c}{n} \\left(1 - \\frac{8}{5}\\frac{\\ln{(n)} + c}{n} \\right)^{n-2}\\\\\n\\\\textbf{(1)} \u0026\\\u003c e^{- 2\\frac{\\ln{(n)} + c}{n} (n-2)} + 3\\frac{\\ln{(n)} + c}{n} \\cdot e^{- \\frac{8}{5}\\frac{\\ln{(n)} + c}{n} (n-2)}\\\\\n\\\\textbf{(2)} \u0026= e^{- 2\\frac{\\ln{(n)} + c}{n} (n-2)} + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} }\\cdot n^{ -\\frac{2}{5} } \\cdot e^{- \\frac{8}{5}\\frac{\\ln{(n)} + c}{n} (n-2)}\\\\\n\u0026= e^{- 2\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- 2c\\frac{n-2}{n} } + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} }\\cdot n^{ -\\frac{2}{5} } \\cdot e^{- \\frac{8}{5}\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- \\frac{8}{5}c\\frac{n-2}{n} }\\\\\n\u0026= e^{- 2\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- 2c\\frac{n-2}{n} } + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} }\\cdot e^{ -\\frac{2}{5}\\ln{(n)} } \\cdot e^{- \\frac{8}{5}\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- \\frac{8}{5}c\\frac{n-2}{n} }\\\\\n\\\\textbf{(3)} \u0026\\\u003c e^{- 2\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- 2c\\frac{n-2}{n} } + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} }\\cdot e^{ -\\frac{2}{5}\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- \\frac{8}{5}\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- \\frac{8}{5}c\\frac{n-2}{n} }\\\\\n\u0026= n^{- 2\\frac{n-2}{n} } \\cdot e^{- 2c\\frac{n-2}{n} } + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} }\\cdot e^{ -\\frac{10}{5}\\frac{n-2}{n}\\ln{(n)} } \\cdot e^{- \\frac{8}{5}c\\frac{n-2}{n} }\\\\\n\u0026= n^{- 2\\frac{n-2}{n} } \\cdot e^{- 2c\\frac{n-2}{n} } + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} }\\cdot n^{ -2\\frac{n-2}{n} } \\cdot e^{- \\frac{8}{5}c\\frac{n-2}{n} }\\\\\n\u0026= n^{- 2\\frac{n-2}{n} } \\cdot e^{- 2c\\frac{n-2}{n} } \\cdot \\left\\[ 1 + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} } \\cdot e^{ \\frac{2}{5}c\\frac{n-2}{n} } \\right\\]\n\\\\end{align\\*}\n$$\n\ndove:\n\n* **(1)** perché $1-x \\\u003c e^{-x}$ per ogni $x \\neq 0$.\n\n* **(2)** perché $\\frac{1}{n} = \\frac{1}{n^{3/5 + 2/5}} = \\frac{1}{n^{3/5} \\cdot n^{2/5}} = \\frac{1}{n^{3/5}} \\cdot n^{-2/5}$.\n\n* **(3)** perché viene moltiplicato $e^{-\\frac{2}{5}\\ln{(n)}}$ per $e^{\\frac{n-2}{n}}$.\n  \n  ---\n\nRiassumendo abbiamo visto che\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}( G \\mbox{ disconnesso} ) \u0026\\geq \\sum\\_{i \\in \\left\\[ n \\right\\]}  \\mathcal{P}( \\mathcal{E}*{i!} )\\\\\n\u0026= \\sum*{i \\in \\left\\[ n \\right\\]} \\left\\[ \\mathcal{P}( \\mathcal{E}*{i} ) - \\sum*{j \\in \\left\\[ n \\right\\] - \\lbrace i \\rbrace } \\mathcal{P}( \\mathcal{E}\\_{i,j} ) \\right\\]\n\\\\end{align\\*}\n$$\ncon\n\n* $\\mathcal{P}(\\mathcal{E}\\_{i}) \\geq \\left(1 - \\pi r^2 \\right)^{n-1}$\n* $\\mathcal{P}(\\mathcal{E}\\_{ij}) \\\u003c n^{- 2\\frac{n-2}{n} } \\cdot e^{- 2c\\frac{n-2}{n} } \\cdot \\left\\[ 1 + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} } \\cdot e^{ \\frac{2}{5}c\\frac{n-2}{n} } \\right\\]$\n\nperciò avremo che il limite inferiore alla probabilità che $G$ sia **non connesso** è\n$$\n\\\\mathcal{P}(G \\mbox{ disconnesso}) \u003e\nn\\left(1 - \\pi r^2 \\right)^{n-1} -\nn(n-1)n^{- 2\\frac{n-2}{n} } \\cdot e^{- 2c\\frac{n-2}{n} } \\cdot \\left\\[ 1 + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} } \\cdot e^{ \\frac{2}{5}c\\frac{n-2}{n} } \\right\\]\n$$\n\nA questo punto è utile vedere che per $n \\rightarrow \\infty$\n$$\n\\\\lim\\_{n \\rightarrow \\infty} n(n-1)n^{- 2\\frac{n-2}{n} } \\cdot e^{- 2c\\frac{n-2}{n} } \\cdot \\left\\[ 1 + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} } \\cdot e^{ \\frac{2}{5}c\\frac{n-2}{n} } \\right\\] = e^{-2c}\n$$ perché\n\n* $\\lim\\_{n \\rightarrow \\infty} n(n-1)n^{- 2\\frac{n-2}{n} } = 1$\n* $\\lim\\_{n \\rightarrow \\infty} e^{- 2c\\frac{n-2}{n} } = e^{-2c}$\n* $\\lim\\_{n \\rightarrow \\infty} 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} } \\cdot e^{ \\frac{2}{5}c\\frac{n-2}{n} } = 0$\n\nDato che questo limite approccia $e^{-2c}$ dall'*alto*, vul dire che per ogni $\\varepsilon \u003e 0$ esisterà un $n\\_{\\varepsilon} \u003e 0$ tale che per $n \\geq n\\_{\\varepsilon}$ è vero che $$\nn(n-1)n^{- 2\\frac{n-2}{n} } \\cdot e^{- 2c\\frac{n-2}{n} } \\cdot \\left\\[ 1 + 3\\frac{\\ln{(n)} + c}{ n^{\\frac{3}{5}} } \\cdot e^{ \\frac{2}{5}c\\frac{n-2}{n} } \\right\\] \\\u003c ( 1 + \\varepsilon )e^{-2c}\n$$\n\nPerciò\n$$\\mathcal{P}(G \\mbox{ disconnesso}) \u003e n\\left(1 - \\pi r^2 \\right)^{n-1} - ( 1 + \\varepsilon )e^{-2c}$$\nPer dimostrare che $\\lim\\_{n \\rightarrow \\infty} \\mathcal{P}(G \\mbox{ disconnesso}) \u003e 0$ basta dimostrare che da un certo $n$ in poi $n\\left(1 - \\pi r^2 \\right)^{n-1} - ( 1 + \\varepsilon )e^{-2c} \u003e 0$.\n\nLa precedente affermazione equivale a dimostrare che da un certo $n$ in poi $n\\left(1 - \\pi r^2 \\right)^{n-1} \u003e ( 1 + \\varepsilon )e^{-2c}$.\n\nIniziamo col calcolare il *logaritmo naturale* di entrambi i membri.\nPartendo dal primo (a sinistra)\n$$\n\\\\begin{align\\*}\n\\\\ln{ \\left( n\\left(1 - \\pi r^2 \\right)^{n-1} \\right) }\n\u0026= \\ln{ (n) } + \\ln{ \\left(\\left(1 - \\pi r^2 \\right)^{n-1} \\right) }\\\\\n\u0026= \\ln{ (n) } + (n-1)\\ln{ \\left(\\left(1 - \\pi r^2 \\right) \\right) }\\\\\n\\\\textbf{(1)} \u0026= \\ln{ (n) } - (n-1)\\sum\\_{k=1}^{\\infty} \\frac{\\left(\\pi r^2\\right)^k}{k}\n\\\\end{align\\*}\n$$\ndove **(1)** perché per $x \\\u003c 1$ vale che $\\ln{(1-x)} = - \\sum\\_{k=1}^{\\infty} \\frac{x^k}{k}$.\n\nPoniamo dunque $r = \\sqrt{ \\frac{\\ln{(n)} + c}{n\\pi} }$ e $\\delta(n)$ la serie precedente che parte da 3 e va $\\infty$.\nOtterremo che\n$$\n\\\\begin{align\\*}\n\\\\ln{ \\left( n\\left(1 - \\pi r^2 \\right)^{n-1} \\right) }\n\u0026= \\ln{ (n) } - (n-1)\\sum\\_{k=1}^{\\infty} \\frac{\\left(\\ln{(n)} + c\\right)^k}{kn^k}\\\\\n\u0026= \\ln{ (n) } - (n-1)\\sum\\_{k=1}^{2} \\frac{\\left(\\ln{(n)} + c\\right)^k}{kn^k} + \\delta(n)\\\\\n\u0026= \\ln{ (n) } - (n-1) \\left\\[ \\frac{\\ln{(n)} + c}{n} + \\frac{\\left(\\ln{(n)} + c\\right)^2}{2n^2} + \\delta(n) \\right\\]\n\\\\end{align\\*}\n$$\nNon resta che stimare $\\delta(n)$.\n$$\n\\\\begin{align\\*}\n\\\\delta(n)\n\u0026= \\sum\\_{k=3}^{\\infty} \\frac{\\left(\\ln{(n)} + c\\right)^k}{kn^k}\\\\\n\u0026\\leq \\sum\\_{k=3}^{\\infty} \\frac{\\left(\\ln{(n)} + c\\right)^k}{3n^k} = \\frac{1}{3} \\sum\\_{k=3}^{\\infty} \\left( \\frac{\\ln{(n)} + c}{n} \\right)^k \\\\\n\u0026\\leq \\frac{1}{3} \\int\\_{2}^{\\infty} \\left( \\frac{\\ln{(n)} + c}{n} \\right)^x ,dx\\\\\n\u0026= \\lim\\_{h \\rightarrow \\infty} \\frac{1}{3} \\int\\_{2}^{h} \\left( \\frac{\\ln{(n)} + c}{n} \\right)^x ,dx\\\\\n\u0026= \\lim\\_{h \\rightarrow \\infty} \\frac{1}{3} \\int\\_{2}^{h} e^{x\\left( \\frac{\\ln{(n)} + c}{n} \\right)} ,dx\\\\\n\u0026= \\lim\\_{h \\rightarrow \\infty} \\left\\[ \\frac{1}{3} \\frac{1}{ \\ln{ \\left( \\frac{\\ln{(n)} + c}{n} \\right) } } e^{x\\left( \\frac{\\ln{(n)} + c}{n} \\right)} \\right\\]*2^h\\\\\n\u0026= \\lim*{h \\rightarrow \\infty} \\left\\[ \\frac{1}{3} \\frac{1}{ \\ln{ \\left( \\frac{\\ln{(n)} + c}{n} \\right) } } \\left( \\frac{\\ln{(n)} + c}{n} \\right)^x \\right\\]*2^h\\\\\n\\\\textbf{(a)} \u0026= - \\frac{1}{3} \\frac{1}{ \\ln{ \\left( \\frac{\\ln{(n)} + c}{n} \\right) } } \\left( \\frac{\\ln{(n)} + c}{n} \\right)^2\\\\\n\\\\textbf{(b)} \u0026= \\frac{1}{3} \\frac{1}{ \\ln{ \\left( \\frac{n}{\\ln{(n)} + c} \\right) } } \\left( \\frac{\\ln{(n)} + c}{n} \\right)^2\n\\\\end{align\\*}\n$$\ndove **(a)** perché $\\lim*{h \\rightarrow \\infty} \\left( \\frac{\\ln{(n)} + c}{n} \\right)^h = 0$, perché $\\frac{\\ln{(n)} + c}{n} \\\u003c 1$ per $n$ abbastanza grande.\nMentre **(b)** perché viene spostato il simbolo negativo su $\\ln{ \\left( \\frac{\\ln{(n)} + c}{n} \\right) }$ trasformandolo in $\\ln{ \\left( \\frac{n}{\\ln{(n)} + c} \\right) }$.\nInfine poiché $\\ln{ \\left( \\frac{n}{\\ln{(n)} + c} \\right) } \\\u003c 1$ per $n$ sufficentemente grande, avremo che\n$$\\delta(n) \\\u003c \\frac{1}{3} \\frac{ \\left( \\ln{(n)} + c \\right)^2 }{n^2}$$\nUnendo i pezzi abbiamo che per valori di $n$ abbastanza grandi\n$$\n\\\\begin{align\\*}\n\\\\ln{ \\left( n\\left(1 - \\pi r^2 \\right)^{n-1} \\right) }\n\u0026= \\ln{ (n) } - (n-1) \\left\\[ \\frac{\\ln{(n)} + c}{n} + \\frac{\\left(\\ln{(n)} + c\\right)^2}{2n^2} + \\delta(n) \\right\\]\\\\\n\u0026\u003e \\ln{ (n) } - (n-1) \\left\\[ \\frac{\\ln{(n)} + c}{n} + \\frac{\\left(\\ln{(n)} + c\\right)^2}{2n^2} +  \\frac{1}{3} \\frac{ \\left( \\ln{(n)} + c \\right)^2 }{n^2} \\right\\]\\\\\n\u0026= \\ln{ (n) } - (n-1) \\left\\[ \\frac{\\ln{(n)} + c}{n} + \\frac{5}{6} \\frac{ \\left( \\ln{(n)} + c \\right)^2 }{n^2} \\right\\]\\\\\n\u0026= \\ln{ (n) } - \\frac{(n-1)}{n}\\left( \\ln{(n)} + c \\right) - \\frac{5}{6} \\frac{(n-1)\\left( \\ln{(n)} + c \\right)^2 }{n^2}\\\\\n\\\\textbf{(c)} \u0026\u003e \\ln{ (n) } - \\left( \\ln{(n)} + c \\right) - \\frac{5}{6} \\frac{(n-1)\\left( \\ln{(n)} + c \\right)^2 }{n^2}\\\\\n\u0026= - c - \\frac{5}{6} \\frac{(n-1)\\left( \\ln{(n)} + c \\right)^2 }{n^2}\n\\\\end{align\\*}\n$$\ndove **(c)** perché $\\frac{(n-1)}{n} \\\u003c 1$.\n\nPer $n \\rightarrow \\infty$ si ha che $\\frac{5}{6} \\frac{(n-1)\\left( \\ln{(n)} + c \\right)^2 }{n^2} \\approx 0$, allora per ogni $\\omega \u003e 0$ esiste sempre un $n\\_{\\omega} \\geq n\\_{\\varepsilon}$ tale che per $n \\geq n\\_{\\omega}$ vale la seguente disuguaglianza\n$$\\frac{5}{6} \\frac{(n-1)\\left( \\ln{(n)} + c \\right)^2 }{n^2} \\\u003c \\omega$$ e ciò implica che per $n$ abbastanza grande $\\ln{ \\left( n\\left(1 - \\pi r^2 \\right)^{n-1} \\right) } \u003e - c - \\omega$, e dunque (elevando a potenza) $n \\left(1 - \\pi r^2 \\right)^{n-1} \u003e e^{- c - \\omega}$.\n\nPonendo $\\omega = c - \\ln{( 1 + \\varepsilon )}$ verrà verificata la\ndisuguaglianza voluta\n$$\nn\\left(1 - \\pi r^2 \\right)^{n-1} \u003e e^{- c - c + \\ln{( 1 + \\varepsilon )}} = e^{-2c}e^{\\ln{( 1 + \\varepsilon )}} = ( 1 + \\varepsilon )e^{-2c} \n$$\ndimostrando così la tesi del teorema\n$$\n\\\\mathcal{P}(G \\mbox{ disconnesso}) \u003e n\\left(1 - \\pi r^2 \\right)^{n-1} - ( 1 + \\varepsilon )e^{-2c} \u003e ( 1 + \\varepsilon )e^{-2c} - ( 1 + \\varepsilon )e^{-2c} = 0\n$$ $\\square$.\n\n---\n\n[^1]: ovvero una *clique* di $n$ nodi.\n\n[^2]: perché $G(n, r(n))$ è un evento aleatorio, e quindi si possono solo fare previsioni probabilistiche.\n\n[^3]: ovvero che per ogni coppia di nodi $x,y$ esista un cammino diretto da $x$ ad $y$ e un cammino diretto da $y$ ad $x$.\n\n[^4]: con probabilità \u003cu\u003ealmeno\u003c/u\u003e $1 - \\left(\\frac{1}{n}\\right)^{\\Omega(1)}$.\n\n[^5]: trovare un'ulteriore delimitazione inferiore.\n\n[^6]: . $\\overline{A} \\cap \\overline{B} \\equiv \\overline{A \\cup B}$.\n\n[^7]: ovvero *disgiunti*.\n","lastmodified":"2022-08-29T13:39:16.87057134+02:00","tags":null},"/AR/6-Small-World":{"title":"","content":"\n# Fenomeno Small World\n\n## Six Degrees of Separation\n\nConsideriamo l'esperimento dello psicologo statunitense Stanley Milgram (1967).\nIn tale esperimento Milgram scelse una persona **target** che risedeva dalla parte opposta degli Stati Uniti. Dopodiché inviò una serie di lettere ad un gruppo di persone con le seguenti informazioni e regole:\n\n1. nella lettera era specificato nome, indirizzo, occupazione e altre informazioni riguardo il target\n1. chi riceveva questa lettera doveva **inoltrarla** (ovvero inviare una sola copia) ad un'altra persona, che secondo lui si avvicinava di più al target. Era possibile inviare la lettera ad una persona solo se la si conosceva di prima persona.\n\nAl termine dell'esperimento Milgram osservò che circa un terzo delle lettere riuscirono ad arrivare al target, ma ancor più interessante che tutte arrivarono mediamente in 6 passi.\n\nQuesto esperimento suggerì due proprietà importanti delle reti sociali:\n\n1. un'abbondanza di **cammini brevi** tra gli individui della rete, noto come **fenomeno Small World** (o *\"Six Degrees of Separation\"*).\n1. tali cammini potevano facilmente essere individuati dagli individui, che altro non conoscono della struttura della rete se non il loro vicinato ed una *euristica* che gli consenta di intuire i vicini più plausibili per i cammini. Questo è noto come **fenomeno della navigabilità**.\n\nCertamente un aiuto molto rilevante per la *navigabilità* è stata la presenza di alcune informazioni riguardo il target nella lettera (apparte il nome).\n\nPer esempio se so che il target abita in un certa regione cercherò come prima cosa di inoltrare la lettera a una persona che geograficamente si avvicina.\nAncora, se so è abbastanza vicino a me e so anche che è un medico, certamente cercherò tra le mie conoscenze\nuna persona che lavora (o che ha a che fare) con l'ambiente sanitario (è meno probabile che mi avvicini se inoltro la lettera a un contadino).\n\nInvece, se avessi avuto **solamente** il nome del target senza essere in grado nemmeno di individuare la sua città, molto probabilmente la lettera sarebbe stata perduta.\n\nPer quanto riguarda l'abbondanza di cammini brevi invece una possibile motivazione \u003cu\u003eintuitiva\u003c/u\u003e è la seguente: supponiamo \n\n \u003e \n \u003e di avere conoscere in maniera diretta 100 persone, e che tali persone conoscono direttamente altre 100 persone.\n \u003e Allora con due \"hop\" posso raggiungere $100 \\cdot 100 = 10000$ altre persone.\n \u003e E se a loro volta gli amici dei miei amici conoscono 100 perso, in tre \"hop\" potrò raggiungere altri $100 \\cdot 100 \\cdot 100 = 1000000$ persone, e così via...\n\n![Crescita puramente esponeziale delle conoscenze.|600](ar-lesson06-img1.png) ^08a676\n\nPurtroppo però questo ragionamento è inconsistente, in quanto si fa un'assunzione molto forte, ovvero che ogni proprio amico conosce altre 100 persone **distinte**.\nIn un conteso reale è però poco plausibile questa proprietà: se sono amico stretto di due persone è *motlo probabile* che prima o poi essi si conoscano e diventino a loro volta conoscenti.\n\nPer esempio le reti di conoscenze dei *social networks* mostrano la presenza di una quantità elevata di **triangoli** tra gli individui, a conferma di quanto osservato.\nLa caratteristica di una rete di avere molti triangoli è detta **chiusura triadica** (**triadic closure**), la quale diminuisce di molto il numero di individui raggiungibili con percorsi brevi rispetto al modello con crescita esponenziale.\n\n![La chiusura triadica diminuisce di molto il numero di persone raggiungibili con percorsi brevi.|600](../images/ar-lesson06-img2.png)\n\n---\n\n## The Watts-Strogatz model\n\nNel 1998 Duncan Watts and Steve Strogatz proposero un modello generativo di grafi aleatori che soddisfano due proprietà precedentemente viste: la presenza di numerosi triangoli e la presenza di cammini brevi che collegano le entità della rete.\n\nIl grafo generato in accordo col **modello Watts-Strogatz** è composto da due componenti:\n\n* una componente **deterministica** che consiste in una **griglia bidimensionale**\n* una componente **aleatoria** sovrastante\n\nLa griglia bidimensionale è un sottoinsieme di $\\mathbb{N}^2$, i cui *punti* sono i nodi del grafo. Nella griglia ogni nodo ha un acro con i suoi vicini posti a destra, sinistra, sopra, sotto e in diagonale.\nPiù formalmente, fissato un $n \\in \\mathbb{N}$:\n$$\nV \\equiv \\lbrace (i,j) \\in \\mathbb{N}^2 | 0 \\leq i \\\u003c n \\land 0 \\leq j \\\u003c n \\rbrace\\\\\nE_1 \\equiv \\lbrace \\lbrace (i,j), (a,b) \\rbrace \\in V^2 | \\left\\[ a \\equiv_n i+\\alpha \\land b \\equiv_n j+\\beta \\right\\] ; \\forall \\alpha,\\beta = -1, 0, 1 \\rbrace\n$$\nSe si fa attenzione alla definizione di $E_1$ (ovvero l'insieme degli archi della componente deterministica), si può vedere che la griglia ha una sorta di *periodicità*, ovvero i nodi a un bordo della griglia sono collegati ai nodi sul bordo opposto.\nIn questa maniera otteniamo un primo grafo con un'alta quantità di *triangoli* (prima proprietà desiderata).\n\nPer costruire la componente aleatoria fissiamo un $k\u003e1$, e per ogni nodo $v \\in V$ esso aggiungerà come ulteriori vicini altri $k$ nodi scelti \u003cu\u003euniformemente a caso\u003c/u\u003e.\n\n![Costruzione modello Watts-Strogatz|450](ar-lesson06-img3.png)\n\nSi può osservare una certa *dicotomia* tra gli archi deterministici e quelli aleatori:\n\n1. gli archi deterministici rappresentano un **legame forte** tra i nodi (**strong tie**), infatti tra due nodi legati da un arco deterministico esistono sempre dei triagoli.\n1. gli archi aleatori rappresentano invece delle conoscenze \"alla lontana\", e in quanto tale un **legame debole** (**weak tie**). Infatti è molto poco probabile trovare triangoli nella componente aleatoria (a meno che $k$ non sia \u003cu\u003emolto\u003c/u\u003e grande).\n\nA questo punto è doveroso chiedersi se effetivamente esistono cammini brevi tra i nodi della rete.\n\nIntuitivamente parlando, se si considerano cammini composti dai soli archi aleatori, è poco probabile incontrare due volte uno stesso nodo in brevi distanze. \nPerciò, nella compononete aleatoria la crescita dei \u003cu\u003enuovi\u003c/u\u003e nodi vicini è più simile al modello con [crescita esponenziale](6%20-%20Small%20World.md#08a676) .\n\nSuccessivamente *Bollobàs \u0026 Ching* diedero una dimostrazione formale a questo fenomeno.\nPiù precisamente dimostrarono la presenza di cammini brevi in un modello con molta meno *randomness*.\n\nConsideriamo un nuovo modello simile a quello Watts-Strogatz, dove però solo un nodo su $k$ ha archi random, e il numero di archi random è pari a 1.\nPartizioniamo poi la rete in \"**città**\" di $k \\times k$ individui, e consideriamo il fenomeno small-world a livello di città.\nCertamente ogni città avrà mediamente $k$ archi random, e inoltre ogni coppia di nodi $u,v$ di una stessa città sarà connessa da un cammino breve di lunghezza *al più* $2k$.\n\nVenne dimostrato che per trovare un cammino relativamente corto tra due nodi $u,v$ di due città differenti, basta che $u$ raggiunga un nodo $w$ nella stessa città (in al più $2k$) passi, e poi tramite pochi salti passare da dua città all'altra fino ad arrivare alla città di $v$.\n\nIn conclusione, anche con un piccolo ammontare di casualità, il modello Watts-Strogatz cattura il fenomeno di \"mondo piccolo\".\n\n### Navigabilità del modello Watts-Strogatz\n\nAssodato che nel modello Watts-Strogatz esistono cammini relativamente corti tra i nodi della rete, quello che ci si chiede è se tali cammini corti sono facilmente rintracciabili dai nodi, che conoscono solamente il loro vicinato e non la struttura dell'intera rete.\n\nSupponiamo che un nodo $u$ deve mandare un messaggio a un nodo $v$ del quale conosce solamente le sue coordinate sulla griglia geometrica.\nIl nodo $u$ potrebbe mandare in broadcast il messaggio a tutti i suoi vicini (che sono 8 o 9), e chiedere a loro di inviare il messaggio a tutti i loro vicini.\nQuesto metodo è noto come `Flooding` dei messaggi, ed è il metodo più veloce per raggiungere il nodo $v$ (in quanto\nequivale ad una *visita in ampiezza*).\n\nIl problema è che dopo $h$ salti, ci sarebbero circa $8^h$ messaggi in circolazione, oltre al fatto che sarebbe scortese chiedere di inviare 8 messaggi ai propri vicini.\n\nVorremmo un modo per trovare un cammino non troppo lungo tra $u$ e $v$ in modo da trasmettere una sola copia del messaggio, e non un numero esponenziale, un po' come fecero le persone che parteciparono all'esperimento di Milgram.\n\nPurtroppo fare questo tipo di ricerca **miope**[^1] in un modello Watts-Strogatz non è possibile.\nPer esempio il nodo $u$ potrebbe pensare di mandare il messaggio al suo vicino che più si avvicina alla destinazione $v$.\nQuesto però potrebbe non essere il modo miglio per raggiongere $v$.\nPer esempio potrebbe esistere un nodo $w$ vicino di $u$ che si allontana di 1 rispetto a $v$ nella griglia deterministica, ma che però è direttamente collegato a $v$ tramite la componente aleatoria.\n\n![Controesempio appena descritto|450](ar-lesson06-img4.png)\n\nPurtroppo però $u$ non può in alcun modo sapere che conviene inviare il messagio a $w$, in quanto conosce \u003cu\u003esolo il suo vicinato\u003c/u\u003e e non quello di $w$.\n\nInoltre è stato anche dimostrato[^2] con questo tipo di ricerca (nota come **ricerca decentralizzata**), non solo non c'è nessuna garanzia di trovare un cammino corto, ma mediamente i cammini trovati sono *molto* più lunghi dei cammini minimi che esistono tra mittente e destinatario.\n\nSostanzialmente il problema è che gli archi random della componente aleatoria sono \"troppo\" casuali per dare un supporto alla ricerca decentralizzata.\nInfatti in un contesto sociale reale, è molto poco probabile che due persone *totalmente a caso* entrino in contatto.\n\nÈ invece più probabile avere archi casuali tra persone più vicine fisicamente, anziché tra persone molto lontane.\n\nQuindi possiamo dire che questo modello non è navigabile, e quindi non rispecchia le caratteristiche volute.\n\n---\n\n## Un modello per la ricerca decentralizzata\n\nVogliamo quindi definire un modello di generazione di reti sociali che in qualche modo consenta una ricerca decentralizzata di caminni che non siano troppo più lunghi dei cammini minimi.\n\nBasandoci sull'osservazione precedentemente fatta che è poco probabile avere archi random \u003cu\u003etotalmente a caso\u003c/u\u003e, possiamo definire un modello che aggiunge un parametro che controlla il *range di copertura* degli archi random[^3].\n\nPiù formalmente siano due nodi $u,v$ con distanza $d(u,v)$ nella *componente deterministica* sottostante, e sia una costante $c \\geq 0$ detta **esponente di clustering**.\nPerciò la probabilità che nella componente aleatoria esista l'arco $(u,v)$ è proporzionale alla quantità $d(u,v)^{-q}$, più precisamente\n$$\\mathcal{P}( (u,v) \\in E_2 ) = \\frac{1}{Z_u} \\cdot \\frac{1}{d(u,v)^q}$$\ndove chiamiamo per comodità $E_2$ l'insieme di archi random, e $Z_u$ è un **fattore di normalizzazione** definito come\n$$Z_u = \\sum\\_{v \\in V \\setminus \\lbrace v \\rbrace} \\frac{1}{d(u,v)^q}$$\nIl fattore di normalizzazione è detto tale in quanto\n$$\\sum\\_{v \\in V \\setminus \\lbrace v \\rbrace} \\mathcal{P}( (u,v) \\in E_2 ) = 1$$\nSe consideriamo come componente deterministica una griglia *simmetrica e periodica* come nel modello Watts-Strogatz, allora il fattore di normalizzazione sarà un certo $Z$ uguale per tutti i nodi.\nQuesto in generale è vero per ogni componente deterministica completamente\nsimmetrica.\nD'ora in poi si farà riferimento a modelli che presentano questo livello di simmetria.\n\nOsserviamo che quando $q=0$ gli archi random sono totalmente casuali, in quanto la probabilità che tale arco esista è uguale per tutti[^4], risultando quindi uguale al modello Watts-Strogatz.\nQuando invece la $q$ è molto grande sostanzialmente la probabilità di trovare archi random molto lunghi diventa molto piccola, perciò la componente aleatoria diventa sempre più simile alla sola componente deterministica.\nRicapitolando quando $q$ è piccolo la casualità è tanta, quando $q$ è grande la casualità è poca.\n\n![\\|550](ar-lesson06-img5.png)\n\nIntuitivamente al variare di $q$ esistono valori migliori e valori perggiori per la ricerca decentralizzata.\nGià sappiamo che per $q=0$ il valore è pessimo.\nÈ possibile però dimostrare, che data una griglia $d$-dimensionale **wrapped**[^5], allora il componente di clustering ottimale sarà esattamente $q = d$.\n\nCerchiamo ora di dare una spiegazione intuitiva a questo fenomeno.\nRiconsideriamo nuovamente l'esperimento di Milgram, dove però abbiamo il mittente `A` che vive negli Stati Uniti mentre il destinatario `B` vive a Roma quartiere Garbatella.\nCertamente la prima cosa che farebbe `A` sarebbe quella di inviare la lettera qunatomeno ad una persona che vive in Europa.\nAnche se `A` non ha amici diretti in Europa a cui inviare la lettera, passandola ad altri amici negli USA troverà brevemente qualcuno che ha amici che vivono oltre oceano.\nPer semplicità assumiamo che `A` invii direttamente la lettera ad un suo amico `C` che vive a Mosca.\nA sua volta `C` cerca tra i suoi amici qualcuno che abiti almeno in Europa Occidentale.\nDa `C` la lettera passa a `D` che vive a Parigi.\nPer fortuna `D` ha un amico in Italia che però vive a Perugia, e quindi la lettera finisce in Umbira. `D` si ricorda di avere un lontano parente `E` nel Lazio, a cui invia la lettera.\nDopodiché `E` invia la lettera ad un suo collega `F` che abita a Roma Centocelle, il quale a sua volta invierà la lettera a un amico `G` che abita a Garbatella.\nDi li, sicuramente in un numero non esagerato di passi la lettera arriva a `B`.\n\nCome si può intuire, il processo di ricerca decentralizzata procede per **scale di risoluzione**. Infatti, anche se per pochi salti la lettera percorre relativamente poca distanza, presto farà un salto che riduce drasticamente la distanza con la destinazione.\n\n**\\[aggiungere immagini\\]**\n\nConsideriamo una semplice griglia \u003cu\u003ebidimensionale\u003c/u\u003e (con $d = 2$) wrapped, e partizioniamo i nodi in base alla distanza dal mittente $u$.\nPiù precisamente partizioniamo i nodi i gruppi in cui la distanza cresce esponenziale, ovvero i nodi da $u$ tra 2 e 4, poi tra 4 e 8, tra 8 e 16, tra 16 e 32, ..., tra $2^h$ e $2^{h+1}$.\n\nDato che i punti in una circonferenza crescono come il quadrato del raggio, avremo che i nodi nell'intervallo tra $2^h$ e $2^{h+1}$ sarà proporzionale a $2^{2h}$.\nInfatti\n$$\\vert \\lbrace x \\in V \\vert 2^h \\leq d(u,x) \\\u003c 2^{h+1} \\rbrace \\vert \\approx (2^{h+1})^2\\pi - (2^h)^2\\pi = 4\\pi 2^{2h} - \\pi 2^{2h} = 3\\pi 2^{2h} $$\n\nConsideriamo l'indice di clustering ottimo per la griglia bidimensionale, ovvero $q=2$.\nPreso un nodo $x$ nell'intervallo tra $2^h$ e $2^{h+1}$, la probabilità che esista un arco random tra $u$ e $x$ è proporzionale proprio $2^{-2h}$, ovvero 1 diviso la distanza tra $u$ e $x$ che compresa tra $2^h$ e $2^{h+1}$, il tutto elevato a $q$ che è pari a 2.\n\nAssodato che la probabilità che $u$ abbia un arco random con un nodo fissato $x$ nell'intervallo $2^h,2^{h+1}$ e proporzionale a $2^{-2h}$, e sapendo che in tale blocco ci sono un numero di nodi proporzionale proprio a $2^{2h}$, possiamo affermare che la probabilità che esista un arco random tra $u$ e un nodo qualsiasi dell'intervallo $2^h,2^{h+1}$ è una probabilità **costante**.\n\nSpecifichiamo perché costante:\nSia l'evento $\\mathcal{E}*x$ che occorre se esiste l'arco random tra $u$ e il nodo $x$ a distanza $2^h \\leq d(u,x) \\\u003c 2^{h+1}$.\nSappiamo che tale evento occore con probabilità\n$$\\mathcal{P}(\\mathcal{E}*x) \\propto d(u,x)^{-2} \\propto 2^{-2h}$$\nSia quindi l'evento $\\mathcal{E}$ che occorre quando esiste un arco random che collega $u$ all'intervallo desiderato.\nTale probabilità sarà pari a\n$$\n\\\\begin{align\\*}\n\\\\mathcal{P}(\\mathcal{E})\n\u0026\\overbrace{=}^{\\textbf{(1)}} \\mathcal{P}(\\bigcup*{x : 2^h \\leq d(u,x) \\\u003c 2^{h+1}} \\mathcal{E}*x)\\\\\n\u0026= \\sum*{x : 2^h \\leq d(u,x) \\\u003c 2^{h+1}} \\mathcal{P}(\\mathcal{E}*x)\\\\\n\u0026\\approx |C*{2^{h+1}}(u) - C*{2^h}(u)| \\cdot \\mathcal{P}(\\mathcal{E}\\_x)\\\\\n\u0026= \\alpha 2^{2h} \\cdot \\beta 2^{-2h}\\\\\n\u0026= \\gamma\n\\\\end{align\\*}\n$$\nper qualche costante $\\alpha, \\beta, \\gamma$.\n\nSpecifichiamo che $C_r(u)$ è il cerchio di raggio $r$ centrato in $u$, mentre l'uguaglianza **(1)** è deta dal fatto che tutti gli eventi del tipo $\\mathcal{E}\\_x$ sono mutuamente disgiunti.\n\nL'ultimo risultato è molto forte, in quanto suggerisce che la probabilità che un arco random che parta da $u$ consenta un salto di risoluzione è **indipendente** dalla risoluzione, che sia $2^4$ o $2^{100}$.\nCiò implica che i weak ties sono distribuiti in maniera **uniforme** tra le risoluzioni, ammesso che poniamo $q$ pari al valore ottimale $d$.\n\n### Prestazioni della ricerca miope (decentralizzata)\n\nNella precedente sezione abbiamo dato un'idea intuitiva del perché una distribuzione inversamente quadratica dei weak ties rispetto alle distanze rende la ricerca decentralizzata possibile.\n\nPer semplicità verrà fatta un'analisi rigorosa (e non intuitiva) di questo fenomeno su una griglia 1-dimensionale, ovvero un *anello*.\n\n![Anello con random links.|300](ar-lesson06-img6.png) ^0b7c7d\n\nAll'interno dell'anello ogni nodo $v$ ha esattamente 2 vicini, detti **contatti locali** (o **local links**), e nella compontente aleatoria da ogni nodo $v$ parte un arco diretto casuale $(v,w)$, detto **contatto a lunga distanza** (o **long-range link**), che esiste con probabilità $d(v,w)^{-1}$.\n\nRicordiamo che la **ricerca miope** consiste essenzialmente nel passare il messaggio al nodo vicino che più si avvicina al destinatario.\nConsiderando la [precedente figura](6%20-%20Small%20World.md#0b7c7d), supponiamo che il nodo `a` voglia inviare il messaggio al nodo `i` dalla parte opposta dell'anello.\nTra i suoi vicini ci sono `b` e `p` collegati da *local links* e il nodo `d` collegato da un *long-range link*. Tra i tre, il più vicino a `i` è il nodo `d`, e quindi `a` gli passa il messaggio.\nDopodiché `d` passa il nodo a `e` che è il suo vicino più prossimo alla destinazione, che a sua volta invia il messaggio al nodo `f` (per gli stessi ragionamenti fatti fin ora).\nInfine `f` inoltra il messaggio attraverso il un *long-range link* al nodo `h`, che è recapita il messaggio al destinatario in quanto suo diretto vicino.\n\n![Risultato della ricera miope da a ad i|300](ar-lesson06-img7.png)\n\nOvviamente questo non è un cammino minimo, per esempio se `a` avesse inviato il messaggio a `b` anziché a `d`, esso sarebbe arrivato a destinazione in soli 3 passi.\nPerò sappiamo che `a` non ha alcuna informazione oltre alla visione del suo vicinato, e il cammino risultate dalla ricerca miope è abbastanza corto da essere un risultato più che accettabile con le poche informazioni a disposizione.\n\nScelti una mittente $s$ e un destinatario $t$ a caso, definiamo la v.a. $X$ come il la lunghezza di un cammino da $s$ a $t$ risultante dalla ricerca miope, e sia $\\mathbb{E}\\left\\[ X \\right\\]$ la lunghezza \u003cu\u003emedia\u003c/u\u003e di tali cammini.\n\nConsiderando una ricerca miope da $s$ a $t$, diremo che essa si trova della fase $j$ se il messaggio si trova ad una distanza compresa tra $2^j$ e $2^{j+1}$ dal destinatario.\n\n![\\|300](ar-lesson06-img8.png)\nOsserviamo che le fasi possono essere al più $\\log\\_{2}{n}$.\n\nPossiamo scrivere $X$ come la somma delle v.a. $X_1, X_2, ..., X\\_{\\log_2{n}}$ dove $X_i$ è la lunghezza complessiva del cammino lungo la fase $i$\n$$X = X_1 + X_2 + ... + X\\_{\\log_2{n}}$$\nPer linearità avremo che\n$$\\mathbb{E}\\left\\[ X \\right\\] = \\mathbb{E}\\left\\[ X_1 + X_2 + ... + X\\_{\\log_2{n}} \\right\\] = \\mathbb{E}\\left\\[ X_1 \\right\\] +  \\mathbb{E}\\left\\[ X_2 \\right\\] + ... +  \\mathbb{E}\\left\\[ X\\_{\\log_2{n}} \\right\\]$$\n\nDi seguito il temoremo che stima $\\mathbb{E}\\left\\[ X \\right\\]$.\n\n \u003e \n \u003e **THM** Sia $\\mathbb{E}\\left\\[ X \\right\\]$ la lunghezza media dei cammini risultati dalla ricerca miope tra una qualsiasi coppia di nodi, allora $$\\mathbb{E}\\left\\[ X \\right\\] \\in O(\\log^2{n})$$\n\nPer dimostrare il precedente teorema basta dimostrare che $\\mathbb{E}\\left\\[ X_i \\right\\] \\in O(\\log{n})$, per ogni fase $i$.\nPrima di procedere alla dimostrazione del teorema però è necessario fare alcune considerazioni sul fattore di normalizzazione $Z$ del modello.\n\nSappiamo che $Z$ è pari alla somma di tutti i $d(u,v)^{-1}$ per ogni $u \\neq v$.\nPerò sappiamo che in un anello ci sono esattamente 2 nodi a distanza 1 da $u$, 2 a distanza 2, 2 a distanza 3, ..., 2 a distanza $n/2$ (assumendo senza perdita di generalità che $n$ sia pari).\nPerciò avremo che\n$$Z = 2\\left( 1 + \\frac{1}{2} + \\frac{1}{3} + ... + \\frac{1}{n/2} \\right)$$\nSappiamo inoltre approssimmare la sommatoria in parentesi come\n$$1 + \\frac{1}{2} + \\frac{1}{3} + ... + \\frac{1}{n/2} \\leq 1 + \\int\\_{1}^{n/2} \\frac{1}{x} ,dx =  1 + \\ln{(n/2)}$$\nTornando a $Z$ avremo che\n$$\n\\\\begin{align\\*}\nZ \u0026\\leq 2(1 + \\ln{(n/2)})\\\\\n\u0026\\leq 2(1 + \\log_2{(n/2)})\\\\\n\u0026= 2 + 2\\log_2{(n/2)}\\\\\n\u0026= 2 + 2\\log_2{(n)} - 2\\log_2{(2)} = 2\\log_2{(n)}\n\\\\end{align\\*}\n$$\nPerciò la probabilità che esista un random edge tra $u$ e $v$ sarè\n$$\\mathcal{P}((u,v) \\in E_2) = \\frac{1}{Z}d(u,v)^{-1} \\geq  \\frac{1}{2\\log{n}}d(u,v)^{-1}$$Procediamo ora alla dimsotrazione del teorema\n\n \u003e \n \u003e **Proof:** Siano i nodi $s,t$ rispettivamente il nodo *mittente* e il nodo *destinatario*. Abbiamo partizionato i nodi in base a distanze dalla sorgente $t$ che si \u003cu\u003edimezzano\u003c/u\u003e, ovvero abbiamo definito la fase $j$ in cui il messaggio appartiene a un nodo $u$ con distanza\n \u003e $$\\frac{d(s,t)}{2^{j+1}} \\leq d(u,t) \\\u003c \\frac{d(s,t)}{2^j}$$\n \u003e Certamente è vero che se esiste un arco $(u,v)$ tale che\n \u003e $$d(v,t) \\leq \\frac{d(u,t)}{2} \\\u003c \\frac{1}{2}\\frac{d(s,t)}{2^j} = \\frac{d(s,t)}{2^{j+1}}$$\n \u003e allora la fase $j$ termina.\n \u003e \n \u003e Abbiamo quindi un limite inferiore alla probabilità che la fase $j$ termini\n \u003e $$\n \u003e \\\\begin{align\\*}\n \u003e \\\\mathcal{P}\\left(\\mbox{la fase } j \\mbox{ termina}\\right)\n \u003e \u0026= \\mathcal{P}\\left((\\exists (u,v) \\in E : d(v,t) \\\u003c \\frac{d(s,t)}{2^{j+1}}\\right)\\\\\n \u003e \u0026\\geq \\mathcal{P}\\left((\\exists (u,v) \\in E : d(v,t) \\leq \\frac{d(u,t)}{2}\\right)\n \u003e \\\\end{align\\*}$$\n \u003e Definiamo ora con $I$ l'insieme di tutti i nodi a distanza da $t$ non più di $\\frac{d(u,t)}{2}$, ovvero\n \u003e $$ I \\equiv \\left{ x \\in V : d(x,t) \\leq \\frac{d(u,t)}{2} \\right} $$\n \u003e Ricordando che $E_1$ è l'insieme di archi della componente deterministica ed $E_2$ gli archi di quella aleatoria, avremo quindi che\n \u003e $$\n \u003e \\\\begin{align\\*}\n \u003e \\\\mathcal{P}\\left(\\exists (u,v) \\in E : d(v,t) \\leq \\frac{d(u,t)}{2}\\right)\n \u003e \u0026= \\mathcal{P}(\\exists v \\in I : (u,v) \\in E)\\\\\n \u003e \u0026= \\mathcal{P}(\\exists v \\in I : (u,v) \\in E_1 \\cup (u,v) \\in E_2)\\\\\n \u003e \u0026= \\sum\\_{v \\in I} \\mathcal{P}((u,v) \\in E_1 \\cup (u,v) \\in E_2)\\\\\n \u003e \u0026= \\sum\\_{v \\in I} \\mathcal{P}((u,v) \\in E_1) + \\mathcal{P}((u,v) \\in E_2)\\\\\n \u003e \u0026\\geq \\sum\\_{v \\in I} \\mathcal{P}((u,v) \\in E_2) = \\sum\\_{v \\in I} \\frac{1}{Z}\\frac{1}{d(u,v)}\n \u003e \\\\end{align\\*}$$\n \u003e Diamo ora una stima alla distanza $d(u,v)$.\n \u003e Certamente $u$ può raggiungere $v$ tramite un cammino del tipo $u \\leadsto t \\leadsto v$, e questo cammino sarà lungo **almeno** $d(u,v)$ $$ d(u,v) \\leq d(u,t) + d(t,v) = d(u,t) + d(v,t) \\leq d(u,t) + \\frac{d(u,t)}{2} = \\frac{3d(u,t)}{2}$$\n \u003e perciò, per ogni $v \\in I$ avremo che\n \u003e $$\n \u003e \\\\begin{align\\*}\n \u003e \\\\sum\\_{v \\in I} \\mathcal{P}((u,v) \\in E_2)\n \u003e \u0026= \\sum\\_{v \\in I} \\frac{1}{Z}\\frac{1}{d(u,v)}\\\\\n \u003e \u0026\\geq \\sum\\_{v \\in I} \\frac{1}{Z}\\frac{2}{3d(u,t)}\\\\\n \u003e (Z \\leq 2\\ln{n}) \u0026\\geq \\sum\\_{v \\in I} \\frac{1}{2\\ln{n}}\\frac{2}{3d(u,t)}\\\\\n \u003e \u0026= \\sum\\_{v \\in I} \\frac{1}{3d(u,t)\\ln{n}}\\\\\n \u003e \u0026= \\frac{|I|}{3d(u,t)\\ln{n}}\n \u003e \\\\end{align\\*}$$\n \u003e Ora dobbiamo stimare $|I|$.\n \u003e Sappiamo che in $I$ ci sono tutti quei nodi a distanza al più $d(u,t)/2$, che siano dal lato destro o sinistro.\n \u003e Per definizione dobbiamo contare anche $t$, in quanto $d(t,t) = 0 \\leq d(u,t)/2$.\n \u003e Avremo quindi\n \u003e $$ \\vert I \\vert = \\lfloor \\frac{d(u,t)}{2} \\rfloor + \\lfloor \\frac{d(u,t)}{2} \\rfloor + 1 \\geq \\frac{d(u,t)-1}{2} + \\frac{d(u,t)-1}{2} + 1 = \\frac{d(u,t)}{2} $$\n \u003e perciò\n \u003e $$\\sum\\_{v \\in I} \\mathcal{P}((u,v) \\in E_2) \\geq \\frac{d(u,t)}{3d(u,t)\\ln{n}} = \\frac{1}{3\\ln{n}}$$\n \u003e Perciò l'evento complementare, ovvero l'evento che la fase $j$ non termina se siamo nel nodo $u$ è pari a $1 -  \\frac{1}{3\\ln{n}}$.\n \u003e Possiamo ora ricavare la probabilità che la fase $j$ non termini entro $h$ passi come segue\n \u003e $$\\mathcal{P}(X_j \\geq h) \\leq \\left( 1 -  \\frac{1}{3\\ln{n}} \\right)^h$$\n \u003e Per conculdere non resta che calcolare $\\mathbb{E}\\left\\[ X_j \\right\\]$.\n \u003e Iniziamo col comporre tale fattore in una sommatoria\n \u003e $$\n \u003e \\\\begin{align\\*}\n \u003e \\\\mathbb{E}\\left\\[ X_j \\right\\]\n \u003e \u0026= 1 \\cdot \\mathbf{P}( X_j = 1 ) + 2 \\cdot \\mathbf{P}( X_j = 2 ) +  3 \\cdot \\mathbf{P}( X_j = 3 ) + ... + \\frac{n}{2} \\cdot \\mathbf{P}\\left( X_j = \\frac{n}{2} \\right)\\\\\n \u003e \u0026= \\mathbf{P}( X_j \\geq 1 ) + 1 \\cdot \\mathbf{P}( X_j = 2 ) +  2 \\cdot \\mathbf{P}( X_j = 3 ) + ... + \\left(\\frac{n}{2} - 1 \\right) \\cdot \\mathbf{P}\\left( X_j = \\frac{n}{2} \\right)\\\\\n \u003e \u0026= \\mathbf{P}( X_j \\geq 1 ) + \\mathbf{P}( X_j \\geq 2 ) +  1 \\cdot \\mathbf{P}( X_j = 3 ) + ... + \\left(\\frac{n}{2} - 2 \\right) \\cdot \\mathbf{P}\\left( X_j = \\frac{n}{2} \\right)\\\\\n \u003e \u0026\\vdots\\\\\n \u003e \u0026= \\mathbf{P}( X_j \\geq 1 ) + \\mathbf{P}( X_j \\geq 2 ) + \\mathbf{P}( X_j \\geq 3 ) + ... + \\mathbf{P}\\left( X_j \\geq \\frac{n}{2} \\right)\\\\\n \u003e \u0026= \\sum\\_{1 \\leq h \\leq n/2} \\mathbf{P}( X_j \\geq h )\n \u003e \\\\end{align\\*}$$\n \u003e dove $n/2$ è il massimo valore che può assumere $X_j$ in quanto $n/2$ è la distanza massima tra due nodi.\n \u003e \n \u003e A questo punto possiamo stimare il valor medio della durata della fase $j$ come\n \u003e $$\n \u003e \\\\begin{align\\*}\n \u003e \\\\mathbb{E}\\left\\[ X_j \\right\\]\n \u003e \u0026= \\sum\\_{1 \\leq h \\leq n/2} \\mathbf{P}( X_j \\geq h )\\\\\n \u003e \u0026\\leq \\sum\\_{1 \\leq h \\leq n/2} \\left( 1 -  \\frac{1}{3\\ln{n}} \\right)^h\\\\\n \u003e \u0026\\leq \\sum\\_{h \\geq 1}^{\\infty} \\left( 1 -  \\frac{1}{3\\ln{n}} \\right)^h\\\\\n \u003e \u0026= \\frac{1}{1 - \\left( 1 -  \\frac{1}{3\\ln{n}} \\right)} = 3\\ln{n} \\in O(\\log{n})\n \u003e \\\\end{align\\*}$$\n \u003e Di conseguenza l'ipotesi del teorema \n \u003e $$\\mathbb{E}\\left\\[ X \\right\\] = \\sum\\_{j = 1}^{\\log_2{n}} \\mathbb{E}\\left\\[ X_j \\right\\] \\in O(\\log^2{n}) ;; \\square$$\n\n### Ricerca miope per $q \\neq d$\n\nPrendiamo il caso $d = 1$ e $q = 0$.\nCon $q = 0$, la probabilità di avere l'arco random $(u,v)$ sarà pari a $1/Z$.\n$$\\mathcal{P}((u,v) \\in E) = \\frac{1}{Z}\\frac{1}{d(u,v)^0} = \\frac{1}{Z}$$\nOsservaimo inoltre che $Z$ sarà pari a\n$$Z = \\sum\\_{v \\neq u}\\frac{1}{d(u,v)^0} = n - 1$$\nQuindi la probabilità di avere un arco random sarà $\\frac{1}{n-1} \u003e \\frac{1}{n}$.\n\nDefiniamo ora l'insieme $R$ di nodi a distanza \u003cu\u003eal più\u003c/u\u003e $\\sqrt{n}$ dal destinatario $t$\n$$R \\equiv \\lbrace x \\in V : d(x,t) \\leq \\sqrt{n} \\rbrace$$\nPrendiamo il mittente $s$ fuori da $R$, avremo che la probabilità di entrare in $R$ tramite un arco random $(u,v)$ sarà\n$$\n\\\\begin{align\\*}\n\\\\forall u \\not\\in R;;;;\n\\\\mathcal{P}(\\exists (u,v) \\in (R, E-R))\n\u0026= \\sum\\_{v \\in R} \\mathcal{P}( (u,v) \\in E_2 )\\\\\n\u0026\u003e \\sum\\_{v \\in R} \\frac{1}{n}\\\\\n\u0026= \\frac{|R|}{n} = \\frac{2\\sqrt{n}}{n} = \\frac{2}{\\sqrt{n}}\n\\\\end{align\\*}\n$$\nSia quindi $Y$ la v.a. che indica quanti passi ci vogliono per raggiungere $R$ partendo da $s$, con probabilità\n$$\\mathcal{P}(Y \\geq h) \\\u003c \\left( 1 - \\frac{2}{\\sqrt{n}} \\right)^h$$\ncon media\n$$\\mathbb{E}\\left\\[ Y \\right\\] = \\sum_h \\mathbf{P}( Y ) \\leq \\frac{1}{1 - \\left( 1 - \\frac{2}{\\sqrt{n}} \\right)} =  \\frac{\\sqrt{n}}{2}$$\ne questo di per se è già un tempo esponenzialmente più grande del tempo che ci impiegherebbe l'intera ricerca miope nel caso $q=1$.\n\nD'altro canto, se $q \u003e 1$, avremo che gli archi random sono più corti rispetto al caso $q=1$, perciò la ricerca miope non migliora.\nAddirittura per $q$ abbastanza grande la rete tende ad essere composta dalla sola componente deterministica.\n\nDi seguito un teorema che racgiude tutti questi raggionamenti\n\n \u003e \n \u003e **THM** sia $X$ la variabile aleatoria che indica la lunghezza del cammino trovato dalla ricerca miope su un anello di $n$ nodi.\n \u003e Comunque si sceglie un $q \\neq 1$ esistono sempre due costanti $\\alpha_q$ e $c_q$ tali che\n \u003e $$\\mathbb{E}\\left\\[ Y \\right\\] \\geq a_q \\cdot n^{c_q}$$\n\nRibadendo che il tutto vale nel caso in cui la componente deterministica sia un anello di $n$ nodi, si possono estendere tutti i raggionamenti anche per un qualsiasi $d \u003e 1$, a scapito di calcoli più complessi.\n\n---\n\n[^1]: ovvero quando i nodi conoscono solamente il proprio vicinato.\n\n[^2]: Klinberg, 2000.\n\n[^3]: ovvero la distanza nella griglia deterministica sottostante tra le estremità dei random edges.\n\n[^4]: probabilità uniforme.\n\n[^5]: periodica.\n","lastmodified":"2022-08-29T13:39:16.931289131+02:00","tags":null},"/AR/7-Communities-Part-1":{"title":"","content":"\nFin ora abbiamo analizzato le reti dal punto di vista *statistico*, disinteressandoci delle caratteristiche dei singoli nodi e soffermandoci su ciò che **mediamente** accadeva. ...\n\n# Reti con struttura disomogenea\n\n## Esperimento di Granovetter\n\nNel 1960, il sociologo Mark Granovetter prosope il seguente esperimento nella sua tesi di dottorato: intervistò una serie di persone che di recente avevano cambiato lavoro, facendo domande poste a capire in che modo erano venuti a conoscenza della nuova opportunità lavorativa.\n\nCome ci si può aspettare la gran parte delle persone erano venuti a conoscenza dell'opportunità da lavoro tramite passaparola.\n\nCiò che invece era meno atteso, è che un gran numero di volte l'informazione arrivò da gente che si conosceva superficialmente.\nQuesto fu sorprendente perché ci si aspetta che gli amici più stretti siano quelli più interessati ad aiutarsi nel momento del bisogno.\n\nUna risposta al fenomeno proposta da Granovetter fu che le persone a noi strette in realtà tendono ad avere le stesse nostre informazioni.\nInfatti è normale che se frequentino più o meno gli stessi posti e persone di un amico stretto.\nOppure, se ho una relazione stretta con una persona è perché ci ho parlato molto nel tempo, e quindi tutte le informazioni importanti che tale persona poteva darmi me le avrà già date in passato.\n\nContrariamente, una persona che conosco poco probabilmente frequenterà altri posti e persone, e quindi avrà accesso ad altre **fonti di informazioni** che provengono al di fuori della mia **comunità**.\n\n## Bridges e Local Bridges\n\nCome si può intuire dall'esperimento di Granovetter i contatti che più sono rilevanti nella diffusione di informazioni in una rete sono quei contatti che collegano due comunità differenti.\nSulla base di questo si può definire il concetto di **bridge edge**, ovvero tutti quegli archi la cui rimozione disconnette la rete.\nOvviamente i bridge edges sono archi *cruciali* per l'accesso alle informazioni, in quanto senza di essi una informazione non potrebbe uscire dalla sua componente.\n\nIn una rete sociale reale (e artificiale) è davvero molto poco probabile che esistano bridge edges, anche perché sappiamo già che le reti sociali presentano delle componenti giganti con buona probabilità.\n\nRilassiamo quindi la totale disconnessione dovuta alla rimozione di tali archi, e definiamo il concetto di **local bridge**. \n\nFormalmente un arco $(u,v)$ è detto local bridge se $u$ e $v$ non hanno altri amici in comuni, ovvero se $N(u) \\cup N(v) \\equiv \\emptyset$.\n\n![In rosso il local bridge|450](ar-lesson07-img1.png)\n\nPossiamo vedere i local bridge come archi la cui rimozione aumenta la distanza tra le due estremita di \u003cu\u003ealmeno\u003c/u\u003e 2.\n\n## Strong \u0026 Weak Ties\n\nL'esperimento di Granovetter mostra che le informazioni sono veicolate tramite le conoscenze più deboli, proprio perché permettono di accingere ad altre fonti di informazioni.\n\nPossiamo quindi definire un modello di rete in cui gli archi sono partizzionati tra archi **forti** (**strong ties**) e archi **deboli** (**weak ties**), che appunto rappresentano i tipi di legami che le persone possono avere.\n\nCertamente in un contesto reale esiste un largo range di tipi di amicizie e conoscenze che ci possono essere tra due individui, però per semplicità cataloghiamo i tipi di conoscenze solo nelle due categorie **strong** e **weak**.\n\nPiù formalmente definiamo questo modello con un grafo $G=(V,S\\cup W)$, dove $S$ è l'insieme degli strong ties e $W$ è quello dei weak ties.\nImportante specificare che i due insiemi sono disgiunti, infatti una persona non può essere sia amica stretta che amica superficiale di un'altra (a meno che non sia una persona falsa, ma questo è un altro discorso...).\n$$S \\cup W \\equiv \\emptyset$$\n\n## The Strong Triadic Closure Property\n\nConsideriamo lo stato di una rete sociali in un dato istante, sarebbe interessante sapere come si evolve nel tempo e quali sono i meccanismi che portano alla creazione o alla rottura di nuovi archi.\n\nUn principio abbastanza intuitivo è il seguente:\n\n \u003e \n \u003e se due nodi hanno un amico stretto in comune, allora è molto probabile che in futuro entrino in contatto e stabiliscano anchessi un rapporto di amicizia stretta.\n\nCiò che si genera quindi tra i tre nodi in questione è la cosidetta **chiusura triadica**.\n\nPensando la chiusura triadica in termini di strong e weak ties possiamo definirla secondo la seguente regola\n\n \u003e \n \u003e Sia il nodo $a$ e due suoi vicini $b$ e $c$, allora l'arco $(b,c)$ probabilmente si creerà se $(a,b),(a,c) \\in S$, ovvero se sono *strong ties*.\n\nDiremo che quindi il nodo $u$ rispetta la **Strong Triadic Closure Property** (`STCP` in breve) se\n$$\\forall (u,v), (u,w) \\in S \\left\\[ (v,w) \\in S \\cup W \\right\\]$$\n\nInfine diciamo che $G$ soddisfa la `STCP` se \u003cu\u003etutti\u003c/u\u003e i suoi nodi la soddisfano.\n\nSe si osserva bene, quando una rete soddisfa la `STCP` essa si **stabilizza** secondo la regola precedentemente descritta, ovvero in futuro non si genereranno più altri archi.\n\n## STCP e Local Bridges\n\n \u003e \n \u003e **THM** Sia una rete $G=(V,S\\cup W)$, un nodo $u \\in V$ che soddisfa la `STCP` e due suoi vicini $x,y$ tali che $(u,x) \\in S$ e $(u,y)$ è\n \u003e un *local bridge* (ovvero $N(u) \\cap N(y) \\equiv \\emptyset$ ) allora certamente $(u,y) \\in W$ (è un *weak tie*).\n\n \u003e \n \u003e **Proof** Se per assurdo $(u,y) \\in S$. Dato che $u$ soddisfa la `STCP` allora deve essere vero che esiste l'arco $(x,y)$, e quindi\n \u003e $x \\in N(y)$. Ma poiché $N(u) \\cap N(y) \\equiv \\emptyset$ e $x \\in N(u)$, allora deve essere vero che $x \\not\\in N(y)$ (**assurdo**) $\\implies (u,y) \\in W$ $\\square$.\n\nIl teorema precedentemente enunciato mostra come una proprietà che ha effetti globali (ovvero essere un *local bridge*) involve in una proprietà strettamente locale (ovvere essere un *weak ties*).\nInfatti la proprietà di *weak ties* è visibile dal punto di vista locale da parte di un nodo: ogni persona sà se un suo amico è stretto o alla lontana.\n\nViceversa, la proprietà di un arco di essere un *local edge* non intuibile da parte di un nodo. Infatti, dato che un nodo conosce solo il suo vicinato non può sapere sapere se ha vicini in comune con un altro suo vicino.\n\n---\n\n## Comunità e Coefficiente di Clustering\n\nAbbiamo definito in precedenza un modello di rete dinamica i cui archi si modificano nel tempo, e dove la rete si stabilizza nel momento in cui essa soddisfa la [STCP](7%20-%20Communities%20-%20Part%201.md#the-strong-triadic-closure-property).\n\nDato che si generano tanti triangoli, allora nel grafo stabilizzato si creeranno gruppi di nodi **fortemente coesi** da una densa quantità di archi.\nChiameremo questi gruppi fortemente coesi **comunità**, o **cluster**.\n\nLa precedente è una definizione informale e discorsiva.\nDal punto di vista formale, quando possiamo dire che un gruppo di nodi è abbastanza **coeso** da essere definito comunità?\nE che significa **coeso**?\n\nPer fare ciò iniziamo col **quantificare** la coesione del nodo $u$ all'interno dei suoi vicini.\nSia quindi il **coefficiente di clustering**\n$$\n\\\\begin{align\\*}\nc(u)\n\u0026= \\frac{ \\vert \\lbrace (x,y) \\in E : x \\in N(u) \\land y \\in N(u) \\rbrace \\vert }{ \\binom{N(u)}{2}  }\\\\\n\u0026= \\frac{ \\vert \\lbrace (x,y) \\in E : x \\in N(u) \\land y \\in N(u) \\rbrace \\vert }{ \\frac{ \\vert N(u) \\vert (\\vert N(u) \\vert - 1) }{2}  }\n\\\\end{align\\*}\n$$\nIntuitivamente tale valore cerca di misuare quanto un nodo $u$ è *ben inserito* nel gruppo sociale formato dai suoi vicini.\nInfatti tale quantità calcola il rapporto tra i triangoli che coinvolgono $u$ e il numero massimo possibile di relazioni che possono esistere tra tutti i suoi vicini.\n\nSe un nodo ha un coefficiente di clustering basso vuol dire che si trova in una posizione periferica rispetto ai suoi mici.\n\nViceversa, un nodo con un coefficiente di clustering è ben inserito tra i suoi amici, e quindi diremo che è un elemento **centrale** nella sua cerchia di conoscenze.\n\nPossiamo quindi vedere e riferirci al coefficiente di clustering come **indice di centralità** di un nodo.\n\nAnalogamente possiamo definire un coefficiente di clustering relativo a un sottoinsieme $C$ di nodi.\nOvvero, dato un sottoinsieme $C \\subseteq V$ definiamo il *coefficiente di clustering di $u$ relativo a* $C$ come la quantità\n$$\n\\\\begin{align\\*}\nc_C(u)\n\u0026= \\frac{ \\vert \\lbrace (x,y) \\in E : x \\in N(u) \\cap C \\land y \\in N(u) \\cap C \\rbrace \\vert }{ \\binom{N(u) \\cap C}{2}  }\\\\\n\u0026= \\frac{ \\vert \\lbrace (x,y) \\in E : x \\in N(u) \\cap C \\land y \\in N(u) \\cap C \\rbrace \\vert }{ \\frac{ \\vert N(u) \\cap C \\vert (\\vert N(u) \\cap C \\vert - 1) }{2}  }\n\\\\end{align\\*}\n$$\nQuesta quantità definisce quanto il nodo $u$ è integrato all'interno del sottoinsieme di nodi $C$: più il coefficiente $c_C(u)$ è elevato più $u$ è *centrale* all'interno di $C$, contrariamente più è basse, meno $u$ è integrato.\n\nPerciò potremmo dire che se $C$ ha tutti nodi con coefficiente di clustering alto, allora $C$ è una **comunità** (o **cluster**).\n\nMa di preciso quanto deve essere elevato questo valore per poter dire che $C$\nè una comunità?\n\nInoltre il coefficiente di clustering è un buon fattore da considerare per identificare le comunità?\n\n---\n\n# Alcuni tipi di Comunità\n\n## Cut-Communities\n\nDato un grafo $G = (V,E)$ e una coppia di nodi $s,t \\in V$, diciamo che una **cut-community** rispetto a $s,t$ è un sottoinsieme proprio e non vuoto dei nodi $C \\subset V$ (con $C \\not\\equiv \\emptyset$) tale che $s \\in C$ e $t \\in \\overline{C} \\equiv V \\setminus C$, e tale che questo sottoinsieme **minimizza** gli archi del taglio $(C,\\overline{C})$, ovvero\n$$\\vert (C, \\overline{C}) \\vert = \\min\\_{A \\subset V}{\\lbrace \\vert (A, \\overline{A}) \\vert : s \\in A \\land t \\in \\overline{A} \\rbrace }$$\nCitando il [Max-Flow/Min-Cut Theorem](https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem), trovare un $s$-$t$ cut minimo equivale a trovare il **flusso massimo** tra $s$ e $t$.\n\nPerciò, dati $s$ e $t$ possiamo trovare una cut community grazie all'algoritmo di max-flow [Ford\u0026Fulkerson](https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm).\n\nPer trovare una cut comunity che sia la più coesa possibile (quindi una cut-community non necessariamente riferita a due nodi $s,t$), si potrebbero calcolare tutti gli $s$-$t$ cut minimi e scegleire quello più piccolo, ovvero basta calcolare un **taglio minimo** del grafo.\n\nOsservare che questo si può fare in *tempo polinomiale*[^1], perciò possiamo affermare che il problema decisionale che stabilisce se un grafo è partizionabile in due cut-communities è collocato nella classe di complessità **P**.\n\nIl problema di questo metodo è che non c'è modo di controllare la dimensione della comunità $C$ risultante, infatti potrebbe capitare che $C$ sia composta dal solo elemento $s$, e ciò è in disaccordo col concetto intuitivo di comunità (una sola persona non può costituire una comunità).\n\nConsideriamo infatti il seguente esempio:\n![Controesempio|450](ar-lesson07-img2.png)\nabbiamo un grafo $G$ composto dall'unione di due *clique* $K_5$\n$$G = K_5^{(u)} \\cup K_5^{(v)}$$\nOltre agli archi delle due clique, per ogni nodo $u_i \\in K_5^{(u)}$ esistono i tre archi $(u_i, v\\_{i-1 \\mod{5}}), (u_i, v_i), (u_i, v\\_{i + 1 \\mod{5}})$ (come mostrato nella precedente figura).\n\nSe si osserva bene, comunque scegliamo un nodo $x$, l'\u003cu\u003eunico\u003c/u\u003e taglio minimo è del tipo $(\\lbrace x \\rbrace, V \\setminus \\lbrace x \\rbrace)$, di dimensione 7.\n\nInfatti, se aggiungessimo un qualsiasi nodo insieme ad $x$ otterremmo un taglio di dimensione strettamente maggiore di 7.\n\nPer esempio $12 = \\vert (\\lbrace u_0, u_1 \\rbrace, V \\setminus \\lbrace u_0, u_1 \\rbrace ) \\vert \u003e \\vert (\\lbrace u_0 \\rbrace, V \\setminus \\lbrace u_0 \\rbrace ) \\vert = 7$.\n\nSe ci riveriamo alla definizione di cut-cumminity, non ha molto senso dire che il solo nodo $u_0$ compone una comunità, per questo è necessario dare una nuova definizione di comunità.\n\n## Web-Communities\n\nUna (**strong**) **web-community** un sottoinsieme **proprio e non vuoto** $C \\subset V$, tale che i nodi che lo compongono hanno più vicini all'interno di $C$ stesso anzichè all'esterno, ovvero\n$$\\forall u \\in C \\left\\[ \\vert N(u) \\cap C \\vert \u003e \\vert N(u) \\setminus C \\vert = \\vert N(u) \\cap (V \\setminus C) \\vert  \\right\\]$$\nAlternativamente è comodo guardare alla precedente proprietà come il fatto che *almeno* la metà dei vicini di $u$ è all'interno di $C$\n$$\\frac{\\vert N(u) \\cap C \\vert}{\\vert N(u) \\vert} \u003e \\frac{1}{2}$$\nRilassando la relazione di maggioranza stretta, possiamo definire in maniera analoga una **weak web-community** qualsiasi sottoinsieme $C$ non vuoto e proprio di $V$ tale che\n$$\\frac{\\vert N(u) \\cap C \\vert}{\\vert N(u) \\vert} \\geq \\frac{1}{2}$$\n\n## Relazione tra cut- e web-communities\n\nIl concetto di cut-community e weak web-community sono in realtà strettamente correlati, risultando nel seguente teorema \n\n \u003e \n \u003e **THM** Sia un grafo $G = (V,E)$. Se $G$ ha una cut-community $C \\subset V$ tale che $|C| \u003e 1$, allora $C$ è anche una weak web-community.\n \u003e Più formalmente, dato un sottoinsieme $C \\subset V$ tale che\n \u003e $$\n \u003e \\\\vert (C, V \\setminus C) \\vert = \\min\\_{A \\subset V}{ \\lbrace \\vert (A, V \\setminus A) \\vert \\rbrace }\\\\\n \u003e \\\\land\\\\\n \u003e 1 \\\u003c \\vert C \\vert \\\u003c \\vert V \\vert$$\n \u003e allora $$\\forall u \\in C ; \\left\\[ \\vert N(u) \\cap C \\vert \\geq \\vert N(u) \\setminus C \\vert \\right\\]$$\n\n \u003e \n \u003e **Proof** Supponiamo per assurdo che l'insieme $C$ non sia una weak web-community, ovvero che\n \u003e $$\\exists u \\in C : \\vert N(u) \\cap C \\vert \\\u003c \\vert N(u) \\setminus C \\vert$$\n \u003e Dato che $C$ ha *almeno* due elementi, allora $C \\setminus \\lbrace u \\rbrace , (V \\setminus C) \\cup \\lbrace u \\rbrace )$ è un taglio del grafo.\n \u003e \n \u003e Calcoliamo ora la dimensione di questo nuovo taglio\n \u003e $$\\begin{align\\*}\n \u003e \\\\vert (C \\setminus \\lbrace u \\rbrace , (V \\setminus C) \\cup \\lbrace u \\rbrace ) \\vert\n \u003e \u0026= \\vert (C, V \\setminus C) \\vert + \\underbrace{\\vert N(u) \\cap C \\vert - \\vert N(u) \\setminus C \\vert}\\_{\\\u003c 1}\\\\\n \u003e \u0026\\\u003c \\vert (C, V \\setminus C) \\vert\n \u003e \\\\end{align\\*}$$\n \u003e Quindi abbiamo trovato un altro taglio **minore** $(C, V \\setminus C)$, e questo è assurdo in quanto essendo $C$ per ipotesi una cut-community deve essere vero che $(C, V \\setminus C)$ è un taglio minimo di $G$.\n \u003e \n \u003e Perciò necessariamente è falsa l'ipotesi che $C$ non sia una weak web-community $\\square$.\n\nAnche se esiste un algoritmo polinomiale che decide se un grafo è partizionabile in cut-community, non ne conosciamo un che **decida** in tempo polinomiale se un grafo è partizionabile in web-communities.\n\nInfatti, sappiamo trovare due cut-communities $C$, $V \\setminus C$ che generino un taglio minimo, ma non sappiamo garantire che $\\vert C \\vert \u003e 1$ e $\\vert V \\setminus C \\vert \u003e 1$.\n\nIn realtà, non solo non conosciamo un algoritmo che possa farlo in tempo polinomiale, ma è possibile dimostrare che tale problema è **NP-completo**[^2].\n\nDefiniamo qundi il problema **Strong Web-Community Partitioning** (**SWCP**) il **problema decisionale** che si occupa di stabilire se dato un grafo $G$ esiste un sottoinsieme dei nodi $C$ tale che $C$ e $V \\setminus C$ sono due strong web-community.\n\n \u003e \n \u003e **THM** il problema **SWCP** è un problema **NP-completo**.\n\nPrima di procedere alla dimostrazione di questo teorema enunciamo e\ndimostriamo il seguente lemma\n\n \u003e \n \u003e **Lemma.** Sia $G$ un grafo partizionabile in due strong web-community.\n \u003e Se esiste un nodo $u$ di grado esattamente 2, allora necessariamente $u$ e i suoi due vicini devo appartenere alla stessa comunità.\n\n^38d602\n\n \u003e \n \u003e **Proof** Consideriamo una partizione in due strong web-communities $C, V \\setminus C = \\overline{C}$, e siano $v, w$ i due soli nodi vicini di $u$.\n \u003e \n \u003e Supponiamo per assurdo che $v \\in C$ e $w \\in \\overline{C}$. Dato che $C, \\overline{C}$ è una partizione di $V$, allora necessariamente o $u \\in C$ o $u \\in \\overline{C}$.\n \u003e \n \u003e Se $u \\in C$ avremo che $\\vert N(u) \\cap C \\vert = \\vert N(u) \\setminus C \\vert$, e quindi $C$ non sarebbe una **strong** web-community.\n \u003e \n \u003e Allora deve essere che $u \\in \\overline{C}$, però avremo $\\vert N(u) \\cap \\overline{C} \\vert = \\vert N(u) \\setminus \\overline{C} \\vert$, e quindi $\\overline{C}$ non è una **strong** web-community.\n \u003e \n \u003e Perciò non può essere vero che $v \\in C$ e $w \\in \\overline{C}$, quindi $u,v,w$ devono necessariamente appartenere alla stessa comunità $\\square$.\n\nProcediamo ora alla dimostrazione del teorema\n\n \u003e \n \u003e **Proof (THM)** Innanzitutto è facile verificare che **SWCP** è un problema in **NP**, basta mostrare un **certificato polinomiale**.\n \u003e \n \u003e Un certificato polinomiale banale è prorpio un sottoinsieme di nodi $C$ tale che $C$ e $V \\setminus C$ sono due strong web-communities.\n \u003e \n \u003e Per verificarne invece la completezza, è necessario mostrare una **riduzione** da un problema già noto essere **NP-completo** al problema in questione.\n \u003e \n \u003e In questo caso verrà mostrata una riduzione dal problema **3-SAT**.\n \u003e $$\\mbox{3-STA} \\preccurlyeq\\_{P} SWCP$$\n \u003e Consideriamo quindi una formula $\\phi = c_1 \\land c_2 \\land ... \\land c_m$ in 3-CNF, con variabili in $X = \\lbrace x_1, x_2, ..., x_n \\rbrace$.\n \u003e Costruiamo quindi il grafo $G$ come segue.\n \u003e \n \u003e L'insieme dei nodi $V$ contiene i nodi $T$ e $F$, che rappresenteranno le assegnazioni `true` e `false`.\n \u003e Questi due nodi sono posizionati nel grafo in modo tale che essi dovranno necessariamente appartenere a due comunità differenti affinché $G$ sia partizionabile in due strong web-community.\n \u003e \n \u003e Per ogni *variabile* $x_i \\in X$ costruiamo un **gadget variabile** come seuge:\n \u003e \n \u003e 1. inseriamo in $V$ i nodi $x_i, \\overline{x_i}, y_i, z_i, t_i, f_i$.\n \u003e 1. inseriamo in $E$ gli archi $(x_i,y_i), (x_i,z_i), (y_i,t_i), (t_i,T), (\\overline{x_i}, z_i), (\\overline{x_i}, y_i), (z_i, f_i), (f_i, F)$.\n \u003e 1. per il nodo $x_i$ aggiungiamo tanti vicini senza nome, tante quante sono le clausole che contengono $x_i$, più 1.\n \u003e 1. stessa cosa per $\\overline{x_i}$ come nel punto 3.\n \u003e \n \u003e ![Esempio gadget variabile.|300](ar-lesson07-img3.png)\n \u003e Osserviamo che se $T$ ed $F$ appartongono a due comunità differenti, allora anche $x_i$ ed $\\overline{x_i}$ apparterranno a due comunità differenti.\n \u003e Infatti, senza perdita di generalità poniamo $T \\in C$ e $F \\in \\overline{C}$:\n \u003e poiché $t_i$ e $f_i$ hanno entrambi grado 2, per il [lemma precedente](7%20-%20Communities%20-%20Part%201.md#38d602) deve necessariamente essere vero che $t_i, y_i \\in C$ e $f_i, z_i \\in \\overline{C}$.\n \u003e \n \u003e Poiché $y_i$ ha grado 3, allora almeno 1 tra $x_i$ e $\\overline{x_i}$ deve appartene a $C$.\n \u003e Stessa cosa per $z_i$, poiché ha grado 3 allora almeno 1 tra $x_i$ e $\\overline{x_i}$ deve appartene a $\\overline{C}$.\n \u003e \n \u003e Poiché $y_i$ e $z_i$ non devono poter essere raggiungibili (altrimenti apparterrebbero alla stessa comunità), allora possiamo dire che o $x_i$ appartiene e $C$ e $\\overline{x_i}$ a $\\overline{C}$, oppure viceversa.\n \u003e \n \u003e Infine, collocati i nodi $x_i$ e $\\overline{x_i}$ nelle rispettive comunità, essi si porteranno appresso i rispettivi vicini senza nome.\n \u003e \n \u003e Continuando, per ogni clausola $c_j$ di $\\phi$, definiamo un **gadget clausola** come segue:\n \u003e \n \u003e 1. inseriamo in $V$ un nodo $c_j$ e un nodo per ognuno dei suoi letterali $l\\_{j1},l\\_{j2},l\\_{j3}$.\n \u003e 1. in $E$ inseriamo gli archi da $c_j$ verso $l\\_{j1},l\\_{j2},l\\_{j3}$ e dai nodi $l\\_{j1},l\\_{j2},l\\_{j3}$ verso il nodo $T$.\n \u003e 1. infine aggiungiamo in $E$ un arco da $c_j$ verso ognuno dei letterali che lo compongono: se in $c_j = x_1 \\lor \\overline{x_2} \\lor \\overline{x_3}$ ollra inseriamo gli archi $(c_j,x_1), (c_j,\\overline{x_2}), (c_j,\\overline{x_3})$.\n \u003e    ![Esempio gadget clausola.|450](ar-lesson07-img4.png)\n \u003e    Notiamo che sempre per il Lemma precedente, dato che $l\\_{j1},l\\_{j2},l\\_{j3}$ hanno tutti grado 2, allora se $G$ è partizionabile in due strong web-community certamente sia $l\\_{j1},l\\_{j2},l\\_{j3}$ che $c_j$ devono essere nella stessa comunità a cui appartiene $T$.\n \u003e \n \u003e Inoltre poiché $c_j$ ha grado esattamente $6$, e poiché 3 dei suoi vicini sono nella comunità a cui appartiene $T$, allora basta che **almeno uno** tra i suoi letterali (nell'esempio predente $x_1, \\overline{x_2}, \\overline{x_3}$) appartenga anch'esso alla comunità in cui si trova $T$.\n \u003e \n \u003e Dalla costruizione appena fatta emerge che quindi $c_j$ deve appartenere alla stessa comunità a cui appartiene $T$, e per rendere ciò possibile **almeno uno** dei letterali che lo compongono deve appartenere alla stessa comunità.\n \u003e \n \u003e Iniziamo col dimostrare che $T$ ed $F$ devono necessariamente appartenere a due comunità differenti, e questo verrà dimostrato dimosrtando che se $T$ ed $F$ appartengono alla stessa comunità $C$ allora $C \\equiv V$\n \u003e $$T, F \\in C \\Leftrightarrow C \\equiv V$$\n \u003e Iniziamo con l'osservare che se $T,F$ appartengono alla stessa comunità $C$ allora anche i nodi $y_i$ e $z_i$ appartengono a $C$, per ogni $i = 1, 2, ..., n$.\n \u003e \n \u003e Consideriamo il letterale $x_i$ che è contenuto in $k$ clausole del tipo $c_j$.\n \u003e Poichè ognuna di queste clausole sono per costruzione nella stessa comunità di $T$ (e quindi in $C$) e poiché $x_i$ ha a altri due suoi vicini $y_i, z_i$ in $C$, risulterà che più della metà dei suoi vicini sono in $C$. Infatti risulta che $x_i$ ha esattamente $k+2$ vicini in $C$ più altri $k+1$ nodi senza nome.\n \u003e Perciò, dovunque insieriamo qui $k+1$ nodi senza nome, per forza $x_i$ deve stare in $C$. Stesso ragionamento per $\\overline{x_i}$.\n \u003e \n \u003e Infine poiché i nodi senza nome hanno un solo vicino (che sicuramente sta in $C$), possiamo concludere che tutti i nodi del grafo stanno in $C$.\n \u003e ![\\|550](ar-lesson07-img5.png)\n \u003e Riassumendo abbiamo visto che affinché $G$ sia partizionabile in due web-communities è necessario che $T$ ed $F$ siano contenuti in due comunità differenti, e se $T$ ed $F$ sono in due comunità differenti abbiamo che anche $x_i$ e $\\overline{x_i}$ sono in due comunità differenti, per ogni $i = 1, 2, ..., n$.\n \u003e Questo significa che ogni partizione di $G$ in due web-communities corrisponde ad una assegnazione di verità per le variabili in $X$.\n \u003e \n \u003e Inoltre, la partizione di $G$ è possibile solo se per ogni clausola $c_j$ *almeno* uno dei suoi letterali appartiene alla stessa comunità di $T$.\n \u003e \n \u003e Perciò, data una partizione $C, V \\setminus C$ in due web-communities di $G$, basterà dare la seguente *assegnazione di verità* per soddisfare $\\phi$\n \u003e $$a(x_i) = \\begin{cases}\n \u003e \\\\texttt{true} \u0026\\mbox{if } x_i \\in C\\\\\n \u003e \\\\texttt{false} \u0026\\mbox{if } x_i \\in V \\setminus C\n \u003e \\\\end{cases}$$\n \u003e dove $C$ è la comunità a cui appartiene $T$.\n \u003e \n \u003e Viceversa, se esiste un'assegnazione $a: X \\rightarrow \\lbrace \\texttt{true}, \\texttt{false} \\rbrace$ che soddisfa $\\phi$, allora è possibile ricavare una partizione di $G$ in due web-communitie.\n \u003e \n \u003e Innanzitutto poniamo $T$ in $C$ ed $F$ in $V \\setminus C$. Dopodiché, dato che $a$ soddisfa $\\phi$, allora insieriamo in $C$ tutti i nodi clausola $c_j$ e i rispettivi $l\\_{j1}, l\\_{j2}, l\\_{j3}$. Infine, per ogni $i$, inseiriamo in $C$ i seguenti nodi:\n \u003e \n \u003e * se $a(x_i) = \\texttt{true}$, inseiriamo $x_i$, i suoi nodi senza nomi, e i nodi $y_i, t_i$.\n \u003e * se $a(x_i) = \\texttt{false}$, inseiriamo $\\overline{x_i}$, i suoi nodi senza nomi, e i nodi $y_i, t_i$.\n \u003e \n \u003e Le due comunità risultanti saranno due cut-communites $\\square$.\n\n---\n\n[^1]: ovvero in tempo $O(n^c)$ per qualche costante $ c \u003e 0 $.\n\n[^2]: un problema `X` è **NP-completo** se \\[ogni\\]{.underline} problema appartenente alla classe **NP** può essere *ridotto polinomialmente* al problema `X`.\n","lastmodified":"2022-08-29T13:39:16.964361383+02:00","tags":null},"/AR/8-Communities-Part-2":{"title":"","content":"\n# Metodi euristici per partizionare in comunità\n\nNella precedente [parte](7%20-%20Communities%20-%20Part%201.md) sono stati introdotti i concetti\n[cut-community](7%20-%20Communities%20-%20Part%201.md#cut-communities) e [web-community](7%20-%20Communities%20-%20Part%201.md#web-communities), e dimostrato che il problema del partizionamento di un grafo in web-communities è un problema **difficile**[^1] dal punto di vista computazionale.\n\nIn questa parte verranno mostrate due famiglie approcci che dal punto di vista euristico riescono a partizionare un grafo in comunità accettabili, ovvero in gruppi di nodi abbastanza coesi tra di loro.\n\nPiù precisamente i due metodi si dividono in:\n\n* **metodi partitivi**, in cui si parte considerando l'intero grafo come unica grande comunità, e la si inizia a disconnettere (rimuovendo archi) finché non si otterranno due comunità distinte e coese. Se si desidera ottenere una **granularità** maggiore basta iterare il metodo sui sottografi ottenuti.\n* **metodi agglomerativi**, in cui si parte considerando ogni singolo nodo una comunità, e man mano si aggiungono gli archi del grafo finché non si otterranno un numero di comunità desiderato con un livello di coesione accettabile.\n\nOsservare che entrambi i metodi consentono di ottenere delle **partizioni nidificate** (**nested**), infatti nel metodo partitivo si genera una partizione a partire da una più grande (approccio **top-down**), e nel metodo agglomerativo si genera una partizione come composizione di altre più piccole (approccio **bottom-up**).\n\n![Schema di partizione metodo partitivo.|350](ar-lesson08-img1.png)\n\n![Schema di partizione metodo agglomerativo.|350](ar-lesson08-img2.png)\nEntrambi i metodi hanno quindi uno *schema di partizione* ad albero.\n\nOsservare infine che entrambi i metodi richiedono la scelta di un arco da rimuovere o aggiungere ad ogni passo.\n\n---\n\n## Edge-Betweenness\n\nIl concetto di **betweennes** di un arco è sfruttato come criterio di rimozione degli archi nei metodi partitivi di partizionamento precedentemente accennati.\nTale concetto a sua volta si basa sulle proprietà di un arco di essere *bridge* o *local bridge*.\n\nSappiamo che per definizione, rimuovere un arco bridge disconnette due porzioni di una rete, mentre rimuovere un local bridge certamente peggiora la connettività tra due comunità.\n\nSappiamo anche che gli archi bridge e local brdige sono dei *weak ties*.\nPerciò, rimuovendo tutti i weak ties da una rete rimangono solamente gruppi di nodi connessi da relazioni forti (*strong ties*), e tali gruppi rispecchiano il concetto intuitivo di comunità (ovvero gruppi di persone collegati da legami forti).\n\nPurtroppo però esistono casi in cui anche rimuovendo tutti i weak ties non avviene un partizionamento in comunità.\n\n![Controesempio: in blu i weak ties e in rosso gli strong ties.|350](ar-lesson08-img3.png)\n\nInfatti, considerando il precedente controesempio, pur rimuovendo l'arco rosso non avremo un partizionamento.\nInvece è evidente che c'è una comunità composta da una clique a destra e una composta da una clique a sinistra.\nPer quanto riguarda il nodo centrale esso può essere inserito indistintamente i una delle due comunità.\n\nPerciò come criterio potremmo considerare la quantità di **traffico** (o **flusso**) di informazioni che passa attraverso gli archi.\n\nPossiamo considerare come \"nuovi archi ponte\" tutti quegli archi attraverso i quali passa una grande quantità di flusso, e che se rimossi rendono più difficile la comunicazione tra due comunità.\n\nSecondo questo criterio possiamo rimuovere gli archi sui quali passa maggior flusso, finché non otterremo un partizionamento accettabile della rete.\n\nPiù formalmente, considerando un grafo \u003cu\u003enon diretto\u003c/u\u003e $G = (V,E)$, definiamo con $\\sigma\\_{st}(u,v)$ il numero di [shortest-paths](https://en.wikipedia.org/wiki/Shortest_path_problem) $\\pi^\\star(s,t)$ (o *camminimi minimi*) tra $s$ e $t$ che passano per l'arco $(u,v)$.\n\nDefiniamo poi con $b\\_{st}(u,v)$ la **betweennes dell'arco** $(u,v)$ **rispetto alla coppia** $s,t$ come la **frazione** di shortest path $\\pi^\\star(s,t)$ che passano per l'arco $(u,v)$ $$\n\\\\begin{align\\*}\n\\\\sigma\\_{st} \u0026= \\vert \\lbrace \\pi^\\star(s,t)  \\rbrace \\vert\\\\\nb\\_{st}(u,v) \u0026= \\frac{\\sigma\\_{st}(u,v)}{\\sigma\\_{st}}\n\\\\end{align\\*}\n$$Definiamo infine la **betweenness** $b(u,v)$ di un arco $(u,v)$ come la *semi-somma* di tutte le betweenness relative $b\\_{st}(u,v)$, per ogni coppia di nodi $s,t$\n$$b(u,v) = \\frac{1}{2} \\sum\\_{(s,t) \\in \\binom{V}{2}} b\\_{st}(u,v)$$\nNotare che il fattore $1/2$ è necessario per evitare di contare le ripetizioni, del tipo $b\\_{st}(u,v)$ e $b\\_{ts}(u,v)$.\n\nAnalogamente alla **edge-betweenness** si può definire una **node-betweenness**, seguendo la stessa definizione.\n\n## Il metodo di Girvan-Newman\n\nIl metodo di *Girvan-Newman* è un metodo partitivo per il partizionamento, basato sul concetto di *edge-betweenness*, abbastanza semplice.\nI passaggi sono i seguenti:\n\n1. Si calcola l'arco $(u,v)$ con betweenness $b(u,v)$ **massima**, e lo si rimuove.\n1. Se il grafo residuo risulta partizionato con in una granularità desiderata allora abbiamo concluso.\n1. Se così non fosse si ricalcola il nuovo arco con betweenness massima del nuovo grafo e si itera finché non si ottiene il risultato desiderato.\n\nL'algoritmo di suo è abbastanza semplice, l'unico problema è il calcolo delle betweenness degli archi.\n\nPurtroppo non si può applicare un approccio brute force calcolando tutti gli shortest path altrimenti la complessità risulterebbe esponenziale.\n\n\u003cu\u003eServe quindi un approccio più efficiente.\u003c/u\u003e\n\n## Algoritmo per il calcolo della betweenness\n\nPer ogni nodo $s \\in V$ l'algoritmo del calcolo della betweenness degli archi si suddivide in tre fasi:\n\n1. Calcolare il sottografo $T(s)$ composto dall'*unione* degli alberi di camminimi minimi radicati in $s$. Anche se il numero di tali alberi può essere esponenziale, in realtà il calcolo di $T(s)$ può essere effettuato in tempo polinomiale con una visita in ampiezza `BFS` con le dovute modifiche. ^8a6088\n1. Mediante una visita `top-down` calcolo i valori $\\sigma\\_{sv}$ per ogni $v \\in V \\setminus \\lbrace s \\rbrace$, e questo vedremo si può fare in tempo polinomiale. ^853300\n1. Infine mediante una visita `bottom-up`, e grazie a quanto calcolato nel punto 2, calcolo per ogni arco $(u,v) \\in T(s)$ tutte le betweennes relative a shortest paths che partono da $s$, ovvero il valore $$b_s(u,v) = \\sum\\_{t \\in V \\setminus \\lbrace s \\rbrace} b\\_{st}(u,v) ;; \\forall (u,v) \\in T(s)$$ ^f5c61f\n\nPer concludere, una volta eseguiti i punti [(1)](8%20-%20Communities%20-%20Part%202.md#8a6088), [(2)](8%20-%20Communities%20-%20Part%202.md#853300) e [(3)](8%20-%20Communities%20-%20Part%202.md#f5c61f)  per ogni nodo $s \\in V$, possiamo ricavare i valori delle betweenness come segue\n$$b(u,v) = \\frac{1}{2} \\sum\\_{s \\in V} b_s(u,v)$$\nOsserviamo che nel punto `3` calcoliamo $b_s(u,v)$ solo per gli archi di $T(s)$, in quanto se $(u,v)$ non appartiene al sottografo degli shortest path $T(s)$ allora vuol dire che non appartiene nessun shortest path, e quindi non avrebbe senso calcolarlo (per definizione di betweenness).\n\nAndiamo ora a vedere un esempio pratico che mostra anche come eseguire i tre passi dell'algoritmo del calcolo della betweenness.\n\n### Fase 1\n\nPer calcolare $T(s)$ basta effettuare una visita in ampiezza `BFS` opportunamente modificata.\n\nDefiniamo con $L_h$ l'insieme di tutti i nodi a distanza $h$ dalla sorgente $s$.\nDiremo che un nodo $v$ si trova al **livello** $h$ se $v \\in L_h$.\n\nSe un nodo $v$ si trova al livello $h$, allora certamente **tutti** i cammini minimi da $s$ a $v$ termineranno con archi che partono da $L\\_{h-1}$.\nPerciò, tutti gli archi $(u,v)$ con $u \\in L\\_{h-1}$ e $v \\in L_h$ faranno parte di $T(s)$.\n\nPerciò possiamo calcolare $T(s)$ nella seguente maniera:\n\n1. Poniamo inizialmente $L_0 = \\lbrace s \\rbrace$ e $T(s) = \\emptyset$.\n1. Per ogni $h \\geq 0$ calcoliamo $L\\_{h+1}$ come tutti quei nodi **fuori** $L_0 \\cup L_1 \\cup ... \\cup L_h$ tali che hanno almeno un vicino in $v \\in L_h$, ovvero come $$ L\\_{h+1} \\equiv \\lbrace v \\in V \\setminus (L_0 \\cup L_1 \\cup ... \\cup L_h) | \\exists u \\in L_h : (u,v) \\in E  \\rbrace$$\n1. Calcolato $L\\_{h+1}$ poniamo $T(s)$ come $$T(s) = T(s) \\cup \\lbrace (u,v) \\in E | u \\in L_h \\land v \\in L\\_{h+1} \\rbrace$$\n   ![Costruzione sottografo dei cammini minimi.|400](ar-lesson08-img4.png)\n\n### Fase 2\n\nCalcolato $T(s)$, possiamo sfruttarlo per calcolare, per ogni $v \\in V$, la quantità $\\sigma\\_{sv}$, ovvero il numero di cammini minimi che vanno da $s$ a $v$.\n\nIniziamo osservando che per ogni nodo $v$ nel livello 1, il numero di cammini minimi sarà pari ad 1 (perché $v$ è diretto vicino di $s$).\n\nInvece al livello 2, il numero di cammini minimi di un generico nodo $v \\in L_2$ è pari alla somma di tutti i $\\sigma\\_{su}$, tali che esiste $(u,v)$ con $u \\in L_1$. Più in generale, per ogni $v \\in L_h$, possiamo calcolare $\\sigma\\_{sv}$ con la seguente formula ricorsiva\n$$\n\\\\begin{align\\*}\n\\\\sigma\\_{sv} \u0026= 1  \u0026h = 1\\\\\n\\\\sigma\\_{sv} \u0026= \\sum\\_{u \\in N(v) \\cap L\\_{h-1}} \\sigma\\_{su}  \u0026h \u003e 1\n\\\\end{align\\*}\n$$\n\n![Calcolo numero dei cammini minimi.|550](ar-lesson08-img5.png)\n\nNotare che questa fase viene eseguita facendo una visita `top-down` del sottografo $T(s)$.\n\n### Fase 3\n\nNella terza fase dobbiamo calcolare per ogni arco $(u,v) \\in T(s)$ la quantità di flusso che ci passa sopra rispetto a $s$, ovvero $$b_s(u,v) = \\sum\\_{t \\in V \\setminus \\lbrace s \\rbrace} b\\_{st}(u,v)$$\nPer fare ciò in questo caso faremo una visita `bottom-up` di $T(s)$.\n\nSi $d$ il numero di livelli in $T(s)$, e consideriamo un arco $(y,x)$ con $y \\in L\\_{d-1}$ e $x \\in L_d$. \n\nOsserviamo che tutti gli shortest path che partono da $s$ e passano attravero l'arco $(y,x)$ sono tutti shortest path che terminano in $x$.\n\nPerciò il flusso che passa su $(y,x)$ rispetto a $s$ sarà pari al rapporto tra il numero di shortest path che vanno da $s$ a $y$ (ovvero $\\sigma\\_{sy}$) e il numero complessivo di shortest path che vanno da $s$ ad $x$ (ovvero $\\sigma\\_{sx}$).\n$$b_s(y,x) = \\sum\\_{t \\in V \\setminus \\lbrace s \\rbrace} b\\_{st}(y,x) = b\\_{sx}(y,x) = \\frac{\\sigma\\_{sx}(y,x)}{\\sigma\\_{sx}} = \\frac{\\sigma\\_{sy}}{\\sigma\\_{sx}}$$\nAnalogamente possiamo applicare questo ragionamento per tutti gli archi che collegano nodi dell'ultimo livello, come mostrato nella seguente [figura](8%20-%20Communities%20-%20Part%202.md#b81567).\n\n![Calcolo di $b_s(y, x)$.|550](ar-lesson08-img6.png) ^b81567\n\nAdesso, saliamo di un livello, e consideriamo gli archi che entrano nel livello $L\\_{d-1}$. \n\nRifacendoci all'[immagine in esempio](8%20-%20Communities%20-%20Part%202.md#a89eb9), consideriamo l'arco $(z, y)$, con $z \\in L\\_{d-2}$ e $y \\in L\\_{d-1}$.\n![Esempio da considerare.](ar-lesson08-img7.png) ^a89eb9\n\nOsserviamo che tra tutti i cammini minimi che passano per l'arco $(z, y)$, una parte saranno cammini che termineranno in $y$, e una parte saranno cammini minimi che andranno ai nodi di livello inferiore.\n\nPerciò la frazione di shortest path che, partendo da $s$, passano per $(z, y)$ è pari alla somma dei seguenti fattori:\n\n* La frazione degli shortest path da $s$ ad $y$, ovvero $\\frac{\\sigma\\_{sz}}{\\sigma\\_{sy}}$.\n* Per ogni *diretto discendente*[^2] $x$ di $y$, una frazione $\\frac{\\sigma\\_{sz}}{\\sigma\\_{sy}}$ della frazione di shortest path da $s$ ad $x$ che passano per l'arco $(y,x)$, ovvero $\\frac{\\sigma\\_{sz}}{\\sigma\\_{sy}} \\cdot \\frac{\\sigma\\_{sy}}{\\sigma\\_{sx}} = \\frac{\\sigma\\_{sz}}{\\sigma\\_{sx}}$.\n\nQuindi, rifacendoci all'esempio, avremo che $$ b_s(z,y) = \\frac{\\sigma\\_{sz}}{\\sigma\\_{sy}} + \\frac{\\sigma\\_{sz}}{\\sigma\\_{sy}} \\cdot \\frac{\\sigma\\_{sy}}{\\sigma\\_{sx}} = \\frac{1}{3} + \\frac{1}{3}\\cdot\\frac{3}{5} = \\frac{8}{15}$$\nCosì facendo abbiamo definito un metodo `bottom-up` per il calcolo tutti i valori $b_s(u,v)$.\n\n![Calcolo di tutti i valori $b_s(u, v)$.|550](ar-lesson08-img8.png)\n\n### Fase finale - Calcolo Betweenness\n\nConcludendo, possiamo calcolare la betweennes di tutti gli archi come già descritto in precedenza $$b(u,v) = \\frac{1}{2} \\sum\\_{s \\in V} b_s(u,v)$$\nNotiamo che questa procedura permette di calcolare la betweennes degli archi in tempo *polinomiale* nella grandezza della rete (e non esponenziale).\n\nInfatti la [fase 1](8%20-%20Communities%20-%20Part%202.md#fase-1) è una semplice visita in ampiezza del grafo (e si può calcolare in tempo $O(|V| + |E|)$), la [fase 2](8%20-%20Communities%20-%20Part%202.md#fase-2) è un'ulteriore visita in ampiezza di $T(s)$ (e si può calcolare ancora in tempo $O(|V| + |E|)$), e infine la [fase 3](8%20-%20Communities%20-%20Part%202.md#fase-3) è nuovamente una visita in ampiezza, partendo però dal livello più basso (acnora una volta $O(|V| + |E|)$).\n\nDato che bisogna iterare questo procedimento per ogni nodo del grafo, e dato che nel caso peggiore abbiamo grafi molto densi con $\\Theta(n^2)$ archi, la complessità temporale dell'esecuzione di questo algoritmo per il calcolo delle betweennes sarà $O(nm) \\in O(n^3)$.\n\n# Rilassare il modello\n\nLa definizione teorica discussa fin ora era basata su assunzioni forti:\nun arco poteva essere un *bridge edge* o no, e poteva rappresentare uno *strong* o *weak tie*.\nRiportare i concetti di *bridge edges* e *strong/waeak ties* in una rete sociale reale è però un'assunzione \u003cu\u003etroppo forte\u003c/u\u003e.\nPer esempio in una rete molto grande è molto raro trovare dei *bridge edges*, inoltre le persone non classificano le proprie relazioni in maniera dicotomica `strong/weak`, in genere ci sono moltissime sfumature.\n\nPer rilassare i concetti di *strong* e *waeak ties* possiamo definire un modello in cui le relazioni tra due nodi della rete sono **pesate** in maniera numerica.\nQuindi invece di considerare una rete $G = (V, S \\cup W)$, potremmo per esempio definire una rete $G = (V,E,w)$ dove $w : E \\rightarrow \\mathbb{N}$ è una funzione che rappresenta la *forza* delle relazioni, più è alto il valore $w(u,v)$ più la relazione tra i nodi $u$ e $v$ è \u003cu\u003eforte\u003c/u\u003e.\n\nPer quanto riguarda il concetto di *bridge edge*, possiamo considerare il concetto di **neighborhood overlap**, ovvero la frazie di amicie in comune che hanno due nodi. $$NO(u,v) = \\frac{ \\vert N(u) \\cap N(v) \\vert }{ \\vert N(u) \\cup N(v) - \\lbrace u,v \\rbrace \\vert }$$\nOsserviamo che un *local bridge* $(u,v)$ ha un neighborhood overlap $NO(u,v) = 0$.\n\nSappiamo che i due concetti *bridge edges* e *strong/waeak ties* sono correllati, ovvero sappiamo che qualora una rete $G$ soddisfa la [STCP](7%20-%20Communities%20-%20Part%201.md#the-strong-triadic-closure-property) allora tutti i *local bridge* sono *weak ties*.\nCiò che si può chiedere è se questo tipo di relazione persiste anche nel modello rilassato appena descritto.\n\nData la generalità del modello rilassato, è più complesso andare a fare un'analisi rigorosa. In aiuto però esistono dei risultati di tipo empirico risultati da un esperimento di *Onnela et al* del 2007.\nVennero presi i registri di una compagnia telefonica e costruito (in maniera anonima ?) sulla basse di essi un grafo, seguendo i seguenti criteri:\n\n1. gli indirizzi telefonici vennero rappresentati dai nodi della rete.\n1. esisteva un arco tra due nodi se essi si erano scambiati almeno una telefonata nelle ultime 18 settimane.\n1. gli archi vennero persati in base alla durata delle chiamate effettuate, più due nodi parlano al telefono, più è alto il peso dell'arco.\n\nTale rete rappresentava una rete socialre reale, in quanto i numeri telefonici erano ad uso *comune* (e non *commericale* o *aziendale*), e inoltre la compagnia telefonica che ha fornito i dati copriva una vasta area di una popolazione.\nA conferma, erano presenti alcune caratteristiche fondamentali delle reti sociali, come per esempio la presenza di *componenti giganti* (in questo caso grade l'84% della rete).\n\nL'esperimento in questione consistette in due fasi:\n\n1. nella prima vennero rimossi gli archi in ordine *decrescente* di peso, e si osservò che la rete si disconnetteva molto lentamente.\n1. nella seconda fase si fece l'opposto, ovvero vennero rimossi gli archi a partire da quelli meno pesati, osservando invece che la rete si disconnetteva molto più velocemente.\n\nIl risultato di questo esperimento suggerisce in maniera empirica che anche nel modello più rilassato c'è una connessione tra neighborhood overlap e peso di un arco.\nDato che la rimozione di archi con peso basso, rendeva più difficile la comunicazione tra gruppi di nodi, è sensato pensare che tanto più il peso di un arco è basso tanto più è bassa la neighborhood overlap di tale arco.\n\n![Esempio di come cresce la neighborhood di un arco $N(u,v)$ al crescere del suo peso $w(u,v)$.|400](ar-lesson08-img9.png)\n\n# Osservazioni finali\n\nRicapitolando tutto quello detto fin ora, una rete sociale è sostanzialmente un agglomerato di gruppi densamente connessi tra di loro con relazioni forti, i quali gruppi sono a loro volta connessi tramite una serie di connessioni deboli.\n\nConcettualmente sappiamo che in un contesto sociale l'appartenenza ad un gruppo comporta vantaggi di vitale importanza.\nIn genere più una persona è ben inserita in un gruppo, ovvero più ha fiducia di chi gli sta intorno, più ne trae vantaggio.\n\nContrariamente, l'esperimento di Granovetter ci suggerisce che avvolte è altrettanto necessario avere contatti con gente appartenente ad altri gruppi, in quanto così facendo avremo accesso a differenti fonti di informazioni potenzialmente molto convenienti.\n\nQueste due osservazioni ci permettono di inutire che i vantaggi dei nodi non dipendono solamente dall'appartenenza a comunità, bensì anche dalla posizione di tali nodi e da quanto sono ben inseriti o meno all'interno dei rispettivi gruppi.\nPer aiutarci definiamo il concetto di **embeddedness** di un arco $(u,v)$ come la quantità di vicinato in comune ai due estremi di un arco, ovvero $$\\text{Emb}(u,v) = \\vert N(u) \\cap N(v) \\vert$$\nOsserviamo che un *local bridge* è un arco con embeddedness pari a $0$.\n\nPiù la embeddedness di un arco è alta, più i due suoi vicini sono ben integrati tra di loro.\nAnalogamente, un nodo che tani archi incidenti con embeddedness alta è un nodo che è ben integrato nel gruppo a cui appartiene.\n\n![\\|500](ar-lesson08-img10.png)\n\nNell'esempio in precedenza si può notare che il nodo `A` è ben integrato nella sua comunità, in quanto ricopre una **posizione centrale**.\nInfatti tutti i suoi archi incidenti hanno una embeddedness alta.\n\nContrariamente il nodo `B` ricopre una posizione marginale nella sua comunità, e infatti ha pochi archi incidenti con embeddedness alta.\n\n[^1]: ovvero **NP-completo**.\n\n[^2]: ovvero quei nodi collegati ad $y$ da un arco e che si trovano al successivo livello più in basso.\n","lastmodified":"2022-08-29T13:39:16.926643095+02:00","tags":null},"/AR/9-Processi-di-diffusione-Part-1":{"title":"","content":"\n# Processi di Diffusione su Reti\n\nUno dei quesiti principali fin ora posti è cercare di capire come le scelte dei singoli individui sono influenzate dal comportamento degli altri individui.\nQuando si fa questo tipo di analisi si può considerare la rete sottostante in due differenti livelli di *risoluzione*: un livello in cui guardiamo la rete dall'alto e osserviamo il comportamento di gruppi di individui, e un livello più dettagliato in cui si considera la struttura della rete come grafo e si cerca di analizzare/intuire come i singoli individui sono influenzati dal loro diretto vicinato.\n\nIn questa parte verrà analizzato il secondo punto di vista, assumendo che i singoli individui abbiano solo una visione *locale* della rete, e non *globale*, e di conseguenza che prendano decisioni in base a ciò che osservano (ovvero in base al comportamento dei loro vicini).\nQuesto framework è abbastanza ragionevole, in quanto è ragionevole pernsare che una persona venga influenzata e cambi comportamento in base al gruppo in cui appartengono, ricevendo così benefini.\nPer esempio è conveniente che una persona adotti una nuova lingua perché la grande maggioranza delle persone con cui a che fare parlano tale lingua, fregandosene di quale sia la lingua più parlata in assoluto al livello globale.\n\nQuesti ragionamenti sono alla base del concetto di **omofilia**.\nPer *omofilia* da una parte si intende la capacità che ha un individuo di creare relazioni con altri individui che più gli assomigliano (riferendoci per esempio alla *chiusura triadica*), e dall'altra parte è la tendenza a cercare di assomigliare a chi li circonda in modo tale da trarne vantaggi. Per esempio in un contesto sociale reale le persone tendono a creare rapporti con altre persone che hanno stessi gusti e/o opinioni, d'altro canto però spesso per ridurre la tensione sociale si tende a scendere a compromessi adattandosi a ciò che vogliono gli altri.\n\n## La diffusione di innovazioni\n\nDi seguito verrà considerato come nuovi comportamenti, pratiche, opinioni e tecnologie si diffondono da persona a persona attraverso le reti sociali, ovvero come le persone influenzano i propri amici a cambiare idea.\nLa comprensione di come questi fenomeni lavorano sono basati su storici studi *empirici/sociologici* noti come **diffusione di innovazioni**.\nUno di questi studi fu quello condotto da *Ryan \u0026 Gross* basato su un esperimento di adozione di nuovi semi ibridi da parte degli agricoltori dell [Iowa](https://www.google.com/maps/place/Iowa,+Stati+Uniti/@41.8508057,-97.8790946,6z/data=!3m1!4b1!4m5!3m4!1s0x87ee5e6ff1f86019:0xc6ef634a57c759d9!8m2!3d41.8780025!4d-93.097702), che mostrò come le scelte del proprio gruppo sociale forscono in maniera indiretta informazioni agli individui sulla convenienza o meno dell'adozione di una nuova innovazione.\n\nRyan e Gross intervistarono gli agricoltori chiedendo loro se conoscevano i nuovi semi e se/quando li avrebbero adottati.\nNotarono che nonstante la maggior parte di loro era venuto a conoscenza dei semi da parte dei venditori, solo un piccolo numero di loro decise di addottare i semi \"a scatola chiusa\".\n\nContrariamente riscontrarono che molti iniziarono a provare i semi solamente dopo aver osservato altri agricoltori conoscenti che li avevano già provati.\n\nQuesto perché appunto si può trarre la seguente informazione:\n\n \u003e \n \u003e *\"Se tanti usano i nuovi semi, allora posso pensare che sono buoni.\"*\n\n## Coordination Game - Modello Lineare\n\nA questo punto potremmo voler *modellare* il processo di diffusione di innovazioni su una rete, e vogliamo farlo in modo da rispettare quanto osservato in precedenza.\n\nVogliamo che gli individui del modello prendano decisioni in maniera del tutto **individuale**, ovvero che non si prendano decisioni mettendosi d'accordo con altri. Inoltre le decisioni devono essere prese sulla base di una stima **rischio/beneficio** che si ha dell'adottare una innovazione.\nOvvero le decisioni vengono prese solamente per un **guadagno personale** senza pensare al bene degli altri, ovvero seguendo la filosofia del *\"se mi conviene lo faccio, altrimenti no\"*.\nQuesto tipo di modello è anche noto come **direc-benefit**.\n\nAssumiamo che tutti della rete partano con uno stato (o idea, opinione, tecnologia, ...) `B`, e che a un certo punto alcuni nodi adottino lo stato `A`.\n\nAssumendo che una volta adottato allo stato `A` non si può più tornare nello stato `B` ci si chiede in quali casi un nodo decide di cambiare stato ad `A`.\n\nPer modellare questa dinamica facciamo riferimento a un **coordination game** in cui due nodi vicini ricavano un vantaggio nell'avere uno stesso stato, e devono coordinarsi nel decidere una strategia in modo tale da massimizzare i profitti, senza però potersi mettere d'accordo.\n\nPiù precisamente sia un arco $(v,w)$ della rete:\n\n* se $v$ e $w$ sono nello stesso stato `A` avranno un guadagno pari ad un valore $a \u003e 0$.\n* se $v$ e $w$ sono nello stesso stato `B` avranno un guadagno pari ad un valore $b \u003e 0$.\n* se $v$ e $w$ sono in due stati discordi non ricevono alcun guadagno reciproco.\n\n![`A-B` coordination game.|300](ar-lesson09-img1.png)\n\nOvviamente il nodo $v$ gioca una copia del coordination game su ognuno dei suoi archi incidenti, perciò il suo guadagno sarà la somma di tutti i guadagni su ogni arco.\n\nAndiamo ora ad analizzare quando al nodo $v$ conviene adottare lo stato `A` oppure no, sapendo che parte dallo stato `B`.\n\nDefiniamo con $n_A$ ed $n_B$ il numero dei suoi vicini rispettivamente negli stati `A` e `B`.\nIntuitivamente viene da pensare che $v$ agisce nei seguenti modi:\n\n* se $b n_B \u003e a n_A$ allora gli conviene rimandere in `B`.\n* se $a n_A \u003e b n_B$ allora gli conviene adottare `A`.\n\nAssumiamo che nel caso di parità di guadagno venga comunque preferita l'innovazione `A` anziché rimanere nello stato attuale.\nPerciò si adotta lo stato `A` se $a n_A \\geq b n_B$.\n\nSupponiamo che una porzione $p$ dei vicini di $v$ sia nello stato `A`, e che una frazione $1-p$ sia nello stato `B`\n$$\n\\\\begin{align\\*}\np \u0026= \\frac{n_A}{\\vert N(v) \\vert}\\\\\n1-p \u0026= \\frac{n_B}{\\vert N(v) \\vert} = \\frac{\\vert N(v) \\vert - n_A}{\\vert N(v) \\vert}\n\\\\end{align\\*}\n$$\nPerciò possiamo dire che a $v$ conviene cambiare stato se\n$$\n\\\\begin{align\\*}\nn_A a \u0026\\geq n_B b\\\\\n(\\vert N(v) \\vert \\cdot p) a \u0026\\geq (\\vert N(v) \\vert \\cdot (1-p)) b\\\\\np a \u0026\\geq (1-p)b\\\\\np \u0026\\geq \\frac{b}{a+b}\n\\\\end{align\\*}\n$$\nDefiniamo con $q = \\frac{b}{a+b}$ la frazione minima dei vicini di $v$ che devono essere nello stato `A` per rendere l'adozione di `A` conveniente rispetto a `B`.\nD'ora in poi ci riferiremo a $q$ con **soglia di adozione**.\n\n![$v$ deve scegliere `A` o `B` in base al suo vicinato|400](ar-lesson09-img2.png)\n\nOsserviamo che quando il guadagno $a$ è molto più grande di $b$, allora la soglia di adozione $q$ è molto bassa, ovvero servono pochi vicini nello stato `A` per convincere anche $v$.\nViceversa, se $a$ è molto più piccolo di $b$ allora la soglia cresce molto (tendendo ad 1), il che significa che servono molti vicini nello stato `A` per convincere $v$.\nInfine, se i due guadagni sono uguali $a = b$, allora occorrono almeno la metà dei vicini nello stato `A`.\n\n---\n\n# Cascading Behavior\n\nIniziamo col chiederci quali sono le possibili **configurazioni di equilibrio** della rete, ovvero configurazioni di stati `A-B` in cui nessuno più cambia stato.\nCertamente due configurazioni banali sono la configurazione in cui nessuno adotta `A`, e quindi sono tutti nello stato `B`, oppure la configurazione in cui, una volta introdotto `A`, tutti passano allo stato `A`.\n\nQuello che ci si può chiedere è:\n\n* esistono condizioni per le quali `A` si diffonde in tutta la rete?\n* se si, entro quanto tempo riesce a farlo?\n* oppure esistono situazioni in cui la diffusione di `A` si blocca in configurazioni intermedie?\n* e per quale motivo si blocca?\n\nIntroduciamo la seguente terminologia:\n\n \u003e \n \u003e Consideriamo un insieme di nodi iniziali che adottano un nuovo comportamento `A`, mentre ogni altro nodo inizia col comportamento `B`.\n \u003e I nodi valutano continuamente la decisione di passare da `B` ad `A` considerando la soglia di adozione $q$.\n \u003e Se eventualmente la **cascata di adozioni** di `A` causa un'adozione *globale* di `A` (ovvero che tutti i nodi con comportamento `B` passano ad `A`) allora diremo che l'insieme iniziale di adottatori di `A` ha causato una **cascata completa** con soglia di adozione $q$.\n\n## Osservazioni empiriche\n\nPer prima cosa consideriamo alcuni esempi.\n\n##### Esempio 1\n\nConsideriamo al seguente rete\n\n![\\|350](ar-lesson09-img3.png)\nForziamo poi lo stato dei nodi $v$ e $w$ ad `A`\n![\\|350](ar-lesson09-img4.png)\nPonendo i guadagni $a = 3$ e $b = 2$ otteremo una *soglia d'adozione* di $q = \\frac{2}{5}$, il che significa che almeno $\\frac{2}{5}$ dei vicini di un nodo devono avere lo stato `A` per convincere tale nodo a cambiare.\n\nNell'esempio in questione, come prima cosa i nodi $r$ e $t$ passeranno allo stato `A` perché hanno entrambi $\\frac{2}{3} \u003e \\frac{2}{5}$ vicini nello stato `A`.\nI nodi $u$ ed $s$ invece rimarranno inizialmente in `B` in quanto solamente $\\frac{1}{3} \\\u003c \\frac{2}{5}$ dei propri vicini è in `A` (ancora non conviene cambiare).\n\n![\\|350](ar-lesson09-img5.png)\nInfine, nel secondo step, anche a $u$ ed $s$ converrà adottare il nuovo stato `A`\n![\\|350](ar-lesson09-img6.png)\nottenendo così una diffusione totale dello stato `A` rispetto allo stato `B`.\n\nSe invece ponessimo come valori $a = 1$ e $b = 3$, avremmo una soglia di adozione pari a $q = \\frac{3}{4}$, la quale non sarebbe soffuciente per la diffusione di `A`.\n\n##### Esempio 2\n\nConsideriamo ora l'`A-B` coordination game su un grafo più grande\n\n![img7|500](ar-lesson09-img7.png) ^88e140\n\ne poniamo ancora i parametri $a = 3$, $b = 2$ e $q = \\frac{b}{a+b} = \\frac{2}{5}$.\n\nSe inizialmente i nodi 7 e 8 adottano lo stato `A`, avremo che al primo step passeranno i nodi 5 e 10, poi 4 e 9 e poi il nodo 6.\nA questo punto a nessun altro nodo della rete converrà adottare `A`.\n\n![img8|550](ar-lesson09-img8.gif)\n\nCiò che vogliamo sapere è come possiamo fare in modo di ottenere una **cascata completa** di `A` su tutta la rete?\n\nCome prima cosa si potrebbe *aumnetare il guadagno* di `A`, abbassando così la sua soglia d'adozione.\nInfatti, se per esempio poniamo i parametri $a = 4$ e $b = 2$ (ovvero con soglia di adozione di $\\frac{1}{3}$) otteremo una **cascata completa** di `A`.\nSe in un contesto reale `A` è una nuova tecnologia, ciò che abbiamo fatto è stato per esempio abbassare il prezzo di `A` in modo convincere più gente a comprarlo.\n\nUn altro modo è invece quello di aumentare e/o cambiare i nodi iniziali nello stato `A` (senza alterare la soglia d'adozione $q$).\nPer esempio consideriamo come insieme di nodi iniziali nello stato `A` i nodi $\\lbrace 2, 7, 8, 12 \\rbrace$ (e ricordiamo che $q = \\frac{2}{5}$ è rimasta invariata).\n\nÈ facile osservare in questo caso che `A` si propaga su tutta la rete.\n![Nodi iniziali $\\lbrace 2, 7, 8, 12 \\rbrace$, $a = 3$ e $b = 2$.|550](ar-lesson09-img9.gif)\nQuindi, se non alteriamo $q$, viene da pensare che se il numero di nodi iniziali supera una certa **soglia critica**, allora avviene una **cascata completa** di `A`.\nIn realtà l'avvenire di una cascata completa di `A` non dipende solamente da quanti nodi iniziali sono forzati nello stato `A`, bensì anche dalla loro posizione. Per esempio se consideriamo altri 4 nodi iniziali $\\lbrace 2, 7, 8, 14 \\rbrace$ non otterremo una cascata completa, nonostante ci siano lo stesso 4 nodi iniziali che adottano `A`.\n\n![Controesempio con nodi iniziali $\\lbrace 2, 7, 8, 14 \\rbrace$.|550](ar-lesson09-img10.gif)\n\n## Cascate e Cluster\n\nCerchiamo ora di capire come mai le cascate complete non dipendono solamente dal numero di iniziatori, ma anche dalle loro posizioni nella rete.\n\nPer prima cosa facciamo alcune definizioni formali\n\n* indichiamo con $V_0 \\subseteq V$ l'insieme di nodi iniziatori di `A`.\n* indichiamo con $V_1 \\subseteq V$ l'insieme di nodi vicini dei nodi che stanno in $V_0$, che adottano `A` al tempo $t = 1$.\n* induttivamente indichiamo con $V_i$ l'insieme di nodi che adottano `A` al tempo $t = i$.\n\nPossiamo dire che la diffusione di `A` si ferma quando $$\\bigcup\\_{i = 0}^{t} V_i = \\bigcup\\_{i = 0}^{t+1} V_i$$\nDi conseguenza possiamo dire che avviene una **cascata completa** di `A` se siste un tempo $t \\geq 0$ tale che $$\\bigcup\\_{i = 0}^{t} V_i = V$$Riguardando l'[esempio 2](9%20-%20Processi%20di%20diffusione%20-%20Part%201.md#88e140), possiamo individuare delle componenti più coese di nodi, più precisamente\n\n* il gruppo $\\lbrace 1,2,3 \\rbrace$.\n* il gruppo $\\lbrace 4,5,6,7,8,9,10 \\rbrace$.\n* il gruppo $\\lbrace 11,12,13,14,15,16,17 \\rbrace$.\n\nDall'esempio si può notare che la diffusione di `A` fa *\"fatica\"* ad uscire dai singoli gruppi.\nIn realtà esiste una relazione tra gruppi di nodi coesi tra loro e le cascate complete.\nDefiniamo un modello di coesione utile ad analizzare tale relazione.\n\n \u003e \n \u003e **Def (Cluster di densità $p$)** Un cluster di densità $p$ è un sottoinsieme di nodi $V' \\subseteq V$ tale che la frazioni di vicini che ogni suo nodo ha in $V'$ è almeno $p$, ovvero $$\\forall u \\in V' ; \\left\\[ \\frac{\\vert N(u) \\cap V' \\vert}{\\vert N(u) \\vert} \u003e p \\right\\]$$\n\nOsservare che una [strong web community](7%20-%20Communities%20-%20Part%201.md#web-communities) è un cluster di densitatà $p$ con $p = \\frac{1}{2}$. Osservare anche che se $V',V''$ sono due cluster di densitatà $p$, allora anche $V' \\cup V''$ è un cluster di densità $p$.\n\nQuesto è facilmente verificabile perché $\\vert N(u) \\cap (V' \\cup V'') \\vert \\geq \\vert N(u) \\cap V' \\vert$ e $\\vert N(u) \\cap (V' \\cup V'') \\vert \\geq \\vert N(u) \\cap V'' \\vert$.\n\n \u003e \n \u003e **THM** Sia il grafo $G=(V,E)$, l'insieme di iniziatori $V_0 \\subseteq V$ e la soglia di adozione $q$ per l'innovazione `A`.\n \u003e L'insieme $V_0$ **non** genera una cascata completa di `A` \u003cu\u003ese e solo so\u003c/u\u003e $G-V_0$ congiene un *cluster di densità* $1 - q$.\n\n \u003e \n \u003e **Proof** Iniziamo col dimostrare il primo verso dell'implicazione, ovvero che se $V_0$ non genera una cascata completa di `A` **allora** $G-V_0$ congiene un *cluster di densità* $1 - q$.\n \u003e \n \u003e Se $V_0$ non genera una cascata completa allora esisteranno dei nodi che al termine non avranno adottato `A`, e quindi esisterà un tempo $t+1$ nel quale la diffusione di `A` si ferma, ovvero quando\n \u003e $$V_t \\neq \\emptyset$$$$V\\_{t+1} = \\emptyset$$\n \u003e \n \u003e Definiamo con $V_A$ l'insieme di tutti i nodi che adottano `A` nel processo di diffusione $$V_A \\equiv \\bigcup\\_{i=0}^{t} V_i$$\n \u003e Poiché stiamo ipotizzando che $V_0$ non genera una cascata completa di `A`, avremo che $V \\setminus V_A \\neq \\emptyset$.\n \u003e \n \u003e Dato che i nodi in $V \\setminus V_A$ non adottano mai `A`, ciò vuol dire che nessuno di essi ha una frazione di vicini nello stato `A` maggiore della soglia di adozione, ovvero $$\\forall u \\in V \\setminus V_A ; \\left\\[ \\frac{\\vert N(u) \\cap V_A \\vert}{\\vert N(u) \\vert} \\\u003c q \\right\\]$$\n \u003e Le precedenti osservazioni implicano la seguente espressione $$\n \u003e \\\\begin{align\\*}\n \u003e 1 \u0026= \\frac{\\vert N(u) \\vert}{\\vert N(u) \\vert}\\\\\n \u003e \u0026= \\frac{\\vert N(u) \\cap V \\vert}{\\vert N(u) \\vert}\\\\\n \u003e \u0026= \\frac{\\vert N(u) \\cap ((V \\setminus V_A) \\cup V_A) \\vert}{\\vert N(u) \\vert}\\\\\n \u003e \u0026= \\frac{\\vert (N(u) \\cap (V \\setminus V_A)) \\cup (N(u) \\cap V_A) \\vert}{\\vert N(u) \\vert}\\\\\n \u003e \u0026= \\frac{\\vert N(u) \\cap (V \\setminus V_A) \\vert}{\\vert N(u) \\vert} + \\frac{\\vert N(u) \\cap  V_A \\vert}{\\vert N(u) \\vert}\\\\\n \u003e \u0026\\\u003c \\frac{\\vert N(u) \\cap (V \\setminus V_A) \\vert}{\\vert N(u) \\vert} + q\n \u003e \\\\end{align\\*}$$\n \u003e ovvero $\\frac{\\vert N(u) \\cap (V \\setminus V_A) \\vert}{\\vert N(u) \\vert} \u003e 1 - q$, il che significa che $V \\setminus V_A$ è un cluster di densità\n \u003e $1 - q$.\n \u003e Inoltre dato che $V_0 \\subseteq V_A$ a maggior ragione $V \\setminus V_A$ è contenuto in $G - V_0$.\n \u003e \n \u003e Ora bisogna dimostrare l'altro verso della dimostrazione, ovvero che se $G - V_0$ contiene un cluster $C \\subseteq V$ di densità $1-q$ allora $V_0$ non genera una cascata completa di `A`.\n \u003e \n \u003e Supponiamo per assurdo che $V_0$ generi una cascata completa di `A`.\n \u003e Allora certamente prima o poi tutti i nodi di $C$ adotterano lo stato `A`.\n \u003e Sia il tempo $t$ in cui i primi nodi di $C$ adottano `A`, ovvero quel $t$ tale che $$\\bigcup\\_{i = 0}^{t-1} V_i \\cap C = \\emptyset$$ $$V_t \\cap C \\neq \\emptyset$$\n \u003e \n \u003e Definiamo con $V'$ tutti i nodi che al tempo $t-1$ si trovano nello stato `A` (e che quindi non sono in $C$), ovvero $V' \\equiv \\bigcup\\_{i = 0}^{t-1} V_i$.\n \u003e \n \u003e Prendiamo uno dei nodi $u \\in C$ che passano in `A` al tempo $t$, ovvero un $u \\in V_t$. Poiché $C$ è un cluster di densità $1-q$ avremo che $$\\frac{\\vert N(u) \\cap C \\vert}{\\vert N(u) \\vert} \u003e 1 - q$$\n \u003e e siccome sappiamo che $u$ ha adottato `A` al tempo $t$ è vero che almeno una frazione $q$ dei suoi vicini era nello stato `A`, ovvero $$\\frac{\\vert N(u) \\cap V' \\vert}{\\vert N(u) \\vert} \\geq q$$\n \u003e \n \u003e Se le precedenti ipotesi sono vere otterremo che \n \u003e $$\n \u003e \\\\begin{align\\*}\n \u003e 1 \u0026= \\frac{\\vert N(u) \\vert}{\\vert N(u) \\vert}\\\\\n \u003e \u0026\\geq \\frac{\\vert N(u) \\cap (V' \\cup C) \\vert}{\\vert N(u) \\vert}\\\\\n \u003e (V' \\cap C = \\emptyset)  \u0026= \\frac{\\vert N(u) \\cap V' \\vert}{\\vert N(u) \\vert} + \\frac{\\vert N(u) \\cap C \\vert}{\\vert N(u) \\vert}\\\\\n \u003e \u0026\u003e q + 1 - q = 1\n \u003e \\\\end{align\\*}$$\n \u003e assurdo! $\\square$\n\nCiò che ci dice il precedente teorema è sostanzialmente che la presenza di cluster (con una certa densità) comporta un ostacolo alla diffusione di una innovazione `A`.\n\nRicordiamo dalle lezioni precedenti ([7 - Communities - Part 1](7%20-%20Communities%20-%20Part%201.md) e [8 - Communities - Part 2](8%20-%20Communities%20-%20Part%202.md)) che generalmente i legami che colleggano due comunità (o cluster) sono dei **legami deboli** (**weak ties**).\nInfatti la forza dei **weak ties** è basata sull'idea che le connessioni sociali deboli (per esempio con persone che vediamo di rado) spesso formano **bridege edges** in una rete sociale.\nPertanto forniscono accesso a fonti di informazioni (per esempio nuove opportunità di lavoro[^1]) che risiedono in parti della rete a cui altrimenti non avremmo accesso.\n\nOsserviamo inoltre che c'è una sostanzile differenza tra venire a conoscenza di una nuova idea e il decidere di adottarla.\nInfatti considerando ancora l'[esempio 2](9%20-%20Processi%20di%20diffusione%20-%20Part%201.md#88e140), possiamo osservare che i nodi 4 e 9 vengono subito a conoscenza dell'innovazione `A` in quanto entrambi sono vicini di un nodo iniziatore, però attendono più tempo prima di adottarlo.\nAnche in un contesto sociale reale, sebbene una barzelletta o un video divertente online avanzano con una velocità notevole, la mobilitazione politica si muove più lentamente, avendo bisogno di prendere slancio all'interno di comunità.\n\nLa soglia di adozione $q$ offre una possibile spiegazione:\ni movimenti sociali tendono ad essere imprese intrinsecamente rischiose, e quindi gli individui tendono a necessitare di soglie più elevate per la partecipazione.\n\nPerciò possiamo concludere che mentre i *weak-ties* che collegano due comunità differenti sono utilissimi alla diffusione di informazioni, allo stesso tempo sono un punto di debolezza (e quindi di ostacolo) per la diffusione di un'innovazione.\n\n## Cluster e Marketing Virale\n\nCiò che è stato discusso nella sezione precedente sostanzilmente arriva alla conclusione che la presenza di cluster di individui fortemente coesi può essere un impedimento alla diffusione di una nuova innovazione.\nPer esempio, se una comunità è eccessivamente densa, i suoi individui potrebbero usare una tecnologia `X` totalmente differente da quella che usata il resto del mondo.\n\nSe un venditore vuole che molta gente adotti un suo prodotto `X` (ovvero se vuole creare una cascata di tale prodotto), può optare per due strategie:\n\n* aumentare il guadagno ricavato dall'adottare `X` aumentando il rapporto *qualità/prezzo*, o abbassando il prezzo o aumentando la qualità. In genere però non è sempre possibile abbassare troppo i prezzi di un prodotto. Da un lato perché il venditore andrebbe a prendere, dall'altro perché in un contesto sociale un prodotto con prezzo troppo basso è spesso sinonimo di scarsa qualità.\n* scegliere in maniera strategica delle **persone chiave** a cui dare il prodotto, in modo da scatenare una cascata nelle rispettive comunità.\n\nIn un contesto reale si tende di più ad applicare la sconda opzione, cercando di mantenere la soglia di adozine di una innovazione il più bassa possibile.\nPerciò una domanda che ci si pone è:\nscegliendo appositamente gli iniziatori, quanto alta posso mantenere la soglia di adozine di una innovazione?\nOvverso, se voglio che l'innovazione `A` crei una cascata completa, quanto basso posso tenere il suo *payoff*?\n\n---\n\n# The Cascade Capacity on Infinite Network with bounded Degree\n\nIn questa sezione analizzeremo in maniera più formale, tramite l'aiuto di alcuni esempi, se esiste e qual è la *threshold* (per una soglia di adozione) che scatena una cascata completa, anche con un insieme \"piccolo\" di nodi **iniziatori**.\n\nPiù in particolare analizzeremo il caso di reti con **infiniti nodi**, ma ognuno con **grado finito**. In questa maniera il concetto di *\"insieme piccolo di iniziatori\"* è definito da qualsiasi **finito**.\n\n \u003e \n \u003e **Problem** Dato un grafo **infinito** $G = (\\mathbb{N}, E)$, dove tutti i nodi hanno un **grado finito**, trovare la *soglia di adozione massima* $q\\_{MAX}$ di $G$ tale che \u003cu\u003eesiste\u003c/u\u003e un sottoinsieme finito $V_0 \\subset \\mathbb{N}$ di iniziatori che genera una cascata completa.\n\nD'ora in poi ci riferiremo alla soglia di adozione massima $q\\_{MAX}$ con il termine **capacità di cascata** di $G$.\n\n## Esempio 1 - Catena infinita\n\nConsideriamo una catena infinita di nodi, dove ogni nodo $i$ ha grado esattamente due ed incidente ai due archi $(i-1, i), (i, i+1)$.\nSeppur tale insieme di nodi è equivalente all'insieme $\\mathbb{Z}$, sappiamo che esiste una biezione con $\\mathbb{N}$.\n\nCome primo caso consideriamo il più piccolo sottoinsieme di nodi iniziatori, composti da un solo nodo, diciamo $V_0 = \\lbrace x \\rbrace$.\nSe poniamo come soglia di adozione $q = \\frac{1}{2}$ otteremo una cascata completa.\n\n![Cascata completa con $V_0 = \\lbrace x \\rbrace$ e $q = \\frac{1}{2}$.](ar-lesson09-img11.gif)\n\nOvviamente si può ottenere una cascata completa anche per $q \\leq \\frac{1}{2}$.\n\nSe invece $q \u003e \\frac{1}{2}$ non si riesce ad ottenere una cascata completa col solo nodo $x$ come iniziatore.\nPeciò ci si può chiedere, esiste un sottoinsieme finito di nodi $V_0$ tale che si riesce ad ottenere una cascata completa?\n\nIn questo caso la risposta è **no**.\nInfatti affinché un generico nodo adotti la nuova tecnologia, è necessario che abbia entrambi i vicini di tale tecnologia.\nPerò non esiste un sottoinsieme **finito** di nodi tali che tutti i nodi `rossi` abbiamo entrambi i vicini `blu`.\nIn tal caso si necessita di un sottoinsieme infinito di nodi iniziatori.\nAnche se qualche nodo `rosso` riesce a passare allo stato `blu`, comunque esisteranno dei nodi `rossi` con al più un vicino `blu`, e quindi non si innesterebbe la cascata.\n\n![Blocco della cascata completa per $V_0 = \\lbrace w,y,z \\rbrace$ e $q \u003e \\frac{1}{2}$.](ar-lesson09-img12.gif)\n\n## Esempio 2 - Griglia\n\nConsideriamo ora una **griglia** infinta $\\mathbb{Z} \\times \\mathbb{Z}$, dove ogni nodo è collegato coi nodi nelle rispettive posizione `UP`, `DOWN`, `LEFT`, `RIGHT`, `NE`, `NW`, `SE` e `SW`, come nella seguente figura\n\n![Griglia infita, dove ogni nodo ha grado esattamente 8.](ar-lesson09-img13.png)\n\nConsideriamo il caso base in cui $\\vert V_0 \\vert = 1$.\nIn tal caso la soglia di adozione deve essere **al più** $q \\leq \\frac{1}{8}$.\nCon una soglia maggiore non si riuscirebbe altrimenti a creare una cascata completa.\n\n![Cascata completa con $\\vert V_0 \\vert = 1$ e soglia d'adozione $q \\leq \\frac{1}{8}$.](ar-lesson09-img14.gif)\n\nAumentando $\\vert V_0 \\vert = 2$ si riesce ad aumentare la soglia di adozione a $q = \\frac{1}{4}$.\nPer fare ciò, basta prendere come nodi iniziatori due nodi *adiacenti*.\n\n![Cascata completa con $\\vert V_0 \\vert = 2$ e soglia d'adozione $q = \\frac{1}{4}$.](../images/ar-lesson09-img15.gif)\n\nAnche con $\\vert V_0 \\vert = 3$ si riesce ad aumentare la soglia di adozione del colore blu a $q = \\frac{3}{8}$. Basta ancora una volta scegliere come iniziatori tre nodi adiacenti.\n\n![Cascata completa con $\\vert V_0 \\vert = 3$ e soglia d'adozione $q = \\frac{3}{8}$.](ar-lesson09-img16.gif)\n\nPurtroppo però per $\\vert V_0 \\vert \u003e 3$ non si riesce ad aumentare in nessun modo la sogia di adozione al di sopra di $\\frac{3}{8}$.\nInfatti è facile convincersi che, qualsiasi sottoinsieme finito di iniziatori prendiamo, si arriverà prima o poi ad una situazione in cui si sarà *quasi* o del tutto colorata di blu un'area rettangolare, dalla quale non si può uscire a meno che non si ha $q \\leq \\frac{3}{8}$.\n\n![Controesempio con $\\vert V_0 \\vert \u003e 3$ e soglia d'adozione $q = \\frac{1}{2}$.](../images/ar-lesson09-img17.gif)\n\nÈ infatti possibile dimostrare che per questa griglia infinita la *capacità di cascata* $q\\_{MAX}$ è proprio $\\frac{3}{8}$.\n\nContinuo nella [lezione successiva →](10%20-%20Processi%20di%20diffusione%20-%20Part%202.md)\n\n[^1]: Esperimento di Granovetter.\n","lastmodified":"2022-08-29T13:39:17.116369438+02:00","tags":null},"/ISTI/0-Inferenza-Statistica-e-Teoria-dellInformazione":{"title":"","content":"\n# Inferenza Statistica e Teoria dell'Informazione\n\n---\n\n## Info corso\n\n* **Docente**: Giampaolo Scalia Tomba\n* **A.A.**: 2021/2022\n* **Semestre**: 2°\n* **CFU**: 6\n* **Università**: Tor Vergata\n\n---\n\n## Table of contents\n\n1. [Distribuzioni](Distribuzioni.md)\n1. [Trasformazioni Univariate](Trasformazioni%20Univariate.md)\n1. [Distribuzioni Multivariate](Distribuzioni%20Multivariate.md)\n1. [Trasformazioni Bivariate](Trasformazioni%20Bivariate.md)\n1. [Convergenza](Convergenza.md)\n1. [CLT - Central Limit Theorem](CLT%20-%20Central%20Limit%20Theorem.md)\n1. [Delta Method](Delta%20Method.md)\n1. [Processo empirico e Statistiche d'ordine](Processo%20empirico%20e%20Statistiche%20d'ordine.md)\n1. [Random Sample](Random%20Sample.md)\n1. [Statistiche Sufficienti](Statistiche%20Sufficienti.md)\n1. [Stimatori Puntuali](Stimatori%20Puntuali.md)\n   1. [Metodo dei Momenti](Metodo%20dei%20Momenti.md)\n   1. [Stimatore di Massima Verosimiglianza](Stimatore%20di%20Massima%20Verosimiglianza.md)\n      1. [Verosimiglianza](Verosimiglianza.md)\n1. [Rao-Blakwell Theorem](Rao-Blakwell%20Theorem.md)\n1. [Cramér-Rao Inequality](Cram%C3%A9r-Rao%20Inequality.md)\n   1. [Informazione di Fisher](Informazione%20di%20Fisher.md)\n1. [Hypothesis Testing](Hypothesis%20Testing.md)\n   1. [Test più comuni](Test%20pi%C3%B9%20comuni.md)\n   1. [p-value - Livello di Significatività di un Test](p-value%20-%20Livello%20di%20Significativit%C3%A0%20di%20un%20Test.md)\n   1. [Test chi-quadro](Test%20chi-quadro.md)\n   1. [I test \"migliori\"](I%20test%20\"migliori\".md)\n1. [Stima per intervalli di confidenza](Stima%20per%20intervalli%20di%20confidenza.md)\n","lastmodified":"2022-08-29T13:39:16.747680281+02:00","tags":null},"/ISTI/Altri-Test":{"title":"","content":"\n## Campione Esponenziale\n\nAbbiamo un [campione](Random%20Sample.md#random-sample) [esponenziale](Distribuzioni.md#esponenziale) $X_1, ..., X_n$ di parametro $\\lambda$ \u003cu\u003esconosciuto\u003c/u\u003e.\nConsideriamo l'*[ipotesi nulla](Hypothesis%20Testing.md#349ec3)* $$H_0: \\lambda = \\lambda_0$$ e definiamo la statistica $$T = \\lambda_0 \\sum\\_{i=1}^{n}X_i$$\nSappiamo che la somma di $n$ esponenziali di parametro $\\lambda$ segue una distribuzione $\\Gamma(n, 1/\\lambda)$, con **notazione Shape-Scale** (vedi [proprietà distribuzione esponenziale](Distribuzioni.md#9fe8ff)).\nAllora, sotto ipotesi nulla avremo che $$T \\sim \\lambda_0 \\Gamma(n, 1/\\lambda_0) = \\Gamma(n,1)$$ per [cambio di scala di una gamma](Distribuzioni.md#cambiamento-di-scala).\n\n````julia\nusing Plots, Distributions\n\nn = 10\nλ = 3\n\nX = rand(Exponential(λ), n, 10000)\nXₛᵤₘₛ = [sum(X[:, i]) for i=1:10000]\n\nΓₙ₁ = Gamma(n, 1)\n\nhistogram(Xₛᵤₘₛ/λ, label=\"T\")\nplot!(0:0.01:25, x -\u003e 5000 * pdf(Γₙ₁, x), lw=2, label=\"Γ(n,1)\", c=:red)\nplot!(yaxis=false)\n````\n\n![\\|600](isti_altri-test_1.png)\n\nPossiamo quindi trovare un **intervallo di accettazione** $\\left\\[a,b\\right\\]$ tale che possiamo definire il seguente test $$\\text{rifiuto } H_0 \\iff T \\not\\in \\left\\[ a,b \\right\\]$$\nPossiamo anche *parametrizzare* tale test per ottenere una *probabilità di errore di tipo I* $\\alpha$ desiderata.\n$$\\begin{align\\*}\n\\\\alpha\n\u0026= P(T \\not\\in \\left\\[ a,b \\right\\])\\\\\n\u0026= 1 - P(a \\leq T \\leq b)\\\\\n\u0026= 1 - (F(b) - F(a))\n\\\\end{align\\*}$$\n\n## Sfruttare le proprietà asintotiche di MLE\n\nSia un generico campione $X_1,...,X_n$ dipendente da un parametro $\\theta$ \u003cu\u003esconosciuto\u003c/u\u003e.\nDefiniamo l'*ipotesi nulla* $$H_0: \\theta = \\theta_0$$\n\nConsideriamo uno [MLE](Stimatore%20di%20Massima%20Verosimiglianza.md#stimatore-di-massima-verosimiglianza-mle) $\\hat\\theta\\_{ML}$ per $\\theta$.\n\nSotto ipotesi nulla $H_0$, sappiamo che [asintoticamente avremo](Stimatore%20di%20Massima%20Verosimiglianza.md#c3b404) $$T = \\sqrt{nI(\\theta_0)} \\cdot {(\\hat\\theta\\_{ML} - \\theta_0)}\\sim N(0, 1)$$\nPeriò possiamo applicare lo [z-test](Test%20pi%C3%B9%20comuni.md#z-test).\n","lastmodified":"2022-08-29T13:39:16.814928855+02:00","tags":null},"/ISTI/CLT-Central-Limit-Theorem":{"title":"","content":"\n# CLT - Central Limit Theorem\n\nSia la sequenza di v.a. $X_1, X_2, ...$ **indipendenti e identicamente distribuite**, e per le quali la relativa [mgf](Distribuzioni%20Multivariate.md#moment-generating-function)  è definita quantomeno in un *intorno* di $0$ (ovvero $M\\_{X_i}(t)$ è definita per $\\vert t \\vert \\\u003c h$, per qualche $h \u003e 0$ fissato).\n\nDato che $M\\_{X_i}(t)$ è definita in $0$ allora esistono le medie $\\mathbb{E}\\left\\[ X_i \\right\\] = \\mu$ e $\\text{Var}(X_i) = \\sigma^2$, entrambe **finite**.\n\nSia $\\overline{X}\\_n$ la **[media campionaria](Random%20Sample.md#media-campionaria)** delle prime $n$ variabili della nostra serie, e indichiamo con $G_n(t)$ la **funzione di ripartizione** della v.a. $\\sqrt{n}(\\overline{X}*n - \\mu)/\\sigma$, ovvero $$G_n(t) = P\\left( \\sqrt{n} \\frac{\\overline{X}*n - \\mu}{\\sigma} \\leq t \\right) = P\\left( \\frac{X_1 + ... + X_n - n\\mu }{\\sqrt{n\\sigma}} \\leq t \\right)$$\nAllora per ogni $x$ **finito** (ovvero $-\\infty \\\u003c x \\\u003c \\infty$) avremo che $$\\lim*{n \\to \\infty}G_n(x) = \\frac{1}{\\sqrt{2\\pi}}\\int*{-\\infty}^{x}e^{-y^2/2},dy = \\Phi(x)$$ ovvero per $n \\to \\infty$ avremo che $\\sqrt{n}(\\overline{X}\\_n - \\mu)/\\sigma$ tenderà ad avere una **[distribuzione normale stadardizzata](Distribuzioni.md#normale-standard)** $N(0,1)$.\n\nOsserviamo che in realtà possiamo dire che $\\sqrt{n}(\\overline{X}\\_n - \\mu) \\xrightarrow{d} N(0,1)$ (vedi [Convergenza \u003e Convergenza in Distribuzione](Convergenza.md#convergenza-in-distribuzione)).\n\n## Versione alternativa\n\n$$\\sqrt{n}(\\overline{X}\\_n - \\mu) \\xrightarrow{d} N(0, \\sigma^2)$$\noppure\n$$\\frac{X_1 + ... + X_n - n\\mu}{\\sqrt{n}} \\xrightarrow{d} N(0, \\sigma^2)$$\n\n---\n\n# Normali Multivariate\n\nSia il vettore *colonna* $\\mathbf{X} = (X_1, ..., X_n)^T$ composto da $n$ **normali indipendenti**.\n\nLa sua media risulterà essere il vettore *colonna* $$\\mathbb{E}\\left\\[ \\mathbf{X} \\right\\] = (\\mathbb{E}\\left\\[ X_1 \\right\\], ..., \\mathbb{E}\\left\\[ X_n \\right\\])^T$$\nTale vettore avrà anche una **matrice di convarianza** $$\\Sigma := \\text{Cov}(\\mathbb{E}\\left\\[ \\mathbf{X} \\right\\]) = \\mathbb{E}\\left\\[ (\\mathbf{X} - \\mathbb{E}\\left\\[ \\mathbf{X} \\right\\])(\\mathbf{X} - \\mathbb{E}\\left\\[ \\mathbf{X} \\right\\])^T \\right\\]$$ di dimensione $n \\times n$.\n\nIn posizione $i,j$ della matrice di covarianza troveremo $\\text{Cov}(X_i, X_j)$.\n\nOsserivamo che $\\Sigma$ è **simmetrica** $$\\Sigma = \\Sigma^T$$ e che lungo la diagonale troviamo la **varianza** della variabile $i$-esima, perché $$\\text{Cov}(X_i, X_i) = \\text{Var}(X_i)$$\nAnche nel caso multivariato il valore atteso preserva la **linearita** con costanti matriciali e vettoriali.\n$$\\mathbb{E}\\left\\[ \\mathbf{X} + \\mathbf{Y} \\right\\] = \\mathbb{E}\\left\\[ \\mathbf{X} \\right\\] + \\mathbb{E}\\left\\[ \\mathbf{Y} \\right\\]$$\n$$\\mathbb{E}\\left\\[ A \\cdot\\mathbf{X} \\right\\] = A \\cdot \\mathbb{E}\\left\\[ \\mathbf{X} \\right\\]$$\n\nNel caso della covarianza invece $$\\text{Cov}(A \\cdot \\mathbf{X}) = A \\cdot \\Sigma \\cdot A^T$$\n\nSia il vettore $\\mathbf{Z} = (Z_1, ..., Z_n)$ composto da sole $N(0,1)$.\nSiano un $\\mu \\in \\mathbb{R}^n$  e $A \\in \\mathbb{R}^{n \\times n}$.\n\nAllora il vettore $\\mathbf{X} = \\mu + A \\mathbf{Z}$ avrà **distribuzione multivariata normale** con media $\\mu$ e matrice di covarianza $\\Sigma = AA^T$.\n\n### Densità normale multivariata\n\nSia il vettore $\\mathbf{Z} = (Z_1, ..., Z_n)$ composto da sole $N(0,1)$.\nSiano un $\\mu \\in \\mathbb{R}^n$  e $A \\in \\mathbb{R}^{n \\times n}$.\nIl vettore $\\mathbf{X} = \\mu + A \\mathbf{Z}$ con media $\\mu$ e matrice di covarianza $\\Sigma = AA^T$ avrà densità $$\\frac{1}{(2\\pi)^{n} \\cdot \\vert \\det{(\\Sigma)}\\vert}\\exp\\left(-\\frac{1}{2}(\\mathbf{X} - \\mu)\\Sigma(\\mathbf{X} - \\mu)^T \\right)$$\n\n---\n\n# CLT Multivariato\n\nSiano i vettori aleatori $\\mathbf{X}\\_1, \\mathbf{X}\\_2, ...$  *i.i.d.* con media $\\mu$ e matrice di covarianza $\\Sigma$.\nAllora avremo che $$\\frac{\\mathbf{X}\\_1 + ... + \\mathbf{X}\\_n - n\\mu}{\\sqrt{n}} \\xrightarrow{d} N(\\mathbf{0}, \\Sigma)$$\n(vedi [CLT - Central Limit Theorem \u003e Versione alternativa](CLT%20-%20Central%20Limit%20Theorem.md#versione-alternativa)).\n","lastmodified":"2022-08-29T13:39:16.781940237+02:00","tags":null},"/ISTI/Convergenza":{"title":"","content":"\n## Convergenza in probabilità\n\nUna sequenza di v.a. $X_1, X_2, ...$ **converga in probabilità** alla a.v. $X$ se per ogni $\\varepsilon \u003e 0$ $$\\lim\\_{n \\to \\infty}P(\\vert X_n - X\\vert \\\u003c \\varepsilon) = 1$$\nPer convenzione scriveremo che $X_n \\xrightarrow{p} X$.\n\n### Teorema Debole dei Grandi Numeri - Weak LLN\n\nSiano $X_1, X_2, ...$ v.a. **i.i.d.** con media $\\mu$ e varianza **finita** $\\sigma^2 \\\u003c \\infty$.\nSia $$\\overline{X}*n = \\dfrac{\\sum*{i=1}^n X_i}{n}$$ la [media campionaria](Random%20Sample.md#media-campionaria) dei primi $n$ elementi.\nAllora per ogni $\\varepsilon \u003e 0$ $$\\lim\\_{n \\to \\infty}P(\\vert \\overline{X}\\_n - \\mu \\vert \\\u003c \\varepsilon) = 1$$ ovvero  $\\overline{X}\\_n$ **converge in probabilità** a $\\mu$.\n\n#### Proof\n\nBasta applicare la *Disuguaglianza di Chebyschev*.\n$$P(\\vert \\overline{X}\\_n - \\mu \\vert \\geq \\varepsilon) \\leq \\frac{\\text{Var}(\\overline{X}\\_n - \\mu)}{\\varepsilon^2} = \\frac{\\text{Var}(\\overline{X}\\_n)}{\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2}$$\nPerciò, fissato un qualsiasi $\\varepsilon \u003e 0$ avremo che\n$$P(\\vert \\overline{X}\\_n - \\mu \\vert \\\u003c \\varepsilon) = 1 - P(\\vert \\overline{X}\\_n - \\mu \\vert \\geq \\varepsilon) \\geq 1 - \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\to \\infty} 1 ;; \\square$$\n\n### Teorema 5.5.4\n\nSiano $X_1, X_2, ...$ v.a. **tendono in probabilità** ad $X$, e sia $h$ una funzione continua.\nAllora $h(X_1), h(X_2), ...$ convergono il probabilità $h(X)$.\n\n---\n\n## Almost Sure Convergence\n\nUna sequenza di v.a. $X_1, X_2, ...$ **converga almost surely** alla a.v. $X$ se per ogni $\\varepsilon \u003e 0$  $$P\\left( \\lim\\_{n \\to \\infty}\\vert X_n - X\\vert \\\u003c \\varepsilon \\right) = 1$$\n\n### Esempio\n\nConsideriamo uno spazio $S = \\left\\[ 0,1 \\right\\]$ con distribuzione unifrome.\nSiano le v.a. $X_n(s) = s + s^n$ e $X(s) = s$, con $s \\sim US$.\nOsserviamo che per ogni $s \\in \\left\\[0,1\\right)$ $X_n(s)$ converge **quasi sicuramente** a $X$.\nInfatti per $n \\to \\infty$ avremo che $s^n \\to 0$ e che quindi $X_n(s) \\to s$.\n\nNon è vero però per $s = 1$, infatti per $n \\to \\infty$ $X_n(1) = 2 \\neq 1 = X(1)$.\n\nPerò dato che la convergenza avviene in $\\left\\[ 0,1 \\right)$ e dato che $P(s \\in \\left\\[ 0,1 \\right)) = 1$ allora possiamo dire che $X_n$ converge quasi sicuramente a $X$. \n\n### Teorema Forte dei Grandi Numeri - Strong LLN\n\nSiano $X_1, X_2, ...$ v.a. **i.i.d.** con media $\\mu$ e varianza **finita** $\\sigma^2 \\\u003c \\infty$.\nSia $\\overline{X}\\_n$ la [media campionaria](Random%20Sample.md#media-campionaria) dei primi $n$ elementi della serie di v.a.\n\nAllora per ogni $\\varepsilon \u003e 0$\n$$P\\left( \\lim\\_{n \\to \\infty} \\vert \\overline{X}\\_n - \\mu \\vert \\\u003c \\varepsilon \\right) = 1$$\novvero $\\overline{X}\\_n$ converge *quasi certamente* a $\\mu$.\n\n---\n\n## Convergenza in Distribuzione\n\nUna sequenza di v.a. $X_1, X_2, ...$ **converge in distribuzione** a una v.a. $X$ se $$\\lim\\_{n \\to \\infty}F\\_{X_n}(x) = F_X(x)$$ per ogni punto $x$ di continuità di $F_X(x)$.\n\nCome notazione, per dire che *\"$X_n$ tende in distribuzione a $X$*\" (sempre per $n$ che tende ad infinito) scriveremo $X_n \\xrightarrow{d} X$.\n\n### Esempio - Il massimo di Uniformi\n\nSiano $X_1, X_2, ...$ v.a. **i.i.d.** uniformi $U\\left(0,1\\right)$, e sia $X\\_{(n)} = \\max\\_{1 \\leq i \\leq n} X_i$ il massimo valora dei primi $n$ elementi.\nVogliamo studiare a cosa tende in distribuzione $X\\_{(n)}$.\n\nPer $n \\to \\infty$ ci aspettiamo che $X\\_{(n)}$ si avvicina sempre di più ad 1, e siccome $X\\_{(n)}$ è sempre minore di 1, avremo che per ogni $\\varepsilon \u003e 0$\n$$P(\\vert X\\_{(n)} - 1 \\vert \\geq \\varepsilon) = P(X\\_{(n)} \\geq 1 + \\varepsilon) + P(X\\_{(n)} \\leq 1 - \\varepsilon) = 0 + P(X\\_{(n)} \\leq 1 - \\varepsilon)$$\nSfruttando ora l'indipendenza avremo che $$P(X\\_{(n)} \\\u003c 1 - \\varepsilon) = P({X_i \\leq 1 - \\varepsilon : i=1,...,n}) = (1-\\varepsilon)^n$$ il quale tende a $0$ per $n \\to \\infty$.\nAbbiamo quindi dimostrato $X\\_{(n)}$ tende in **probabilità** ad 1, ovvero $X\\_{(n)} \\xrightarrow{p} 1$.\n\nPoniamo ora $\\varepsilon = t/n$\n$$P(X\\_{(n)} \\leq 1 - t/n) = (1-t/n)^n \\xrightarrow{n \\to \\infty} e^{-t}$$\n\nRiarrangiando i termini otteremo che $$P(n \\cdot (1 - X\\_{(n)}) \\leq t) \\rightarrow 1 - e^{-t}$$\novvero abbiamo dimostrato che la v.a. $n \\cdot (1 - X\\_{(n)})$ tende in distribuzione ad una **[esponenziale](Distribuzioni.md#esponenziale)** di parametro 1.\n\n### Teorema 5.5.12 (importante)\n\nSe una sequenza $X_1, X_2, ...$ tende in **probabilità** ad una variabile $X$ allora tende anche in **distribuzione**.\n\n### Teorema 5.5.13 (importante)\n\nUna sequenza $X_1, X_2, ...$ tende in **probabilità** ad una **cosante** $\\mu$ \u003cu\u003ese e solo se\u003c/u\u003e tende a $\\mu$ anche in **distribuzione**.\n\nPiù formalmente, l'affermazione che $$P(\\vert X_n - \\mu \\vert \u003e \\varepsilon) \\xrightarrow{n \\to \\infty} 0 ;; \\forall \\varepsilon \u003e 0$$ è **equivalente** a\n$$F\\_{X_n}(x) =\nP(X_n \\leq x) \\xrightarrow{n \\to \\infty}\n\\\\begin{cases}\n0 \u0026x \\\u003c \\mu\\\\\n1 \u0026x \\geq \\mu\n\\\\end{cases}$$\n","lastmodified":"2022-08-29T13:39:16.761594063+02:00","tags":null},"/ISTI/Cram%C3%A9r-Rao-Inequality":{"title":"","content":"\n# Cramér-Rao Inequality\n\nSia un [campione](Random%20Sample.md#random-sample) $X_1, ..., X_n$ con [densità congiunta](Distribuzioni%20Multivariate.md#joint-pdf) $f(\\mathbf{x} \\vert \\theta)$.\nSia $W(\\mathbf{X})$ una **statistica** che rispetta le seguenti proprietà\n\n1. $$\\frac{d}{d\\theta}\\mathbb{E}*{\\theta}\\left\\[ W(\\mathbf{X}) \\right\\] = \\int*{\\mathbb{R}^n} \\frac{\\partial}{\\partial \\theta}\\left\\[ W(\\mathbf{x}) \\cdot f(\\mathbf{x} \\vert \\theta) \\right\\] , d\\mathbf{x}$$\n1. $$\\text{Var}*{\\theta}(W(\\mathbf{X})) \\\u003c \\infty$$\n   Allora avremo che $$\\text{Var}*{\\theta}(W(\\mathbf{X})) \\geq \\frac{\\left(\\frac{d}{d\\theta}\\mathbb{E}*{\\theta}\\left\\[ W(\\mathbf{X}) \\right\\]\\\\right)^2}{\\mathbb{E}*{\\theta}\\left\\[ (\\frac{\\partial}{\\partial\\theta} \\log{f(\\mathbf{X} \\vert \\theta)})^2 \\right\\]} = \\frac{\\left(\\frac{d}{d\\theta}\\mathbb{E}\\_{\\theta}\\left\\[ W(\\mathbf{X}) \\right\\]\\\\right)^2}{I(\\theta)}$$ dove $I(\\theta)$ è l'[informazione di Fisher](Informazione%20di%20Fisher.md) del parametro $\\theta$.\n\nRicordiamo che se $W$ è uno [stimatore non distorto](Stimatori%20Puntuali.md#401481) di $\\theta$ allora avremo che $$\\mathbb{E}*{\\theta}\\left\\[ W(\\mathbf{X}) \\right\\] = \\theta \\implies \\frac{d}{d\\theta}\\mathbb{E}*{\\theta}\\left\\[ W(\\mathbf{X}) \\right\\] = 1$$ e quindi la disuguaglianza diventa $$\\text{Var}\\_{\\theta}(W(\\mathbf{X})) \\geq \\frac{1}{I(\\theta)}$$ ^c8c14d\n\n---\n\n## Esempio - Esponenziale\n\nConsideriamo il campione [esponenziale](Distribuzioni.md#esponenziale) $X_1, ..., X_n$.\nLa distribuzione congiunta è $$f(\\mathbf{x} \\vert \\lambda) = \\lambda^ne^{- \\lambda\\sum_i x_i}$$\nDa [Informazione di Fisher \u003e Esempio - Campione esponenziale](Informazione%20di%20Fisher.md#esempio-campione-esponenziale) sappiamo che la sua informazione di Fisher è $$I(\\lambda) = \\frac{n}{\\lambda^2}$$\n\nSia quindi la [media campionaria](Random%20Sample.md#media-campionaria) $\\overline{X} = (X_1 + ... + X_n)/n$ uno [stimatore puntuale](Stimatori%20Puntuali.md#stimatori-puntuali) della media di una v.a. esponenziale, ovvero $1/\\lambda$.\nSi può verificare che $\\overline{X}$ è [non distorto](Stimatori%20Puntuali.md#401481), infatti $$\\mathbb{E}*\\\\lambda\\left\\[ \\overline{X} \\right\\] = \\frac{1}{n} \\sum*{i=1}^{n}\\mathbb{E}*\\\\lambda\\left\\[ X_i \\right\\] = \\frac{1}{\\lambda}$$\nPerciò applicando la [disuguaglianza di Cramér-Rao](Cram%C3%A9r-Rao%20Inequality.md#c8c14d) avremo che $$\\text{Var}*\\\\lambda(\\overline{X}) \\geq \\frac{1}{I(\\theta)} = \\frac{\\lambda^2}{n}$$ \n\nProviamo ora a considerare lo stimatore $$\\hat{\\lambda} = \\frac{1}{\\overline{X}}$$ per il parametro $\\lambda$.\n\nDalle [proprietà delle normali](Distribuzioni.md#50a917) avremo che la distribuzione di $\\overline{X}$ tende **asintoticamente** a \n$$\\overline{X} \\xrightarrow{d} N(\\mu, \\sigma^2/n) = N\\left(\\frac{1}{\\lambda}, \\frac{1}{n\\lambda^2} \\right)$$\n\nApplichiamo quindi il [Metodo Delta](Delta%20Method.md#teorema-metodo-delta) con funzione $$g(x) = \\frac{1}{x}$$ ottenendo quindi $$\\sqrt{n}\\left( \\hat{\\lambda} - \\lambda\\right) = \\sqrt{n}\\left(g(1/\\overline{X}) - g(1/\\lambda)\\right) \\xrightarrow{d} N(0, \\hat{\\sigma}^2 \\left\\[ g'(1/\\lambda) \\right\\]^2) = N\\left(0, \\frac{\\lambda^2}{n} \\right)$$\nOvvero $\\hat{\\lambda}$ [converge in distribuzione](Convergenza.md#convergenza-in-distribuzione) a $N(\\lambda, \\lambda^2/n)$, perciò $\\hat{\\lambda}$ è uno stiamtore **asintoticamente** non distorto per $\\lambda$, ovvero $$\\lim\\_{n \\to \\infty} \\mathbb{E}\\left\\[ \\hat\\lambda \\right\\] = \\lambda$$\nAnalogamente per la sua *varianza asintotica* $$\\lim\\_{n \\to \\infty} \\text{Var}\\left( \\hat\\lambda \\right) = \\frac{\\lambda^2}{n} = \\frac{1}{I(\\lambda)}$$ dunque la più piccola varianza che si può ottenere.\n\nPossiamo quindi concludere che $\\hat\\lambda$ è **asintoticamente ottimale**.\n\n(Osservare che avvolte valore atteso e varianza di uno stimatore non sono sempre ottimali per $n$ finito).\n","lastmodified":"2022-08-29T13:39:16.776166747+02:00","tags":null},"/ISTI/Delta-Method":{"title":"","content":"\n# Teorema - Metodo Delta\n\nSia la v.a. $X_n$ tale che $X_n \\xrightarrow{p} \\mu$ e $\\sqrt{n}(X_n - \\mu) \\xrightarrow{d} N(0, \\sigma^2)$.\nSia inoltre la funzione $g$ *differenziabile* in un intorno di $\\mu$.\nAllora avremo che\n$$g(X_n) \\xrightarrow{p} g(\\mu)$$ $$\\sqrt{n}(g(X_n) - g(\\mu)) \\xrightarrow{d} N(0, \\sigma^2 \\left\\[ g'(\\mu) \\right\\]^2  )$$\n\n### Dimostrazione\n\nPer il primo sviluppo di Taylor avremo per un $x$ sufficientemente *\"vicino\"* a $\\mu$\n$$g(x) = g(\\mu) + g'(\\mu)(x-\\mu) + o(\\vert x - \\mu \\vert)$$\n$$\\implies g(x) - g(\\mu) = g'(\\mu)(x-\\mu) + o(\\vert x - \\mu \\vert)$$\nPer per $n \\to \\infty$ abbiamo che $X_n \\to \\mu$, perciò\n$$\\sqrt{n}(g(X_n) - g(\\mu)) = g'(\\mu)\\sqrt{n}(X_n - \\mu) + o(\\vert \\sqrt{n}(X_n - \\mu )\\vert)$$\n\nSe $X_n$ tende a $\\mu$ in probabilità allora anche $(X_n - \\mu)$ tende a 0 in probabilità, perciò $$\\sqrt{n}(g(X_n) - g(\\mu)) = g'(\\mu)\\sqrt{n}(X_n - \\mu)$$\n$$\\implies \\frac{\\sqrt{n}(g(X_n) - g(\\mu))}{g'(\\mu) \\sigma} = \\frac{\\sqrt{n}(X_n - \\mu)}{\\sigma} \\xrightarrow{d} N(0,1)$$\nPer l'ultimo passaggio è stato applicato il [CLT - Central Limit Theorem](CLT%20-%20Central%20Limit%20Theorem.md).\n\nPossiamo quindi concludere che $\\sqrt{n}(g(X_n) - g(\\mu))$ [converge in distribuzione](Convergenza.md#convergenza-in-distribuzione) ad una normale $N(0, \\sigma^2 \\left\\[ g'(\\mu) \\right\\]^2)$ $\\square$.\n\n---\n\n### Esempio I\n\nSupponiamo di avere un [random sample](Random%20Sample.md#random-sample) $X_1, ..., X_n$ con media $\\mu$, varianza $\\sigma^2$ e media campionaria $\\overline{X}$.\nSupponiamo inoltre di voler studiare la distribuzione $\\dfrac{1}{\\overline{X}}$.\n\nPonendo $g(x) = 1/x$ avremo che\n$$\\sqrt{n}\\left(\\frac{1}{\\overline{X}} - \\frac{1}{\\mu}\\right) = \\sqrt{n}\\left(g(\\overline{X}) - g(\\mu)\\right) \\xrightarrow{d} N(0, \\sigma^2/\\mu^4)$$\n\n---\n\n## Proprietà utili\n\nSia $X_n \\xrightarrow{p} \\mu$.\nAllora avremo che\n$$g(X_n) \\xrightarrow{d} g(\\mu) + g'(\\mu)(X_n - \\mu)$$\nCalcolando la media, *asintoticamente* otteremo\n$$\\begin{align\\*}\n\\\\mathbb{E}\\left\\[ g(X_n) \\right\\]\n\u0026= \\mathbb{E}\\left\\[ g(\\mu) + g'(\\mu)(X_n - \\mu) \\right\\]\\\\\n\u0026= g(\\mu) + g'(\\mu)\\mathbb{E}\\left\\[(X_n - \\mu)\\right\\]\\\\\n\u0026= g(\\mu) + g'(\\mu)(\\underbrace{\\mathbb{E}\\left\\[X_n\\right\\]}\\_{= \\mu} - \\mu)\\\\\n\u0026= g(\\mu)\n\\\\end{align\\*}$$\ne\n$$\\begin{align\\*}\n\\\\text{Var}(g(X_n))\n\u0026= \\mathbb{E}\\left\\[ \\right(g(X_n) - \\mathbb{E}\\left\\[ X_n \\right\\] \\left)^2 \\right\\]\\\\\n\u0026= \\mathbb{E}\\left\\[ (g(X_n) - g(\\mu))^2 \\right\\]\\\\\n\u0026= \\mathbb{E}\\left\\[ (g'(\\mu)(X_n - \\mu))^2 \\right\\]\\\\\n\u0026= \\left\\[g'(\\mu)\\right\\]^2 \\cdot \\mathbb{E}\\left\\[ (X_n - \\mu)^2 \\right\\]\\\\\n\u0026= \\left\\[g'(\\mu)\\right\\]^2 \\cdot \\text{Var}(X)\n\\\\end{align\\*}$$\n\n---\n\n### Esempio II\n\nSupponiamo di avere $X_1, ..., X_n$ v.a. **iid** *Bernoulliano* di parametro $p$.\nUn interessante parametro che spesso si studia è il rapporto di efficienza $p/(1-p)$.\n\nPer la [legge dei grandi numeri](Convergenza.md#teorema-debole-dei-grandi-numeri-weak-lln) sappiamo che possiamo *stimare* il parametro $p$ tramite le osservazioni $X_1, ..., X_n$, semplicemente tramite la media campionaria $$\\hat{p} = \\frac{1}{n}\\sum\\_{i=1}^{n}X_i$$ (questo perché appunto la media di una bernoulliana è appunto $p$).\nCi chiediamo se $\\dfrac{\\hat{p}}{1-\\hat{p}}$ è un buono **stimatore** di $p/(1-p)$.\n\nPer esempio, poniamo la funzione $$g(p) = \\frac{p}{1 - p}$$ con derivata prima $$g'(p) = \\frac{1}{(1-p)^2}$$\n\nCerchiamo di calcolare la **varianza del nostro stimatore**\n$$\\begin{align\\*}\n\\\\text{Var}(g(\\hat{p}))\n\u0026= \\left\\[ g'(\\mathbb{E}\\left\\[ \\hat{p} \\right\\]) \\right\\]^2 \\cdot \\text{Var}(\\hat{p})\\\\\n\u0026= \\left\\[ g'(p) \\right\\]^2 \\cdot \\text{Var}(\\hat{p})\\\\\n\u0026= \\left\\[ g'(p) \\right\\]^2 \\cdot \\frac{\\text{Var}(p)}{n}\\\\\n\u0026= \\frac{1}{(1-p)^4} \\cdot \\frac{p(1-p)}{n}\\\\\n\u0026= \\frac{p}{n(1-p)^3}\n\\\\end{align\\*}$$\n\n---\n\n# Metodo Delta del Secondo Ordine\n\nSia $X_n$ una sequenza di v.a. tale che $\\sqrt{n}(X_n - \\mu) \\xrightarrow{d} N(0, \\sigma^2)$.\nPer una data funzione $g$ e per uno specifico valore $\\mu$, supponiamo che $g'(\\mu) = 0$ e che $g''(\\mu) \\neq 0$.\n\nAllora $$n(g(X_n) - \\mu) \\xrightarrow{d} \\sigma^2 \\frac{g''(\\mu)}{2} \\chi_1^2$$\n","lastmodified":"2022-08-29T13:39:16.735952135+02:00","tags":null},"/ISTI/Distribuzioni":{"title":"","content":"\n# Continue\n\n# Normale\n\n### Notazione\n\n$$N(\\mu, \\sigma^2)$$\n\n### Parametri\n\n* **media** $\\mu$\n* **varianza** $\\sigma^2$\n\n### CDF\n\n$$X \\sim N(\\mu, \\sigma^2) \\implies F_X(x) = \\frac{1}{\\sqrt{2\\pi}} \\int\\_{-\\infty}^{x}e^{-\\dfrac{1}{2}\\left( \\dfrac{t-\\mu}{\\sigma} \\right)^2} ,dt$$\n\n### PDF\n\n$$X \\sim N(\\mu, \\sigma^2) \\implies f_X(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{- \\dfrac{1}{2}\\left( \\dfrac{x-\\mu}{\\sigma}\\right)^2}$$\n\n### MGF\n\n$$X \\sim N(\\mu, \\sigma^2) \\implies M_X(t) = \\exp{\\left( \\mu t + \\sigma^2 \\frac{t^2}{2} \\right)}$$\n\n## Normale Standard\n\nUna **normale standard** è un normale con parametri $\\mu = 0$ e $\\sigma^2 = 1$, ovvero $N(0,1)$.\nAvremo quindi\n\n* Supporto $\\mathbb{R}$\n* Media $\\mu = 0$\n* Varianza $\\sigma^2 = 1$\n* cdf $$\\Phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\int\\_{-\\infty}^{x}e^{-t^2/2} ,dt$$\n* pdf $$\\phi(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}$$\n* mgf $M_X(t) = e^{t^2/2}$\n\nOsserviamo che $X \\sim N(\\mu, \\sigma^2)$ avra *pdf* $$f_X(x) = \\frac{1}{\\sigma} \\cdot \\phi\\left( \\frac{x - \\mu}{\\sigma} \\right)$$ e *cdf* $$f_X(x) = \\Phi\\left( \\frac{x - \\mu}{\\sigma} \\right)$$\n\n## Proprietà importanti\n\nSia $X \\sim N(\\mu, \\sigma^2)$\n\n1. La v.a. $aX + b$ equivlae a una normale $N(a\\mu + b, |a|\\sigma)$.\n1. Caso particolare del predente: sia $Z \\sim N(0, 1)$. Allora la v.a. $\\sigma^2 Z + \\mu$ è una normale $N(\\mu, \\sigma^2)$. \n1. $e^X \\sim \\ln{(N(\\mu, \\sigma^2))}$.\n1. La v.a. $\\vert X - \\mu \\vert / \\sigma$ avrà distribuzione **chi** con 1 grado di libertà: $\\vert X - \\mu \\vert / \\sigma \\sim \\chi_1$.\n1. La v.a. $(X/\\sigma)^2$ ha distribuzione **chi quadro non centrata** con $1$ grado di libertà: $$\\left( \\frac{X}{\\sigma}\\right)^2 \\sim \\chi_1^2\\left( \\frac{\\mu^2}{\\sigma^2} \\right)$$\n   Nel caso in cui $\\mu = 0$ avremo semplicemente una **chi quadro** $\\chi_1^2$\n1. La [media campionaria](Random%20Sample.md#media-campionaria) $\\overline{X}\\_n$ di $n$ normali **indipendenti** ha una distribuzione $N(\\mu, \\sigma^2/n)$. ^50a917\n1. La sommma di $n$ normali **indipendenti** ha distribuzione $N(n\\mu, n\\sigma^2)$.\n\n### Bin(n,p) $\\to$ N(np, np(1-p))\n\nSia $X \\sim \\text{Bin}(n,p)$ con media $\\mu = np$ e varianza $\\sigma^2 = np(1-p)$.\nPossiamo approssimare $X$ con una normale $Y \\sim N(np, np(1-p))$.\n\n![\\|400](isti-distr-1.png)\n\n---\n\n# Cauchy\n\n### Notazione\n\n$$\\text{Cauchy}(x_0, \\gamma)$$\n\n## PDF\n\n$$ f\\_{(x_0, \\gamma)}(x) = \\frac{1}{\\pi} \\frac{\\gamma}{(x- x_0)^2 + \\gamma^2}$$\noppure moltiplicando per $\\gamma^2/\\gamma^2$\n$$ f\\_{(x_0, \\gamma)}(x) = \\frac{1}{\\gamma\\pi} \\frac{1}{\\left(\\cfrac{x- x_0}{\\gamma}\\right)^2 + 1}$$\n\n### Media e Varianza\n\nLa media di $X \\sim \\text{Cauchy}(x_0, \\gamma)$ è $\\mu = x_0$.\n$X$ non ha varianza.\n\n#### Casi particolari\n\n$$X \\sim \\text{Cauchy}(0, 1) \\implies f_X(x) = \\frac{1}{\\pi}\\frac{1}{x^2 + 1}$$\n\n$$X \\sim \\text{Cauchy}(0, \\gamma) \\implies f_X(x) = \\frac{1}{\\gamma\\pi}\\frac{1}{(x/\\gamma)^2 + 1}$$\n\n## Somma di Cauchy indipendinti\n\nSiano $X \\sim \\text{Cauchy}(0, \\sigma)$ e $Y \\sim \\text{Cauchy}(0, \\tau)$ **indipendenti**, ovvero tali che\n$$f_X(x) = \\frac{1}{\\sigma\\pi}\\frac{1}{(x/\\sigma)^2 + 1}$$\n$$f_Y(y) = \\frac{1}{\\tau\\pi}\\frac{1}{(y/\\tau)^2 + 1}$$\n$$f\\_{X,Y}(x,y) = f_X(x)f_Y(y)$$\n\nSia la v.a. $Z = X+Y$.\nGrazie al [teorema 5.2.9](Random%20Sample.md#teorema-5-2-9-convolution-formula) possiamo dire che $Z$ avrà pdf\n$$f_Z(z) = \\int\\_{-\\infty}^{\\infty}f_X(w)f_Y(z-w) , dw = \\int\\_{-\\infty}^{\\infty} \\frac{1}{\\sigma\\pi}\\frac{1}{(w/\\sigma)^2 + 1}\\frac{1}{\\tau\\pi}\\frac{1}{((z-w)/\\tau)^2 + 1}$$\nIntegrando accuratamente per *decomposizioni parziali* e qualche *antidifferenziazione* otteremo che $$f_Z(z) = \\frac{1}{(\\sigma + \\tau)\\pi}\\frac{1}{\\left(\\cfrac{z}{\\sigma+\\tau}\\right)^2 + 1}$$\novvero $Z$ è una $\\text{Cauchy}(0, \\sigma + \\tau)$.\n\n---\n\n# Esponenziale\n\n## Notazione\n\n$$\\text{Exp}(\\lambda)$$\n\n## Parametri\n\n$$\\lambda \u003e 0$$\n\n## Supporto\n\n$$\\mathbb{R}^+$$\n\n## Funzione di ripartizione\n\n$$F(x) = 1 - e^{-\\lambda x}$$\n\n## Funzione di densità\n\n$$f(x) = \\lambda e^{-\\lambda x}$$\n\n## Media\n\n$$\\frac{1}{\\lambda}$$\n\n## Varianza\n\n$$\\frac{1}{\\lambda^2}$$\n\n## Funzione generatrice dei momenti\n\n$$\\left(1 - \\frac{t}{\\lambda}\\right)^{-1}$$\n\n## Proprietà\n\n1. Siano $X_1,...,X_n$ v.a. **indipendenti** esponenziali di parametri $\\lambda_1, ..., \\lambda_n$. Allora la v.a. $\\min{{X_1, ..., X_n}}$ è anch'essa una esponenziale di paramtro $\\lambda = \\lambda_1 + ... + \\lambda_n$\n1. Siano $X_1,X_2$ due v.a. esponenziali **indipendenti** e di parametri $\\lambda_1, \\lambda_2$. Allora la v.a. $Z = X_1 + X_2$ avrà densità $$\\begin{align\\*}\n   f_Z(z)\n   \u0026= \\int\\_{0}^{z}f\\_{X_1}(w)f\\_{X_2}(z-w) , dw\\\\\n   \u0026=\\int\\_{0}^{z}\\lambda_1e^{-\\lambda_1w}\\lambda_2e^{-\\lambda_2(z-w)} , dw\\\\\n   \u0026= \\lambda_1\\lambda_2e^{-\\lambda_2z}\\int\\_{0}^{z}e^{(\\lambda_2 - \\lambda_2)w},dw\\\\\n   \u0026= \\begin{cases}\n   \\\\lambda^2ze^{-\\lambda z} \u0026\\mbox{se } \\lambda_1 = \\lambda_2 = \\lambda\\\\\n   \\\\frac{\\lambda_1\\lambda_2}{\\lambda_2-\\lambda_1}(e^{-\\lambda_1 z} - e^{-\\lambda_2 z}) \u0026\\mbox{se } \\lambda_1 \\neq \\lambda_2\n   \\\\end{cases}\n   \\\\end{align\\*}$$\n1. Siano $X_1, ..., X_n$ **i.i.d.** $U\\left\\[ 0,1 \\right\\]$, allora $$\\lim\\_{n \\to \\infty} n \\min{{X_1, ..., X_n}} \\sim \\text{Exp}(1)$$\n1. Sia $X \\sim \\text{Exp}(\\lambda)$, allora $kX \\sim \\text{Exp}(\\lambda / k)$. Un caso particolare è $\\lambda X \\sim \\text{Exp}(1)$.\n1. Sino $X_1, ..., X_n$ **i.i.d.** $\\text{Exp}(\\lambda)$, allora $X_1 + ... + X_n \\sim \\Gamma(n, 1/\\lambda)$ (vedi [Gamma](Distribuzioni.md#gamma)). ^9fe8ff\n1. $\\hat\\lambda\\_{ML} = 1/\\overline{X}$, con *bias* $b = \\lambda/(n-1)$. Perciò lo stimatore di massima verosimiglianza non distorto sarà $\\hat\\lambda^\\**{ML} = \\hat\\lambda*{ML} - b$ .\n1. $I(\\lambda) = \\lambda^{-2}$\n\n---\n\n# Poisson\n\n## Notazione\n\n$$\\text{Poisson}(\\lambda)$$\n\n## Parametri\n\n$$\\lambda \u003e 0$$\n\n## Supporto\n\n$$\\mathbb{N}^+$$\n\n## Funzione di ripartizione\n\n$$F(x) = \\frac{\\Gamma(n+1, \\lambda)}{x!}$$\n\n## Funzione di densità\n\n$$f(x) = \\frac{\\lambda^x}{x!} e^{-\\lambda}$$\n\n## Media\n\n$$\\lambda$$\n\n## Varianza\n\n$$\\lambda$$\n\n## Funzione generatrice dei momenti\n\n$$e^{\\lambda(e^t - 1)}$$\n\n## Proprietà\n\nSiano $Y_1 \\sim \\text{Poisson}(\\lambda_1)$ e $Y_2 \\sim \\text{Poisson}(\\lambda_2)$ **indipendenti**.\nAllora avremo che\n\n* $Y = Y_1 + Y_2$ è una poisson di parametro $\\lambda = \\lambda_1 + \\lambda_2$.\n* La distribuzione di $Y_1$ **condizionata** al fatto che $Y = n$ è una **binomiale** di parametri $n$ e $\\lambda_1/\\lambda$.\n\n---\n\n# Chi Quadro\n\nLa **distribuzione chi quadrato** è la distribuzione della somma dei quadrati di variabili aleatorie normali **indeipendenti**.\n\n## Notazione\n\n$$\\chi^2\\_{k}$$\n\n## Parametri\n\n* **Gradi di lebertà** $$k \\in \\mathbb{N} \\setminus { 0 }$$\n\n## Supporto\n\n$$\\left\\[ 0, \\infty \\right\\]$$\n\n## Funzione di ripartizione\n\n$$F(x) = \\frac{1}{\\Gamma\\left( \\frac{k}{2} \\right)} \\cdot \\gamma\\left( \\frac{k}{2}, \\frac{x}{2} \\right)$$ dove $$\\gamma(s,x) = \\int\\_{0}^{x}t^{s-1}e^{-t} , dt$$\n\n## Funzione di densità\n\n$$f(x) = \\frac{1}{ 2^{k/2} \\cdot \\Gamma\\left( \\frac{k}{2} \\right)} x^{k/2 - 1} e^{-x/2}$$\n\n## Media\n\n$$k$$\n\n## Varianza\n\n$$2k$$\n\n## Funzione generatrice dei momenti\n\n$$M_X(t) = (1 - 2t)^{}-k/2 ;; \\forall t \\in \\left\\[ -\\frac{1}{2}, \\frac{1}{2} \\right\\]$$\n\n## Proprietà\n\n* La somma di due v.a. $\\chi^2_n, \\chi^2_m$ è una $\\chi^2\\_{n+m}$\n* Sia $X_1, ..., X_n$ un campione di normali $N(\\mu, \\sigma^2)$. Allora lo stimatore $S^2$ segue una distribuzione $$S^2 \\sim \\frac{\\sigma^2}{n-1}\\chi^2\\_{n-1} \\iff (n-1)\\frac{S^2}{\\sigma^2} \\sim \\chi^2\\_{n-1}$$\n\n---\n\n# Gamma\n\n## Notazione\n\n* **Shape-Scale** $$\\Gamma(k, \\theta)$$\n* **Shape-Rate** $$\\Gamma(\\alpha, \\beta)$$\n\n## Parametri\n\n* **Shape**: $k = \\alpha \\in \\mathbb{R}^+$\n* **Scale**: $\\theta = \\beta^{-1} \\in \\mathbb{R}^+$\n* **Rate**: $\\beta = \\theta^{-1} \\in \\mathbb{R}^+$\n\n## Funzione di ripartizione\n\n$$P(k,x) = \\frac{\\gamma(k, x/\\theta)}{\\Gamma(k)}$$ dove $$\\gamma(a,x) = \\int_0^x e^{-t}t^{a-1} , dt$$ e\n$$\\Gamma(x) =\n\\\\begin{cases}\\int_0^{\\infty}e^{-t}t^{x-1} , dt \u0026\\mbox{per } x \\in \\mathbb{R}\\\\\nx-1! \u0026\\mbox{per } x \\in \\mathbb{N}\n\\\\end{cases}$$\n\n## Funzione di densità\n\n$$f(x) = \\frac{\\theta^{-k}}{\\Gamma(k)} x^{k-1}e^{-x/\\theta}$$\n\n## Media\n\n$$k\\theta = \\frac{\\alpha}{\\beta}$$\n\n## Varianza\n\n$$k \\theta^2 = \\frac{\\alpha}{\\beta^2}$$\n\n## Funzione generatrice dei momenti\n\n$$M_X(t) = (1-t\\theta)^{-k} ;; \\forall t  \\\u003c \\theta^{-1}$$\n\n## Proprietà\n\n### Cambiamento di scala\n\nSia $X \\sim \\Gamma(k, \\theta)$ allora $aX \\sim \\Gamma(k, a\\theta)$.\nOppure espresso con notazione **shapre-rate** avremo che se $X \\sim \\Gamma(\\alpha, \\beta)$ allora $aX \\sim \\Gamma(\\alpha, \\beta/c)$.\n\n### Somme di Gamma\n\nSiano $X_1, ..., X_n$ **indipendenti** tali che $X_i \\sim \\Gamma(k_i, \\theta)$, allora $X_1 + ... + X_n \\sim \\Gamma(k_1 + ... + k_n, \\theta)$.\n\n### Altre proprietà importanti\n\n1. $$\\Gamma(1, \\theta) = \\text{Exp}(1/\\theta)$$\n1. $$X \\sim N(0,1) \\implies X^2 \\sim \\Gamma\\left(\\frac{1}{2}, \\frac{1}{2}\\right)$$\n1. Siano $X_1, ..., X_n \\sim N(0,1)$ *i.i.d*, allora $$\\sum\\_{i=1}^{n}X_i^2 \\sim \\chi_n^2 = \\Gamma\\left(\\frac{n}{2}, \\frac{1}{2} \\right)$$\n1. Il momento $n$-esimo di una gamma è $$\\mathbb{E}\\left\\[ X^n \\right\\] = \\theta^n\\frac{\\Gamma(n+k)}{\\Gamma(k)}$$\n1. La somma $X_1, ..., X_n$ v.a. $\\Gamma(k_i, \\theta)$ **indipententi** ha distribuzione $$X_1 + ... + X_n \\sim \\Gamma(k_1 + ... + k_n, \\theta)$$\n1. Per valori di $k$ abbastanza grandi avremo che la distribuzione gamma converge ad una normale con $\\mu = k\\theta$ e $\\sigma = k \\theta^2$.\n\n---\n\n# Distribuzione $t$ di Stundet\n\n## Notazione\n\n$$t(\\nu)$$\n\n## Parametri\n\n* **Gradi di libertà** $$\\nu \\in \\mathbb{R}^+$$\n\n## Supporto\n\n$$(-\\infty, \\infty)$$\n\n## Funzione di densità\n\n$$f(x) = \\frac{\\Gamma\\left( \\frac{\\nu +1}{2} \\right)}{\\sqrt{\\nu \\pi} ; \\Gamma\\left( \\frac{\\nu}{2} \\right)} \\left( 1 + \\frac{x^2}{\\nu} \\right)^{-\\dfrac{\\nu +1}{2}}$$ \n![\\|400](isti-distr-2.png)\n\n## Media\n\n$$\\mu = \\begin{cases}\n0 \u0026\\mbox{se } \\nu \u003e 0\\\\\n\\\\texttt{undefined} \u0026\\mbox{altrimenti}\n\\\\end{cases}$$\n\n## Varianza\n\n$$\\sigma^2 = \\begin{cases}\n\\\\dfrac{\\nu}{\\nu-2} \u0026\\mbox{se } \\nu \u003e 2\\\\\n\\\\infty \u0026\\mbox{se } 1 \\\u003c \\nu \\leq 2\\\\\n\\\\texttt{undefined} \u0026\\mbox{altrimenti}\n\\\\end{cases}$$\n\n## Funzione generatrice dei momenti\n\nINDEFINITA\n\n---\n\n---\n\n# Discrete\n\n# Uniforme\n\n---\n\n# Bernoulli\n\n---\n\n# Geometrica\n\n---\n\n# Ipergeometrica\n\n---\n\n# Binomiale\n\n---\n\n# Multinomiale (multivariata)\n\nLa distribuzione multinomiale è una *generalizzazione* di una binomiale.\n\n## Notazione\n\n$$\\text{Multi}(n,k,(p_1,...,p_k))$$\n\n## Parametri\n\n* **Numero di tentativi** $$n \\in \\mathbb{N}^+$$\n* **Numero di possibili eventi (mutualmente disgiunti)** $$k \\in \\mathbb{N}^+$$\n* **Probabilità dei signoli eventi** $$(p_1,...,p_n) \\in \\left\\[ 0,1 \\right\\]^n : \\sum\\_{i=1}^{n} p_i = 1$$\n\n## Supporto\n\n$$\\bigg{ \\mathbf{X} \\in {0,1,...,n}^k : \\sum\\_{i=1}^{k}X_i = n\\bigg} \\subset \\mathbb{N}^k$$\n\nOsservare che il numero di elementi nel supporto è $$\\binom{n+k-1}{k-1}$$\n\n## Distribuzione\n\n$$P(X_1 =x_1 ,..., X_k = x_k) = \\frac{n!}{x_1! \\cdots x_k!}p_1^{x_1} \\cdots p_k^{x_k}$$\n\n## Media\n\n$$\\mathbb{E}\\left\\[ X_i \\right\\] = np_i$$\n\n## Varianza\n\n$$\\text{Var}(X_i) = np_i(1-p_i)$$\n$$\\text{Cov}(X_i, X_j) = -np_ip_j$$\n\n## Proprietà\n\n1. $$\\text{Multi}(1,2,(p, 1-p)) \\equiv \\text{Bernoulli}(p)$$\n1. $$n \u003e 2 \\implies \\text{Multi}(n,2,(p, 1-p)) \\equiv \\text{Binom}(n, p)$$\n","lastmodified":"2022-08-29T13:39:16.778103453+02:00","tags":null},"/ISTI/Distribuzioni-Multivariate":{"title":"","content":"\n## Joint PMF\n\nSia $(X,Y)$ una *v.a. **discreta bivariata***.\nLa funzione $f\\_{X,Y}: \\mathbb{R}^2 \\to \\mathbb{R}$ definita come\n$$f\\_{X,Y}(x,y) = P(X = x \\cap Y = y)$$\nè detta **joint probability mass function** (**funzione di probabilità congiunta**).\n\nOsservare che per v.a. discrete avremo\n$$P((X,Y) \\in A) = \\sum\\_{(x,y) \\in A}f\\_{X,Y}(x,y)$$\n\nPer esempio per $X,Y \\sim U{1,2,3}$ avremo\n$$P(X = 3, Y \\leq 2) = P((X,Y) \\in {(1,3), (2,3), (3,3)}) = f\\_{X,Y}(1,3) + f\\_{X,Y}(2,3) + f\\_{X,Y}(3,3) = \\frac{1}{3}$$\n\n### Proprietà\n\nSia $g$ una funzione definita su tutti i possibili valori di $(X,Y)$.\nAllora avremo che $g(X,Y)$ sarà anch'essa una v.a. multivariata, con media\n$$\\mathbb{E}\\left\\[ g(X,Y) \\right\\] = \\sum\\_{(x,y) \\in \\text{SUP}(X,Y)}g(x,y)f\\_{X,Y}(x,y)$$\n\n### Esempio\n\nConsideriamo la seguente tabella\n![\\|500](img/isti-01-1.png)\nCalcolare la media della v.a. $g(X,Y) = XY$.\n\n$$\\mathbb{E}\\left\\[ XY \\right\\] = 0 \\cdot \\frac{1}{36} \\cdot \\left\\[ 2 + 4 + 6 + 8 + 10 + 12 \\right\\] + 1 \\cdot \\frac{1}{18} \\cdot \\left\\[ 3 + 5 + 7 + 9 + 11 \\right\\] + 2 \\cdot \\frac{1}{18} \\cdot \\left\\[ 4 + 6 + 8 + 10 \\right\\] + 3 \\cdot \\frac{1}{18} \\cdot \\left\\[ 5 + 7 + 9 \\right\\] + 4 \\cdot \\frac{1}{18} \\cdot \\left\\[ 6 + 8 \\right\\] + 5 \\cdot 7 \\cdot \\frac{1}{18} = 13 \\cdot \\frac{11}{18}$$\n\n## Teorema 4.1.6 - Distribuzioni marginali\n\nSia $(X,Y)$ una v.a. bivariata discreta con *joint pmf* $f\\_{X,Y}(x,y)$.\nAllora le **marginal pmf** (**distribuzioni marginali**) $f_X(x) = P(X = x)$ e $f_Y(y) = P(Y = y)$ sono definite come\n$$f_X(x) = \\sum\\_{y \\in \\mathbb{R}} f\\_{X,Y}(x,y)$$\n$$f_Y(y) = \\sum\\_{x \\in \\mathbb{R}} f\\_{X,Y}(x,y)$$\n\n## Joint PDF\n\nSia $(X,Y)$ una *v.a. **continua bivariata***.\nLa funzione $f\\_{X,Y}: \\mathbb{R}^2 \\to \\mathbb{R}$ è detta **joint probability density function** (**funzione di densità congiunta**) per il vettore aleatorio $(X,Y)$ se per ogni $A \\subseteq \\mathbb{R}^2$ è vero che\n$$P((X,Y) \\in A) = \\iint_A f\\_{X,Y}(x,y) , dx , dy$$\n\n### Proprietà\n\nAnalogamente a prima, sia $g$ una funzione definita su tutti i possibili valori di $\\mathbb{R}^2$.\nAllora avremo che $g(X,Y)$ sarà anch'essa una v.a. multivariata continua, con media\n$$\\mathbb{E}\\left\\[ g(X,Y) \\right\\] = \\iint\\_{\\mathbb{R}^2}g(x,y)f\\_{X,Y}(x,y)$$\n\n## Estensione continua di teorema 4.1.6\n\nSia $(X,Y)$ una v.a. bivariata continua con *joint pdf* $f\\_{X,Y}(x,y)$.\nAllora le **marginal pdf** (**densità marginali**) $f_X(x)$ e $f_Y(y)$ sono definite come\n$$f_X(x) = \\int\\_{-\\infty}^{\\infty} f\\_{X,Y}(x,y) , dy$$\n$$f_Y(y) = \\int\\_{-\\infty}^{\\infty} f\\_{X,Y}(x,y) , dx$$\n\n### Esercizio I\n\nSia la **joint pdf** definita come segue\n$$\nf\\_{X,Y}(x,y) = \\begin{cases}\n6xy^2 \u0026\\text{per } x, y \\in (0,1)\\\\\n0 \u0026\\text{altrimenti}\n\\\\end{cases}\n$$\nLa funzione di porbabilità sarà quindi\n$$\n\\\\int\\_{-\\infty}^{\\infty}\\int\\_{-\\infty}^{\\infty}f(x,y) ,dx,dy =\n\\\\int\\_{0}^{1}\\int\\_{0}^{1}6xy^2 ,dx,dy =\n\\\\int\\_{0}^{1}3x^2y^2 \\Big\\vert_0^1,dy =\n\\\\int\\_{0}^{1}3y^2,dy = y^3 \\Big\\vert_0^1 = 1\n$$\n\nSupponiamo ora di voler calcolare la probabilità $P(X+Y \\geq 1)$.\nSia l'insieme $A := {(x,y): x+y \\geq 1}$.\nPossiamo quindi esprimere la nostra probabilità come $P((X,Y) \\in A)$.\n\nPer caclore ora la nostra probabilità dobbiamo integrare sul piano $A$.\nPerò dato che la *densità* al di fuori del quadrato unitario $(0,1) \\times (0,1)$ è nulla, allora integrare su $A$ equivale ad integrare nell'intersezione tra $A$ è il quarato unitario.\nPerciò\n$$\\begin{align\\*}\nA'\n\u0026= A \\cap \\left\\[(0,1) \\times (0,1) \\right\\]\\\\\n\u0026= { (x,y) : x+y \\geq 1, 0 \\\u003c x \\\u003c 1, 0 \\\u003c y \\\u003c 1 }\\\\\n\u0026= { (x,y) : y \\geq 1 - x, 0 \\\u003c x \\\u003c 1, 0 \\\u003c y \\\u003c 1 }\\\\\n\u0026= { (x,y) : 1 - x \\leq y \\\u003c 1, 0 \\\u003c x \\\u003c 1}\\\\\n\\\\end{align\\*}$$\n\nPerciò avremo che\n$$P(X+Y \\geq 1) = P((X,Y) \\in A') = \\int\\_{0}^{1}\\int\\_{1-x}^{1} 6xy^2 ,dy,dx = \\frac{9}{10}$$\n\n### Esercizio II\n\nSiano $X,Y \\in \\mathbb{R}^+$ v.a. i.i.d. **esponenziali** di parametro 1, ovvero $f(x) = e^{-x}$ e $f(y) = e^{-y}$.\nGrazie all'indipendenza avremo che la loro densità congiunta sarà\n$$f(x,y) = P(X=x, Y=y) = P(X = x)P(Y=y) = f(x)f(y) = e^{-x}e^{-y} = e^{-(x+y)}$$\n\nSia la v.a. $S=X+Y$ con funzione di ripartizione\n$$F_S(t) = P(S \\leq t) = P(X+Y \\leq t)$$\nAvremo quindi\n$$F_S(t) = \\int\\_{0}^{t}\\int\\_{0}^{t-x} f(x,y) ,dy,dx = \\int_0^t -e^{-(x+y)} \\Big\\vert_0^{t-x} ,dx = \\int_0^t e^{-x} - e^{-t} ,dx = -e^{-x} -xe^{-t} \\Big\\vert_0^t = -e^{-t} - te^{-t} + 1$$\n\nDa $F_S(t)$ siamo in grado di calcolare la densità di $S$\n$$f_S(t) = D(F_S(t)) = te^{-t} \\sim \\Gamma(2,1)$$\n\n---\n\n## Indipendenza\n\nSia $(X,Y)$ un v.a. **bivariata** con *densità congiunta* $f(x,y)$.\nAllora $X$ e $Y$ sono **indipendenti** se e solo se esistono due funzioni $g(x)$ e $f(y)$ tali che\n$$f(x,y) = g(x) h(y) ;; \\forall x,y \\in \\mathbb{R}$$\n\n### Proof\n\nCertamente c'è indipendenza allora avremo che $g(x) = f_X(x)$ e $h(y) = f_Y(y)$.\n\nViceversa, supponiamo che $f(x,y) = g(x)h(y)$.\nDefiniamo $$\\int\\_{\\mathbb{R}} g(x) ,dx = c$$ e $$\\int\\_{\\mathbb{R}} h(y) ,dy = d$$ tali che $c,d$ soddisfano\n$$\\begin{align\\*}\ncd\n\u0026= \\left( \\int\\_{\\mathbb{R}} g(x) ,dx \\right) \\left( \\int\\_{\\mathbb{R}} h(y) ,dy \\right)\\\\\n\u0026= \\iint\\_{\\mathbb{R}^2} g(x)h(y) ,dx,dy\\\\\n\u0026= \\iint\\_{\\mathbb{R}^2} f(x,y) ,dx,dy\\\\\n\u0026= 1\n\\\\end{align\\*}$$\nOvvero il loro prodotto deve essere una distribuzione.\n\nCalcoliamo le densità marginali\n$$f_X(x) = \\int\\_{\\mathbb{R}} g(x)h(y) , dy = g(x)d$$\n$$f_Y(y) = \\int\\_{\\mathbb{R}} g(x)h(y) , dx = h(y)c$$\n\nUnendo i due punti precedenti avremo che\n$$f(x,y) = g(x)h(y) = (h(y)c) \\cdot (g(x)d) = f_X(x)f_Y(y) ;;\\square$$\n\n### Esempio\n\nSia $f(x,y) = \\frac{1}{8} x^2 y^4 e^{-y-(x/2)}$ per $x \u003e0$ e $y\u003e0$, altrimenti $f(x,y) = 0$.\nSicuramente $X$ e $Y$ sono indipedenti, infatti $f(x,y) = g(x)h(y)$ con\n$$\ng(x) = \\begin{cases}\nx^2e^{-x/2} \u0026x \u003e 0\\\\\n0 \u0026x \\leq 0\n\\\\end{cases}\n$$\ne\n$$\nh(y) = \\begin{cases}\n\\\\frac{1}{8}y^4e^{-y} \u0026x \u003e 0\\\\\n0 \u0026x \\leq 0\n\\\\end{cases}\n$$\n\n---\n\n## Moment Generating Function\n\nSia $X$ una v.a.\nLa sua **funzione generatrice dei momenti** (**mgf**) è definita come\n$$M_X(t) = \\mathbb{E} \\left\\[ e^{tX} \\right\\]$$\n\n## Teorema - somma mgf\n\nSiano $X$ e $Y$ v.a. **indipendenti** con mgf $M_X(t)$ e $M_Y(t)$.\nAllora la v.a. $Z=X+Y$ avrà mgf\n$$M_Z(t) = \\mathbb{E} \\left\\[ e^{t(X+Y)} \\right\\] = \\mathbb{E} \\left\\[ e^{tX} e^{tY} \\right\\] = \\mathbb{E} \\left\\[ e^{tX} \\right\\]\\\\mathbb{E} \\left\\[ e^{tY} \\right\\] = M_X(t)M_Y(t)$$\n\n## MGF of Normal variable\n\nSia $X \\sim N(\\mu, \\sigma^2)$.\nEssa avrà mgf\n$$M_X(t) = e^{\\mu t + \\frac{1}{2}\\sigma^2t^2}$$\n\n## MGF of sum of normal variables\n\nSiano $X \\sim N(\\mu_1, \\sigma_1^2)$  e $Y \\sim N(\\mu_2, \\sigma_2^2)$.\nLa mgf della v.a. $Z = X+Y$ sarà\n$$M_Z(t) = M_X(t)M_Y(t) = \\exp((\\mu_1+\\mu_2)t + (\\sigma_1^2 + \\sigma_2^2)t^2/2)$$\nOvvero $Z \\sim N(\\mu_1+\\mu_2, \\sigma_1^2+\\sigma_2^2)$.\n\n---\n","lastmodified":"2022-08-29T13:39:16.753388589+02:00","tags":null},"/ISTI/Esercizi/Esercizi-stimatori-consistenti":{"title":"","content":"\n## Esercizio 10.1\n\nSia un [campione](../Random%20Sample.md#random-sample) $X_1, ..., X_n$ di una popolazione con *pdf* $$f(x \\vert \\theta) = \\frac{1}{2}(1+\\theta x)$$ per $x, \\theta \\in (-1, 1)$.\n\nTrovare uno **[stimatore consistente](../Stimatori%20Puntuali.md#consistenza-di-uno-stimatore)** per il parametro $\\theta$.\n\n### Soluzione\n\nIniziamo col calcolare la media della distribuzione $$\\mu = \\mathbb{E}*{\\theta}\\left\\[ X \\right\\] = \\frac{1}{2}\\int*{-1}^{1}x + \\theta x^2 , dx = \\frac{\\theta}{3}$$ e la varianza $$\\sigma^2 = \\text{Var}*{\\theta}(X) = \\mathbb{E}*{\\theta}\\left\\[ X^2 \\right\\] - \\mu^2 = \\frac{1}{2}\\int\\_{-1}^{1} x^2 + \\theta x^3 , dx - \\frac{\\theta^2}{9} = \\frac{3-\\theta^2}{9}$$\n\nConsideriamo ora la **[media campionaria](../Random%20Sample.md#media-campionaria)** $\\overline{X} = \\sum_i X_i/n$.\nRicordiamo dal [Random Sample \u003e Teorema 5 2 6 - Proprietà importanti](../Random%20Sample.md#teorema-5-2-6-proprieta-importanti) che\n\n1. $$\\mathbb{E}\\left\\[ \\overline{X} \\right\\] = \\mu = \\frac{\\theta}{3}$$\n1. $$\\text{Var}(\\overline{X}) = \\frac{\\sigma^2}{n} = \\frac{3-\\theta^2}{9n}$$\n\nPerciò ponendo lo stimatore $\\hat\\theta = 3 \\overline{X}$ avremo che $$\\mathbb{E}\\left\\[ \\hat\\theta \\right\\] = \\mathbb{E}\\left\\[ 3\\overline{X} \\right\\] = \\theta$$ e $$\\text{Var}(\\hat\\theta) = \\text{Var}(3\\overline{X}) = 9 \\cdot \\text{Var}(\\overline{X}) = \\frac{3-\\theta^2}{n}$$ \nOvvero $\\hat\\theta$ è uno stimatore **non distorto** e **asintoticamente efficiente** per $\\theta$.\n\nPer la **[legge dei grandi numeri](../Convergenza.md#teorema-debole-dei-grandi-numeri-weak-lln)** abbiamo che $$1 = \\lim\\_{n \\to \\infty} P(\\vert \\overline{X} - \\mu \\vert \\\u003c \\varepsilon) = \\lim\\_{n \\to \\infty} P(\\vert 3\\overline{X} - 3\\mu \\vert \\\u003c 3\\varepsilon) = \\lim\\_{n \\to \\infty} P(\\vert \\hat\\theta - \\theta \\vert \\\u003c \\varepsilon')$$ per ogni $\\varepsilon \u003e 0$.\nPericò $\\hat\\theta$ è anche uno **stimatore consistente**, ovvero $\\hat\\theta \\xrightarrow{p} \\theta$.\n\nConsideriamo ora uno **[MLE](../Stimatore%20di%20Massima%20Verosimiglianza.md#stimatore-di-massima-verosimiglianza-mle)** $\\hat\\theta\\_{ML}$ per $\\theta$.\nRicordiamo che $$\\hat\\theta\\_{ML} = \\arg \\max\\_{\\theta \\in (-1,1)} \\ln{L(\\theta \\vert \\mathbf{x})}$$ con $$\\ln{L(\\theta \\vert \\mathbf{x})} = -n\\ln2 + \\sum\\_{i=1}^{n}\\ln{(1 + \\theta x_i)}$$\n\nRicordiamo inoltre che $\\hat\\theta\\_{ML}$ è uno dei punti in cui la [score funcion](../Stimatore%20di%20Massima%20Verosimiglianza.md#03be6d) si annulla $$S(\\hat\\theta \\vert \\mathbf{x}) = \\sum\\_{i=1}^{n} \\frac{d}{d\\theta}\\ln{(1 + \\theta x_i)} = \\sum\\_{i=1}^{n} \\frac{x_i}{1 + \\theta x_i} = 0$$\nCalcolare il reale punto di massima può risultare complesso, possiamo però calcolare la **varianza asintotica** grazie alle [proprietà asintotiche di un MLE](../Stimatore%20di%20Massima%20Verosimiglianza.md#proprieta-asintotiche-molto-importanti) $$\\lim\\_{n \\to \\infty} \\text{Var}(\\hat\\theta\\_{ML}) = \\frac{1}{I(\\theta)}$$ con $$\\begin{align\\*}\nI(\\theta)\n\u0026= \\mathbb{E}*{\\theta}\\left\\[ \\left( \\frac{d}{d \\theta} \\ln{f(X \\vert \\theta)} \\right)^2 \\right\\]\\\\\n\u0026= \\mathbb{E}*{\\theta}\\left\\[ \\left( \\frac{X}{1 + \\theta X}\\right)^2 \\right\\]\\\\\n\u0026= \\int\\_{-1}^{1}\\frac{x^2}{(1+ \\theta x)^2} \\cdot \\frac{1}{2}(1+ \\theta x) , dx\\\\\n\u0026= \\frac{1}{2}\\int\\_{-1}^{1}\\frac{x^2}{1+ \\theta x} , dx\\\\\n\u0026= \\frac{1}{2\\theta^3}\\log{\\frac{1+\\theta}{1-\\theta}} - \\frac{1}{\\theta^2}\n\\\\end{align\\*}$$\n","lastmodified":"2022-08-29T13:39:16.74819474+02:00","tags":null},"/ISTI/Hypothesis-Testing":{"title":"","content":"\n# Hypothesis Testing\n\nA fronte di un [campionamento](Random%20Sample.md#random-sample) $\\mathbf{X}$ da una popolazione $f(\\mathbf{X} \\vert \\theta)$, un **test d'ipotesi** cerca di **decidere** se il campionamento $\\mathbf{X}$ è compatibile rispetto ad una data **ipotesi** riguardante il parametro **sconosciuto** $\\theta$.\n\nDato che $\\theta$ appartiene ad uno *spazio di parametri* $\\Theta$, un'ipotesi è semplicemente un'asserzione del tipo $$\\theta \\in \\Theta_0 \\subset \\Theta$$ detta anche **ipotesi nulla** e segnata con $H_0$. ^137feb\n\nRifiutare l'ipotesi nulla equivale semplicemente nell'accettare il suo complemento, chiameremo **ipotesi alternativa** e la indicheremo con $H_A$ o $H_1$, e sono del tipo $$\\theta \\in \\Theta_0^c \\equiv \\Theta \\setminus \\Theta_0$$ ^7a2fae\n\nUn test d'ipotesi è quindi semplicemente una **regola** che, per ogni possibile campione $\\mathbf{X}$, ci dice se **rifiutare o no** l'ipotesi nulla $H_0$. ^349ec3\n\n \u003e \n \u003e **Esempio**\n \u003e Prendiamo un campione $X_1,...,X_n$ di una popolazione $N(\\theta, \\sigma^2)$, con $\\theta$ sconosciuto.\n \u003e Consideriamo una ipotesi $$H_0: \\theta \\leq 17$$\n \u003e Un test famoso consiste nel \u003cu\u003erifutare\u003c/u\u003e $H_0$ se e solo se $\\overline{X} \u003e 17 + \\sigma/\\sqrt{n}$.\n\nIl sottoinsieme $C$ dei dati che portano al **rifuto** di $H_0$ è detta **regione critica**. ^6568cf\n\n \u003e \n \u003e Nell'esempio precedente, la regione critca equivale al sottoinsieme di $\\mathbb{R}^n$ di tutti quei $n$-uple $\\mathbf{x}$ tali che $$\\frac{1}{n}\\sum\\_{i=1}^{n}x_i \u003e 17 + \\frac{\\sigma}{\\sqrt{n}}$$\n\nLa probabilità quindi che $H_0$ sia rifiutata equivale quindi alla probabilità di campionare all'interno della regione critica, e tale probabilità è nota come **funzione critica** $$\\psi(\\mathbf{X}) = P(\\text{rifiuto } H_0) = P(\\mathbf{X} \\in C)$$\n\nPuò capitare che un test dia un risultato errato.\nBisogna distinguere gli errori di un test di ipotesi, perché spesso nella realtà i diversi tipi di errori hanno gravità differenti.\nPer esempio, dire a una persona malata che in realtà è in salute è un errore molto più grave del dire a una persona in salute che in realtà ha una malattia.\nDistinguiamo quindi:\n\n* **Errore di I tipo**: rifiutare $H_0$ quando in realtà $H_0$ è vera. In termini di eventi avremo $$\\mathbf{X} \\in C ;\\vert; \\theta \\in \\Theta_0$$ ^361948\n* **Errore di II tipo**: accettare $H_0$ quando in realtà $H_0$ è falsa. In termini di eventi avremo $$\\mathbf{X} \\in C^c ;\\vert; \\theta \\in \\Theta^c_0$$ ^f0afe5\n\n![\\|600](isti_test_ipotesi_errors.png)\n\nPer comodità, indicheremo\n$$\\alpha = P(\\mathbf{X} \\in C ;\\vert; \\theta \\in \\Theta_0)$$\n$$\\beta = P(\\mathbf{X} \\in C^c ;\\vert; \\theta \\in \\Theta^c_0)$$\n\nOsserviamo che possiamo sempre ricondurre un errore di tipo II ad un errore di tipo I e viceversa, semplicemente esprimendolo in funzione dell'*ipotesi alternativa*.\nInfatti dire *\"accettare $H_0$ quando in realtà $H_0$ è falsa\"* equivale a dire *\"rifiutare $H_1$ quando in realtà $H_1$ è vera\"*.\n\nPerciò, convenzionalmente, si sceglie sempre qual è l'errore più grave e lo si esprime sempre come errore di tipo I, utilizzando opportunamente $H_0$ o $H_1$.\n\n## Potenza di un Test\n\nDato un test, definiamo la **potenza del test** come la probabilità di rifiutare l'*ipotesi nulla* in funzione del parametro $\\theta$.\n$$\\beta(\\theta) = P(\\mathbf{X} \\in C \\vert \\theta)$$\nAlcune volte ci si riferisce alla potenza di un test con $\\Pi(\\theta)$.\n\n \u003e \n \u003e **Esempio - Bernoulli trials**\n \u003e Supponiamo di aver lanciato una moneta per $10$ volte, e vogliamo sapere se è equilibrata $p=1/2$ oppure no.\n \u003e Per esempio un test può essere quello di accettare o rifiutare l'ipotesi nulla $$H_0: p = \\frac{1}{2}$$\n \u003e Consideriamo un test banale, per esempio il test che rifiuta $H_0$ se si ottengono *nessuna* oppure *tutte* teste, ovvero $$\\text{rifiuto } H_0 \\iff \\sum\\_{i=1}^{10}X_i \\in {0, 10}$$\n \u003e Avremo quindi che la potenza di questo test sarà $$\\beta(p) = (1-p)^{10} + p^{10}$$\n \u003e ![\\|500](isti_test_ipotesi_1.png)\n\n \u003e \n \u003e **Esempio - Normale**\n \u003e Consideriamo ancora una volta un [densità normale](Distribuzioni.md#normale) del tipo $$f(x \\vert \\theta) = N(\\theta, 25)$$ con \u003cu\u003emedia ignota\u003c/u\u003e.\n \u003e Sia l'*ipotesi nulla* $$H_0: \\theta \\leq 17$$ e il test $$\\text{rifiuto } H_0 \\iff \\overline{X}\\_n \u003e 17 + \\frac{5}{\\sqrt{n}}$$\n \u003e Tale test avrà potenza $$\\beta(\\theta) = P(\\overline{X}\\_n \u003e 17 + 5/\\sqrt{n})$$\n \u003e Sappiamo anche che $\\overline{X}\\_n \\sim N(\\theta, 25/n)$.\n \u003e Perciò, normalizzando opportunamente, avremo che $$\\begin{align\\*}\n \u003e \\\\beta(\\theta)\n \u003e \u0026= P(\\overline{X}\\_n \u003e 17 + 5/\\sqrt{n})\\\\\n \u003e \u0026= 1 - P(\\overline{X}\\_n \\leq 17 + 5/\\sqrt{n})\\\\\n \u003e \u0026= 1 - P\\bigg(\\underbrace{\\frac{\\overline{X}*n -\\theta}{5/\\sqrt{n}}}*{\\sim N(0,1)} \\leq \\frac{17 + 5/\\sqrt{n} - \\theta}{5/\\sqrt{n}}\\bigg)\\\\\n \u003e \\\\\n \u003e \u0026= 1 - \\Phi\\left(\\frac{17 + 5/\\sqrt{n} - \\theta}{5/\\sqrt{n}}\\right)\n \u003e \\\\end{align\\*}$$\n \u003e Ricordiamo che $\\Phi(x)$ è la **funzione di ripartizione** di un [Normale Standard](Distribuzioni.md#normale-standard).\n \u003e \n \u003e Osserviamo cosa accade alla potenza del test con un dato $n$ fissato\n \u003e ![\\|500](isti_test_ipotesi_2.png)\n \u003e \n \u003e Supponiamo che il valore reale di $\\theta$, chiamiamolo $\\theta^*$, sia $\\theta^* = 15$.\n \u003e Al crescere di $n$ avremo che $\\beta(\\theta^\\*) = \\beta(15) \\to 0$ tenderà a $0$.\n \u003e Il che è giusto, in quanto $\\beta$ equivale alla probabilità di incorrere in un errore di tipo I, ovvero di rifiutare $H_0$ sapendo che in realtà $H_0$ è corretta.\n \u003e ![\\|500](isti_test_ipotesi_4.png) \n \u003e \n \u003e Simmetricamente avremo che se $\\theta^\\* = 19$ avremo che la probabilità di rifiutare $H_0$, ovvero la potenza $\\beta(\\theta^*)$ tende a $1$.\n \u003e E ciò è corretto perché $\\theta^* \u003e 17$.\n \u003e \n \u003e La regione invece più incerta è qulla intermedia attorno a $17$.\n \u003e Ovviamente, la funzione ideale sarebbe qulla \"*a gradini*\" che assume $0$ per valori $\\theta \\leq 17$ e $1$ per $\\theta \u003e 17$.\n \u003e Osserivamo però, che al crescere del numero di campioni $n$, la funzione potenza $\\beta(\\theta)$ tende sempre di più ad approssimare la funsione ideale\n \u003e ![\\|500](isti_test_ipotesi_3.png)\n\n## Ampiezza di un test\n\nDa prima abbiamo visto che la **potenza di un test** è una funzione che calcola la probabilità di *rifiutare* $H_0$ al variare del parametro incognito $\\theta$.\n\nConsideriamo un'ipotesi nulla generica, del tipo $$H_0 : \\theta \\in \\Theta_0$$ e un test $T$ che indica qunado rifiutare $H_0$.\n\nAllora averemo che l'**ampiezza** del test $T$ è la quantità definita come $$\\sup\\_{\\theta \\in \\Theta_0} \\beta(\\theta)$$ ovvero la probabilità pià alta che abbiamo di commettere un **[errore di I tipo](Hypothesis%20Testing.md#361948)**.\n\nPerciò, più è piccola l'ampiezza di un test, più è *qualitativamente* migliore.\n\n### Osservazione\n\nOsservare che quando siamo in un contesto con **ipotesi semplici** del tipo $$H_0: \\theta = \\theta_0$$ avremo che spazio dei parametri che soddisfano $H_0$ è composto da un solo elemento $$\\Theta_0 = { \\theta_0}$$\nPerciò avremo che l'ampiezza del test corrisponde alla potenza calcolata in $\\theta_0$\n$$\\sup\\_{\\theta \\in \\Theta_0} \\beta(\\theta) = \\beta(\\theta_0)$$\n","lastmodified":"2022-08-29T13:39:16.754459696+02:00","tags":null},"/ISTI/I-test-migliori":{"title":"","content":"\nAbbiamo visto che ci sono svariati modi di definire un test.\nQuello che ci si può chiedere è se dobbiamo necessariamente ogni volta ricavarci un test definendo una statistica opportuna (vedi per esempio [z-test](Test%20pi%C3%B9%20comuni.md#z-test) o [t-test](Test%20pi%C3%B9%20comuni.md#t-test-di-student)), oppure se esiste una famiglia di test \"**migliore**\" a livello qualitativo rispetto agli altri.\n\n## Test \"più potente\"\n\nAbbiamo visto che l'[ampiezza](Hypothesis%20Testing.md#ampiezza-di-un-test) di un test è una sorta di *misura* della sua qualità.\n\nUn **test più potente** di ampiezza $\\alpha$ è un test $T^\\*$ per le ipotesi $$H_0: \\theta = \\theta_0; ; H_1: \\theta = \\theta_1$$ tale che\n\n1. la [potenza](Hypothesis%20Testing.md#potenza-di-un-test) del test $T^*$ calcolata in $\\theta_0$ è pari ad $\\alpha$ $$\\beta\\_{T^*}(\\theta_0) = \\alpha$$\n   Osserviamo che dato che siamo un contesto con ipotesi **semplici**, allora avremo che $\\Theta_0 = {\\theta_0}$, perciò dire che $T^\\*$ ha potenza $\\alpha$ equivale a dire che ha anche [ampiezza](Hypothesis%20Testing.md#ampiezza-di-un-test) $\\alpha$ ([vedi](Hypothesis%20Testing.md#osservazione)). Stiamo quindi **fissando** ad $\\alpha$ l'errore di primo tipo.\n1. Per ogni altro test $T$ di ampiezza $\\leq \\alpha$ allora deve valere che $$\\beta\\_{T^\\*}(\\theta_1) \\geq \\beta\\_{T}(\\theta_1)$$ ovvero la probabilità di commettere un [errore di II tipo](Hypothesis%20Testing.md#f0afe5) è più alta.\n\n## Test del Rapporto di Verosimiglianza Semplice - simple LRT\n\nIl **test del Rapporto di Verosimiglianza Semplice** funziona nel caso particolare in cui abbiamo **ipotesi semplici**, del tipo $$H_0: \\theta = \\theta_0$$\n$$H_1: \\theta = \\theta_1$$\n\nTale test consiste nel **rifiutare** $H_0$ se la [statitisca](Random%20Sample.md#46a026) $$\\lambda = \\frac{L(\\theta_0 | X_1,...,X_n)}{L(\\theta_1 | X_1,...,X_n)}$$ (ovvero il rapporto tra le [funzioni di verosimiglianza](Verosimiglianza.md#likelihood-function) calcolati in $\\theta_0$ e $\\theta_1$) è **minore** di un certo valore $k$ **fissato** in modo tale da ottenere l'[ampiezza](Hypothesis%20Testing.md#ampiezza-di-un-test) desiderata. \n$$\\text{rifiuto } H_0 \\iff \\lambda \\\u003c k$$ ^224e66\n\nSi può dimostrare che (sempre nel caso di **ipotesi semplici**) il test del rapporto di verosimiglianza semplice è **più potente**.\n\n## Teorema *(Lemma di Neyman-Pearson)*\n\nSia un [campione](Random%20Sample.md#random-sample) $X_1, ..., X_n$ da una popolazione $f_X(\\cdot \\vert \\theta)$, ovvero dipendente da un parametro $\\theta$ **ignoto**.\nPoniamoci in uno spazio dei parametri con soli due elementi $$\\Theta = {\\theta_0, \\theta_1}$$\nPerciò avremo solo due possibili ipotesi \u003cu\u003esemplici\u003c/u\u003e $$H_0: \\theta = \\theta_0; ; H_1: \\theta = \\theta_1$$\nSiano $k^\\* \u003e0$ e la [regione critica](Hypothesis%20Testing.md#6568cf) $C^\\* \\in \\mathbb{R}^n$ tali che:\n\n1. la [potenza](Hypothesis%20Testing.md#potenza-di-un-test) (e quindi anche l'[ampiezza](Hypothesis%20Testing.md#ampiezza-di-un-test) perché siamo nel contesto semplice) del test è $\\alpha$ $$\\beta(\\theta_0) = P((X_1, ..., X_n) \\in C^\\* \\vert \\theta = \\theta_0) = \\alpha$$\n1. considerando il [rapporto di verosimiglianza semplice](I%20test%20\"migliori\".md#224e66) $\\lambda$ avremo che $$\\begin{cases}\\lambda \\leq k^\\* \u0026\\text{se } (X_1,..., X_n) \\in C^*\\\\ \\lambda \u003e k^* \u0026\\text{se } (X_1, ..., X_n) \\not\\in C^*\\\\end{cases}$$\n   Osserviamo che $k^*$ è totalmente definito da $\\lambda$ e $C^\\*$.\n\nSotto le ipotesi del teorema, avremo che il test $T^*$ con regione critica $C^*$ è un **test più potente di ampiezza** $\\alpha$ per le ipotesi semplici $H_0, H_1$.\n\n### Esempio - Esponenziale\n\nSia un campione [esponenziale](Distribuzioni.md#esponenziale) $X_1, ..., X_n$ di parametro $\\theta$ sconosciuto.\n\nSiano le ipotesi \u003cu\u003esemplici\u003c/u\u003e $$H_0: \\theta = \\theta_0; ; H_1: \\theta = \\theta_1$$\n\nCalcoliamo il rapporto di verosimiglianza semplice $$\\lambda = \\frac{\\theta_0^n \\cdot e^{-\\theta_0 \\sum_i x_i}}{\\theta_1^n \\cdot e^{-\\theta_1 \\sum_i x_i} } = \\left(\\frac{\\theta_0}{\\theta_1}\\right)^n e^{(\\theta_1 - \\theta_0)\\sum_i x_i}$$\nAvremo che $$\\lambda \\leq k^\\* \\iff \\ln{\\lambda} \\leq \\ln{k^*} \\iff \\sum\\_{i=1}^{n}x_i \\leq \\frac{1}{(\\theta_1 - \\theta_0)}\\ln{\\left( \\left(\\frac{\\theta_1}{\\theta_0}\\right)^n k^*\\\\right)} = k'$$\nRicavando $k'$ si può in maniera molto semplice ricavare anche $k^\\*$.\n\nPerciò il test $$\\text{rifiuto } H_0 \\iff X_1 + ... + X_n \\leq k'$$ è un **test più potente di ampiezza** $\\alpha$.\n\nVediamo ora come ricavare $k'$ in funzione di $\\alpha$.\nOsserviamo che $$\\alpha = \\beta(\\theta_0) = P\\_{\\theta_0}(X_1 + ... + X_n \\leq k') = F\\_{X_1 + ... + K_n}(k')$$\nRicordiamo che la somma di $n$ v.a. esponenziali i.i.d. è una [gamma](Distribuzioni.md#gamma) $\\Gamma(n, 1/\\theta)$.\nPerciò avremo che $$\\alpha = \\beta(\\theta_0) = \\int\\_{0}^{k'} \\frac{\\theta_0^n}{\\Gamma(n)} x^{n-1}e^{\\theta_0 x} , dx$$ ovvero $\\alpha$ è un equazione in $k'$.\n\nFissando quindi $\\alpha$ possiamo quindi ricavarci il $k'$, e di conseguenza il valore di $k^\\*$.\n\n---\n\n## Test del Rapporto di Verosimiglianza (generalizzato) - LRT\n\nConsideriamo ora il caso più generale di ipotesi del tipo $$H_0: \\theta \\in \\Theta_0$$ e $$H_1: \\theta \\in \\Theta \\setminus \\Theta_0$$\n\nIl **rapporto di verosimiglianza generalizzato** è la quantità $$\\lambda_n = \\frac{\\sup\\_{\\theta \\in \\Theta_0} L(\\theta \\vert X_1, ..., X_n)}{\\sup\\_{\\theta \\in \\Theta} L(\\theta \\vert X_1, ..., X_n)}$$ ovvero il rapporto del superiore della verosimiglianza per $\\theta \\in \\Theta_0$ (ovvero nell'ipotesi nulla) e il superiore di \u003cu\u003etutti\u003c/u\u003e i valori possibili di $\\theta$.\n\n````ad-important\ntitle: Osservazione importante!\nOsservare che il valore di $\\theta$ che massimizza il denominatore di $\\lambda_n$ equivale al [[Stimatore di Massima Verosimiglianza#Stimatore di Massima Verosimiglianza - MLE|MLE]] $\\hat\\theta_{ML}$.\n\n````\n\nIl **test del rapporto di verosimiglianza (generalizzato)** (o **LRT**) è definito come $$\\text{rifiuto } H_0 \\iff\\lambda_n \\leq k^*$$ dove $k^*$ è definito dall'[ampiezza](Hypothesis%20Testing.md#ampiezza-di-un-test) $\\alpha$ del test (come prima).\n\nOssevare che dato che la [funzione di verosimiglianza](Verosimiglianza.md#likelihood-function) dipende da delle distribuzioni, allora avremo che anche $\\lambda_n$ seguirà una distribuzione in fuzione dei dati $X_1, ..., X_n$.\nCi riferiremo alla distribuzione di $\\lambda_n$ con $$\\Lambda_n(X_1, ..., X_n)$$\nIn genere non è sempre facile studiare $\\lambda_n$ però esistono dei risultati asintotici sulla distribuzione $\\Lambda_n$ che si possono sfruttare.\nSi può infatti dimostrare che $$-2\\log{\\Lambda_n} \\sim \\chi^2$$ per $n$ grande (ma *\"non troppo\"*).\n\nPericò, fissando un **quantile** $\\phi\\_{1-\\alpha}$ della $\\chi^2$, possiamo definire il test $$\\text{rifiuto } H_0 \\iff -2\\log{\\lambda_n} \u003e \\phi\\_{1-\\alpha}$$ dove $\\alpha$ è l'ampiezza del test.\n\n### Esempio - Normal LRT\n\nSia un campione [normale](Distribuzioni.md#normale) $X_1, ..., X_n$ da una popolazione $N(\\theta, 1)$\nConsideriamo le ipotesi $$H_0: \\theta = \\theta_0; ; H_1: \\theta \\neq \\theta_0$$\nAvremo quindi $\\Theta_0 \\equiv {\\theta_0}$ e $\\Theta_1 \\equiv \\Theta \\setminus {\\theta_0}$.\n\nCalcoliamo il **rapporto di verosimiglianza generalizzato** $$\\lambda_n = \\frac{\\sup\\_{\\theta \\in \\Theta_0} L(\\theta \\vert X_1, ..., X_n)}{\\sup\\_{\\theta \\in \\Theta} L(\\theta \\vert X_1, ..., X_n)}$$\n\nOsserviamo che essendo $\\theta_0$ l'\u003cu\u003eunico\u003c/u\u003e elemento di $\\Theta_0$ avremo come numeratore $L(\\theta_0 \\vert X_1, ..., X_n)$.\nInvece al denominatore avremo che il $\\theta$ che lo massimizza è il [MLE](Stimatore%20di%20Massima%20Verosimiglianza.md#stimatore-di-massima-verosimiglianza-mle) $\\hat\\theta\\_{ML}$ di una normale.\nSappiamo da [Stimatore di Massima Verosimiglianza \u003e Esempio - Normale](Stimatore%20di%20Massima%20Verosimiglianza.md#esempio-normale) che lo stimatore di ML di una normale è la sua [media campionaria](Random%20Sample.md#media-campionaria) $$\\hat\\theta\\_{ML} = \\overline{X}$$\nPerciò avremo che\n$$\\begin{align\\*}\n\\\\lambda_n\n\u0026= \\frac{L(\\theta_0 \\vert X_1,..., X_n)}{L(\\overline{X} \\vert X_1, ..., X_n)}\\\\\n\u0026= \\frac{(2\\pi)^{-n/2}\\exp\\left\\[ -\\sum\\_{i=1}^{n}(x_i - \\theta_0)^2/2 \\right\\]}{(2\\pi)^{-n/2}\\exp\\left\\[ -\\sum\\_{i=1}^{n}(x_i - \\overline{x})^2/2 \\right\\]}\\\\\n\u0026= \\exp\\left\\[ \\frac{1}{2}\\left( \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 -\\sum\\_{i=1}^{n}(x_i - \\theta_0)^2\\right) \\right\\]\n\\\\end{align\\*}$$\n\nSemplifichiamo ora\n$$\\begin{align\\*}\n\\\\sum\\_{i=1}^{n}(x_i - \\theta_0)^2\n\u0026= \\sum\\_{i=1}^{n}((x_i - \\overline{x})  + (\\overline{x} - \\theta_0))^2\\\\\n\u0026= \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 + 2(\\overline{x}-\\theta_0)\\sum\\_{i=1}^{n}(x_i - \\overline{x}) + \\sum\\_{i=1}^{n}(\\overline{x} - \\theta_0)^2\\\\\n\u0026= \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 + 2(\\overline{x}-\\theta_0)(\\underbrace{(x_1 + ... + x_n)}*{n\\overline{x}} - n\\overline{x}) + n(\\overline{x} - \\theta_0)^2\\\\\n\u0026= \\sum*{i=1}^{n}(x_i - \\overline{x})^2 + n(\\overline{x} - \\theta_0)^2\n\\\\end{align\\*}$$\n\nPerciò $$\\lambda_n = \\exp\\left\\[ -\\frac{1}{2}n(\\overline{x} - \\theta_0)^2 \\right\\]$$\n\nDefiniamo quindi la [regione critica](Hypothesis%20Testing.md#6568cf) $$C \\equiv {\\mathbf{x} \\in \\mathbb{R}^n : \\lambda_n \\leq k} \\equiv \\Bigg{\\mathbf{x} \\in \\mathbb{R}^n : \\vert \\overline{x} - \\theta_0 \\vert \\geq  \\sqrt{-2\\frac{\\log{k}}{n}} \\Bigg}$$\nDato che $0 \\\u003c k \\leq 1$ avremo che $\\log{k} \\leq 0$, perciò l'*argomento* della radice sarà positivo (ottenendo un valore reale a destra della disuguaglianza).\n","lastmodified":"2022-08-29T13:39:16.772612493+02:00","tags":null},"/ISTI/Informazione-di-Fisher":{"title":"","content":"\n# Informazione di Fisher\n\nSia $\\mathbf{X}$ un [campione aleatorio](Random%20Sample.md#random-sample) dipendente da un parametro (sconosciuto) $\\theta$.\nL'**informazione di Fisher** è una funzione definita in due modi\n\n1. $$I(\\theta) = \\mathbb{E}*\\\\theta \\left\\[ \\left(\\frac{\\partial}{\\partial \\theta}\\ln{f(\\mathbf{X} \\vert \\theta)} \\right)^2 \\right\\] = \\mathbb{E}*\\\\theta \\left\\[ \\left(\\frac{\\partial}{\\partial \\theta}\\ln{L(\\theta \\vert \\mathbf{X})} \\right)^2 \\right\\]$$\n1. $$I(\\theta) = -\\mathbb{E}*\\\\theta \\left\\[ \\frac{\\partial^2}{\\partial \\theta^2}\\ln{f(\\mathbf{X} \\vert \\theta)} \\right\\] = -\\mathbb{E}*\\\\theta \\left\\[ \\frac{\\partial^2}{\\partial \\theta^2}\\ln{L(\\theta \\vert \\mathbf{X})} \\right\\]$$\n\n## Esempio - Campione esponenziale\n\nSia $\\mathbf{X}$ un [campione](Random%20Sample.md#random-sample) [esponenziale](Distribuzioni.md#esponenziale) di parametro $\\lambda$.\nLa [verosimiglianza](Verosimiglianza.md#likelihood-function) risulta quindi essere $$L(\\lambda \\vert \\mathbf{x}) = f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\theta) = \\prod\\_{i=1}^{n}\\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda\\sum_i x_i}$$\nIl suo logaritmo risulta invece $$\\ln{L(\\lambda \\vert \\mathbf{x})} = -\\lambda\\sum\\_{i=1}^{n}x_i + n\\ln{\\lambda}$$ con derivate\n$$\\begin{align\\*}\n\\\\frac{d}{d\\lambda} \\ln{L(\\lambda \\vert \\mathbf{x})} \u0026= \\frac{n}{\\lambda} - \\sum\\_{i=1}^{n}x_i\\\\\n\\\\frac{d^2}{d\\lambda^2} \\ln{L(\\lambda \\vert \\mathbf{x})} \u0026= -\\frac{n}{\\lambda^2}\\\\\n\\\\end{align\\*}$$\n\nPerciò (dato che la derivata seconda non dipende più dal campione $\\mathbf{X}$) l'informazione di Fisher sarà $$I(\\lambda) = \\frac{n}{\\lambda^2}$$\n\n# Proprietà\n\n## Adattività\n\nL'informazione di Fisher è **adattiva** rispetto a due campioni $\\mathbf{X}, \\mathbf{Y}$ **indipendenti**.\n$$I\\_{\\mathbf{X}, \\mathbf{Y}}(\\theta) = I\\_{\\mathbf{X}}(\\theta) + I\\_{\\mathbf{Y}}(\\theta)$$\n\nNe segue quindi che l'informazione di un campione $X_1, ..., X_n$ di v.a. **i.i.d.** è pari a $n$ volte l'informazione di Fisher di un generico $X_i$.\n$$I\\_{X_1, ..., X_n}(\\theta) = n \\cdot I\\_{X_1}(\\theta)$$\n\n## Implicazioni sulla Sufficienza di una statistica\n\nRichiamando il [Teorema di Fattorizzazione](Statistiche%20Sufficienti.md#teorema-di-fattorizzazione) avremo che data una **statistica sufficiente** $T$ per un parametro $\\theta$\n$$\\begin{align\\*}\n\\\\frac{\\partial}{\\partial \\theta}\\ln{L(\\theta \\vert \\mathbf{X})}\n\u0026= \\frac{\\partial}{\\partial \\theta}\\ln{f(\\mathbf{X} \\vert \\theta)}\\\\\n\u0026= \\frac{\\partial}{\\partial \\theta}\\ln{(g(T(\\mathbf{X}) \\vert \\theta) \\cdot h(\\mathbf{X}))}\\\\\n\u0026= \\frac{\\partial}{\\partial \\theta}\\ln{g(T(\\mathbf{X}) \\vert \\theta)}\\\\\n\u0026= \\frac{\\partial}{\\partial \\theta}\\ln{L(\\theta \\vert T(\\mathbf{X}))}\n\\\\end{align\\*}$$\n\nPerciò per statistiche sufficienti $T$ si ha che $$I\\_{\\mathbf{X}}(\\theta) = I\\_{T(\\mathbf{X})}(\\theta)$$\n\nInvece per statistiche $T$ *in generale* vale che $$I\\_{\\mathbf{X}}(\\theta) \\geq I\\_{T(\\mathbf{X})}(\\theta)$$\n\n## Implicazioni sulla Efficienza di una statistica\n\nLa [disuguaglianza di Cramér-Rao](Cram%C3%A9r-Rao%20Inequality.md) stabilisce una correlazione tra **informazione di Fisher** e **varianza di uno stimatore non distorto**.\nPiù precisamente ricordiamo che dato uno stimatore non distorto $\\hat{\\theta}$ del parametro $\\theta$ vale che $$\\text{Var}(\\hat{\\theta}) \\geq \\frac{1}{I(\\theta)}$$\n\n---\n\n## Esempio - Bernoulliane\n\nSia il [campione](Random%20Sample.md#random-sample) $X_1, ..., X_n$ di $\\text{Bernoulli}(\\theta)$, con [probabilità congiunta](Distribuzioni%20Multivariate.md#joint-pmf)\n$$f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\theta) = \\prod\\_{i=1}^{n}\\theta^{x_i}(1-\\theta)^{1 - x_i} = \\theta^s(1-\\theta)^{n-s}$$ dove $s = \\sum_i x_i$.\n\nPer [adattività](Informazione%20di%20Fisher.md#adattivita) avremo che\n$$\\begin{align\\*}\nI\\_{\\mathbf{X}}(\\theta)\n\u0026= n \\cdot I\\_{X_1}(\\theta)\\\\\n\u0026= -n \\cdot \\mathbb{E}*{\\theta}\\left\\[ \\frac{\\partial^2}{\\partial \\theta^2}\\ln{L(\\theta \\vert X_1)} \\right\\]\\\\\n\u0026= -n \\cdot \\mathbb{E}*{\\theta}\\left\\[ \\frac{\\partial^2}{\\partial \\theta^2}\\ln{\\left( \\theta^{X_1}(1-\\theta)^{1-X_1} \\right)} \\right\\]\\\\\n\u0026= -n \\cdot \\mathbb{E}\\_{\\theta}\\left\\[ -\\frac{X_1}{\\theta^2} - \\frac{(1-X_1)}{(1 - \\theta)^2} \\right\\]\\\\\n\u0026= -n\\cdot \\left( - \\frac{1}{\\theta} - \\frac{1}{1-\\theta} \\right)\\\\\n\u0026= n \\cdot \\frac{1}{\\theta(1-\\theta)}\n\\\\end{align\\*}$$\n","lastmodified":"2022-08-29T13:39:16.825575362+02:00","tags":null},"/ISTI/Metodo-dei-Momenti":{"title":"","content":"\n# Metodo dei Momenti\n\nSia il [campione](Random%20Sample.md#random-sample) $X_1, ..., X_n$ di una popolazione con *pdf* o *pmf* $f(x \\vert \\theta_1, ..., \\theta_k)$, ovvero dipendente da certi parametri (sconosciuti) $\\theta_1, ..., \\theta_k$.\n\nIl **metodo dei momenti** consente nell'eguagliare i primi $k$ momenti con i primi $k$ **momenti campionari**.\n\nIl **momento campionario** $j$-esimo di un campione $X_1, ..., X_n$ è definito come $$M_j = \\frac{1}{n}\\sum\\_{i=1}^{n}X_i^j$$\n\nDato che invece il momento (semplice) $j$-esimo $\\mu_j$ dipende dai parametri $(\\theta_1, ..., \\theta_k)$, scriveremo $$\\mu_j = \\mu_j(\\theta_1, ...,\\theta_k) = \\mathbb{E}\\_{\\theta_1, ..., \\theta_k} \\left\\[ X^j \\right\\]$$\n\nOtterremo così un sistema di $k$ equazioni a $k$ incognite\n$$\\begin{cases}\n\\\\mu_1(\\theta_1, ..., \\theta_k) \u0026= m_1\\\\\n\\\\mu_2(\\theta_1, ..., \\theta_k) \u0026= m_2\\\\\n\u0026\\vdots\\\\\n\\\\mu_k(\\theta_1, ..., \\theta_k) \u0026= m_k\\\\\n\\\\end{cases}$$\n\nRisolvendo questo sistema (se possibile) troveremo una prima stima $(\\hat{\\theta}\\_1, ..., \\hat{\\theta}\\_k)$ dei parametri $(\\theta_1, ..., \\theta_k)$.\n\n## Esempio - Normale\n\nSia un *campione normale* $X_1, ..., X_n$ iid in $N(\\mu, \\sigma^2)$, con $\\mu, \\sigma^2$ i parametri sconosciuti.\n\nPoniamo quindi $(\\theta_1, \\theta_2) = (\\mu, \\sigma^2)$, e applichiamo il metodo dei momenti per $k=2$.\n\nAvremo quindi\n$$\\begin{align\\*}\n\\\\mu_1 = \\mathbb{E}\\left\\[ X_i \\right\\] = \\mu, \u0026\u0026M_1 = \\frac{1}{n}\\sum\\_{i=1}^{n}X_i = \\overline{X}\\\\\n\\\\mu_2 = \\mathbb{E}\\left\\[ X_i \\right\\] = \\mu^2 + \\sigma^2, \u0026\u0026M_2 = \\frac{1}{n}\\sum\\_{i=1}^{n}X_i^2\n\\\\end{align\\*}$$\nPerciò avremo\n$$\\begin{cases}\n\\\\theta_1 = \\overline{X}\\\\\n\\\\theta_1^2 + \\theta_2 = \\frac{1}{n}\\sum\\_{i=1}^{n}X_i^2\n\\\\end{cases}$$\n$$\\begin{align\\*}\n\\\\implies\\theta_2\n\u0026= \\frac{1}{n}\\sum\\_{i=1}^{n}X_i^2 - \\overline{X}^2\\\\\n\u0026= \\frac{1}{n}\\left\\[\\\\sum\\_{i=1}^{n}X_i^2 - n\\overline{X}^2\\right\\]\\\\\n\u0026= \\frac{1}{n}\\left\\[\\\\sum\\_{i=1}^{n}(X_i - \\overline{X})^2\\right\\]\\\\\n\u0026= \\frac{n-1}{n}S^2\n\\\\end{align\\*}$$\n(Per quest'utlima equazione vedere [Random Sample \u003e Teorema 5 2 4](Random%20Sample.md#teorema-5-2-4)).\n\nIn conclusione i nostri stimatori saranno\n$$\\begin{align\\*}\n\\\\hat{\\mu} \u0026= \\overline{X}\\\\\n\\\\hat{\\sigma}^2 \u0026= \\frac{n-1}{n}S^2\n\\\\end{align\\*}$$\n\n## Esempio - Binomiale\n\nSia il campione $X_1, ..., X_n$ di binomiali $\\text{Bin}(N, p)$, ovvero tali che $$P(X_i = h \\vert N,p) = \\binom{N}{h}p^{h}(1-p)^{n-h};; \\forall h = 0,1,...,N$$\n\nIn questo caso i parametri che vogliamo stimare sono $(\\hat{N}, \\hat{p}) = (N, p)$, perciò poniamo il sistema\n$$\\begin{cases}\n\\\\hat{N}\\hat{p} \u0026= \\overline{X}\\\\\n\\\\hat{N}\\hat{p}(1-\\hat{p}) \u0026= \\frac{1}{n}\\sum\\_{i=1}^{n}X_i^2\\\\\n\\\\end{cases}\n; \\longrightarrow ;\n\\\\begin{cases}\n\\\\hat{p} \u0026= \\overline{X}/\\hat{N}\\\\\n\\\\overline{X}(1-\\overline{X}/\\hat{N}) \u0026= \\frac{1}{n}\\sum\\_{i=1}^{n}X_i^2\\\\\n\\\\end{cases}$$\n$$\\longrightarrow ;\n\\\\begin{cases}\n\\\\hat{p} \u0026= \\overline{X}/\\hat{N}\\\\\n1-\\overline{X}/\\hat{N} \u0026= \\dfrac{\\sum\\_{i=1}^{n}X_i^2/n}{\\overline{X}}\n\\\\end{cases}\n; \\longrightarrow ;\n\\\\overline{X}/\\hat{N} = 1 - \\dfrac{\\sum\\_{i=1}^{n}X_i^2/n}{\\overline{X}} = \\dfrac{\\overline{X} - \\sum\\_{i=1}^{n}X_i^2/n}{\\overline{X}}\n$$\n$$; \\longrightarrow ;\n\\\\dfrac{\\hat{N}}{\\overline{X}} = \\dfrac{\\overline{X}}{\\overline{X} - \\sum\\_{i=1}^{n}X_i^2/n}\n$$\n$$\\implies\n\\\\begin{align\\*}\n\\\\overline{X} \u0026= \\dfrac{\\overline{X}^2}{\\overline{X} - \\sum\\_{i=1}^{n}X_i^2/n}\\\\\n\\\\hat{p} \u0026= \\dfrac{\\overline{X}}{\\hat{N}}\n\\\\end{align\\*}$$\n","lastmodified":"2022-08-29T13:39:16.8173397+02:00","tags":null},"/ISTI/Processo-empirico-e-Statistiche-dordine":{"title":"","content":"\n# Processo Empirico\n\nSiano il [campionamento casuale](Random%20Sample.md#random-sample) $X_1, ..., X_n$.\nIl **processo empirico** (o **funzione di ripartizione empirica**) è una funzione che stima la funzione di ripartizione $F(x)$, definita come $$\\hat{F}*n(x) = \\frac{1}{n} \\sum*{i=1}^{n} 1({X_i \\leq x})$$\n\nOsserviamo che la v.a. $\\sum\\_{i=1}^{n}1({X_i \\leq x})$ segue una **distribuzione binomiale** con probabilità di successo $p = P(X_i \\leq x) = F(x)$, perciò avremo che $\\hat{F}\\_n(x) \\sim \\text{Bin}(n, F(x))$.\n\nEssendo quindi tale funzione **probabilistica**, ha senso calcolarne la media e la varianza.\n$$\\mathbb{E}\\left\\[ \\hat{F}\\_n(x) \\right\\] = \\frac{1}{n} \\mathbb{E}\\left\\[ \\text{Bin}(n, F(x)) \\right\\] = \\frac{1}{\\cancel{n}}\\cancel{n}F(x) = F(x)$$\n$$\\text{Var}(\\hat{F}(x)) = \\frac{1}{n^2} \\text{Var}(\\text{Bin}(n, F(x))) = \\frac{F(x)(1 - F(x))}{n} \\xrightarrow{n \\to \\infty} 0$$\n\nOsservare che tale funzione $\\hat{F}\\_n(x)$ è **costante a tratti** con salti i ognuno dei valori $X_i$ (ordinati) di ampiezza $1/n$.\n\nQuesta applicazione (come molte) altre motiva l'introduzione delle **[statistiche d'ordine](Processo%20empirico%20e%20Statistiche%20d'ordine.md#statistiche-d-ordine)**.\n\n---\n\n# Statistiche d'ordine\n\nData una sequenza $X_1, ..., X_n$, definiamo una **statistica d'ordine** come un'*applicazione* $(X_1, ..., X_n) \\mapsto X\\_{(1)}, ..., X\\_{(n)}$ tale che il vettore risultante è **ordinato in maniera non decrescente**, ovvero $$X\\_{(1)} \\leq X\\_{(2)} \\leq ... \\leq X\\_{(n)}$$\nSpesso si è interessati alla **distribuzione** di queste statistiche d'ordine, sia per i songli elementi sia per l'intero vettore.\nVediamo alcuni esempi.\n\n## Distribuzione del massimo\n\nCerchiamo di capire che distribuzione segue $X\\_{(n)}$.\nPartendo dalla funzione di ripartizione, avremo che $X\\_{(n)} \\leq t$ **se e solo se** tutti gli altri elementi sono $\\leq t$ (questo per $X\\_{(n)}$ è appunto il massimo).\n\nPertanto la sua ripartizione sarà $$F\\_{X\\_{(n)}}(t) = P(X\\_{(n)} \\leq t) = P(X\\_{(i)} \\leq t ; \\forall i = 1 ... n) = \\left\\[F(t)\\right\\]^n$$\nLa sua *densità* invece sarà $$f\\_{X\\_{(n)}}(x) = n\\left\\[ F(x) \\right\\]^{n-1} \\cdot f(x)$$\n\n## Distribuzione del minimo\n\nDiscorso del tutto analogo per il minimo.\nPerciò $X\\_{(1)} \\geq t$ **se e solo se** tutti gli altri $X\\_{(i)}$ saranno $\\geq t$.\n$$P(X\\_{(1)} \\geq t) = P(X\\_{(i)} \\geq t ; i=1, ..., n\\forall) = \\left\\[ 1 - F(t) \\right\\]^n$$\n$$\\implies F\\_{X\\_{(1)}}(t) = 1 - \\left\\[ 1 - F(t) \\right\\]^n$$\n\n$$f\\_{X\\_{(1)}}(t) = n\\left\\[ 1-F(x)\\right\\]^{n-1} \\cdot f(x)$$\n\n## Distribuzioni intermedie\n\nChiediamoci ora qual è la distribuzione di $X\\_{(k)}$.\nOsserviamo che $X\\_{(k)} \\leq t$ **se e solo se** \u003cu\u003ealmeno\u003c/u\u003e $k$ v.a. sono $\\leq t$.\n\nSia la v.a. $T$ che conta il numero di *\"successi\"*, ovvero il numero di $1({X\\_{(i)} \\leq t})$.\nOsserviamo che $T \\sim \\text{Bin}(n, F(t))$\nPerciò $$P(X\\_{(k)} \\leq t) = P(T \\geq k) = \\sum\\_{i=k}^{n}P(T=i) = \\sum\\_{i=1}^{n} \\binom{n}{i}F(t)^i(1-F(t))^{n-i}$$\n\n### Esempio: massimo di uniformi\n\nSiano $X_1, ..., X_n \\sim U\\left\\[ 0,1 \\right\\]$ **i.i.d.**.\nSi vuole calcolare la media di $X = \\max_i X_i$.\n\nCome visto in precedenza avremo $$F_X(t) = \\left\\[ F(t) \\right\\]^n = t^n$$\n$$f_X(x) = nx^{n-1}$$\n\nPerciò la sua media sarà $$\\mathbb{E}\\left\\[ X \\right\\] = \\int_0^1 xf_X(x) , dx = \\int_0^1 nx^n , dx = \\frac{nx^{n+1}}{n+1} \\Bigg\\vert_0^1 = \\frac{n}{n+1}$$\nTale risultato è ragionevole.\nInfatti per $n \\to \\infty$ avremo che il massimo tende ad 1, però il suo valore è sempre $\\\u003c 1$ perché la probabilità che sia esattamente 1 è nulla.\n","lastmodified":"2022-08-29T13:39:16.757369667+02:00","tags":null},"/ISTI/Random-Sample":{"title":"","content":"\n## Random Sample\n\nLe v.a. $X_1,...,X_n$ sono dette un **campionamento** (o **random sample**) di **dimensione** $n$ da una **popolazione** $f(x)$ se $X_1,...,X_n$ sono **mutualmente indipendenti** e se la [densità marginale](Distribuzioni%20Multivariate.md#teorema-4-1-6-distribuzioni-marginali) è la stessa $f(x)$.\n\nAlternativamente $X_1, ..., X_n$ sono anche dette **i.i.d.** con *pdf* o *pmf* $f(x)$.\n\nOsserviamo che se il campionamento $(X_1, ..., X_n)$ ha [distribuzione congiunta](Distribuzioni%20Multivariate.md#joint-pmf) $f(x_1, ..., x_n)$, per indipendenza avremo la seguente uguaglianza\n\n$$f(x_1, ..., x_n) = f(x_1) \\cdot ... \\cdot f(x_n) = \\prod\\_{i = 1}^{n} f(x_i)$$\nAnalogamente quando il campionamento dipende da un singolo **parametro condiviso** $\\theta$.\n$$f(x_1, ..., x_n \\vert \\theta) = \\prod\\_{i=1}^{n} f(x_i \\vert \\theta)$$\n\n### Esempio - campionamento di esponenziali\n\nSia $X_1,...,X_n$ un campionamento da una popolazione esponenziale $\\text{Exp}(\\beta)$.\nOvvero\n$$X_i = e^{-x_i/\\beta}$$\nSupponendo quindi che $\\beta$ è il **parametro** sul quale il campionamento dipende, avremo quindi una [joint pdf](Distribuzioni%20Multivariate.md#joint-pdf) del tipo\n$$f(x_1,...,x_n \\vert \\beta) = \\prod\\_{i=1}^{n}f(x_i \\vert \\beta) = \\prod\\_{i=1}^{n}\\frac{1}{\\beta}e^{-x_i/\\beta} = \\frac{1}{\\beta^n}e^{-(x_1+...+x_n)/\\beta}$$\nQuesta *pdf* può essere molto utile per rispondere ad alcune domande.\nPer esempio supponiamo che $X_i$ indichi il tempo (espresso in anni) entro il quale un circuito si rompe.\nPerciò, qual è la probabilità che tutti i circuiti sopravvivano più di 2 anni?\n$$\\begin{align\\*}\nP(X_1 \u003e 2, ..., X_n \u003e 2)\n\u0026= \\int\\_{2}^{\\infty} \\cdots \\int\\_{2}^{\\infty} f(x_1, ..., x_n \\vert \\theta) , dx_1 \\cdots dx_n\\\\\n\u0026= \\int\\_{2}^{\\infty} \\cdots \\int\\_{2}^{\\infty} \\prod\\_{i=1}^{n}\\frac{1}{\\beta}e^{-x_i/\\beta} , dx_1 \\cdots dx_n\\\\\n\u0026= \\int\\_{2}^{\\infty} \\cdots \\int\\_{2}^{\\infty} \\left\\[-e^{-x/\\beta} \\right\\]*{2}^{\\infty} \\prod*{i=2}^{n}\\frac{1}{\\beta}e^{-x_i/\\beta} , dx_2 \\cdots dx_n\\\\\n\u0026= \\int\\_{2}^{\\infty} \\cdots \\int\\_{2}^{\\infty}  e^{-2/\\beta} \\prod\\_{i=2}^{n}\\frac{1}{\\beta}e^{-x_i/\\beta} , dx_2 \\cdots dx_n\\\\\n\u0026;;\\vdots\\\\\n\u0026= \\left( e^{-2/\\beta}\\right)^n\\\\\n\u0026= e^{-2n/\\beta}\n\\\\end{align\\*}$$\n\nRicordando che $\\beta$ è il **valore atteso** di $\\text{Exp}(\\beta)$ (in questo caso in quanto tempo in media si rompe un circuito), avremo che se $\\beta \\approx n$ allora tale probabilità sarà prossima ad 1.\n\n---\n\n## Somme di variabili aleatorie di un campionamento\n\nSia $X_1, ..., X_n$ un [random sample](Random%20Sample.md#random-sample) di dimensione $n$ di una generica popolazione, e sia $T(x_1, ..., x_n)$ una funzione il cui dominio è lo spazio di campionamento di $(X_1, ..., X_n)$.\n\nLa v.a. (o vettore) $Y \\sim T(X_1, ..., X_n)$ è chiamata **statistica**. ^46a026\n\nLa distribuzione di probabilità di una statistica $Y$ è anche chiamata **distribuzione campionaria** (o **sampling distribution**).\n\n### Media campionaria\n\nLa **media campionaria** di un sampling $X_1, ..., X_n$ è semplicemente la **media aritmetica**\n$$\\overline{X} = \\frac{X_1 + ... + X_n}{n}$$\n\n### Varianza campionaria\n\nLa **varianza campionaria** di un sampling $X_1, ..., X_n$ è definita come\n$$S^2 = \\frac{\\sum\\_{i=1}^{n}(X_i - \\overline{X})^2}{n-1}$$\n\nAnalogamente la **deviazione standard campionaria** è definita come $S = \\sqrt{S^2}$.\n\n### Teorema 5.2.4\n\nSia i valori $x_1, ..., x_n$ e i valori $\\overline{x} = (x_1 + ... + x_n)/n$ e $s^2 = (\\sum_i (x_1 - \\overline{x})^2)/(n-1)$\nAllora valgono le seguenti prorpietà:\n\n1. $$\\overline{x} = \\arg \\min\\_{a \\in \\mathbb{R}}\\sum\\_{i=1}^{n}(x_i - a)^2$$\n1. $$(n-1)s^2 = \\sum\\_{i=1}^{n}x_i^2 - n\\overline{x}$$\n\n#### Proof\n\n$$\\begin{align\\*}\n\\\\sum\\_{i=1}^{n}(x_i - a)^2\n\u0026= \\sum\\_{i=1}^{n}(x_i - \\overline{x} + \\overline{x} - a)^2\\\\\n\u0026= \\sum\\_{i=1}^{n}((x_i - \\overline{x}) + (\\overline{x} - a))^2\\\\\n\u0026= \\sum\\_{i=1}^{n}(x-\\overline{x})^2 + 2\\sum\\_{i=1}^{n}(x_i - \\overline{x})(\\overline{x} - a) + \\sum\\_{i=1}^{n}(\\overline{x} - a)^2\n\\\\end{align\\*}$$\ne tale quantità è minimizzata per $a = \\overline{x}$.\n\n$$\\begin{align\\*}\n(n-1)s^2\n\u0026= \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2\\\\\n\u0026= \\sum\\_{i=1}^{n}x_i^2 - 2\\sum\\_{i=1}^{n}x_i\\overline{x} + \\sum\\_{i=1}^{n}\\overline{x}^2\\\\\n\u0026= \\sum\\_{i=1}^{n}x_i^2 - \\frac{2}{n}\\sum\\_{i=1}^{n}x_i(x_1 + ... + x_i + ... + x_n) + n\\overline{x}^2\\\\\n\u0026= \\sum\\_{i=1}^{n}x_i^2 - \\frac{2}{n}\\sum\\_{i=1}^{n}(x_ix_1 + ... + x_i^2 + ... + x_ix_n) + n\\overline{x}^2\\\\\n\u0026= \\sum\\_{i=1}^{n}x_i^2 - \\frac{2}{n}\\sum\\_{i=1}^{n}\\left\\[ x_i^2 + \\sum\\_{j \\neq i} x_ix_j \\right\\] + n\\overline{x}^2\\\\\n\u0026= \\sum\\_{i=1}^{n}x_i^2 - \\frac{2}{n}\\underbrace{\\left\\[\\\\sum\\_{i=1}^{n} x_i^2 + 2\\sum\\_{j \\neq i} x_ix_j \\right\\]}*{(x_1 + ... +x_n)^2 = \\overline{x}^2n^2} + n\\overline{x}^2\\\\\n\u0026= \\sum*{i=1}^{n}x_i^2 - 2n\\overline{x}^2 + n\\overline{x}^2\\\\\n\u0026= \\sum\\_{i=1}^{n}x_i^2 - n\\overline{x}^2 ;; \\square\n\\\\end{align\\*}$$\n\n### Lemma 5.2.5 - media e lemma\n\nSia $X_1, ..., X_n$ un random sampling, e sia una funzione $g(x)$ tale che $\\mathbb{E}\\left\\[ g(X_i)\\right\\]$ e $\\text{Var}(g(X_i))$ esistono.\nAllora avremo che\n\n1. $$\\mathbb{E}\\left\\[ \\sum\\_{i=1}^{n}g(X_i) \\right\\] = n\\mathbb{E}\\left\\[ g(X_1) \\right\\]$$\n1. $$\\text{Var}\\left( \\sum\\_{i=1}^{n}g(X_i) \\right) = n\\text{Var}\\left( g(X_1) \\right)$$\n\n#### Proof\n\nPer il punto 1 basta sfruttare la **linearità**.\nPer il punto 2 basta osservare che nel caso di **indipendenza** allora anche la varianza è lineare $\\square$.\n\n### Teorema 5.2.6 - Proprietà importanti\n\nSia il random sample $X_1, ..., X_n$ con media $\\mu$ e vairanza finita $\\sigma^2 \\\u003c \\infty$.\nAllora valgono le seguenti proprietà:\n\n1. $$\\mathbb{E}\\left\\[ \\overline{X} \\right\\] = \\mu$$ ^69143c\n1. $$\\text{Var}\\left(\\overline{X}\\right) = \\frac{\\sigma^2}{n}$$ ^2864bf\n1. $$\\mathbb{E}\\left\\[ S^2 \\right\\] = \\sigma^2$$ ^89dd43\n\n#### Proof\n\nPer il [punto 1](Random%20Sample.md#69143c) sfruttiamo la linearità del valore atteso\n$$\\mathbb{E}\\left\\[ \\overline{X} \\right\\] = \\mathbb{E}\\left\\[ \\frac{1}{n}\\sum\\_{i=1}^{n}X_i \\right\\] = \\frac{1}{n}n\\mathbb{E}\\left\\[ X_1 \\right\\] = \\mu $$\n\nAnalogamente per il [punto 2](Random%20Sample.md#2864bf)\n$$\\text{Var}\\left( \\overline{X} \\right) = \\text{Var}\\left( \\frac{1}{n} \\sum\\_{i=1}^{n} X_i \\right) = \\frac{1}{n^2} \\text{Var}\\left( \\sum\\_{i=1}^{n} X_i \\right) = \\frac{1}{n^2}n \\text{Var}\\left( X_1 \\right) = \\frac{\\sigma^2}{n}$$\n\nIn fine per il [punto 3](Random%20Sample.md#89dd43) sfruttiamo il [Teorema 5 2 4](Random%20Sample.md#teorema-5-2-4) \n$$\\begin{align\\*}\n\\\\mathbb{E}\\left\\[ S^2 \\right\\]\n\u0026= \\mathbb{E}\\left\\[ \\frac{1}{n-1} \\sum\\_{i=1}^{n}(X_i - \\overline{X})^2 \\right\\]\\\\\n\u0026= \\frac{1}{n-1} \\mathbb{E}\\left\\[ \\sum\\_{i=1}^{n}X_i^2 - n\\overline{X}^2 \\right\\]\\\\\n\u0026= \\frac{1}{n-1} \\left( n\\mathbb{E}\\left\\[X_1^2\\right\\] - n\\mathbb{E}\\left\\[\\\\overline{X}^2 \\right\\] \\right)\n\\\\end{align\\*}$$\nOsserviamo che\n$$\\text{Var}(X) = \\mathbb{E}\\left\\[X^2\\right\\] - \\mathbb{E}^2\\left\\[X\\right\\] \\implies \\sigma^2 = \\mathbb{E}\\left\\[X^2\\right\\] - \\mu^2 \\implies \\mathbb{E}\\left\\[X^2\\right\\] = \\sigma^2 + \\mu^2$$\nPerciò sfruttando i punti [1](Random%20Sample.md#69143c) e [2](Random%20Sample.md#2864bf) avremo che\n$$\\begin{align\\*}\n\\\\mathbb{E}\\left\\[ S^2 \\right\\]\n\u0026= \\frac{1}{n-1} \\left( n(\\sigma^2 - \\mu^2) - n\\left(\\frac{\\sigma^2}{n} - \\mu^2 \\right) \\right)\\\\\n\u0026=\\frac{n}{n-1} \\left( \\sigma^2 - \\cancel\\mu^2 - \\frac{\\sigma^2}{n} + \\cancel\\mu^2 \\right)\\\\\n\u0026=\\frac{n}{n-1} \\left( \\sigma^2 - \\frac{\\sigma^2}{n} \\right)\\\\\n\u0026= \\sigma^2 ;; \\square\n\\\\end{align\\*}$$\n\n#### Oservazione\n\nIl punto [punto 3](Random%20Sample.md#89dd43) spiegato il perché nella definizione di $S^2$ si divide per $n-1$ e non per $n$.\n\n---\n\n## Teorema 5.2.7 - FGM della media campionaria\n\nSia $X_1,...,X_n$ un *random sample*, dove ogni v.a. ha [fgm](Distribuzioni%20Multivariate.md#moment-generating-function) $M_X(t)$.\nAllora la *fgm* della media campionaria $\\overline{X}$ risulterà essere $$M\\_{\\overline{X}}(t) = \\left\\[ M_X(t/n) \\right\\]^n$$ dove $X$ è un qualsiasi $X_i$ (tanto sono i.i.d.).\n\n### Proof\n\nSfruttando il fatto che $X_1,...,X_n$ sono i.i.d. otteremo $$M\\_{\\overline{X}}(t) = \\mathbb{E}\\left\\[ e^{t \\overline{X}} \\right\\] = \\mathbb{E}\\left\\[ e^{t (X_1 + ... + X_n)/n} \\right\\] = \\mathbb{E}\\left\\[ \\prod\\_{i=1}^{n} e^{(t/n)X_i} \\right\\] =  \\prod\\_{i=1}^{n} M\\_{X_i}(t/n) = \\left\\[ M_X(t/n) \\right\\] ; ; \\square$$\n\n### Esempio - Normale\n\nSiano $X_1, ..., X_n$ un campio di normali $N(\\mu, \\sigma^2)$.\nLa funzione generatrice dei momenti della media campionaria sarà quindi\n$$\\begin{align\\*}\nM\\_{\\overline{X}}(t)\n\u0026= \\left\\[ M_X(t/n) \\right\\]^n\\\\\n\u0026= \\left\\[ \\mathbb{E}\\left\\[ e^{(t/n) \\cdot N(\\mu, \\sigma^2)} \\right\\] \\right\\]^n\\\\\n\u0026= \\left\\[ \\exp{\\left( \\mu (t/n) + \\sigma^2 \\frac{(t/n)^2}{2}\\right)} \\right\\]^n\\\\\n\u0026= \\exp{\\left( n \\left( \\mu (t/n) + \\sigma^2 \\frac{(t/n)^2}{2}\\right) \\right)}\\\\\n\u0026= \\exp{\\left( \\mu t + (\\sigma^2/n) \\frac{t^2}{2} \\right)}\n\\\\end{align\\*}$$\n\nPerciò $\\overline{X}$ ha una distribuzione $N(\\mu, \\sigma^2/n)$.\n\nOsserviamo dal [teorema 5.6.2](Random%20Sample.md#teorema-5-2-6-proprieta-importanti) che la distribuzione normale che descrive $\\overline{X}$ ha appunto parametri $\\mathbb{E}\\left\\[\\\\overline{X}\\right\\]$ e $\\text{Var}(\\overline{X})$.\n\n---\n\n## Teorema 5.2.9. - Convolution formula\n\nSiano $X, Y$ due v.a. **cpntinue**, **indipendenti** e con *pdf* relativamente $f_X(x)$ e $f_Y(y)$.\nSia $Z = X + Y$, allora la sua pdf sarà\n$$f_Z(z) = \\int\\_{-\\infty}^{\\infty} f_X(w) f_Y(z-w) , dw$$\n\n#### Proof\n\nSia $W = X$.\nIl *Jacobiano* della trasformazione da $(X, Y)$ a $(Z, W)$ sarà 1.\nInfatti avremo che $Z = g_1(X,Y) = X+Y$ e $W = g_2(X,Y) = X$ con **inverse**\n$$\\begin{align\\*}\nX = g^{-1}\\_1(Z, W) \u0026= W\\\\\nY = g^{-1}\\_2(Z, W) \u0026= Z-W\n\\\\end{align\\*}$$\n\nInfatti\n$$J = \\left\\vert\n\\\\begin{array}{c}\n\\\\dfrac{\\partial}{\\partial Z} W \u0026 \\dfrac{\\partial}{\\partial W} W\\\\\n\\\\dfrac{\\partial}{\\partial Z} Z-W \u0026 \\dfrac{\\partial}{\\partial W} Z-W\n\\\\end{array}\n\\\\right\\vert\n= -1$$\n\nPerciò la distribuzione congiunta di $Z,W$ risulterà essere $$f\\_{Z,W}(z, w) = f\\_{X,Y}(w, z-w) \\vert J \\vert = f\\_{X}(w)f_Y(z-w)$$\nPer ottenere la distribuzione marginale di $Z$ basta fissare un valore di $z$ e integrare su $w$\n$$f_Z(z) = \\int\\_{-\\infty}^{\\infty} f\\_{Z, W}(z, w) , dw = \\int\\_{-\\infty}^{\\infty} f_X(w)f_Y(z-w) , dw ;; \\square$$\n\n### Esempio - somma di v.a. di Cauchy\n\nSia il campionamento $Z_1, ..., Z_n$ campionati da una $\\text{Cauchy}(0,1)$.\nRicordiamo che $$\\text{Cauchy}(x_0, \\gamma) = \\frac{1}{\\pi} \\frac{\\gamma}{(x- x_0)^2 + \\gamma^2}$$ perciò $$Z_i \\sim \\text{Cauchy}(0,1) = \\frac{1}{\\pi} \\frac{1}{x^2 + 1}$$\n[Sappiamo](Distribuzioni.md#somma-di-cauchy-indipendinti) che la somma di $n$ $\\text{Cauchy}(0,1)$ è ancora una $\\text{Cauchy}(0, n)$.\n$$Z = \\sum\\_{i=1}^{n}Z_i \\sim \\text{Cauchy}(0,n) \\implies f_Z(z) = \\frac{1}{n\\pi}\\frac{1}{(z/n)^2 + 1}$$\nDato che $\\overline{Z} = g(Z) = Z/n$, e dato $Z = g^{-1}(\\overline{Z}) = n\\overline{Z}$, avremo che la distribuzione della media campionaria $\\overline{Z}$ è \u003cu\u003eancora\u003c/u\u003e una $\\text{Cauchy}(0,1)$!\nInfatti $$f\\_{\\overline{Z}}(z) = f_Z(g^{-1}(z)) \\cdot \\left\\vert \\frac{d}{dz} g^{-1}(z) \\right\\vert = f_Z(nz) \\cdot n = \\cancel{n}\\frac{1}{\\cancel{n}\\pi}\\frac{1}{\\left( \\cfrac{\\cancel{n}z}{\\cancel{n}}\\right)^2 + 1} = \\frac{1}{\\pi}\\frac{1}{z^2 + 1} = \\text{Cauchy}(0,1)$$\n","lastmodified":"2022-08-29T13:39:16.770231208+02:00","tags":null},"/ISTI/Rao-Blakwell-Theorem":{"title":"","content":"\n# Rao-Blakwell Theorem\n\nSia un [campionamento](Random%20Sample.md#random-sample) $\\mathbf{X} = (X_1, ..., X_n)$ dipendente da un parametro $\\theta$, sia $T(\\mathbf{X})$ una **[statistica sufficiente](Statistiche%20Sufficienti.md#statistica-sufficiente)** per $\\theta$, e sia $W(\\mathbf{X})$ uno **[stimatore non distorto](Stimatori%20Puntuali.md#401481)** per $\\tau(\\theta)$.\n\nDefiniamo la funzione $$\\phi(t) = \\mathbb{E}\\left\\[ W(\\mathbf{X}) \\vert ;t; \\right\\]$$\n\nAllora avremo che\n\n1. $$\\mathbb{E}\\_{\\theta}\\left\\[ \\phi(T(\\mathbf{X})) \\right\\] = \\tau(\\theta)$$ ^75479a\n1. $$\\text{Var}*\\\\theta\\big(\\phi(T(\\mathbf{X}))\\big) \\leq \\text{Var}*\\\\theta(W(\\mathbf{X}))$$ ^57e6d5\n\nOvvero $\\phi(T(\\mathbf{X}))$ è il **miglior** stimatore non distorto di $\\tau(\\theta)$.\n\n## Proof\n\nPrima di iniziare è utile ricordare che per ogni coppia di v.a. $X,Y$ si ha che\n\n* $\\mathbb{E}\\left\\[ \\mathbb{E}\\left\\[ X \\vert Y \\right\\]\\\\right\\] = \\mathbb{E}\\left\\[ X \\right\\]$\n* $\\text{Var}(X) = \\text{Var}(\\mathbb{E}\\left\\[ X \\vert Y \\right\\]) + \\mathbb{E}\\left\\[\\\\text{Var}( X \\vert Y) \\right\\]$\n\nIl [punto 1](Rao-Blakwell%20Theorem.md#75479a) è banalmente verificabile $$\\mathbb{E}*{\\theta}\\left\\[ \\phi(T(\\mathbf{X})) \\right\\] = \\mathbb{E}*{\\theta}\\left\\[ \\mathbb{E}\\left\\[ W(\\mathbf{X}) \\vert T(\\mathbf{X}) \\right\\] \\right\\] = \\mathbb{E}\\_\\\\theta\\left\\[ W(\\mathbf{X}) \\right\\] = \\tau(\\theta)$$ perciò $\\phi(T(\\mathbf{X}))$ è **non distorto** per $\\tau(\\theta)$.\n\nInvece per il [punto 2](Rao-Blakwell%20Theorem.md#57e6d5) abbiamo che\n$$\\begin{align\\*}\n\\\\text{Var}*\\\\theta(W(\\mathbf{X}))\n\u0026= \\text{Var}*\\\\theta(\\mathbb{E}\\left\\[ W(\\mathbf{X}) \\vert T(\\mathbf{X}) \\right\\]) + \\mathbb{E}*\\\\theta\\left\\[ \\text{Var}(W(\\mathbf{X}) \\vert T(\\mathbf{X})) \\right\\]\\\\\n\u0026= \\text{Var}*\\\\theta\\big(\\phi(T(\\mathbf{X}))\\big) + \\mathbb{E}*\\\\theta\\left\\[ \\text{Var}(W(\\mathbf{X}) \\vert T(\\mathbf{X})) \\right\\]\\\\\n\u0026\\geq \\text{Var}*\\\\theta\\big(\\phi(T(\\mathbf{X}))\\big)\n\\\\end{align\\*}$$\nPerciò abbiamo che $\\phi(T(\\mathbf{X}))$ è **uniformemente** migliore di $W(\\mathbf{X})$.\n\nOra manca solo dimostrare che $\\phi(T(\\mathbf{X}))$ è uno stimatore.\nBasta osservare che $\\phi(t) = \\mathbb{E}\\left\\[ W(\\mathbf{X}) \\vert ;t; \\right\\]$ è una funzione dei soli parametri $X_1, ..., X_n$, perciò è *indipendente* da $\\theta$, perciò è uno stimatore $\\square$.\n\n---\n\n# Conclusioni\n\nIl teorema di Rao-Blakwell in sintesi ci dice che è inutile cercare stimatori che non siano funzioni della [statistica sufficiente minimale](Statistiche%20Sufficienti.md#def-statistica-sufficiente-minimale).\n","lastmodified":"2022-08-29T13:39:16.751049609+02:00","tags":null},"/ISTI/Statistiche-Sufficienti":{"title":"","content":"\nSpesso un esperimento fa uso di un [campionamento](Random%20Sample.md#random-sample) $\\mathbf{X} = (X_1, ..., X_n)$ per cercare di inferire qualche informazione riguardo un **parametro sconosciuto** $\\theta$.\nPer fare ciò fi fa uso di **statistiche**, ovvero funzioni definite sul supporto di un campionamento.\n\nOgni statistica $T(\\mathbf{X})$ definisce una sorta di *riduzione* o *riassunto* delle informazioni contenute nei dati, estraendone solamente quelle significative.\nSi può pensare alla mappa $\\mathbf{X} \\to T(\\mathbf{X})$ come una *riduzione di complessità* che non perde informazione su $\\theta$.\n\n# Statistica Sufficiente\n\nIn genere siamo interessati a definire (e trovare) statistiche che siano in qualche modo *\"migliori\"* di altre.\n\nSupponiamo di aver trovato una statistica tale che qualsiasi altra statistica non riesce ad estrapolare altre informazioni in più dal campione, ovvero una statistica *\"sufficiente\"* ai nostri scopi.\nUna **statistica sufficiente** per un parametro sconosciuto $\\theta$ è una funzione che in qualche modo racchiude tutte le informazioni riguardo $\\theta$ che sono contenute all'interno di $\\mathbf{X}$.\n\nPiù formalmente, una statistica $T(\\mathbf{X})$ è una **statistica sufficiente** per $\\theta$ se la distribuzione condizionata di $\\mathbf{X}$ dato il valore di $T(\\mathbf{X})$ è **indipendente** da $\\theta$.\n\nIn maniera intuitiva, fissiamo lo spazio definito da $T(\\mathbf{X}) = t$: siamo interessati a conosce informazioni riguardo la distribuzione di tutti quei $X_1, ..., X_n$ tali che $T(\\mathbf{X}) = t$.\nOvvero vogliamo calcolare la distribuzione congiunta $$f\\_{\\mathbf{X} \\vert T(\\mathbf{X}) = t}(\\mathbf{x}, t)$$\nSe tale distribuzione **indipendente** dal parametro $\\theta$ (dal quale $\\mathbf{X}$ dipdende) allora possiamo affermare che $T$ è una statistica sufficiente.\n\n## Esempio - Bernoulliane\n\nConsideriamo una serie di bernoulliane indipendenti $\\mathbf{X} = (X_1, ..., X_n)$ di parametri $\\theta = p$.\nConsideriamo una prima statistica $T(\\mathbf{X}) = X_1$: essa è sufficiente ?\n\nCalcoliamo quindi $$f\\_{\\mathbf{X} | X_1 = x^*}(x_1, ..., x_n, x^*)$$\nInnanzitutto sappiamo che $$f\\_{\\mathbf{X}}(x_1, ..., x_n) = p^{x_1 + ... + x_n}(1-p)^{n - (x_1 + ... x_n)}$$ perciò $$f\\_{\\mathbf{X} | X_1 = x^*}(x_1, ..., x_n, x^*) = p^{x^\\* + x_2 ... + x_n}(1-p)^{n - (x^\\* + x_2 + ... + x_n)}$$\nQuesta purtroppo non è una statistica sufficiente perché la distribuzione condizionata dipende ancora da $p$.\n\nConsideriamo una seconda statistica $S(\\mathbf{X}) = X_1 + ... + X_n$.\nEssendo $S$ una somma di bernoulliane indipendenti, allora possiamo affermare che $S \\sim \\text{Bin}(n, p)$.\nAllora \n$$\\begin{align\\*}\nf\\_{\\mathbf{X} | X_1 + ... X_n = s}(x_1, ..., x_n, s)\n\u0026= \\frac{p^{s}(1-p)^{n - s}}{\\binom{n}{s}p^s(1-p)^s}\\\\\n\u0026= \\frac{1}{\\binom{n}{s}}\n\\\\end{align\\*}$$\novvero una uniforme.\n\nPerciò possiamo dire che $S$ è una statistica sufficiente per $p$.\n\n## Esempio - Poisson\n\nSia $X_1, ..., X_n$ un campionamento con v.a. di $\\text{Poisson}(\\lambda)$ (vedi [Distribuzioni \u003e Poisson](Distribuzioni.md#poisson)).\nLa sua [densità congiunta](Distribuzioni%20Multivariate.md#joint-pmf) riuslta quindi essere $$f\\_{\\mathbf{X}}(x_1, ..., x_n) = \\prod\\_{i=1}^{n}f\\_{X_i}(x_i) = \\frac{\\lambda^{x_1 + ... + x_n}e^{-n\\lambda}}{x_1!\\cdots x_n!}$$\nCome prima, poniamo la statistica $T(\\mathbf{X}) = X_1 + ... + X_n$.\n\nEssendo $T$ una somma di Poisson indipendenti, allora avremo che $T$ sarà anchessa una poisson di parametro $n\\lambda$.\nPerciò\n$$\\begin{align\\*}\nf\\_{\\mathbf{X} | X_1 + ... X_n = s}(x_1, ..., x_n, s)\n\u0026= \\left(\\frac{\\lambda^{s}e^{-n\\lambda}}{x_1!\\cdots x_n!}\\right) \\Big/ \\left( \\frac{(n\\lambda)^{s}e^{-n\\lambda}}{s!}\\right)\\\\\n\u0026= \\frac{s!}{x_1! \\cdots x_n!}\\frac{1}{n^2}\n\\\\end{align\\*}$$\novvero $T$ è una statistica sufficiente.\n\n## Esempio - Media campionaria di Normali\n\nSia un campionamento $X_1, ..., X_n$ di normali $N(\\mu, \\sigma^2)$, con $\\sigma^2$ noto e $\\mu$ sconosciuto.\nSia la statistica $T(\\mathbf{X}) = \\overline{X}$.\nSi vuole quindi stimare se la [media campionaria](Random%20Sample.md#media-campionaria) è una statistica sufficiente per $\\mu$.\n\nIniziamo col scrivere la [densità congiunta](Distribuzioni%20Multivariate.md#joint-pdf) di $\\mathbf{X}$\n$$\\begin{align\\*}\nf\\_{\\mathbf{X}}(x_1, ..., x_n)\n\u0026= \\prod\\_{i=1}^{n}f\\_{X_i}(x_i)\\\\\n\u0026= \\prod\\_{i=1}^{n} (2\\pi\\sigma^2)^{-1/2}\\exp{\\left\\[ -\\frac{1}{2\\sigma^2}(x_i - \\mu)^2 \\right\\]}\\\\\n\u0026= (2\\pi\\sigma^2)^{-n/2}\\exp{\\left\\[ -\\frac{1}{2\\sigma^2}\\sum\\_{i=1}^{n}(x_i - \\mu)^2 \\right\\]}\\\\\n\u0026= (2\\pi\\sigma^2)^{-n/2}\\exp{\\left\\[ -\\frac{1}{2\\sigma^2}\\sum\\_{i=1}^{n}(x_i - \\overline{x} + \\overline{x} - \\mu)^2 \\right\\]}\n\\\\end{align\\*}$$\n\nCerchiamo di riformulare la sommatoria all'esponente in maniera più utile\n$$\\begin{align\\*}\n\\\\sum\\_{i=1}^{n}(x_i - \\overline{x} + \\overline{x} - \\mu)^2\n\u0026= \\sum\\_{i=1}^{n}((x_i - \\overline{x}) + (\\overline{x} - \\mu))^2\\\\\n\u0026= \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 + 2\\sum\\_{i=1}^{n}(x_i - \\overline{x})(\\overline{x} - \\mu) + \\sum\\_{i=1}^{n}(\\overline{x} - \\mu)^2\\\\\n\u0026= \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 + 2(\\overline{x} - \\mu)\\sum\\_{i=1}^{n}(x_i - \\overline{x}) + n(\\overline{x} - \\mu)^2\n\\\\end{align\\*}$$\n\nLa sommatoria $\\sum_i x_i - \\overline{x}$ è pari a $0$, infatti\n$$\\begin{align\\*}\n\\\\sum\\_{i=1}^{n} x_i - \\overline{x}\n\u0026= \\sum\\_{i=1}^{n} x_i - \\sum\\_{i=1}^{n}\\overline{x}\\\\\n\u0026= (x_1 + ... + x_n)  - n \\overline{x}\\\\\n\u0026= (x_1 + ... + x_n)  - (x_1 + ... + x_n) = 0\\\\\n\\\\end{align\\*}$$\n\nPericò proseguendo che\n$$f\\_{\\mathbf{X}}(x_1, ..., x_n) = (2\\pi\\sigma^2)^{-n/2}\\exp{\\left\\[ - \\left( \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 + n(\\overline{x} - \\mu)^2 \\right)/(2\\sigma^2) \\right\\]}$$\n\nVediamo ora la distribuzione condizionata a $\\overline{X}$\n$$\\begin{align\\*}\nf\\_{\\mathbf{X} \\vert \\overline{X} = x^*}(x_1, ..., x_n, x^*)\n\u0026= \\frac{(2\\pi\\sigma^2)^{-n/2}\\exp{\\left\\[ - \\left( \\sum\\_{i=1}^{n}(x_i - x^*)^2 + n(x^* - \\mu)^2 \\right)/(2\\sigma^2) \\right\\]}}{(2\\pi\\sigma^2/n)^{-1/2}\\exp{\\left\\[ -n(x^\\* - \\mu)^2/(2\\sigma^2)  \\right\\]}}\\\\\n\u0026= n^{1/2} (2\\pi\\sigma^2)^{-(n-1)/2} \\exp{\\left( - \\frac{1}{2\\sigma^2}\\sum\\_{i=1}^{n}(x_i - x^*)^2 \\right)} \n\\\\end{align*}$$\n\nSi vede chiaramente che tale dinsità è **indipendente** dal valore di $\\mu$, perciò abbiamo dimostrato che, nel caso di normali, la media campionaria è una statistica sufficiente per il parametro $\\mu$.\n\n---\n\nLa ricerca di statistiche sufficienti per un campione può essere semplificata dal Factorization Theorem\n\n# Teorema di Fattorizzazione\n\nSia il campione $\\mathbf{X} = X_1, ..., X_n$ dipendente da un parametro $\\theta$, e sia la sua [densità congiunta](Distribuzioni%20Multivariate.md#joint-pdf) $f\\_{\\theta}(\\mathbf{x})$.\n\nUna statistica $T(\\mathbf{X})$ è *sufficiente* per il paramtro $\\theta$ **se e solo se** per ogni punto $\\mathbf{x}$ e ogni parametro $\\theta$, la densità $f\\_\\\\theta$ può essere fattorizzata come $$f\\_{\\theta}(\\mathbf{x}) = g\\_{\\theta}(T(\\mathbf{x})) \\cdot h(\\mathbf{x})$$ dove $g\\_{\\theta}$ è una funzione definita sulla statistica $T$ e dipendente dal parametro in questione $\\theta$, mentre $h$ è una funzione definita nei soli valori $x_1, ..., x_n$ e **indipendente** da $\\theta$.\n\nUna notazione equivalente \u003cu\u003eche verrà utilizzata in maniera intercambiabile\u003c/u\u003e è la seguente $$f(\\mathbf{x} \\vert \\theta) = g(T(\\mathbf{x}) \\vert \\theta) \\cdot h(\\mathbf{x})$$\n\n## Esempio - continuo esempio Normale\n\nRiprendiamo l'[esempio precedente](Statistiche%20Sufficienti.md#esempio-media-campionaria-di-normali), avevamo che $$f\\_{\\mathbf{X}}(x_1, ..., x_n \\vert \\mu) = (2\\pi\\sigma^2)^{-n/2}\\exp{\\left\\[ - \\left( \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 + n(\\overline{x} - \\mu)^2 \\right)/(2\\sigma^2) \\right\\]}$$  ^188fc0\n\nScomponendo l'esponente avremo \n$$f\\_{\\mathbf{X}}(x_1, ..., x_n \\vert \\mu) = (2\\pi\\sigma^2)^{-n/2}\\exp{\\left( - \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 /(2\\sigma^2) \\right)} \\exp{\\left( -n(\\overline{x} - \\mu)^2/(2\\sigma^2) \\right)}$$\n\nPerciò ponendo $$g(T(x_1, ..., x_n) \\vert \\mu) = \\exp{\\left( -n(\\overline{x} - \\mu)^2/(2\\sigma^2) \\right)}$$ e $$h(x_1, ..., x_n) = (2\\pi\\sigma^2)^{-n/2}\\exp{\\left( - \\sum\\_{i=1}^{n}(x_i - \\overline{x})^2 /(2\\sigma^2) \\right)}$$ troviamo la *fattorizzazione* desidarata $$f\\_{\\mathbf{X}}(x_1, ..., x_n \\vert \\mu) = h(x_1, ..., x_n) \\cdot g(T(x_1, ..., x_n) \\vert \\mu)$$\n\n## Esempio - Statistica sufficiente Uniforme\n\nSia il campione $X_1, ..., X_n$ di v.a. **discrete** i.i.d. $U\\left\\[ 1, \\theta \\right\\]$, dove $\\theta$ è il parametro sconosciuto che si vuole stimare.\n\nLa densità di ogni v.a. è \n$$f(x_i \\vert \\theta) = \\begin{cases}\n\\\\frac{1}{\\theta} \u0026\\text{se } x_i \\leq \\theta\\\\\n0 \u0026\\text{altrimenti}\n\\\\end{cases}$$\n\nMentre la densita congiuta risulta essere\n$$f(x_1, ..., x_n \\vert \\theta) = \\begin{cases}\n\\\\theta^{-n} \u0026\\text{se } x_i \\in {1, ..., \\theta} ; \\forall i = 1, ..., n\\\\\n0 \u0026\\text{altrimenti}\n\\\\end{cases}$$\n\nLa condizione $x_i \\in {1, ..., \\theta} ; \\forall i = 1, ..., n$ può essere espressa come \n$$\\left\\[ x_i \\in \\mathbb{N} ; \\forall i = 1, ..., n \\right\\] ;; \\land ;; \\left\\[ \\max\\_{i=1,...,n} x_i \\leq \\theta \\right\\]$$\n\nConsideriamo quindi la statistica $$T(\\mathbf{X}) = \\max\\_{X_i \\in \\mathbf{X}} X_i$$\n\nPossiamo quindi **fattorizzare** $f(x_1, ..., x_n \\vert \\theta)$ come segue\n$$g(T(\\mathbf{x}) \\vert \\theta) = \\begin{cases}\n\\\\theta^{-n} \u0026\\text{se } T(\\mathbf{x}) \\leq \\theta\\\\\n0 \u0026\\text{altrimenti}\n\\\\end{cases}$$\ne\n$$h(\\mathbf{x}) = \\begin{cases}\n1 \u0026\\text{se } \\mathbf{x} \\in \\mathbb{N}^n\\\\\n0 \u0026\\text{altrimenti}\n\\\\end{cases}$$\n\nInfatti avremo che $$f(\\mathbf{x} \\vert \\theta) = g(T(\\mathbf{x}) \\vert \\theta) \\cdot h(\\mathbf{x})$$\nquindi per il [Teorema di Fattorizzazione](Statistiche%20Sufficienti.md#teorema-di-fattorizzazione) $T$ è una statistica sufficiente per $\\theta$.\n\n## Esempio Multivariato - Statistica sufficiente Normale (Media e Varianza)\n\nSia il campione normale $X_1,...,X_n$ di $N(\\mu, \\sigma^2)$ indipendenti.\nIn questo caso però (per sfortuna) sia $\\mu$ che $\\sigma^2$ non sono noti.\nPerciò in questo caso avremo il **vettore** di parametri $$\\pmb{\\theta} = (\\mu, \\sigma^2)$$\n\nDefiniamo quindi una statistica multivariata $T(\\mathbf{X}) = (T_1(\\mathbf{X}), T_2(\\mathbf{X})) = (\\overline{X}, S^2)$ come segue\n$$\\begin{align\\*}\nT_1(\\mathbf{x}) \u0026= \\overline{x} = (x_1 + ... + x_n)\\\\\nT_2(\\mathbf{x}) \u0026= s^2 = \\frac{1}{n-1}\\sum\\_{i=1}^{n}(x_i - \\overline{x})^2\n\\\\end{align\\*}$$\n\nCi si chede se $T$ è una statistica sufficiente per il parametro (multivariato) $\\pmb{\\theta}$.\n\nVogliamo quindi trovare una fattorizzazione di $f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\mu, \\sigma^2)$ del tipo\n$$f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\mu, \\sigma^2) = h(\\mathbf{x}) \\cdot g\\left( T_1(\\mathbf{x}), T_2(\\mathbf{x}) \\vert \\mu, \\sigma^2 \\right)$$\n\nOsserviamo che la densità congiunta $f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\mu, \\sigma^2)$ di $n$ normali indipendenti (vedi [qua](Statistiche%20Sufficienti.md#188fc0)) è una valida funzione $g(\\cdot, \\cdot \\vert \\mu, \\sigma^2))$ infatti\n$$g(\\mathbf{t} \\vert \\pmb{\\theta}) = g(t_1, t_2 \\vert \\mu, \\sigma^2) = \\exp{\\left\\[ -\\frac{1}{2\\sigma^2} \\left( (n-1)t_2+ n(t_1 - \\mu)^2 \\right) \\right\\]}$$\nricordando che $\\sum_i (x_i - \\overline{x})^2 = (n-1)s^2$.\n\nIn fine, ponendo $h(\\mathbf{x}) = 1$ otterremo che possiamo fattorizzare $$f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\pmb{\\theta}) = g(T(\\mathbf{x}) \\vert \\pmb{\\theta}) \\cdot h(\\mathbf{x})$$ ovvero che $\\overline{X}, S^2$ sono una statistica sufficiente per $\\mu, \\sigma^2$ nel modello normale.\n\n---\n\n# Statistica Sufficiente Minimale\n\nIn precedenza abbiamo visto che una statistica sufficiente è semplicemente un funzione che *\"riduce la complessità\"* di un campionamento, senza però perdere informazioni riguardo un determinato parametro.\n\nDato il fatto che possono esseistere molteplici statistiche sufficienti, ci si può chiedere se esistono statistiche *\"più sufficienti\"* di altre, ovvero funzioni che riducono al minimo la complessità dei dati.\n\nInfatti, supponiamo di avere una statistica sufficiente $T(\\mathbf{X})$ su un campione $\\mathbf{X}$, e supponiamo che esista una fuzione $r(T(\\mathbf{X})) = T^*(\\mathbf{X})$.\nSe $r$ è invertibile, ovvero esiste $r^{-1}$, allora si può dimostrare che anche $T^*$ è una statistica sufficiente, infatti\n$$f(\\mathbf{x} \\vert \\theta) = g(T(\\mathbf{x}) \\vert \\theta) \\cdot h(\\mathbf{x})$$\n$$\\implies f(\\mathbf{x} \\vert \\theta) = g\\left(r^{-1}(T^*(\\mathbf{x}) \\vert \\theta \\right) \\cdot h(\\mathbf{x})$$\nPonendo $g^*(x \\vert \\theta) = g(r^{-1}(x) \\vert \\theta)$ avremo che $$\\implies f(\\mathbf{x} \\vert \\theta) = g^*\\\\left(T^*(\\mathbf{x}) \\vert \\theta\\right) \\cdot h(\\mathbf{x})$$ ovvero $T^\\*$ è una statistica sufficiente.\n\n## Def. Statistica Sufficiente Minimale\n\nUna statistica sufficiente $T(\\mathbf{X})$ è detta **statistica sufficiente minimale** se, per ogni altra statistica sufficiente $T'$, $T$ è in funzione di $T'$. \n\nOsserviamo dire che $T$ è in funzione di $T'$ equivale a dire che se $T'(\\mathbf{x}) = T'(\\mathbf{y})$ allora $T(\\mathbf{x}) = T(\\mathbf{y})$, per ogni coppia di punti $\\mathbf{x}, \\mathbf{y}$ su cui $T$ è definito.\n\n## Teorema 6.2.13 - Condizione sufficiente\n\nSia una statistica sufficiente $T(\\mathbf{X})$ su un campionamento $X_1,...,X_n$ con densità congiunta $f(\\mathbf{x} \\vert \\theta)$.\nSe per ogni coppia di punti $\\mathbf{x}, \\mathbf{y}$ tali che $T(\\mathbf{x}) = T(\\mathbf{y})$ abbiamo che il quoziente $f(\\mathbf{x} \\vert \\theta) / f(\\mathbf{y} \\vert \\theta)$ è una **costante indipendente da** $\\theta$, allora avremo che $T$ è una **statistica sufficiente minimale**.\n\n### Esempio - Campione Esponenziale\n\nSia il campione $X_1, ..., X_n$ di [esponenziali](Distribuzioni.md#esponenziale)  $\\text{Exp}(\\lambda)$, con densità congiunta\n$$f(\\mathbf{x} \\vert \\lambda) = \\lambda^n \\exp(-\\lambda(x_1 + ... + x_n))$$\n\nStudiamo il quoziente $$\\frac{f(\\mathbf{x} \\vert \\lambda)}{f(\\mathbf{y} \\vert \\lambda)} = \\frac{\\lambda^n \\exp(-\\lambda(x_1 + ... + x_n))}{\\lambda^n \\exp(-\\lambda(y_1 + ... + y_n))} = \\exp{\\left(-\\lambda\\left(\\sum\\_{i=1}^{n}x_i - \\sum\\_{i=1}^{n}y_i \\right)\\right)}$$\nQuesto quoziente diventa indipendente dal parametro $\\lambda$ (ovvero *scompare*) solamente quando $\\sum_i x_i = \\sum_i y_i$.\n\nPer esempio, una statistica $T$ per la quale si ha un quoziente costante è $T(x_1, ..., x_n) = x_1 + ... + x_n$.\nCon questa statistica, se troviamo due punti $\\mathbf{x}, \\mathbf{y}$ tali che $T(\\mathbf{x}) = x_1 + ... + x_n = y_1 + ... + y_n = T(\\mathbf{y})$, avremo un **quoziente costante** (pari ad 1 in questo caso).\n\nÈ facile anche dimostrare (tramite il [Teorema di Fattorizzazione](Statistiche%20Sufficienti.md#teorema-di-fattorizzazione)) che $T$ è anche una statistia sufficiente per $\\lambda$, infatti basta porre\n$$g(T(\\mathbf{x}) \\vert \\lambda) = \\lambda^n \\exp{(-\\lambda T(\\mathbf{x}))}$$ e $$h(\\mathbf{x}) = 1$$\nDimostrando così che $T$ è una **statistica sufficiente minimale** per $\\lambda$.\n","lastmodified":"2022-08-29T13:39:16.789396981+02:00","tags":null},"/ISTI/Stima-per-intervalli-di-confidenza":{"title":"","content":"\n# Stima per intervalli di confidenza\n\n---\n\n## Definizione Intervallo di confidenza\n\nSia un [campione](Random%20Sample.md#random-sample) $X_1, ..., X_n$ da una popolazione con [densità](Distribuzioni%20Multivariate.md#joint-pdf) $f_X(x \\vert \\theta)$, dipendenti da un parametro $\\theta$ \u003cu\u003esconosciuto\u003c/u\u003e.\nSiano due [statistiche](Random%20Sample.md#46a026) $T_1, T_2$ tali che\n\n1. $T_1(\\mathbf{X}) \\leq T_2(\\mathbf{X})$ per ogni campione $\\mathbf{X} \\in \\mathbb{R}^n$\n1. $P(T_1(\\mathbf{X}) \\leq \\theta \\leq T_2(\\mathbf{X})) = 1 - \\alpha$\n\nAllora l'**intervallo** $\\left\\[ T_1(\\mathbf{X}), T_2(\\mathbf{X}) \\right\\]$ si dice **intervallo di confidenza con grado di confidenza** $1 - \\alpha$ per $\\theta$.\n\n---\n\n## Stima della media di una Normale con varianza nota\n\nSia un campione [normale](Distribuzioni.md#normale) $X_1, ..., X_n \\sim N(\\mu, \\sigma^2)$ con $\\mu$ **sconosciuto** e $\\sigma$ **noto**.\n\nConsideriamo l'[ipotesi nulla](Hypothesis%20Testing.md#137feb) $$H_0: \\mu = \\mu_0$$ e [ipotesi alternatica](Hypothesis%20Testing.md#7a2fae) $$H_1: \\mu \\neq \\mu_1$$\n\nDalla [teorema del limite centrale](CLT%20-%20Central%20Limit%20Theorem.md#clt-central-limit-theorem) sappiamo che **sotto ipotesi nulla** $H_0$ $$Z = \\frac{\\overline{X}*n - \\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0,1)$$\nPericò dato un generico $k\u003e0$ avremo  che $$P(-k \\leq Z \\leq k) = \\int*{-k}^{k}\\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2} , dx = \\Phi(k) - \\Phi(-k)$$\nPer **simmetria** di una normale standardizzata avremo che $$\\Phi(k) - \\Phi(-k) = 2\\int\\_{0}^{k}\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2} , dx = 2 \\Phi^*(k)$$ dove per comodità indichiamo con $$\\Phi^*(k) = \\int_0^{k}\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2} , dx$$\nOsserivamo che $$-k \\leq Z \\leq k \\iff -k \\leq \\frac{\\overline{X} - \\mu_0}{\\sigma/\\sqrt{n}} \\leq k \\iff \\overline{X} - \\frac{k\\sigma}{\\sqrt{n}} \\leq \\mu_0 \\leq \\overline{X} + \\frac{k\\sigma}{\\sqrt{n}}$$\nOvvero $$P(-k \\leq Z \\leq k) = P(T_1(\\mathbf{X}) \\leq \\mu \\leq T_2(\\mathbf{X})) = 2 \\Phi^\\*(k)$$ dove $$T_1(\\mathbf{X}) = \\overline{X} - \\frac{k\\sigma}{\\sqrt{n}}$$ e $$T_2(\\mathbf{X}) = \\overline{X} + \\frac{k\\sigma}{\\sqrt{n}}$$\n\nPerciò se volessimo che tale porbabilità sia pari a $1-\\alpha$ basterà risolvere l'equazione $$2\\Phi^{*}(k) = 1-\\alpha$$ $$k = \\Phi^{*-1}\\left(\\frac{1-\\alpha}{2}\\right)$$\nPer esempio, nel nostro caso, ponendo $k$ pari al quantile $\\phi\\_{1 - \\alpha/2}$ otterremo un intervallo di confidenza con probablità $$P(-\\phi\\_{1-\\alpha/2} \\leq Z \\leq \\phi\\_{1-\\alpha/2}) = (1-\\alpha/2) - (1 - (1-\\alpha/2)) = 1 - \\alpha$$\nSe volessimo un grado di confidenza del $95%$ basta verificare che $$1-\\alpha = 0.95 \\implies \\alpha/2 = 0.025 \\implies 1 -\\alpha/2 = 0.975$$\nBasterà consultare la [tabella dei quantili](quantili.pdf) della normale standard, e verificare che $$\\phi\\_{1-\\alpha/2} = \\phi\\_{0.975} = 1.96$$ \n\nIn conclusione $$P\\left(\\overline{X} - \\frac{1.96\\sigma}{\\sqrt{n}} \\leq \\mu_0 \\leq \\overline{X} + \\frac{1.96\\sigma}{\\sqrt{n}}\\right) \\approx 0.95$$ ovvero se $\\mu_0$ appartiene all'**intervallo aleatorio** $\\left\\[ T_1, T_2\\right\\]$  allora possiamo dire con una confidenza del $95%$ che il reale valore della media $\\mu$ è $\\mu_0$.\n\n### Osservazione importante\n\nImportante osservare che possono esistere svariati intervalli $\\left\\[ a,b\\right\\]$ la cui probabilità $$P(\\theta_0 \\in \\left\\[a,b \\right\\]) = 1 - \\alpha$$\nÈ però preferibile trovare sempre l'intervallo con **ampiezza** $b-a$ più piccolo possibile.\n\nNel caso di distribuzioni **simmetriche**, come la normale standard, è possibile dimostrare che quello di ampiezza minima è sempre quello simmetrico e centrato in zero, del tipo $\\left\\[ -k, k \\right\\]$ (per $k \\in \\mathbb{R}^+$).\n\n---\n\n## Stima della media di una Normale con varianza sconosciuta\n\nSia un campione [normale](Distribuzioni.md#normale) $X_1, ..., X_n \\sim N(\\mu, \\sigma^2)$ con $\\mu$ e $\\sigma$ **sconosciuti**.\n\nConsideriamo le ipotesi $$H_0: \\mu = \\mu_0; ; H_1: \\mu \\neq \\mu_1$$\nNon conoscendo $\\sigma$ potremmo pensare di **stimarlo**, per esempio con la [varianza campionaria](Random%20Sample.md#varianza-campionaria) $S = \\sqrt{S^2}$.\n\nPurtroppo però la statistica $$T = \\frac{\\overline{X} - \\mu_0}{S/\\sqrt{n}}$$ non segue una [normale standardizzata](Distribuzioni.md#normale-standard) $N(0,1)$, nemmeno sotto ipotesi nulla $H_0$.\n\nSappiamo però che sotto ipotesi nulla $H_0$, la statistica $T$ segue una [distribuzione t di Student](Distribuzioni.md#distribuzione-t-di-stundet) con $n-1$ *gradi di libertà*.\n\nPerciò, scegliendo due valori $t_1 \\leq t_2$, avremo che $$t_1 \\leq T \\leq t_2 \\iff \\underbrace{\\overline{X} - t_2\\frac{S}{\\sqrt{n}}}*{T_1} \\leq \\mu_0 \\leq \\underbrace{\\overline{X} - t_1\\frac{S}{\\sqrt{n}}}*{T_2}$$ [tabella dei quantili](quantili.pdf) della\nPer via della **simmetria** della distribuzione *t* di Student sappiamo che l'intervallo di ampiezza minima è quello **simmetrico**, ovvero con $t_1 = - t_2$.\nPerciò consultiamo la [tabella dei quantili](quantili.pdf) della distribuzion *t* di Student e poniamo $t_2 = \\phi\\_{1-\\alpha/2}$.\n\nQuindi $$P(T \\in \\left\\[ - \\phi\\_{1-\\alpha/2}, \\phi\\_{1-\\alpha/2}\\right\\]) = P(\\mu_0 \\in \\left\\[ T_1, T_2 \\right\\]) = 1 - \\alpha$$\n\nSupponiamo di avere $n=10$ e di volere un *grado di confidenza* di $1 - \\alpha = 95%$.\nConsultando la [tabella dei quantili](quantili.pdf) avremo che\n$$\\begin{align\\*}\n1-\\alpha \u0026= 0.95\\\\\n\\\\implies \\alpha/2 \u0026= 0.025\\\\\n\\\\implies 1-\\alpha/2 \u0026= 0.975\\\\\n\\\\implies t_2 \u0026= \\phi\\_{1-\\alpha/2} = \\phi\\_{0.975} = 2.262\n\\\\end{align\\*}$$\n\n---\n\n## Stima tramite MLE\n\nPrendiamo un campione $X_1, ..., X_n$ dipendente da un parametro $\\theta$ \u003cu\u003esconosciuto\u003c/u\u003e, e consideriamo le ipotesi $$H_0: \\theta = \\theta_0;; H_1: \\theta \\neq \\theta_0$$\nSia $\\hat\\theta\\_{ML}$ il [MLE](Stimatore%20di%20Massima%20Verosimiglianza.md#stimatore-di-massima-verosimiglianza-mle) per $\\theta$.\nSappiamo che per campioni grandi (asintoticamente) avremo che $$\\sqrt{nI(\\hat\\theta\\_{ML})} \\cdot (\\hat\\theta\\_{ML} - \\theta_0) \\sim N(0,1)$$ (vedi [proprietà asintotiche dei MLE](Stimatore%20di%20Massima%20Verosimiglianza.md#proprieta-asintotiche-molto-importanti)).\n\nPerciò definendo la statistica $$Z = \\sqrt{nI(\\hat\\theta\\_{ML})} \\cdot (\\hat\\theta\\_{ML} - \\theta_0)$$ possiamo eseguire la stima per intervalli di confidenza come in precedenza.\n\nInfatti $$P(-\\phi\\_{1-\\alpha/2} \\leq Z \\leq \\phi\\_{1-\\alpha/2}) = P\\left(\\hat\\theta\\_{ML}-\\frac{\\phi\\_{1-\\alpha/2}}{\\sqrt{nI(\\hat\\theta\\_{ML})}} \\leq \\theta_0 \\leq \\hat\\theta\\_{ML}+\\frac{\\phi\\_{1-\\alpha/2}}{\\sqrt{nI(\\hat\\theta\\_{ML})}}\\right) = 1-\\alpha$$\n\n---\n\n## Stima di $p$ per una Binomiale\n\n\\[DA FINIRE...\\]\n","lastmodified":"2022-08-29T13:39:16.784145678+02:00","tags":null},"/ISTI/Stimatore-di-Massima-Verosimiglianza":{"title":"","content":"\n# Stimatore di Massima Verosimiglianza - MLE\n\nSia un [campionamento](Random%20Sample.md#random-sample) $\\mathbf{X} = (X_1, ..., X_n)$.\nPer ogni possibile valore osservabile $\\mathbf{x}$, sia $\\hat{\\theta}(\\mathbf{x})$ un **parametro** che **massimizza** la [funzione di massima verosimiglianza](Verosimiglianza.md#likelihood-function) $L(\\theta \\vert \\mathbf{x})$ (notare $\\mathbf{x}$ fissato), ovvero\n$$\\hat{\\theta}(\\mathbf{x}) = \\arg \\max\\_{\\theta \\in \\Theta} L(\\theta \\vert \\mathbf{x})$$\n\nAllora uno **stimatore di massima verosimiglianza** (o **MLE - maximum likelihood estimator**) del parametro $\\theta$ basato sul campione $\\mathbf{X}$ è $\\hat{\\theta}(\\mathbf{X})$.\n\nDato che nel caso multivariato $L$ è uguale al prodotto delle singole densità, conviene calcolare il massimo della **log-verosimiglianza**, ovvero il logaritmo di $L(\\theta \\vert \\mathbf{x})$.\nPer via della **monotonia** del logaritmo, un punto di massimo per $L$ equivale a un punto di massimo anche per $\\ln{L}$.\n\nPerciò *derivando* in $\\theta$ la *log-verosimiglianza* e ponendola pari a $0$ troveremo un potenziale punto di massimo.\nPer assicurarci che tale punto è di massimo e non di minimo, servirà fare la seconda derivata e virificare che sia **minore** di $0$.\n\nCi riferiremo alla derivata della log-verosimiglianza con **score function** $$S(\\theta, \\mathbf{X}) = \\frac{d}{d \\theta}\\ln{L(\\theta \\vert \\mathbf{X})} = \\sum\\_{i=1}^{n} \\frac{d}{d \\theta}\\ln{f(x_i \\vert \\theta)}$$ ^03be6d\n\n## Esempio - Normale\n\nSia un campionamento $X_1, ..., X_n$ di $N(\\theta,1)$.\nAvremo quindi che la verosimiglianza sarà pari a $$L(\\theta \\vert \\mathbf{x}) = \\prod\\_{i=1}^{n}\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(x_i - \\theta)^2} = (2\\pi)^{-n/2}e^{-\\frac{1}{2}\\sum_i (x_i - \\theta)^2}$$ \nMentre la *log-verosimiglianza* sarà $$\\ln{(L(\\theta \\vert \\mathbf{x}))} = -\\frac{1}{2}\\sum\\_{i=1}^{n}(x_i - \\theta)^2 - \\frac{n}{2}\\ln{(2\\pi)}$$\n\nPer calcolare il $\\theta$ che massimizza tale quantità inizamo col calcolare la derivata prima $$\\frac{d}{d\\theta} \\ln{(L(\\theta \\vert \\mathbf{x}))} = - \\frac{1}{2} \\sum\\_{i=1}^{n}2(x_i - \\theta)(-1)= \\sum\\_{i=1}^{n}(x_i - \\theta) = n \\overline{x} - n \\theta$$\nTale derivata è pari a $0$ per $\\theta = \\overline{x}$.\n\nOra bisogna capire se tale valore massimizza oppure minimizza la verosimiglianza (ovvero se è un punto di *massimo* o di *minimo*).\nCalcoliamo quindi la derivata seconda $$\\frac{d^2}{d\\theta^2} \\ln{(L(\\theta \\vert \\mathbf{x}))} \\Big\\vert\\_{\\theta = \\overline{x}} = -n\\Big\\vert\\_{\\theta = \\overline{x}} = -n \\\u003c 0$$\nPerciò $\\theta = \\overline{x}$ è un punto di massimo (quantomeno locale).\n\nFacendo il limite per $\\theta \\to \\pm \\infty$ si ha che la *log-verosimiglianza* tende a $-\\infty$, perciò $\\theta = \\overline{x}$ è l'unico punto di massimo.\n\nIn conclusione $\\hat{\\theta} = \\overline{X}$ è uno **stimatore di massima verosimiglianza**.\n\n## Esempio - Bernoulli\n\nSia il campionamento $X_1, ..., X_n$ di bernoulliane di parametro sconosciuto $p = \\theta$.\nPerciò la verosimiglianza risulta essere $$L(\\theta \\vert \\mathbf{x}) = \\prod\\_{i=1}^{n} \\theta^{x_i}(1-\\theta)^{1 - x_i} = \\theta^{s}(1-\\theta)^{n-s}$$ dove $s = x_1 + ... + x_n$.\n\nLa *log-verosimiglianza* risulta invece $$\\ln{(L(\\theta \\vert \\mathbf{x}))} = s\\log(\\theta) + (n-s)\\log(1-\\theta)$$ con derivarte $$\\frac{d}{d\\theta} \\ln{(L(\\theta \\vert \\mathbf{x}))} = \\frac{s}{\\theta} - \\frac{n-s}{1 - \\theta}$$ e $$\\frac{d^2}{d\\theta^2} \\ln{(L(\\theta \\vert \\mathbf{x}))} = -\\frac{s}{\\theta^2} - \\frac{n-s}{(1 - \\theta)^2}$$\n\nLa derivata prima è nulla quando $$\\begin{align\\*}\n\\\\frac{s}{\\theta} - \\frac{n-s}{1 - \\theta} \u0026= 0\\\\\n(1-\\theta)s - \\theta(n-s) \u0026= 0\\\\\ns - \\cancel{s\\theta} - n\\theta + \\cancel{s\\theta} \u0026= 0\\\\\n\\\\theta \u0026= \\frac{s}{n}\n\\\\end{align\\*}$$ ovvero quando $\\theta = \\overline{x}$\n\nÈ possibile verificare che tale punto è anche un punto di massimo **globale**, perciò avremo che $\\hat{p} = \\overline{X}$ è uno stimatore di massima verosimiglianza.\n\n---\n\n# Proprietà di un MLE\n\n## Invarianza di uno MLE\n\nSia $\\hat{\\theta}$ uno **stimatore di massima verosimiglianza** di un parametro $\\theta$.\nAllora per ogni funzione $\\tau(\\theta)$ avremo che $\\tau(\\hat{\\theta})$ è uno stimatore di massima verosimiglianza per $\\tau(\\theta)$.\n\n## Proprietà asintotiche (molto importanti)\n\nGli stimatori di massima verosimiglianza possono essere distorti ma, sotto condizioni abbastanza generali, sono però **consistenti** e, per $n$ che tende ad infinito, risultano **asintoticamente corretti** e **massimamente efficienti**.\nInoltre, sempre per $n$ che tende ad infinito, la loro distribuzione tende ad una normale.\n\nIn termini tecnici, uno MLE $\\hat\\theta\\_{ML}$ per un parametro $\\theta$ è:\n\n1. **Asintoticamente corretto (non distorto)**: anche se $\\hat\\theta\\_{ML}$ risulta **distorto**, asintoticamente avremo sempre che $$\\lim\\_{n \\to \\infty} \\mathbb{E}\\left\\[ \\hat\\theta\\_{ML} \\right\\] = \\theta$$\n1. **Consistente**: ovvero che $\\hat\\theta\\_{ML}$ **[converge in probabilità](Convergenza.md#convergenza-in-probabilita)** a $\\theta$ $$\\hat{\\theta}\\_{ML} \\xrightarrow{p} \\theta$$\n1. **Asintoticamente efficiente**: la varianza di $\\hat{\\theta}*{ML}$ tende asintoticamente la suo **[limite inferiore](Cram%C3%A9r-Rao%20Inequality.md#cramer-rao-inequality)**, ed essendo $\\hat{\\theta}*{ML}$ asintoticamente non distorto avremo che $$\\lim\\_{n \\to \\infty} \\text{Var}(\\hat\\theta\\_{ML}) = \\frac{1}{I(\\theta)}$$\n1. **Asintoticamente normale**: per $n \\to \\infty$ avremo che $$\\hat\\theta\\_{ML} \\sim N\\left(\\theta, \\frac{1}{I\\_{\\mathbf{X}}(\\theta)}\\right) = N\\left(\\theta, \\frac{1}{nI\\_{X_1}(\\theta)}\\right)$$ oppure normalizzando $$\\sqrt{n}(\\hat\\theta\\_{ML} - \\theta) \\approx \\frac{S(\\theta \\vert \\mathbf{X})}{nI(\\theta)} \\sim N\\left(0, \\frac{1}{I(\\theta)}\\right)$$ ^c3b404\n","lastmodified":"2022-08-29T13:39:16.73885749+02:00","tags":null},"/ISTI/Stimatori-Puntuali":{"title":"","content":"\n# Stimatori puntuali\n\nUno **stimatore puntuale** è una qualsiasi statistica $T(X_1, ..., X_n)$ usata per stimare il valore di uno o più parametri **sconosciuti**.\n\nPiù in generale, supponiamo di avere una distribuzione $$f(\\mathbf{X} \\vert \\theta_1, ...,  \\theta_k)$$ con $\\theta_1, ..., \\theta_k \\in \\Theta$ dei parametri dai quali la distribuzione dipende.\n\nEsistono due filosofie di pensiero su come poter stimare i parametri:\n\n* **Approccio Frequentista** \\[da fare\\]\n* **Approccio Bayesiano** \\[da fare\\]\n\nQuello che in generale si vuole è che uno stimatore $T(\\mathbf{X})$ sia il più *\"simile\"* possibile al parametro da stimare $\\theta$.\nIn base ai valori che il campione $\\mathbf{X}$ può assumere, la stima $T$ a sua volta assume valori differenti.\nPerciò per *\"simile\"* si intende che a prescindere dal campione, $T$ assume dei valori concentrati in un intorno di $\\theta$ con alta probabilità.\n\nAbbiamo quindi bisogno di *quantificare* la qualità di uno stimatore, per decidere quale è meglio di altri.\n\nUna prima proprietà desiderabile per uno stimatore è che esso sia **non distorto** o **un-biased**, ovvero che la sua media corrisponda al parametro desiderato $$\\mathbb{E}*{\\theta} \\left\\[ T(\\mathbf{X}) \\right\\] = \\theta, ; \\forall \\theta \\in \\Theta$$\nPerciò a prescindere dal valore del parametro, uno stiamtore non distorto in media assumerà sempre il valore di $\\theta$ (ovviamente calcolando la media tenendo conto del valore che $\\theta$ assume se necessario, ovvero calcolando $\\mathbb{E}*{\\theta}$).\n\nUn'altra proprietà desiderata è che la stiame $T(\\mathbf{X})$ sia il più possibile **concentrata** attorno al suo valore atteso.\nPerciò si vuole minimizzare la sua varianza $$\\text{minimize Var}\\_{\\theta}(T(\\mathbf{X}))$$\n\nPiù in generale uno stiamtore è detto **UMVUE** (**uniformly minimum variance unbiased estimator**) se è **un-biased** e se per ogni $\\theta$ possibile abbia una varianza più piccola rispetto a tutti gli altri stimatori (ovvero la minimizza).\n\nAltri termini utili sono:\n\n* il **bias** o **distorsione** $$\\text{bias}(T) = \\mathbb{E}\\_{\\theta} \\left\\[ T(\\mathbf{X}) \\right\\] - \\theta$$ Ovviamente se $\\text{bias}(T) = 0$ allora $T$ è non distorto. ^401481\n* L'**errore quadratico medio** $$\\text{MSE}(T) = \\mathbb{E}\\left\\[ \\left(T(\\mathbf{X}) - \\theta \\right)^2 \\right\\] = \\text{Var}\\_{\\theta}(T(\\mathbf{X})) + \\text{bias}(T)^2$$\n\n### Esempio\n\nRichiamando il [Random Sample \u003e Teorema 5 2 6 - Proprietà importanti](Random%20Sample.md#teorema-5-2-6-proprieta-importanti), si può dimostrare che $\\overline{X}$ e $S^2$ sono entrambi **stimatori non distorti** per $\\mu$ e $\\sigma^2$, ovvero $$\\text{bias}(\\overline{X}) = 0$$ $$\\text{bias}(S^2) = 0$$\n\nInvece sappiamo che la v.a. $(n-1)S^2/\\sigma^2 \\sim \\chi^2\\_{n-1}$ ([vedi](Distribuzioni.md#chi-quadro-proprieta)) con media $n-1$ e varianza $2(n-1)$.\nPerciò $$\\text{Var}(S^2) = \\text{Var}(\\sigma^2 \\chi^2\\_{n-1}/(n-1)) = \\left(\\frac{\\sigma^2}{n-1}\\right)^2 \\cdot \\text{Var}(\\chi^2\\_{n-1}) = 2\\frac{\\sigma^4}{n-1}$$ e quindi $$\\text{MSE}(S^2) = \\text{Var}(S^2) + \\underbrace{\\text{bias}(S^2)}\\_{=0} = 2\\frac{\\sigma^4}{n-1}$$\n\nConsideriamo ora un nuovo stimatore della varianza, un pochino più distorto $$\\hat{\\sigma}^2 = \\frac{\\sum\\_{i=1}^{n}(X_i - \\overline{X})^2}{n} = \\frac{n-1}{n}S^2$$\n\nCalcoliamo la sua media $$\\mathbb{E}\\left\\[ \\hat{\\sigma}^2 \\right\\] = \\mathbb{E}\\left\\[ \\frac{n-1}{n}S^2 \\right\\] = \\frac{n-1}{n}\\sigma^2$$ e il suo bias $$\\text{bias}(\\hat{\\sigma}^2) = \\sigma^2 - \\frac{n-1}{n}\\sigma^2 = -\\frac{\\sigma^2}{n}$$\nCalcoliamo ora l'errore di tale stimatore $$\\begin{align\\*}\n\\\\text{MSE}(\\hat{\\sigma}^2)\n\u0026= \\text{Var}(\\hat{\\sigma}^2) - \\frac{\\sigma^2}{n}\\\\\n\u0026= \\left( \\frac{n-1}{n} \\right)^2 \\text{Var}(S^2) - \\frac{\\sigma^2}{n}\\\\\n\u0026= 2\\sigma^4\\frac{n-1}{n^2} - \\frac{\\sigma^2}{n}\\\\\n\u0026\\leq 2\\sigma^4\\frac{n-1}{n^2}\\\\\n\u0026= 2\\frac{\\sigma^4}{n}\\frac{n-1}{n}\\\\\n\u0026\\\u003c 2\\frac{\\sigma^4}{n-1}\\underbrace{\\frac{n-1}{n}}\\_{\\\u003c1}\\\\\n\u0026\\\u003c 2\\frac{\\sigma^4}{n-1} = \\text{MSE}(S^2)\n\\\\end{align\\*}$$ ovvero abbiamo dimostrato che benché $\\hat{\\sigma}^2$ sia distorto, esso ha un errore minore di quello precedente, ovvero $\\text{MSE}(\\hat{\\sigma}^2) \\\u003c \\text{MSE}(S^2)$.\nCiò significa che $\\hat{\\sigma}^2$ è mediamente più concentrato attorno al valore del parametro da stimare.\n\nPer fortuna entrambi gli errori tendono a $0$ al crescere di $n$, perciò entrambi tendono asintoticamente al $\\sigma^2$.\n\nTale proprietà di convergenza asintotica è detta anche **consistenza**\n\n## Consistenza di uno stimatore\n\nUno stimatore è detto **consistente** se [tende in probabilità](Convergenza.md#convergenza-in-probabilita) al parametro interessato $T(\\mathbf{X}) \\xrightarrow{p} \\theta$, ovvero se $$\\lim\\_{n \\to \\infty}P(\\vert T(\\mathbf{X}) - \\theta \\vert \\\u003c \\varepsilon) = 1$$ per ogni $\\varepsilon \u003e 0$.\n\nPerciò uno stimatore consistente non è per forza non distorto, ma lo si può considerare come **\"asintoticamente non distorto\"**.\n\n---\n\n# Metodi frequentisti per trovare stimatori\n\nVedi:\n\n* [Metodo dei Momenti](Metodo%20dei%20Momenti.md)\n* [Stimatore di Massima Verosimiglianza](Stimatore%20di%20Massima%20Verosimiglianza.md)\n","lastmodified":"2022-08-29T13:39:16.820688411+02:00","tags":null},"/ISTI/Test-chi-quadro":{"title":"","content":"\n# Test goodness-of-fit (bontà d'adattamento)\n\nSupponiamo di avere un campione di dati $\\mathbf{X} = X_1, ..., X_n$, e che esistano $k$ **classi di eventi possibili** $A_1, ..., A_k$.\nOvvero ogni elemento $X_i$ può risolversi in uno solo dei $k$ possibili eventi.\nPerciò, indichiamo con $p_j$ la probabilità che avvenga l'evento $j$-esimo $$P(X_i \\in A_j) = p_j ;; \\forall i=1,...,n$$\n\nDato che gli eventi formano una partizione di $\\Omega$, avremo quindi che $$\\sum\\_{i=1}^{k} p_i = 1$$\n\nPossiamo modellare il nostro esperimento con una [distribuzione multinomiale](Distribuzioni.md#multinomiale-multivariata).\nIndichiamo con $$Y_j = \\sum\\_{i=1}^{n} 1({X_i \\in A_j}) ;; \\forall j =1, ..., k$$ ovvero $Y_j$ **conta** il numero di volte che nel campione $\\mathbf{X}$ occorre l'evento $j$-esimo $E_j$.\n\nAvremo quindi che $$\\mathbf{Y} = (Y_1, ..., Y_k) \\sim \\text{Multi}(n, k, (p_1, ..., p_k))$$\n\nDato che i parametri $\\mathbf{p} = (p_1, ..., p_k)$ sono ignoti, consideriamo la seguente *[ipotesi nulla](Hypothesis%20Testing.md#349ec3)* $$H_0: \\mathbf{p} = \\mathbf{p}^{(0)}$$\n\nDefiniamo ora la statistica $$T = \\sum\\_{i=1}^{k}\\frac{(Y_i - np^{(0)}\\_i)^2}{np^{(0)}\\_i}$$\n(Vedere media distribuzione multinomiale!).\n\nÈ possibile dimostrare (\\[TO DO\\]) che (**sotto ipotesi nulla**) *asintoticamente* $T \\sim \\chi^2\\_{k-1}$ segue una distribuzione [chi-quadro](Distribuzioni.md#chi-quadro) con $k-1$ gradi di libertà.\nIl numero di gradi di libertà è $k-1$ perché siamo vincolati dal fatto che $p_1 + ... + p_k = 1$.\n\nRiconducendoci quindi ad una distribuzione *chi-quadro* siamo in gradi di eseguire uno [t-test](Test%20pi%C3%B9%20comuni.md#t-test-di-student).\nConsultando quindi la *tabella dei quinatili di una chi-quadro* possiamo facilmente definire un test con precisione $1-\\alpha$.\n\nUn modo più semplice ed empirico per vedere questo test è il seguente:\n\n \u003e \n \u003e Supponiamo di avere $A_1, ..., A_k$ come insieme di possibili eventi.\n \u003e Prendiamo un campione di $n$ elementi.\n \u003e Siano $O_1, ..., O_k$ la frequenza (il numero di volte) con il quale i singoli eventi si sono presentati, dette anche **frequenze osservate**.\n \u003e Supponiamo che ci aspettavamo di osservare le frequenze $E_1, ..., E_k$, dette **frequenze teoriche** o **attese**.\n \u003e Nel nostro caso $E_i$ sta ad indicare $np^{(0)}\\_i$, per ogni evento $i$.\n \u003e \n \u003e |Evento|A_1|A_2|...|A_k|\n \u003e |------|---|---|---|---|\n \u003e |Frequenze osservate|O_1|O_2|...|O_k|\n \u003e |Frequenze attese|E_1|E_2|...|E_k|\n \u003e \n \u003e Allora la nostra statistica sarà $$T = \\sum\\_{i=1}^{k}\\frac{(O_i - E_i)^2}{E_i} \\sim \\chi^2\\_{k-1}$$\n\n## Esempio\n\nUn dado viene lanciato 2000 volte e i vari risultati escono con le seguenti sequenze\nEsito | Occorrenza\n-|-\n1|388\n2|322\n3|314\n4|316\n5|344\n6|316\n\nSi può affermare che il dado è non equo?\nConsideriamo come *ipotesi nulla* $$H_0: p_i = 1/6 ; \\forall i =1,...,6$$ ovvero che il dado sia equo.\n\nSotto ipotesi nulla avremo la seguente statistica $$T = \\sum\\_{i=1}^{6}\\frac{(Esito_i - 2000/6)^2}{2000/6} = 12.616$$\nSappiamo che $T$ segue una distribuzione $\\chi^2$ con $6-1 = 5$ gradi di libertà.\n\nSupponiamo di voler avere un errore $\\alpha = 0.05 = 5%$.\nDando uno sguardo alle [tabelle dei quantili](quantili.pdf) abbiamo che\n$$P(T \\leq 11.070) = 0.95 \\implies P(T = 12.616) \\leq P(T \u003e 11.070) = 1 - 0.95 = \\alpha$$\nOvvero la probabilità che $T$ abbia assunto tale valore, sotto ipotesi $H_0$ è minore di $\\alpha$, dobbaimo perciò **rifiutare** $H_0$.\n\n---\n\n# Test del chi quadro per tabelle di contingenza\n\nUn altro tipo di test $\\chi^2$ è quello per **tabelle di contingenza**.\nSupponiamo di avere un campione di $n$ elementi, classificabili due **differenti criteri**.\nPer esempio, supponiamo di aver campionato da 5 differenti stati dell'unione europea $n$ persone, e di aver chiesto che frutto preferiscono mangiare d'estate tra cocco 🥥, anguria 🍉 o ananas 🍍.\n\nPossiamo rappresentare tali dati come una tabella dove abbiamo $r$ righe che rappresentano le classi del primo criterio, e $c$ colonne che rappresentano le classi del secondo criterio.\n\\\\ | 🥥 | 🍉 | 🍍\n-|-|-|-\n🇮🇹| 40 | 80 | 21\n🇫🇷 | 45 | 67 | 35\n🇩🇪 | 58 | 17 | 69\n🇪🇸 | 12 | 33 | 91\n🇵🇹| 7 | 101 | 38\n\nIl test $\\chi^2$ per **tabelle di contingenza** serve per verificare l'**ipotesi di indipendenza tra i due criteri di valutazione** (nel nostro caso voglia valutare l'indipendenza tra nazionalità e gusti).\n\nPossiamo modellare i nostri dati come una [multinomiale](Distribuzioni.md#multinomiale-multivariata) ${X\\_{ij} : 1 \\leq i \\leq r \\land 1 \\leq j \\leq c}$ dove ogni evento $(i,j)$ avviene con probabilità $p\\_{ij}$.\nSe c'è indipendenza tra i due criteri allora avremo che esistono due vettori $\\underline{\\alpha} = (\\alpha_1, ..., \\alpha_r)$ e $\\underline{\\beta} = (\\beta_1, ..., \\beta_c)$ tali che $$\\forall i,j ; p\\_{ij} = \\alpha_i \\cdot \\beta\\_{j}$$\nQuesta sarà la nostra **ipotesi nulla**.\n\nPer stimare $\\underline{\\alpha}, \\underline{\\beta}$ iniziamo col fare le **somme marginali** di righe e colonne, ovvero\n\n$$r_i = \\sum\\_{j=1}^{c} X\\_{ij}$$\n$$c_j = \\sum\\_{i=1}^{r} X\\_{ij}$$\nOsserviamo che $$n = \\sum\\_{i=1}^{r} r_i = \\sum\\_{j=1}^{c} c_j$$\n\\\\ | 🥥 | 🍉 | 🍍 | $r_i$ \n-|-|-|-|-\n🇮🇹 | 40 | 80  | 21 | 141\n🇫🇷 | 45 | 67  | 35 | 147\n🇩🇪 | 58 | 17  | 69 | 144\n🇪🇸 | 12 | 33  | 91 | 136\n🇵🇹 | 7  | 101 | 38 | 146\n$c_j$  |162 | 298 | 254 | $n = 714$\n\nApprossimiamo quindi il valore atteso come $$\\mathbb{E}\\left\\[ X\\_{ij} \\right\\] = np\\_{ij} \\approx n \\cdot \\frac{r_i}{n} \\cdot \\frac{c_j}{n} = \\frac{r_i c_j}{n}$$\nA questo punto, definiamo la statistica $$T = \\sum\\_{i,j} \\frac{\\left(X\\_{ij} - \\dfrac{r_ic_j}{n}\\right)^2}{\\dfrac{r_ic_j}{n}}$$\nSotto ipotesi nulla $H_0$ avremo che $T \\sim \\chi^2\\_{(r-1)(c-1)}$ ovvero segue una [distribuzione chi-quadro](Distribuzioni.md#chi-quadro) con $(r-1) \\cdot (c-1)$ **gradi di libertà**.\nPerciò noi avremo\n$$T = \\frac{(40 - 31.99)^2}{31.99} + ... + \\frac{(38 - 51.938)^2}{51.938} = 203.277$$\n\nNel nostro caso, la probabilità che $T$ assuma il valore osservato è pressoche nulla sotto ipotesi $H_0$, perciò troppo rilevante per essere solamente un caso.\n\nPossiamo rifiutare $H_0$, e supporre che invece esista qualche dipendenza tra i gusti e la nazionalità.\n\n## Esempio semplice\n\nSupponiamo di aver testato due antibiotici, e di aver contato i guariti alla fine della cura sperimentale.\nRaccogliamo tutti i dati, e otteniamo la seguente tabella di contingenza.\n\n|Trattamento \\ Esito|Guariti|Non guariti|Totale|\n|:------------------|:-----:|:---------:|:----:|\n|Antibiotico 1|52|10|62|\n|Antibiotico 2|40|21|61|\n|**Totale**|92|31|123|\n\nStimiamo i valori attesi con la formula \n$$np\\_{ij} = \\frac{r_ic_j}{n}$$\nTrattamento \\ Esito Atteso | Guariti Attesi | Non guariti Attesi\n:-|:-:|:-:\nAntibiotico 1 | 46.37 | 15.63\nAntibiotico 2 | 45.63 | 15.37\n\nCi si chiede quindi se effeticamente il primo trattamento è migliore del primo oppure no, ovvero se il numero dei guarti dipende dal trattamento (la nostra **ipotesi nulla** $H_0$).\n\nSotto $H_0$ avremo quindi\n$$T = \\frac{(52-46.37)^2}{46.37} + \\frac{(10-15.63)^2}{15.63} + \\frac{(40-45.63)^2}{45.63}+ \\frac{(21-15.37)^2}{15.37} = 5.46$$\n\nSotto ipotesi nulla $T \\sim \\chi^2_1$ e quindi la probabilità che abbia assunto il valore osservato $5.46$ è compresa tra il $2.5%$ e l'$1%$ (ovvero è poco probabile che $H_0$ sia vero).\n\nPossiamo rifiutare $H_0$, e affermare che \n\n \u003e \n \u003e **Antibiotico 1 è migliore di Antibiotico 2 con una certezza del 97.5%**\n\nInfatti, osservando le [tabelle](quantili.pdf) avremo che \n$$P(T \\geq 5.46) \\leq P(T \\geq 5.024) = 0.025$$\n$$P(T \\geq 5.46) \\geq P(T \\geq 6.635) = 0.01$$\n","lastmodified":"2022-08-29T13:39:16.832346277+02:00","tags":null},"/ISTI/Test-pi%C3%B9-comuni":{"title":"","content":"\n# Test più comuni\n\n# z-test\n\n## Distribuzione normale, varianza nota, media sconosciuta - part 1\n\nSia il [campionamento](Random%20Sample.md#random-sample) $X_1, ..., X_n$ da una popolazione [normale](Distribuzioni.md#normale) $N(\\theta, \\sigma^2)$, con $\\theta$ sconosciuto.\nConsideriamo l'*[ipotesi nulla](Hypothesis%20Testing.md#349ec3)* $$H_0: \\theta = \\theta_0$$ e quella *alternativa* $$H_1: \\theta = \\theta_1$$\n\nConsideriamo ora il valore $$T = \\frac{\\overline{X} - \\theta_0}{\\sigma/\\sqrt{n}}$$ e definiamo il test $$\\text{rifiuto } H_0 \\iff |T| \u003e c$$ dove $c$ verrà scelto appositamente per rendere il valore di $\\alpha = P(\\mathbf{X} \\in C \\vert \\theta = \\theta_0)$ (rifiuto $H_0$ nonstante sia vera) il più piccolo possibile.\n\nCalcoliamo qual è il valore di $c$ migliore che ci da una probabilità di errore $\\alpha$ abbastanza piccola\nSotto l'ipotesi nulla (ovvero se $\\theta = \\theta_0$) avremo che $T \\sim N(0,1)$, perciò scgliendo per esempio $c = 1.96$ avremo che\n$$\\begin{align\\*}\n\\\\alpha\n\u0026= P(\\mathbf{X} \\in C \\vert \\theta = \\theta_0)\\\\\n\u0026= P(|T| \u003e 1.96)\\\\\n\u0026= 1 - P(-1.96 \\leq T \\leq 1.96)\\\\\n\u0026= 1 - (\\Phi(1.96) - \\Phi(-1.96))\\\\\n\u0026\\approx 5%\n\\\\end{align\\*}$$\nSe per esempio invece volessimo trovare un $c$ che ci dia una probabilità di errore più bassa, per esempio $\\alpha \\approx 2.5%$ dobbiamo risolvere l'equazione in $c$\n$$\\begin{align\\*}\n0.025\n\u0026= P(\\mathbf{X} \\in C \\vert \\theta = \\theta_0)\\\\\n\u0026= P(|T| \u003e c)\\\\\n\u0026= 1 - P(-c \\leq T \\leq c)\\\\\n\u0026= 1 - (\\Phi(c) - \\Phi(-c))\n\\\\end{align\\*}$$\n\n^3d2fb2\n\novvero risolvendo $$0.975 = \\Phi(c) - \\Phi(-c)$$\nPerciò nel nostro caso, con $c = 2.25$ avremo all'incirca il $2.5%$ che il test commetta un errore.\n\n## Distribuzione normale, varianza nota, media sconosciuta - part 2\n\nSupponiamo di essere nella situazione del [precedente esercizio](Test%20pi%C3%B9%20comuni.md#distribuzione-normale-varianza-nota-media-sconosciuta-part-1), con la differenza che le ipotesi sono del tipo\n$$\\begin{align\\*}\nH_0: \\theta \\leq \\theta_0\\\\\nH_1: \\theta \u003e \\theta_0\\\\\n\\\\end{align\\*}$$\nSi rifiuta $H_0$ se $$T = \\frac{\\overline{X} - \\theta_0}{\\sigma/\\sqrt{n}} \u003e c$$ ovvero se $T$ è *\"troppo\"* più grande di un certo $c$.\n\nSupponiamo che vogliamo avere una probabilità di errore $\\alpha \\approx 5%$.\nAllora calcoliamo\n$$\\begin{align\\*}\n0.05\n\u0026= P(\\mathbf{X} \\in C \\vert \\theta = \\theta_0)\\\\\n\u0026= P(T \u003e c)\\\\\n\u0026= 1 - P(T \\leq c)\\\\\n\u0026= 1 - \\Phi(c)\n\\\\end{align\\*}$$\nPerciò per trovare il $c$ desiderato in funzione di $\\alpha$ dato basta risolvere l'equazione $$1 -\\alpha = \\Phi(c)$$\nNel nostro caso $c \\approx 1.65$.\n\n---\n\n## Distribuzione approssimativamente normale, varianza nota, media sconosciuta\n\n\\[TODO\\]\n\n---\n\n# t-test (di Student)\n\n## Distribuzione normale, varianza e media sconosciute\n\nConsideriamo un [campionamento](Random%20Sample.md#random-sample) $X_1, ..., X_n$ da una popolazione [normale](Distribuzioni.md#normale) $N(\\mu, \\sigma^2)$, con $\\mu, \\sigma$ **ignoti**.\n\nApprossimiamo $\\sigma^2$ con la [media campionaria](Random%20Sample.md#media-campionaria) $S^2$, e definiamo la quantità $$T = \\frac{\\overline{X} - \\mu_0}{S/\\sqrt{n}}$$ dove $\\mu_0$ fa parte della nostra ipotesi, del tipo $H_0: \\mu \\leq \\mu_0$ oppure $H_0: \\mu = \\mu_0$.\n\nEsiste un risultato di [William Gosset](https://it.wikipedia.org/wiki/William_Sealy_Gosset), sotto pseudonimo *Student*, che dimostra che $T$ segue una [distribuzione t di Student](Distribuzioni.md#distribuzione-t-di-stundet) con $n-1$ *gradi di libertà*.\n\nTale distribuzione assomiglia ad una [normale](Distribuzioni.md#normale), ma più *\"schiacciata\"* e quindi con maggiore probabilità nelle code.\nAl crescere dei gradi di libertà, tende sempre di più ad una normale standard $N(0,1)$.\nIntuitivamente, possiamo pensare ad una distribuzione normale che tiene conto dell'insicurezza introdotta dalla stima $S^2$, che tale insicurezza tende a diminuire al crescere di $n$.\n\nA questo punto, come nel caso della normale, consideriamo il test $$\\text{rifiuto } H_0 \\iff |T| \u003e c$$ oppure $$\\text{rifiuto } H_0 \\iff T \u003e c$$ a seconda del tipo di ipotesi.\n\n---\n\n# Varianti su differenze di valori attesi\n\n## Differenza tra due valori attesi, campioni indipendenti, varianze note\n\nConsideriamo due campionamenti **indipendenti** $\\mathbf{X}\\_1$ e $\\mathbf{X}\\_2$ rispettivamente di lunghezze $n_1$ ed $n_2$, con medie $\\mu_1, \\mu_2$ sconosciute e \u003cu\u003evarianze note\u003c/u\u003e $\\sigma_1^2, \\sigma_2^2$.\n\nSupponiamo di voler verificare l'*ipotesi nulla* $$H_0: \\mu_1 = \\mu_2$$ ovvero di voler verificare se i due campioni hanno la stessa media.\n\nRiformulare l'ipotesi nulla come $$H_0: \\mu_1 - \\mu_2 = 0$$\n\nPossiamo  quindi stimare la differenza tra i due parametri ignoti $\\mu_1 - \\mu_2$, semplicemente tramite la differenza tra le due [medie campionarie](Random%20Sample.md#media-campionaria) $\\overline{X}\\_1 - \\overline{X}\\_2$.\n\nPrima di procedere, calcoliamo lo **standard error** di questa differenza, partendo dalla varianza\n$$\\begin{align\\*}\n\\\\text{Var}(\\overline{X}\\_1 - \\overline{X}\\_2)\n\u0026= \\mathbb{E}\\left\\[ (\\overline{X}\\_1 - \\overline{X}\\_2)^2 \\right\\] - (\\mu_1 - \\mu_2)^2\\\\\n\u0026= \\mathbb{E}\\left\\[ \\overline{X}\\_1^2 \\right\\] + \\mathbb{E}\\left\\[ \\overline{X}\\_2^2 \\right\\] -  \\cancel{2\\mathbb{E}\\left\\[ \\overline{X}\\_1 \\overline{X}\\_2 \\right\\]} - \\mu_1^2 - \\mu_2^2 + \\cancel{2\\mu_1\\mu_2}\\\\\n\u0026= \\left(\\mathbb{E}\\left\\[ \\overline{X}\\_1^2 \\right\\] - \\mu_1^2\\right) + \\left(\\mathbb{E}\\left\\[ \\overline{X}\\_2^2 \\right\\] - \\mu_2^2\\right)\\\\\n\u0026= \\text{Var}(\\overline{X}\\_1) + \\text{Var}(\\overline{X}\\_2)\\\\\n\u0026= \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}\n\\\\end{align\\*}$$\n\nImportante notare che abbiamo ottenuto questo risultato solamente sfruttando l'**indipendenza** dei due campioni.\nL'ulitma disuguaglianza è invece data da [Random Sample \u003e ^2864bf](Random%20Sample.md#2864bf).\n\nL'errore standard risulterà quindi essere $\\sqrt{\\sigma_1^2/n_1 + \\sigma_2^2/n_2}$.\n\nDefiniamo quindi la statistica $$T = \\frac{\\left(\\overline{X}\\_1 - \\overline{X}\\_2\\right) - (\\mu_1 - \\mu_2)}{\\sqrt{\\sigma_1^2/n_1 + \\sigma_2^2/n_2}} \\overbrace{=}^{\\text{sotto } H_0} \\frac{\\overline{X}\\_1 - \\overline{X}\\_2}{\\sqrt{\\sigma_1^2/n_1 + \\sigma_2^2/n_2}}$$ la quale avrà distribuzione $N(0,1)$.\n\nA questo punto, come prima vogliamo **rifiutare** $H_0$ se $|T| \u003e c$.\n\nCalcoliamo quindi la probabilità di errore tipo I, con la [fromula precedente](Test%20pi%C3%B9%20comuni.md#3d2fb2) $$1 - \\alpha = \\Phi(c) - \\Phi(-c)$$\n\n---\n\n## Differenza tra due valori attesi, campioni indipendenti, varianze ignote\n\nCome prima, consideriamo due **campioni indipendenti** $\\mathbf{X}\\_1$ e $\\mathbf{X}\\_2$ rispettivamente di lunghezze $n_1$ ed $n_2$, con medie $\\mu_1, \\mu_2$  e varianze $\\sigma_1^2, \\sigma_2^2$ **sconosciute**.\n\nSostituendo $\\sigma_1^2$ e $\\sigma_2^2$ con le reispetive varianze campionarie $S_1^2$ e $S_2^2$ questa volta non si ottiene che\n$$T = \\frac{\\left(\\overline{X}\\_1 - \\overline{X}\\_2\\right) - (\\mu_1 - \\mu_2)}{\\sqrt{S_1^2/n_1 + S_2^2/n_2}}$$\n**non** segue una distribuzione $t$ di Student, come nel [caso precedente](Test%20pi%C3%B9%20comuni.md#distribuzione-normale-varianza-e-media-sconosciute).\n\nIn questo caso possiamo applicare 2 approcci:\n\n1. Se $n_1, n_2$ sono molto grandi (per esempio $\\geq 30$ o $\\geq 60$ a seconda dei libri) allora possiamo dire che $T$ segue una distribuzione che *approssima* una $t$ di Student con $n_1 + n_2 - 2$ gradi di libertà. Questo perché al crescere della grandezza del campione, l'approssimazione $S^2$ stima sempre meglio $\\sigma^2$.\n1. se si può supporre che la distribuzione dei dati sia \u003cu\u003enormale\u003c/u\u003e e che le due varianze ignote siano comunque \u003cu\u003euguali\u003c/u\u003e, $\\sigma_1 = \\sigma_2 = \\sigma$, allora è possibile trovare una stima di $\\sigma$ basata sulle due varianze campionarie $S^2_1$ e $S^2_2$.\n   Tale stima è nota come **pooled variance stimate** ed è definita come $$S^2 = \\frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{(n_1 - 1) + (n_2 - 1)}$$\n   In tal modo avremo che $$T = \\frac{\\left(\\overline{X}\\_1 - \\overline{X}\\_2\\right) - (\\mu_1 - \\mu_2)}{\\sqrt{S_1^2/n_1 + S_2^2/n_2}} = \\frac{\\left(\\overline{X}\\_1 - \\overline{X}\\_2\\right) - (\\mu_1 - \\mu_2)}{S\\sqrt{1/n_1 + 1/n_2}}$$ avrà un distribuzione [t di Student](Distribuzioni.md#distribuzione-t-di-stundet) con $n_1 + n_2 - 2$ gradi di libertà.\n\n---\n\n# t-test (di Welch)\n\n## Differenza tra due valori attesi, campioni indipendenti, varianze ignote differenti\n\nPoniamoci nel [contesto precedente](Test%20pi%C3%B9%20comuni.md#differenza-tra-due-valori-attesi-campioni-indipendenti-varianze-ignote), e supponiamo di non poter in alcun modo assumere che le due varianze ignote siano uguali.\n\nEsiste un terzo approccio che **approssima** una soluzione, e che è ritenuta essere una buona approssimazione.\nCome prima definiamo la statistica $$T = \\frac{\\overline{X}\\_1 - \\overline{X}\\_2}{\\sqrt{S_1^2/n_1 + S_2^2/n_2}}$$\n(Ricorda, stiamo semprsotto ipotesi nulla $H_0: \\mu_1 - \\mu_2 = 0$)\n\nE possibile **approssimare** $T$ con una distribuzione $t$ di studente con un numero di gradi libertà $\\nu$ calcolato con l'approssimazione di Welch-Satterthwaite $$\\nu \\approx \\frac{\\left(\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}\\right)^2}{\\frac{S_1^4}{n_1^2(n_1 - 1)} + \\frac{S_2^4}{n_2^2(n_2 - 1)}}$$\n\nMolti software (per esempio R) preferiscono presentare questo test come alternativa primaria per il confronto di due mediei poiché l'ipotesi di **varianze note** o **variance ignote ma uguali** raramente si presenta.\n","lastmodified":"2022-08-29T13:39:16.76174064+02:00","tags":null},"/ISTI/Trasformazioni-Bivariate":{"title":"","content":"\n## Trasformazioni Bivariate\n\nSia $(X,Y)$ una v.a. bivariata con distribuzione nota.\nConsideriamo ora una seconda v.a. bivariata $(U,V)$ con $U \\sim g_1(X,Y)$ e $V \\sim g_2(X,Y)$.\n\nSia un qualsiasi sottoinsieme $B \\subseteq \\mathbb{R}^2$.\nAllora avremo che $(U,V) \\in B$ se $(X,Y) \\in A$, dove\n$$A := { (x,y) : (g_1(x,y), g_2(x,y)) \\in B}$$\nPerciò\n$$P((U,V) \\in B) = P((X,Y) \\in A)$$\novvero la distribuzione di $(U,V)$ è completamente definita dalla distribuzione di $(X,Y)$.\n\nInoltre, fissati dei valori $(U,V) = (u,v)$ definiamo l'insieme $A\\_{u,v} = { (x,y) : g_1(x,y) = u \\land g_2(x,y) = v}$.\nQuindi\n$$f\\_{U,V}(u,v) = P(U=u, V=v) = P((X,Y) \\in A\\_{u,v}) = \\sum\\_{(x,y) \\in A\\_{u,v}} f\\_{X,Y}(x,y)$$\n\n### Esempio - somme di Poisson indipendeti\n\nSiano $X,Y$ due v.a. di *Poisson* **indipendenti** di parametri rispettivamente $\\theta$ e $\\lambda$.\nOvvero\n$$f_X(x) = \\theta^x\\frac{e^{-\\theta}}{x!}$$\n$$f_Y(y) = \\lambda^y\\frac{e^{-\\lambda}}{y!}$$\nPer ogni $x,y \\in \\mathbb{N}$.\n\nAvremo che la loro [probabilità congiunta](Distribuzioni%20Multivariate.md#joint-pmf) sarà\n$$f\\_{X,Y}(x,y) = f_X(x)f_Y(y) = \\frac{\\theta^xe^{-\\theta}}{x!}\\frac{\\lambda^ye^{-\\lambda}}{y!}$$\n\nDefiniamo ora $U = X+Y$ e $V=Y$, ovvero $g_1(x,y) = x+y$ e $g_2(x,y)=y$.\n\nDescriviamo l'insieme $B$ dei possibili valori di $u,v$.\nSicuramente $v$ può assumere come valore un qualsiasi valore intero non negativo.\nInvece, dato che $v=y$, avremo che $u = x+y = x+v$.\nPerciò $u$ può assumere un valore non minore di $v$.\nQuindi $$B := {(u,v) \\in \\mathbb{N}^2 : u \\geq v \\geq 0}$$\n\nInvece, per ogni $(u,v) \\in B$, l'unica coppia $(x,y)$ che soddisfa $u = g_1(x,y)$ e $v = g_2(x,y)$ è definita come\n$$\\begin{cases}\ny = v\\\\\nx = u - v\n\\\\end{cases}$$\nPerciò avremo che $A\\_{u,v}$ sarà sempre composto dal singolo elemento $(u-v,v)$.\n$$A\\_{u,v} := {(u-v, v)}$$\nPerciò avremo che la densità conginuta di $(U,V)$ sarà\n$$f\\_{U,V}(u,v) = f\\_{X,Y}(u-v, v) = \\frac{\\theta^{(u-v)}e^{-\\theta}}{(u-v)!}\\frac{\\lambda^ve^{-\\lambda}}{v!}$$\nper ogni $u \\geq v \\geq 0$ interi.\n\nCalcoliamo ora le densità marginali di $U$ e $V$.\nDato che $v \\leq u$ allora avremo che\n$$\\begin{align\\*}\nf_U(u)\n\u0026= \\sum\\_{v=0}^{u}\\frac{\\theta^{(u-v)}e^{-\\theta}}{(u-v)!}\\frac{\\lambda^ve^{-\\lambda}}{v!}\\\\\n\u0026= e^{-(\\theta+\\lambda)}\\sum\\_{v=0}^{u}\\frac{\\theta^{(u-v)}}{(u-v)!}\\frac{\\lambda^v}{v!}\\\\\n\u0026= \\frac{e^{-(\\theta+\\lambda)}}{u!}\\sum\\_{v=0}^{u}\\frac{u!}{v!(u-v)!}\\theta^{(u-v)}\\lambda^v\\\\\n\u0026= \\frac{e^{-(\\theta+\\lambda)}}{u!}\\sum\\_{v=0}^{u}\\binom{u}{v}\\theta^{(u-v)}\\lambda^v\\\\\n\u0026= \\frac{e^{-(\\theta+\\lambda)}}{u!}(\\theta + \\lambda)^u\n\\\\end{align\\*}$$\novvero una Poisson di parametro $(\\theta + \\lambda)$.\nPossiamo concludere che $$U \\sim \\text{Poisson}(\\theta + \\lambda)$$ da cui il seguente teorema.\n\n## Teorema somme di Poisson indipendenti\n\nSiano $X \\sim \\text{Poisson}(\\theta)$ e $Y \\sim \\text{Poisson}(\\lambda)$ **indipendenti**.\nAllora \n$$X+Y \\sim \\text{Poisson}(\\theta + \\lambda)$$\n\n---\n\n## Jacobiano di una trasformazione\n\nSia $(X,Y)$ è una v.a. bivariata **continua** con [densità congiunta](Distribuzioni%20Multivariate.md#joint-pdf) $f\\_{X,Y}(x,y)$.\nSia $(U,V)$ una **trasformazione** di $(X,Y)$ tale che $U \\sim g_1(X,Y)$ e $V \\sim g_2(X,Y)$.\nÈ possibile esprimere $f\\_{U,V}(g_1(x,y),g_2(x,y))$ in termini di $f\\_{X,Y}(x,y)$.\n\nSiano i supporti \n$$A := {(x,y) : f\\_{X,Y}(x,y) \u003e 0}$$\n$$B := { (u,v) : u = g_1(x,y) \\land v = g_2(x,y)}$$\nOsserviamo che in questo caso abbiamo che $$B \\equiv \\mathbf{g}(A)$$ dove $\\mathbf{g} = (g_1, g_2)$.\n\nPer semplicità assumiamo che per ogni $(x,y) \\in A$ esiste un **unico** $(u,v) \\in B$ tale che $(u,v) = (g_1(x,y), g_2(x,y))$, ovvero che $\\mathbf{g}$ sia **biunivoca**.\n\nIn questa maniera possiamo definire una funzione invera $\\mathbf{h} = (h_1, h_2)$ tale che $$\\mathbf{h}(B) \\equiv A$$ ovvero\n$$x = h_1(u,v) \\equiv g_1^{-1}(g_1(x,y))$$\n$$y = h_2(u,v) \\equiv g_2^{-1}(g_2(x,y))$$\nIl ruolo che giocava la derivata nelle [Trasformazioni Univariate](Trasformazioni%20Univariate.md), nel caso bivariato (o multiariato in generale) è giocato dal **Jacobiano della trasformazione**, ovvero dal **determinante del gradiente**.\n$$\nJ = \\left\\vert \\begin{array}{cc}\n\\\\dfrac{\\partial x}{\\partial u} \u0026 \\dfrac{\\partial x}{\\partial v}\\\\\n\\\\dfrac{\\partial y}{\\partial u} \u0026 \\dfrac{\\partial y}{\\partial v}\n\\\\end{array} \\right\\vert\n= \\dfrac{\\partial x}{\\partial u} \\cdot \\dfrac{\\partial y}{\\partial v} - \\dfrac{\\partial x}{\\partial v} \\cdot \\dfrac{\\partial y}{\\partial u}\n$$\nAndando a sostituire opportunamente avremo che\n$$\\begin{align\\*}\n\\\\dfrac{\\partial x}{\\partial u} \u0026= \\dfrac{\\partial}{\\partial u} h_1(u, v)\\\\\n\\\\dfrac{\\partial x}{\\partial v} \u0026= \\dfrac{\\partial}{\\partial v} h_1(u, v)\\\\\n\\\\dfrac{\\partial y}{\\partial u} \u0026= \\dfrac{\\partial}{\\partial u} h_2(u, v)\\\\\n\\\\dfrac{\\partial y}{\\partial v} \u0026= \\dfrac{\\partial}{\\partial v} h_2(u, v)\n\\\\end{align\\*}$$\nPerciò avremo che la [densità marginale](Distribuzioni%20Multivariate.md#joint-pdf) di $(U,V)$ sarà $0$ al di fuori del suo support $B \\equiv \\mathbf{g}(A)$, mentre dentro sarà\n$$f\\_{U,V}(u,v) = f\\_{X,Y}\\left( h_1(u,v), h_2(u,v) \\right) \\cdot \\vert J \\vert$$\n\n### Prodotto di variabili Beta\n\nSiano $X \\sim \\text{Beta}(\\alpha, \\beta)$ e $Y \\sim \\text{Beta}(\\alpha + \\beta, \\gamma)$ v.a. **indipendenti** con pdf\n$$f_X(x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha - 1}(1-x)^{\\beta - 1}$$\n$$f_Y(y) = \\frac{\\Gamma(\\alpha+\\beta+\\gamma)}{\\Gamma(\\alpha+\\beta)\\Gamma(\\gamma)}y^{\\alpha + \\beta - 1}(1-y)^{\\gamma - 1}$$\nPer indipendenza la loro [densità congiunta](Distribuzioni%20Multivariate.md#joint-pdf) sarà quindi\n$$f\\_{X,Y}(x,y) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha - 1}(1-x)^{\\beta - 1}\\frac{\\Gamma(\\alpha+\\beta+\\gamma)}{\\Gamma(\\alpha+\\beta)\\Gamma(\\gamma)}y^{\\alpha + \\beta - 1}(1-y)^{\\gamma - 1}$$\nper ogni $x,y \\in (0,1)$.\n\nConsideriamo le strasformazioni $U = XY$ e $V=X$.\nAvremo quindi $g_1(x,y) = xy = u$ e $g_2(x,y) = x = v$\n\nOsservare che dato che $y \\\u003c 0$ allora $xy \\\u003c x$, ovvero $u \\\u003c v$.\nPerciò il supporto di $(U,V)$ sarà\n$$\\mathbf{g}(A) = B = { (u,v) : 0 \\\u003c u \\\u003c v \\\u003c 1}$$\nOsservare che la funzione $\\mathbf{g} = (g_1, g_2)$ è **biettiva** in $A$, perciò invertibile, con \n$$x = g^{-1}\\_2(u, v) = v$$\n$$y = g^{-1}\\_1(u, v) = \\frac{u}{x} = \\frac{u}{v}$$\nPerciò il Jacobiano risulta essere\n$$\nJ = \\left\\vert \\begin{array}{cc}\n\\\\dfrac{\\partial x}{\\partial u} \u0026 \\dfrac{\\partial x}{\\partial v}\\\\\n\\\\dfrac{\\partial y}{\\partial u} \u0026 \\dfrac{\\partial y}{\\partial v}\n\\\\end{array} \\right\\vert\n= \\left\\vert \\begin{array}{cc}\n\\\\dfrac{\\partial v}{\\partial u} \u0026 \\dfrac{\\partial v}{\\partial v}\\\\\n\\\\dfrac{\\partial (u/v)}{\\partial u} \u0026 \\dfrac{\\partial (u/v)}{\\partial v}\n\\\\end{array} \\right\\vert\n= \\left\\vert \\begin{array}{cc}\n0 \u0026 1\\\\\n\\\\dfrac{1}{v} \u0026 -\\dfrac{u}{v^2}\n\\\\end{array} \\right\\vert\n= -\\frac{1}{v}\n$$\n\nPericò la densità congiunta di $(U,V)$ risulta essere\n$$f\\_{U,V}(u,v) = f\\_{X,Y}(v, u/v) = \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta)\\Gamma(\\gamma)}v^{\\alpha-1}(1-v)^{\\beta - 1}\\left(\\frac{u}{v}\\right)^{\\alpha + \\beta - 1}\\left( 1 - \\frac{u}{v}\\right)^{\\gamma - 1} \\frac{1}{v}$$\nCertamente la distribuzione marginale di $V$ sarà $\\text{Beta}(\\alpha, \\beta)$.\nPerò anche la distribuzione di $U$ risulterà essere una Beta, infatti\n$$\\begin{align\\*}\nf_U(u)\n\u0026= \\int\\_{u}^{1} f\\_{U,V}(u, v) , dv\\\\\n\u0026= \\int\\_{u}^{1} \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta)\\Gamma(\\gamma)}v^{\\alpha-1}(1-v)^{\\beta - 1}\\left(\\frac{u}{v}\\right)^{\\alpha + \\beta - 1}\\left( 1 - \\frac{u}{v}\\right)^{\\gamma - 1} \\frac{1}{v} , dv\\\\\n\u0026= \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta)\\Gamma(\\gamma)}\\int\\_{u}^{1} (1-v)^{\\beta - 1} u^{\\alpha - 1} \\left(\\frac{u}{v}\\right)^{\\beta}\\left( 1 - \\frac{u}{v}\\right)^{\\gamma - 1} \\frac{1}{v} , dv\\\\\n\u0026= \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta)\\Gamma(\\gamma)}u^{\\alpha - 1}\\int\\_{u}^{1} (1-v)^{\\beta - 1} \\left(\\frac{u}{v}\\right)^{\\beta-1}\\left( 1 - \\frac{u}{v}\\right)^{\\gamma - 1} \\left(\\frac{u}{v^2}\\right) , dv\\\\\n\u0026= \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta)\\Gamma(\\gamma)}u^{\\alpha - 1}\\int\\_{u}^{1} \\left(\\frac{u}{v} -u \\right)^{\\beta - 1}\\left( 1 - \\frac{u}{v}\\right)^{\\gamma - 1} \\left(\\frac{u}{v^2}\\right) , dv\\\\\n\\\\end{align\\*}$$\nFacendo un cambio di variabile, e ponendo $w = \\dfrac{u}{v}\\frac{1}{1-u}$ otterremo che $dw = -\\dfrac{u}{v^2(1-u)}$ e con le opportune sostituzioni\n$$\\begin{align\\*}\nf_U(u)\n\u0026= \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta)\\Gamma(\\gamma)}u^{\\alpha - 1}(1-u)^{\\beta + \\gamma - 1}\\int\\_{0}^{1} w^{\\beta - 1} (1 - \\beta)^{\\gamma - 1} , dw\\\\\n\u0026= \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta)\\Gamma(\\gamma)}u^{\\alpha - 1}(1-u)^{\\beta + \\gamma - 1} \\frac{\\Gamma(\\beta)\\Gamma(\\alpha)}{\\Gamma(\\beta + \\gamma)}\\\\\n\u0026= \\frac{\\Gamma(\\alpha + \\beta + \\gamma)}{\\Gamma(\\alpha)\\Gamma(\\beta + \\gamma)}u^{\\alpha - 1}(1-u)^{\\beta + \\gamma - 1}\n\\\\end{align\\*}$$\novvero $U = XY \\sim \\text{Beta}(\\alpha, \\beta + \\gamma)$.\n\n---\n\n### Somma e differenza di Normali\n\nSiano le v.a. $X,Y \\sim N(0, 1)$ **indipendenti**, con pdf\n$$f_X(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}$$\n$$f_Y(y) = \\frac{1}{\\sqrt{2\\pi}}e^{-y^2/2}$$\nLa loro densità congiunta risulta quindi essere\n$$f\\_{X,Y}(x,y) = \\frac{1}{2\\pi} e^{- (x^2+y^2)/2}$$\nIl supplemento di $(X,Y)$ risulta quindi essere $A \\equiv \\mathbb{R}^2$.\n\nConsideriamo $U = g_1(X,Y) = X+Y$ e $V = g_2(X,Y) = X-Y$.\nOsserviamo che il supporto di $(U,V)$ è uguale a $\\mathbb{R}^2$, infatti\n$$B := { (u,v) : u=x+y, v=x-y} \\equiv \\mathbb{R}^2$$\nPer foruna esiste una unica soluzine per il sistema\n$$\\begin{cases}\nu = x+y\\\\\nv = x-y\n\\\\end{cases}$$\novvero\n$$\n\\\\left(\\begin{array}{cc|c}\n1 \u0026 1 \u0026 u\\\\\n1 \u0026 -1 \u0026 v\n\\\\end{array}\\right)\n\\\\rightarrow\n\\\\left(\\begin{array}{cc|c}\n1 \u0026 1 \u0026 u\\\\\n0 \u0026 -2 \u0026 v -u\n\\\\end{array}\\right)\n\\\\rightarrow\n\\\\left(\\begin{array}{cc|c}\n1 \u0026 1 \u0026 u\\\\\n0 \u0026 1 \u0026 \\dfrac{u-v}{2}\n\\\\end{array}\\right)\n\\\\rightarrow\n\\\\left(\\begin{array}{cc|c}\n1 \u0026 0 \u0026 \\dfrac{u+v}{2}\\\\\n0 \u0026 1 \u0026 \\dfrac{u-v}{2}\n\\\\end{array}\\right)\n$$\nCiò implica che le due trasformazioni $g_1, g_2$ sono **invertibili**, ovvero\n$$x = g_1^{-1}(u, v) = \\frac{u+v}{2}$$\n$$y = g_2^{-1}(u, v) = \\frac{u-v}{2}$$\nPossiamo quindi calcoalre la [densità congiunta](Distribuzioni%20Multivariate.md#joint-pdf) di $f\\_{U,V}(u,v)$ come\n$$f\\_{U,V}(u,v) = f\\_{X,Y}(g^{-1}*1(u,v),g^{-2}*1(u,v)) \\cdot \\vert J \\vert$$\ndove\n$$\nJ = \\left\\vert\n\\\\begin{array}{cc}\n\\\\dfrac{\\partial}{\\partial u}\\dfrac{u+v}{2} \u0026 \\dfrac{\\partial}{\\partial v}\\dfrac{u+v}{2}\\\\\n\\\\dfrac{\\partial}{\\partial u}\\dfrac{u-v}{2} \u0026 \\dfrac{\\partial}{\\partial v}\\dfrac{u-v}{2}\n\\\\end{array}\n\\\\right\\vert\n= \\left\\vert\n\\\\begin{array}{cc}\n\\\\dfrac{1}{2} \u0026 \\dfrac{1}{2}\\\\\n\\\\dfrac{1}{2} \u0026 -\\dfrac{1}{2}\n\\\\end{array}\n\\\\right\\vert\n= -\\frac{1}{2}\n$$\nperciò\n$$\\begin{align\\*}\nf*{U,V}(u,v)\n\u0026= \\frac{1}{4\\pi}\\exp{\\left( -\\frac{1}{2} \\left\\[ \\frac{(u+v)^2}{4} + \\frac{(u-v)^2}{4} \\right\\]\\\\right)}\\\\\n\u0026= \\frac{1}{4\\pi}\\exp{\\left( -\\frac{1}{2} \\left\\[ \\frac{u^2+v^2+2uv}{4} + \\frac{u^2 + v^2 - 2uv}{4} \\right\\]\\\\right)}\\\\\n\u0026= \\frac{1}{4\\pi}\\exp{\\left( -\\frac{1}{2} \\left\\[ \\frac{u^2}{2} + \\frac{v^2}{2}  \\right\\]\\\\right)}\n\\\\end{align\\*}$$\nScoponendo tale risultato avremo che\n$$f*{U,V}(u,v) = \\left( \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}}e^{-u^2/4} \\right) \\cdot \\left( \\frac{1}{\\sqrt{2\\pi}\\sqrt{2}}e^{-v^2/4} \\right)$$\nOvvero $U = X+Y \\sim N(0, 2)$ e $V = X-Y \\sim N(0,2)$, infatti\n$$N(\\mu, \\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp{\\left\\[-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right\\]}$$\n\n---\n\n### Trasformazione Polare di due Normali Standard Indipendenti\n\nSiano $X, Y \\sim N(0, 1)$ **indipendenti**, e siano $(R, \\theta)$ le **coordinate polari** del punot $(X,Y)$.\n\nQuindi avremo che $R = \\sqrt{X^2 + Y^2}$ e $\\theta = \\tan^{-1}{\\left( \\frac{Y}{X} \\right)}$.\nLe funzione inverse sarrano invece $X = R \\cos{\\theta}$ e $Y = R \\sin{\\theta}$.\n$$\nJ = \\left\\vert \\begin{array}{cc}\n\\\\dfrac{\\partial}{\\partial R} R\\cos{\\theta} \u0026 \\dfrac{\\partial}{\\partial \\theta} R\\cos{\\theta}\\\\\n\\\\dfrac{\\partial}{\\partial R} R\\sin{\\theta} \u0026 \\dfrac{\\partial}{\\partial \\theta} R\\sin{\\theta}\n\\\\end{array} \\right\\vert =\n\\\\left\\vert \\begin{array}{cc}\n\\\\cos{\\theta} \u0026 -R\\sin{\\theta}\\\\\n\\\\sin{\\theta} \u0026 R\\cos{\\theta}\n\\\\end{array} \\right\\vert =\nR(\\cos^2{\\theta} + \\sin^2{\\theta}) = R\n$$\n\nLa densità di $(X,Y)$ è $$f\\_{X,Y}(x,y) = \\frac{1}{\\sqrt{2\\pi}}e^{-(x^2+y^2)/2}$$ perciò la densità di $(R, \\theta)$ risulterà essere $$f\\_{R,\\theta}(r, \\vartheta) = f\\_{X,Y}(r\\cos{\\vartheta}, r \\sin{\\vartheta}) \\cdot r = \\frac{r}{\\sqrt{2\\pi}} e^{-r^2/2}$$\n","lastmodified":"2022-08-29T13:39:16.743595632+02:00","tags":null},"/ISTI/Trasformazioni-Univariate":{"title":"","content":"\n## Trasformazioni Univariate\n\nSia una v.a. $X$ con pdf $f_X(x)$.\nSia $S$ il **supporto** di $X$, ovvero l'insieme di tutte le $x$ per le quali $f_X(x) \u003e 0$.\n$$S \\equiv {x \\in \\mathbb{R} : f_X(x) \u003e 0}$$\n\nSupponiamo di avere una trasformazione $y = g(x)$ **biettiva** e definita su $S$.\nData la biettività, allora esiste l'inversa $x = g^{-1}(x)$.\n\nSia la v.a. $Y \\sim g(X)$.\nAllora avremo che\n$$f_Y(y) = f_X(g^{-1}(y)) \\cdot \\left\\vert \\frac{d}{dy} g^{-1}(y) \\right\\vert$$\n\n### Esempio I\n\nSia $X$ una v.a. con pdf\n$$f(x) = \\begin{cases}\n\\\\frac{1}{8}(4-x) \u00260 \\\u003c x \\\u003c 4\\\\\n0 \u0026\\text{altrimenti}\n\\\\end{cases}$$\n\n^6cca74\n\ne sia $Y = X^2$ (biettiva in nel supporto $(0,4)$).\n\nUn primo approccio per calcolare $f_Y$ è passando calcolando $F_Y$ e poi derivando\n$$F_Y(y) = P(Y \\leq y) = P(X^2 \\leq y) = P(X \\leq \\sqrt{y}) = F_X(\\sqrt{y})$$\nOsservare che $g(x) = x^2$ e $g^{-1}(y) = \\sqrt{y}$.\nPerciò abbiamo che\n$$F_Y(y) = F_X(g^{-1}(y))$$\nPerciò\n$$\\begin{align\\*}\nf_Y(y)\n\u0026= \\frac{d}{dy} F_Y(y)\\\\\n\u0026= \\frac{d}{dy}F_X(g^{-1}(y))\\\\\n\u0026= \\frac{d}{d\\sqrt{y}}F_X(\\sqrt{y}) \\cdot \\frac{d}{dy}\\sqrt{y}\\\\\n\u0026= f_X(\\sqrt{y}) \\cdot \\frac{1}{2\\sqrt{y}}\\\\\n\u0026= \\frac{1}{8}\\left( 4 - \\sqrt{y} \\right) \\cdot \\frac{1}{2\\sqrt{y}}\\\\\n\u0026= \\frac{1}{16}\\left( \\frac{4}{\\sqrt{y}} - 1 \\right)\n\\\\end{align\\*}$$\n\n### Esempio II\n\nSia $X$ con pdf analoga al [precedente esercizio](Trasformazioni%20Univariate.md#6cca74), e sia $Y = g(X) = 16 - X^2$.\n\nAbbiamo che $g$ è biettiva su $S = (0, 4)$, con supporto $g(S) = (0, 16)$.\nPerciò la sua inversa sarà\n$$x = g^{-1}(y) = \\sqrt{16 - y}$$\n\nAllora \n$$\\begin{align\\*}\nf_Y(y)\n\u0026= f_X(\\sqrt{16-y}) \\cdot \\left\\vert - \\frac{1}{2\\sqrt{16-x}} \\right\\vert\\\\\n\u0026= \\frac{1}{8}\\left( 4 - \\sqrt{16-y}\\right) \\cdot \\frac{1}{2\\sqrt{16-x}}\\\\\n\u0026= \\frac{1}{16}\\left( \\frac{4}{\\sqrt{16-y}} - 1 \\right)\n\\\\end{align\\*}$$\n","lastmodified":"2022-08-29T13:39:16.740528934+02:00","tags":null},"/ISTI/Verosimiglianza":{"title":"","content":"\n# Verosimiglianza\n\n## Likelihood function\n\nSia un [campione](Random%20Sample.md#random-sample) $\\mathbf{X} = (X_1, ..., X_n)$ dipendente da una serie di parametri $\\theta_1, ..., \\theta_k$, con [densità congiunta](Distribuzioni%20Multivariate.md#joint-pdf) $f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\theta_1, ..., \\theta_k)$.\nSupponiamo che il **campione osservato** sia $\\mathbf{X} = \\mathbf{x}$, allora la **funzione di verosimiglianza** (o **likelihood function**) è una funzione definita come $$L(\\theta_1, ..., \\theta_k \\vert \\mathbf{x}) = f\\_{\\mathbf{X}}(\\mathbf{x} \\vert \\theta_1, ..., \\theta_k) = \\prod\\_{i=1}^{n}f\\_{X_i}(x_i \\vert \\theta_1, ..., \\theta_k)$$\n\nOsservare che se $\\mathbf{X}$ è **discreto** allora avremo che $$L(\\theta_1, ..., \\theta_k \\vert \\mathbf{x}) = P\\_{\\theta_1, ..., \\theta_k}( \\mathbf{X} = \\mathbf{x})$$\n\nSupponiamo per esempio che $\\mathbf{X}$ dipenda da un solo parametro $\\theta$ (sconosciuto).\nSe troviamo due punti $\\theta_1, \\theta_2$ tali che $$L(\\theta_1 \\vert \\mathbf{x}) \u003e L(\\theta_2 \\vert \\mathbf{x})$$ allora avremo che il campione osservato $\\mathbf{x}$ è più propenso ad avere $\\theta = \\theta_1$ anziché $\\theta = \\theta_2$, il che può essere interpretato come indicazione che è più plausibile che $\\theta_1$ sia il reale parametro anziché $\\theta_2$.\n\nSe invece $\\mathbf{X}$ è una **continua** allora avremo che (se $f\\_\\\\mathbf{X}$ è continua in $\\mathbf{x}$) per ogni $\\varepsilon \u003e 0$ \u003cu\u003esufficientemente piccolo\u003c/u\u003e allora \n$$P\\_\\\\theta(\\mathbf{x}-\\varepsilon \\\u003c X \\\u003c \\mathbf{x}+\\varepsilon) \\approx 2\\varepsilon f(\\mathbf{x} \\vert \\theta) = 2\\varepsilon L(\\theta \\vert \\mathbf{x})$$\n\nPerciò il rapporto tra due likelihood function di due parametri $\\theta_1, \\theta_2$ da un'*approssimazione* del rapporto delle probabilità che venga osservato $\\mathbf{x}$ in un intervallo abbastanza piccolo (dati i due parametri), ovvero+\n$$\\frac{P\\_{\\theta_1}(\\mathbf{x}-\\varepsilon \\\u003c X \\\u003c \\mathbf{x}+\\varepsilon)}{P\\_{\\theta_2}(\\mathbf{x}-\\varepsilon \\\u003c X \\\u003c \\mathbf{x}+\\varepsilon)} \\approx \\frac{L(\\theta_1 \\vert \\mathbf{x})}{L(\\theta_2 \\vert \\mathbf{x})}$$\n\n## Principio di Verosimiglianza\n\nSiano due campioni osservati $\\mathbf{x}$ e $\\mathbf{y}$.\nSe la verosimiglianza $L(\\theta \\vert \\mathbf{x})$ è proporzionale a $L(\\theta \\vert \\mathbf{y})$ per una data cosante $C\\_{\\mathbf{x}, \\mathbf{y}}$ **indipendentemente** da $\\theta$, ovvero $$L(\\theta \\vert \\mathbf{x}) = C\\_{\\mathbf{x}, \\mathbf{y}} \\cdot L(\\theta \\vert \\mathbf{y}) ;; \\forall \\theta$$ allora si può concludere che $\\mathbf{x}$ e $\\mathbf{y}$ hanno un **campionamento identico**.\n","lastmodified":"2022-08-29T13:39:16.750178499+02:00","tags":null},"/ISTI/p-value-Livello-di-Significativit%C3%A0-di-un-Test":{"title":"","content":"\n# p-value\n\nUn altro metodo per verificare se è corretto accettare o rifiutare una [ipotesi](Hypothesis%20Testing.md) è il calcolo del **p-value**, noto anche come **significatività osservata**.\nIn parole semplici, potrebbe capitare di osservare dei dati che inducono al rifiuto dell'*ipotesi nulla* $H_0$.\nIl *p-value* aiuta a capire se la differenza tra i dati osservati e l'ipotesi nulla sia dovuta a un puro caso, oppure se in realtà tale differenza è **statisticamente rilevante**, ovvero difficilmente dovuta a un puro caso.\n\nConsideriamo un [campione](Random%20Sample.md#random-sample) $X_1, ..., X_n$ preso da una popolazione della quale non conosciamo le media $\\mu$, e definiamo l'ipotesi nulla $$H_0: \\mu \\leq \\mu_0$$\nNormaliziamo i dati tramite un semplice [z-test](Test%20pi%C3%B9%20comuni.md#z-test), definendo il valore osservato $$T = \\frac{\\overline{X} - \\mu_0}{\\sigma/\\sqrt{n}}$$ che avrà una distribuzione normale standardizzata $N(0,1)$.\n\nIl p-value è definita come la probabilità di ottenere un risultato \"**più estremo**\" di quello osservato $T$, sotto l'ipotesi che $H_0$ sia vera.\n\nDefiniamo cosa si intende per *\"più estremo\"*.\n\nNel nostro esempio ($H_0: \\mu \\leq \\mu_0$) abbiamo un test **unilaterale destro**, ovvero il z-test rifiuta $H_0$ se $T \u003e c$ per un certo $c$ fissato.\nPerciò per valori estremi si intedono dati osservati $T$ che vanno verso la **coda destra** di una normale.\nPerciò, il p-value in questo caso è definito come $$p(X_1,...,X_n) = P(Z \\geq T ;\\vert; H_0) = 1 - \\Phi(T) = \\Phi(-T)$$ dove $Z \\sim N(0,1)$.\n\n````julia\nusing Distributions, Plots\n\nx = collect(-3:0.01:3)\ny = pdf.(Normal(), x)\n\nc = 1.2\ni = x .≥ c\n\nT = 0.73\nj = x .≥ T\n\nplot(x[j],y[j], fillrange=zero(x[j]), label=\"p-value\", fillstyle=:x, fillcolor=:orange, c=:orange)\nplot!(x[i],y[i], fillrange=zero(x[i]), fα=.17, label=\"α\", fillcolor=:blue, c=:blue)\nplot!(x,y, lw=2, label=:none, c=:blue)\nvline!([c], c=:black, ls=:dash, label=\"c\")\nvline!([T], c=:black, ls=:dot, label=\"T\")\n````\n\n![](isti_p-value_2.png)\n\nPerciò, dire che $T \u003e c$ equivale a dire che il p-value $p(X_1, ..., X_n) \\\u003c \\alpha$, ovvero la differenza tra i dati osservati e l'ipotesi è **significativamente** rilevante.\n\n \u003e \n \u003e più il *p-value* è piccolo, più la *significatività* è alta poiché il risultato del test ci dice che $H_0$ non spiega adeguatamente i dati osservati.\n\nPerciò il test del *p-value* consiste nel $$\\text{rifiutare } H_0 \\iff p(X_1, ..., X_n) \\\u003c \\alpha$$\n\nConsideriamo ora il caso simmetricamente opposto, l'**unilaterale sinistro** con $$H_0: \\mu \\geq \\mu_0$$\nIn questo caso si rifiuta $H_0$ quando $T \\\u003c c$, bisogna quindi calcolare il p-value per valori inerenti alla **coda sinistra** della normale.\nPerciò avremo un p-value definito in maniera opposta a prima, ovvero $$p(X_1, ..., X_n) = P(Z \\leq T ; \\vert ; H_0) = \\Phi(T)$$\nAnalogamente, rifiutaremo $H_0$ se $p(X_1, ..., X_n) \\\u003c \\alpha$.\n\n````julia\nc = -1\ni = x .≤ c\n\nT = -1.5\nj = x .≤ T\n\nplot(x[j],y[j], fillrange=zero(x[j]), label=\"p-value\", fillstyle=:x, fillcolor=:orange, c=:orange)\nplot!(x[i],y[i], fillrange=zero(x[i]), fα=.17, label=\"α\", fillcolor=:blue, c=:blue)\nplot!(x,y, lw=2, label=:none, c=:blue)\nvline!([c], c=:black, ls=:dash, label=\"c\")\nvline!([T], c=:black, ls=:dot, label=\"T\")\n````\n\n![](isti_p-value_3.png)\nSe prendiamo in esempio la figura in esempio, abbiamo che $p(\\mathbf{X}) \\\u003c \\alpha$, ovvero i dati osservati risultano *significativamente differenti* da ci che ci si aspettava se $H_0$ fosse vera, perciò rifiutiamo $H_0$.\n\nInfine consideriamo il caso **bilaterale**, con iptesi nulla del tipo $$H_0: \\mu = \\mu_0$$\nAvevamo [visto](Test%20pi%C3%B9%20comuni.md#distribuzione-normale-varianza-nota-media-sconosciuta-part-1) che rifiutavamo $H_0$ quando $\\vert T \\vert \u003e c$.\nIn questo caso, dato che rifiutavamo $T$ nelle due code in maniera \u003cu\u003esimmetrica\u003c/u\u003e, avevamo $\\alpha/2$ di errore sulla coda destra e $\\alpha/2$ di errore sulla coda sinistra.\nPerciò è significativo rifiutare $H_0$ quando $$p(X_1,...,X_n) \\\u003c \\frac{\\alpha}{2}$$\n\n````julia\nc = 1.5\ni₁, i₂ = x .≥ c, x .≤ -c\n\nT = 0.73\nj = x .≥ T\n\nplot(x[j],y[j], fillrange=zero(x[j]), label=\"p-value\", fillstyle=:x, fillcolor=:orange, c=:orange)\nplot!(x[i₁],y[i₁], fillrange=zero(x[i₁]), fα=.17, label=\"right α/2\", fillcolor=:blue, c=:blue)\nplot!(x[i₂],y[i₂], fillrange=zero(x[i₂]), fα=.2, label=\"left α/2\", fillcolor=:purple, c=:blue)\nplot!(x,y, lw=2, label=:none, c=:blue)\nvline!([c, -c], c=:black, ls=:dash, label=\"c, -c\")\nvline!([T], c=:black, ls=:dot, label=\"T\")\n````\n\n![](isti_p-value_4.png)\nNella figura in esempio accetteremo $H_0$ perché la differenza tra il valore atteso e dati osservati non è abbastanza significativa.\n","lastmodified":"2022-08-29T13:39:16.836523611+02:00","tags":null},"/Propriet%C3%A0-utili":{"title":"","content":"\n# Covarianza\n\n* $$\\text{Cov}(X,Y) = \\mathbb{E}\\left\\[ (X-\\mathbb{E}\\left\\[ X \\right\\])(Y -\\mathbb{E}\\left\\[ Y \\right\\])  \\right\\] = \\mathbb{E}\\left\\[ XY \\right\\] - \\mathbb{E}\\left\\[ X \\right\\]\\\\mathbb{E}\\left\\[ Y \\right\\]$$\n* $$\\text{Cov}(X,X) = \\text{Var}(X)$$\n* $$\\text{Cov}(X,Y) = \\text{Cov}(Y,X)$$\n* $$\\text{Cov}(aX + b, Y) = a \\cdot \\text{Cov}(X,Y)$$\n* $$\\text{Cov}(X + A,Y) = \\text{Cov}(X,Y) + \\text{Cov}(A,Y)$$\n\n# Formula probabilità totali\n\nSia l'evento $A$ e la v.a. $X$ con supporto $\\chi$.\nAllora $$P(A) = \\int\\_{\\chi}P(A \\vert X = x)f\\_{X}(x) , dx$$\n\n````ad-example\ntitle: Esempio d'uso\n\nSiano $X,Y$ due v.a. **i.i.d.** con supporto $\\mathbb{R}$, e sia $D = X - Y$.\n\nAllora avremo che \n$$\\begin{align*}\nF_D(t)\n\u0026= P(X-Y \\leq t) = P(X \\leq t + Y)\\\\\n\u0026= \\int_{\\mathbb{R}} P(X \\leq t + Y \\vert Y = y) f_Y(y) \\, dy\\\\\n\u0026= \\int_{\\mathbb{R}} P(X \\leq t + y) f_Y(y) \\, dy\\\\\n\u0026= \\int_{\\mathbb{R}} F_X(X \\leq t + y) f_Y(y) \\, dy\n\\end{align*}$$\n````\n","lastmodified":"2022-08-29T13:39:16.966039453+02:00","tags":null},"/root":{"title":"","content":"\n# Index\n\n* [Analisi di reti](AR/0%20-Analisi%20di%20reti.md)\n* [Algorithmic Game Theory - by Tim Roughgarden](AGT/0%20-%20Algorithmic%20game%20theory.md)\n* [Inferenza Statistica e Teoria dell'Informazione](ISTI/0%20-%20Inferenza%20Statistica%20e%20Teoria%20dell'Informazione.md)\n","lastmodified":"2022-08-29T13:39:16.791809466+02:00","tags":null}}