<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Herding - Seguire il Gregge Abbiamo visto che quando degli individui sono connessi tra di loro in una rete, le loro decisioni e comportamenti possono essere influenzati (ed influenzare) da quello degli altri individui vicini."><title>ðŸª´ Alessandro Straziota's Notes</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://Alessandrostr95.github.io//icon.png><link href=https://Alessandrostr95.github.io/styles.b3e1e36b0403ac565c9392b3e23ef3b6.min.css rel=stylesheet><link href=https://Alessandrostr95.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://Alessandrostr95.github.io/js/darkmode.ff3928c070aaa41dd4e6a0d10ab7e115.min.js></script>
<script src=https://Alessandrostr95.github.io/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://Alessandrostr95.github.io/js/popover.abe6a51cc7138c5dff00f151dd627ad1.min.js></script>
<script src=https://Alessandrostr95.github.io/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://Alessandrostr95.github.io/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://Alessandrostr95.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://Alessandrostr95.github.io/",fetchData=Promise.all([fetch("https://Alessandrostr95.github.io/indices/linkIndex.12ce054d07db7354a1a118a75dec1a5f.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://Alessandrostr95.github.io/indices/contentIndex.068b8904bb64a00c9464ed48895ebd2f.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://Alessandrostr95.github.io",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://Alessandrostr95.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/Alessandrostr95.github.io\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://Alessandrostr95.github.io/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://Alessandrostr95.github.io/>ðŸª´ Alessandro Straziota's Notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=https://github.com/Alessandrostr95/quartz/tree/hugo/content/AR/12%20-%20Herding.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#a-simple-herding-experiment-il-gioco-delle-urne>A Simple Herding Experiment: Il Gioco delle Urne</a></li><li><a href=#teorema-di-bayes>Teorema di Bayes</a></li><li><a href=#un-modello-generale-di-sequential-decision-making>Un Modello Generale di Sequential Decision Making</a><ol><li><a href=#punto-1-decisioni-individuali>Punto 1: Decisioni Individuali</a></li><li><a href=#punto-2-informazioni-private>Punto 2: Informazioni Private</a></li><li><a href=#punto-3-osservazioni>Punto 3: Osservazioni</a></li><li><a href=#punto-4-decisioni-sequenzali>Punto 4: Decisioni Sequenzali</a></li><li><a href=#punto-5-decisioni-razionali>Punto 5: Decisioni Razionali</a></li><li><a href=#punto-6-massa-critica>Punto 6: Massa Critica</a></li></ol></li><li><a href=#considerazioni>Considerazioni</a></li></ol></nav></details></aside><a href=#herding---seguire-il-gregge><h1 id=herding---seguire-il-gregge><span class=hanchor arialabel=Anchor># </span>Herding - Seguire il Gregge</h1></a><p>Abbiamo visto che quando degli individui sono connessi tra di loro in una <em>rete</em>, le loro decisioni e comportamenti possono essere influenzati (ed influenzare) da quello degli altri individui vicini.</p><p>Nello studio dei
<a href=/AR/9-Processi-di-diffusione-Part-1/ rel=noopener class=internal-link data-src=/AR/9-Processi-di-diffusione-Part-1/>processi di diffusione</a> abbiamo visto come il comportamento dei singoli individui veniva influenzato dalla <em>diretta comunicazione</em> col proprio viciano.
In questa sezione vedremo come le decisioni dei singoli individui possono essere influenzate dalle osservazioni fatte sul comportamento degli altri, senza lo scambio di alcuna informaione. In sostanza come Ã¨ possibile <em>estrapolare informazioni</em> dal comportamento della massa.</p><p>Come primo esempio supponiamo di essere in vacanza in un nuovo posto e di dover scegliere un ristorante in cui mangiare.
In base alle nostre recerche <strong>personali</strong> scopriamo che il ristorante <code>A</code> Ã¨ il migliore che ci sia in zona, e quindi decidiamo di andarci.
Poco prima di entrare vediamo che nel ristorante accanto, il ristorante <code>B</code>, c&rsquo;Ã¨ moltissima clientela, mentre il ristorante <code>A</code> Ã¨ praticamente vuoto.
Non Ã¨ del tutto irrazionale pensare che tutte le persone che vanno al ristorante <code>B</code> abbiano <strong>informazioni private</strong> che noi non abbiamo, e supporre che in realtÃ  il ristorante Ã¨ il migliore.
In effetti il fatto che il ristorante <code>A</code> sia quasi vuoto non aiuta:
verrebbe da pensare che siamo in possesso di informazioni non del tutto esatte o complete.
PerciÃ² decidiamo anche noi di andare al ristorante <code>B</code>.</p><p>In questo caso diremo che Ã¨ avvenuta una <strong>cascata informativa</strong> (o <strong>herding</strong>).
In poche parole, una cascata informativa occorre quando gli individui prendono decisioni in maniera sequenziale, osservando ciÃ² che hanno fatto gli altri prima e cercando di inferire qualche informazione aggiuntiva che ha spinto gli altri ad agire in tale maniera.</p><p>La cosa piÃ¹ interessante Ã¨ che gli individui che <em>&ldquo;imitano&rdquo;</em> gli altri non lo fanno del tutto stupida, bensÃ¬ facendo una serie di ragionamenti ed inferenze piÃ¹ che sensate.
Naturalmente, l&rsquo;imitazione puÃ² verificarsi anche a causa della pressione sociale all&rsquo;esigienza di volersi conformare, senza alcuna causa informativa sottostante, e non Ã¨ sempre facile distinguere questi due fenomeni.
Consideriamo infatti l&rsquo;esperimento di <em>Milgram</em>, <em>Bickman</em> e <em>Berkowitz</em> del 1960, in cui venivano poste agli angoli delle strade dei gruppi di persone (da un minimo di 1 a un massimo di 15) a guardare il cielo senza alcun motivo.
Si Ã¨ osservato quanti passanti si sono fermati e hanno volto lo sguardo al cielo.
Come prima osservazione si Ã¨ visto che con una sola persona, pochissimi passanti si fermavano. Se invece 5 persone fissavano il cielo, alcuni passanti si fermavanom a imitare, ma la maggior parte li ignorava.
Infine, con un gruppo di 15 persone che guardano verso l&rsquo;alto, hanno scoperto che il 45% dei passanti imitava, fermandosi e guardare il cielo cercando di capire.</p><p>Quest&rsquo;ultimo esperimento lascia pensare che esiste una <strong>soglia critica</strong> oltre la quale si scatena l&rsquo;<em>herding</em> su una considerevole porzione di popolazione.
Infatti, se camminando per strada vediamo due persone che fissano il cielo, Ã¨ naturale pensare che i due individui non siano proprio sani mentalmente.
Se invece ne vediamo 15, molto propbabilmente guarderemo anche noi verso l&rsquo;alto, per cercare di capire cosa c&rsquo;Ã¨ di interessante.</p><p>Alcune domande nascono spontanee:</p><ul><li>esiste sempre una soglia critica che scatena l&rsquo;herding di massa?</li><li>e se esiste, come fare a trovarla?</li></ul><a href=#a-simple-herding-experiment-il-gioco-delle-urne><h2 id=a-simple-herding-experiment-il-gioco-delle-urne><span class=hanchor arialabel=Anchor># </span>A Simple Herding Experiment: Il Gioco delle Urne</h2></a><p>Consideriamo un genere di gioco con la seguente tipologia di regole</p><ol><li>C&rsquo;Ã¨ una decisione da prendere</li><li>I giocatori prendono le proprie decisioni in sequenza (uno dopo l&rsquo;altro), e ogni persona puÃ² osservare le scelte fatte da coloro che hanno agito prima.</li><li>Ogni giocatore ha alcune <em>informazioni private</em> che aiutano a guidare la propria decisione.</li><li>Un giocatore non puÃ² osservare direttamente le informazioni private che gli altri giocatori hanno, ma puÃ² trarre deduzioni su queste informazioni private da ciÃ² che fanno.</li></ol><p>Secondo queste indicazioni, instanziamo un gioco con le seguenti regole:</p><ul><li>C&rsquo;Ã¨ uno <strong>scommettitore</strong> in una stanza chiusa, e una serie di <strong>giocatori</strong> all&rsquo;esterno.</li><li>Lo scommettitore inserisce due palline rosse ed una blu in un&rsquo;urna (che chiameremo <code>MR</code>, a <em>Maggioranza Rossa</em>), e due palline blu e una rossa in un&rsquo;altra urna (che chiameremo <code>MB</code>, a <em>Maggioranza Blu</em>).</li><li>Lo scommettitore poi mischia le due urne e ne sceglie una a caso (senza avere la possibilitÃ  di vederne il contenuto).</li><li>Un giocatore alla volta entra nella stanza ed estrae una pallina dall&rsquo;urna, e poi la reinserisce.</li><li>Il giocatore comunica a tutti quanti se ritiene che l&rsquo;urna sia <code>MR</code> o <code>MB</code> (sulla base delle sue informazioni). <strong>Importante:</strong> il giocatore non deve comunicare il colore della pallina pescata.</li><li>Al termine vinceranno solo i giocatori che hanno indovinato quale urna Ã¨ stata scelta inizialmente (<code>MR</code> o <code>MB</code>).</li></ul><p>Per definizione di questo gioco, l&rsquo;informazione privata dei singoli giocatori Ã¨ l&rsquo;esito dell&rsquo;estrazione (pallina blu o pallina rossa), e questa non viene mai condivisa con gli altri.
Un giocatore perÃ² puÃ² inferire quale urna Ã¨ meglio scegliere in base alle scelte fatte dagli altri prima (come vedremo adesso).</p><p>Primo giocatore</p><blockquote><p>prima di estrarre la pallina, il primo giocatore Ã¨ in possesso della sola informazione <em>&ldquo;l&rsquo;urna Ã¨ <code>MR</code> o <code>MB</code>&rdquo;</em>.
Non avnedo altre informazioni, a prescindere da cosa pescherÃ  il primo giocatore, la probabilitÃ  che l&rsquo;urna sia <code>MR</code> o <code>MB</code> Ã¨ la stessa.
PerciÃ² gli conviene scomettere sul colore della pallina estratta: se pesca una pallina blu gli conviene scommettere su <code>MB</code> (stesso discorso per <code>MR</code>).</p></blockquote><p>Secondo giocatore</p><blockquote><p>a questo punto il secondo giocatore puÃ² dedurre l&rsquo;esito dell&rsquo;estrazione del primo giocatore sulla base della sua scommessa.
Senza perdita di generalitÃ , supponiamo che il primo giocatore abbia scommesso <code>MB</code> (e che quindi abbia estratto una pallina blu).
Se il secondo estrae una pallina blu, allora sa che sono state esatratte due palline blu consecutive, e che quindi Ã¨ piÃ¹ conveniente scommettere su <code>MB</code>.
Se invece estrae una pallina rossa, si ritrova nella stessa situazione inizale del primo giocatore (senza alcuna informazione rilevante), perciÃ² gli conviene scommettere <code>MR</code> in accordo alla sua estrazione.</p></blockquote><p>Terzo giocatore</p><blockquote><p>anche il terzo giocatore Ã¨ in grado di dedurre le estrazioni dei giocatori precedenti: se sono discordi allora sono avvenute due estrazioni discorde, se sono concorde allora sono avvenute due estrazioni di palline dello stesso colore.
Consideriamo il caso in cui le prime due estrazioni siano discordi, in questo caso al terzo giocatore conviene rispondere in accordo a ciÃ² che pesca (se pesca una pallina blu gli conviene votare <code>MB</code>, se ne pesca una rossa gli conviene votare <code>MR</code>).
Consideriamo ora il caso in cui i primi due giocatori abbiamo voti condori, e senza perdita di generalitÃ  supponiamo che abbiano entrambi votato <code>MB</code>.
Se il terzo giocatore pesca una pallina blu, allora vuol dire che sono state estratte tre palline blu di seguito, rafforzando la propbailitÃ  che <code>MB</code> sia la risposta esatta.
Se invece estrae una rossa, comunque Ã¨ piÃ¹ probabile che la risposta esatta sia <code>MB</code>, perchÃ© sono state estratte due palline blu di seguito e poi una rossa.
Quindi in ogni caso gli conviene votare <code>MB</code>.</p></blockquote><p>Quarto giocatore</p><blockquote><p>a questo punto il quarto giocatore puÃ² dedurre ciÃ² che hanno fatto <u>tutti</u> i giocatori precedenti solamente se ci sono 2 voti concordi ed uno discorde (2 a 1).
PerchÃ© se ci fossero 3 voti concordi, sappiamo che il terzo giocatore avrebbe votato in accordo ai primi due in ogni caso a prescindere dall&rsquo;esito della sua estrazione.
Supponiamo di essere nella situazione di <em>&ldquo;3 a 0&rdquo;</em> per <code>MB</code>. Al quarto giocatore conviene votare <code>MB</code> in ogni caso (esattamente come per il terzo giocatore).</p></blockquote><p>A questo punto, dal quinto giocatore in poi, si genera una <em>cascata informativa</em> a favore di <code>MB</code>, a prescindere dalle singole estrazioni.</p><a href=#teorema-di-bayes><h2 id=teorema-di-bayes><span class=hanchor arialabel=Anchor># </span>Teorema di Bayes</h2></a><p>Per formalizzare meglio la meccanica precedentemente descritta Ã¨ necessario enunciare il <strong>Teorema di Bayes</strong>.</p><blockquote><p><strong>Teorema di Bayes</strong> siano i due eventi $A,B \in \Omega$ di probabilitÃ  <u>non nulla</u>, allora $$\mathcal{P}(A | B) = \frac{\mathcal{P}(B | A) \cdot \mathcal{P}(A)}{ \mathcal{P}(B) }$$</p></blockquote><p>^967e98</p><blockquote><p><strong>Proof</strong> per definizione di probabilitÃ  condizionata abbiamo che $$
\begin{align*}
\mathcal{P}(A | B) &= \frac{\mathcal{P}(A \cap B)}{\mathcal{P}(B)}\\\mathcal{P}(B | A) &= \frac{\mathcal{P}(A \cap B)}{\mathcal{P}(A)}
\end{align*}$$
ciÃ² implica che $$\mathcal{P}(A \cap B) = \mathcal{P}(A | B) \cdot \mathcal{P}(B) = \mathcal{P}(B | A) \cdot \mathcal{P}(A)$$ Sostituendo opportunamente otteniamo l&rsquo;enunciato del teorema $$\mathcal{P}(A | B) = \frac{\mathcal{P}(A \cap B)}{\mathcal{P}(B)} = \frac{\mathcal{P}(B | A) \cdot \mathcal{P}(A)}{\mathcal{P}(B)} ;; \square$$</p></blockquote><p>Facendo qualche opportuna sostituzione, possiamo riscrivere $\mathcal{P}(B)$ come segue
$$
\begin{align*}
\mathcal{P}(B) &= \mathcal{P}(B \cap \Omega)\\&= \mathcal{P}(B \cap (A \cup A^{\mathcal{C}}))\\&= \mathcal{P}((B \cap A) \cup (B \cap A^{\mathcal{C}}))\\&= \mathcal{P}(B \cap A) + \mathcal{P}(B \cap A^{\mathcal{C}})\\&= \mathcal{P}(B | A) \cdot \mathcal{P}(A) + \mathcal{P}(B | A^{\mathcal{C}}) \cdot \mathcal{P}(A^{\mathcal{C}})
\end{align*}
$$</p><p>^61562b</p><p>perciÃ² $$\mathcal{P}(A | B) = \frac{\mathcal{P}(B | A) \cdot \mathcal{P}(A)}{ \mathcal{P}(B | A) \cdot \mathcal{P}(A) + \mathcal{P}(B | A^{\mathcal{C}}) \cdot \mathcal{P}(A^{\mathcal{C}}) }$$</p><p>Siano gli eventi:</p><ul><li>$MR$ : <em>&ldquo;l&rsquo;urna Ã¨ a maggioranza rossa&rdquo;</em></li><li>$MB$ : <em>&ldquo;l&rsquo;urna Ã¨ a maggioranza blu&rdquo;</em></li><li>$r$ : <em>&ldquo;Ã¨ stata estratta una pallina rossa&rdquo;</em></li><li>$b$ : <em>&ldquo;Ã¨ stata estratta una pallina blu&rdquo;</em></li></ul><p>Osserviamo inoltre che i precedenti eventi sono mutualmente complementari
$$
\begin{align*}
MR &= MB^{\mathcal{C}}\\MB &= MA^{\mathcal{C}}\\b &= r^{\mathcal{C}}\\r &= b^{\mathcal{C}}
\end{align*}$$</p><p>Secondo le regole del gioco sappiamo che
$$
\begin{align*}
\mathcal{P}(MR) &= \mathcal{P}(MB) = \frac{1}{2}\\\mathcal{P}(r | MR) &= \frac{2}{3}; ;; \mathcal{P}(b | MR) = \frac{1}{3}\\\mathcal{P}(r | MB) &= \frac{1}{3}; ;; \mathcal{P}(b | MB) = \frac{2}{3}
\end{align*}$$</p><p><strong>Giocatore 1:</strong> Supponiamo senza perdita di generalitÃ  che il primo giocatore estrae una pallina blu, essi dovrÃ  calcolare la probabilitÃ  che l&rsquo;urna sia a maggioranza blu o rossa, e questo si puÃ² fare grazie al
<a href=/AR/12-Herding/ rel=noopener class=internal-link data-src=/AR/12-Herding/>teorema di Bayes</a>
$$
\begin{align*}
\mathcal{P}(MB | b) &= \frac{\mathcal{P}(b | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(b | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(b | MR) \cdot \mathcal{P}(MR)} = \frac{2}{3}\\\\\mathcal{P}(MR | b) &= \frac{\mathcal{P}(b | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(b | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(b | MB) \cdot \mathcal{P}(MB)} = \frac{1}{3}
\end{align*}
$$</p><p>perciÃ² al primo giocatore conviene votare in accordo alla sua estrazione.</p><p><strong>Giocatore 2:</strong> Vediamo ora quale strategia Ã¨ migliore per il secondo giocatore.
Consideriamo come prima situazione quella in cui esso estrae una pallina rossa, ed indichiamo con $br$ l&rsquo;evento <em>&ldquo;sono state estratte in ordine una pallina blu e poi una rossa&rdquo;</em>.
Dato che il secondo giocatore sa esasttamente cosa ha pescato il primo (dato che lo puÃ² inferire con certezza assumendo che il primo giocaotre giochi correttamente), si puÃ² affermare che il secondo giocatore si trova a dover calcolare le seguenti probabilitÃ 
$$
\begin{align*}
\mathcal{P}(MB | br) &= \frac{\mathcal{P}(br | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(br | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(br | MR) \cdot \mathcal{P}(MR)} = \frac{1}{2}\\\\\mathcal{P}(MR | br) &= \frac{\mathcal{P}(br | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(br | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(br | MB) \cdot \mathcal{P}(MB)} = \frac{1}{2}
\end{align*}
$$</p><p>perciÃ² il secondo giocatore non puÃ² estrarre alcuna informazione utile dall&rsquo;estrazione del primo, e quindi gli conviene scommettere in accordo a ciÃ² che estrae.</p><p>Consideriamo ora il caso in cui il secondo giocate estrae una pallina blu.
In questo l&rsquo;informazione riguardo la prima estrazione Ã¨ realmente utile, in quanto possiamo dire che la probabilitÃ  Ã¨ nettamente piÃ¹ sbilanciata verso <code>MB</code>
$$
\begin{align*}
\mathcal{P}(MB | bb) &= \frac{\mathcal{P}(bb | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(bb | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(bb | MR) \cdot \mathcal{P}(MR)} = \frac{4}{5}\\\\\mathcal{P}(MR | bb) &= \frac{\mathcal{P}(bb | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(bb | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(bb | MB) \cdot \mathcal{P}(MB)} = \frac{1}{5}
\end{align*}
$$</p><p><strong>Giocatore 3:</strong> A questo punto (sempre supponendo che la prima estrazione sia stata una pallina blu) possiamo essere in due situazioni differenti</p><ul><li>$br$: sono avvenute in sequenza le estrazioni <em>blu-rossa</em></li><li>$bb$: sono avvenute in sequenza le estrazioni <em>blu-blu</em></li></ul><p>Partendo dalla prima, vediamo quale Ã¨ la strategia migliore per il terzo giocatore.
<strong>Caso $brb$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | brb) &= \frac{\mathcal{P}(brb | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(brb | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(brb | MR) \cdot \mathcal{P}(MR)} = \frac{2}{3}\\\\\mathcal{P}(MR | brb) &= \frac{\mathcal{P}(brb | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(brb | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(brb | MB) \cdot \mathcal{P}(MB)} = \frac{1}{3}
\end{align*}
$$</p><p><strong>Caso $brr$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | brr) &= \frac{\mathcal{P}(brr | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(brr | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(brr | MR) \cdot \mathcal{P}(MR)} = \frac{1}{3}\\\\\mathcal{P}(MR | brr) &= \frac{\mathcal{P}(brr | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(brr | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(brr | MB) \cdot \mathcal{P}(MB)} = \frac{2}{3}
\end{align*}
$$</p><p>PerciÃ² se i pirmi due voti sono discordi al terzo giocatore conviene votare in accordo alla sua estrazione (come giÃ  intuito in precedenza).</p><p>Vediamo ora cosa accade se i primi due giocatori hanno voti concordi.
<strong>Caso $bbb$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | bbb) &= \frac{\mathcal{P}(bbb | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(bbb | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(bbb | MR) \cdot \mathcal{P}(MR)} = \frac{8}{9}\\\\\mathcal{P}(MR | bbb) &= \frac{\mathcal{P}(bbb | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(bbb | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(bbb | MB) \cdot \mathcal{P}(MB)} = \frac{1}{9}
\end{align*}
$$</p><p><strong>Caso $bbr$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | bbr) &= \frac{\mathcal{P}(bbr | MB) \cdot \mathcal{P}(MB)}{\mathcal{P}(bbr | MB) \cdot \mathcal{P}(MB) + \mathcal{P}(bbr | MR) \cdot \mathcal{P}(MR)} = \frac{2}{3}\\\\\mathcal{P}(MR | bbr) &= \frac{\mathcal{P}(bbr | MR) \cdot \mathcal{P}(MR)}{\mathcal{P}(bbr | MR) \cdot \mathcal{P}(MR) + \mathcal{P}(bbr | MB) \cdot \mathcal{P}(MB)} = \frac{1}{3}
\end{align*}
$$</p><p>In questo caso al giocatore 3 conviene votare in accordo a ciÃ² che hanno votato i primi due giocatori, a prescindere da quale sarÃ  l&rsquo;esito della sua estrazione.</p><p><strong>Giocatore 4:</strong> Senza perdita di generalitÃ  consideriamo il caso in cui le prime due estrazioni sono entrambe <em>blu</em>.
Il giocatore 4 non puÃ² essere certo di cosa ha estratto il giocatore 3, perciÃ² gli conviene sempre calcolare due probabilitÃ  differenti, quella in cui il terzo ha estratto una pallina <em>rossa</em> e quella in cui ne ha estratta una <em>blu</em>.
$$
\begin{align*}
\mathcal{P}(MB | bbbb) = \frac{16}{17}; ;; &\mathcal{P}(MR | bbbb) = \frac{1}{17}\\\mathcal{P}(MB | bbbr) = \frac{8}{9}; ;; &\mathcal{P}(MR | bbbr) = \frac{1}{9}\\\mathcal{P}(MB | bbrb) = \frac{8}{9}; ;; &\mathcal{P}(MR | bbrb) = \frac{1}{9}\\\mathcal{P}(MB | bbrr) = \frac{1}{2}; ;; &\mathcal{P}(MR | bbrr) = \frac{1}{2}
\end{align*}
$$</p><p>PerciÃ² votando <code>MB</code> il giocatore 4 non ricade mai nella strategia che minimizza la probabilitÃ  di sucesso.
Al piÃ¹ puÃ² ritrovarsi nel caso in cui le probabilitÃ  di successo e insuccesso equivalgono, ovvero quando giocatori 3 e 4 estraggono entrambi una pallina <em>rossa</em>. Putroppo perÃ² il giocatore 4 non puÃ² sapere cosa ha estratto il terzo giocatore, perciÃ² gli conviene votare comunque <code>MB</code> a prescindere dalla sua estrazione.</p><p><strong>Giocatore 5:</strong> sapendo che le prime due estrazioni sono state <em>blu-blu</em>, il giocatore 5 (come il giocatore 4) deve calcolare tutte le probabilitÃ  rispetto alle possibili combinazioni di estrazioni dei giocatori 3 e 4.</p><p><strong>Caso $bbbb$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | bbbbb) = \frac{32}{33}; ;; &\mathcal{P}(MR | bbbbb) = \frac{1}{33}\\\mathcal{P}(MB | bbbbr) = \frac{8}{9}; ;; &\mathcal{P}(MR | bbbbr) = \frac{1}{9}
\end{align*}
$$</p><p><strong>Caso $bbbr$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | bbbrb) = \frac{8}{9}; ;; &\mathcal{P}(MR | bbbrb) = \frac{1}{9}\\\mathcal{P}(MB | bbbrr) = \frac{2}{3}; ;; &\mathcal{P}(MR | bbbrr) = \frac{1}{3}
\end{align*}
$$</p><p><strong>Caso $bbrb$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | bbrbb) = \frac{8}{9}; ;; &\mathcal{P}(MR | bbrbb) = \frac{1}{9}\\\mathcal{P}(MB | bbrbr) = \frac{2}{3}; ;; &\mathcal{P}(MR | bbrbr) = \frac{1}{3}
\end{align*}
$$</p><p><strong>Caso $bbrr$:</strong>
$$
\begin{align*}
\mathcal{P}(MB | bbrrb) = \frac{2}{3}; ;; &\mathcal{P}(MR | bbrrb) = \frac{1}{3}\\\bigstar \mathcal{P}(MB | bbrrr) = \frac{1}{3}; ;; &\mathcal{P}(MR | bbrrr) = \frac{2}{3}
\end{align*}
$$</p><p>Al giocatore 5 conviene sempre scommettere su <code>MB</code> a meno che il terzo e il quarto giocatore non abbiano estratto due palline <em>rosse</em>.
Questo purtroppo il giocatore 5 non puÃ² saperlo, in quanto i giocatori 3 e 4 voteranno <code>MB</code> a prescindere dall&rsquo;esito delle proprie estrazioni.</p><p>PerciÃ² possiamo dire che se le prime due estrazioni sono <em>blu-blu</em> si genera una cascata imitativa in cui tutti i giocatori voteranno <code>MB</code>, a prescindere dalle proprie informazioni private!</p><a href=#un-modello-generale-di-sequential-decision-making><h2 id=un-modello-generale-di-sequential-decision-making><span class=hanchor arialabel=Anchor># </span>Un Modello Generale di Sequential Decision Making</h2></a><p>Come visto negli esperimenti precedenti o nel gioco delle due urne, il fenomeno dell&rsquo;<em>Herding</em> si presenta in situazioni che hanno delle caratteristiche in comune, ovvero:</p><ol><li>Ogni individuo deve prendere una decisione.</li><li>Ogni individuo ha una propria informazione <strong>privata</strong>.</li><li>Ogni individuo riceve dalla rete un&rsquo;informazione incompleta, ovvero sa le scelte degli altri individui ma non l&rsquo;informazione che li ha spinti a prendere tali decisioni.</li><li>Le decisioni vengono prese in sequenza, dopo aver osservato quello che hanno fatto gli altri in precedenza.</li><li>Ogni individuo prende la propria decisione in maniera <strong>puramente razionale</strong>: inferisce dalle proprie osservazioni quale Ã¨ la strategia migliore da adottare, senza alcuna influenza o pressione sociale.</li><li>Si scatena una <strong>cascata informativa</strong> (<strong>herding</strong>), quando una certa <strong>massa critica</strong> prende una medesima decisione.</li></ol><p>Descriviamo ora in maniera formale un modello che cattura tutte queste caratteristiche</p><a href=#punto-1-decisioni-individuali><h3 id=punto-1-decisioni-individuali><span class=hanchor arialabel=Anchor># </span>Punto 1: Decisioni Individuali</h3></a><p>Per semplicitÃ  assumiamo che le decisioni da prendere sono <strong>decisioni binarie</strong>.
Senza perdita di generalitÃ  assumiamo che le uniche due alternative sono</p><ul><li><code>Y</code>: l&rsquo;individuo <em>accetta</em> una proposta.</li><li><code>N</code>: l&rsquo;individuo <em>rifiuta</em> una proposta.</li></ul><p>Solo una delle due alternative Ã¨ quella giusta. La probabilitÃ  che <code>Y</code> sia l&rsquo;alternativa giusta Ã¨ $\mathcal{P}(Y) = p$, mentre la probabilitÃ  che quella giusta sia <code>N</code> Ã¨ $\mathcal{P}(N) = 1-p$.</p><p>Se un individuo <strong>accetta</strong> (<code>Y</code>) una proposta avrÃ  un <em>profitto</em> $v_g > 0$<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> se <code>Y</code> era la risposta corretta, o una <em>perdita</em> $v_b \leq 0$<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> se la risposta <code>Y</code> era errata.</p><p>Contrariamente, se l&rsquo;individuo <strong>non accetta</strong> (<code>N</code>) non otterrÃ  nessun profitto e nessuna perdita.</p><p>AffinchÃ© sia <em>equivalente</em> per undividuo accettare (<code>Y</code>) o rifiutare (<code>N</code>), deve essere che
$$v_g p + v_b(1-p) = 0$$</p><a href=#punto-2-informazioni-private><h3 id=punto-2-informazioni-private><span class=hanchor arialabel=Anchor># </span>Punto 2: Informazioni Private</h3></a><p>Ongi individuo possiede un&rsquo;<strong>informazione privata</strong>, che possiamo assumere ricevere sottoforma di <strong>segnale privato</strong>.
I due possibili segnali possono essere <code>A</code> (<code>Accetta</code>) ed <code>R</code> (<code>Rifiuta</code>).</p><p>Se la scelta giusta Ã¨ <code>Y</code>, allora la probabilitÃ  di ricevere come segnale privato <code>A</code> Ã¨ $q > \frac{1}{2}$.
Viceversa se la scelta giusta Ã¨ <code>N</code>, allora la probabilitÃ  di ricevere come segnale privato <code>A</code> Ã¨ $1 - q$.
Simmetricamente per <code>R</code>.</p><p>PiÃ¹ formalmente possiamo esprimere queste proprietÃ  con probabilitÃ  condizionate
$$
\begin{align*}
\mathcal{P}(A | Y) = q ;; &\mathcal{P}(A | N) = 1 - q\\\\\mathcal{P}(R | Y) = 1 - q ;; &\mathcal{P}(R | N) = q
\end{align*}
$$</p><a href=#punto-3-osservazioni><h3 id=punto-3-osservazioni><span class=hanchor arialabel=Anchor># </span>Punto 3: Osservazioni</h3></a><p>L&rsquo;individuo $i$-esimo che deve prendere una decisione ricava dalla rete la sequenza $(X_1, &mldr;, X_{i-1}) \in \lbrace Y, N \rbrace^{i-1}$ delle decisioni prese dai precedenti $i-1$ individui.</p><a href=#punto-4-decisioni-sequenzali><h3 id=punto-4-decisioni-sequenzali><span class=hanchor arialabel=Anchor># </span>Punto 4: Decisioni Sequenzali</h3></a><p>L&rsquo;individuo $i$-esimo prende una decisione dopo che i precedenti $i-1$ individui hanno preso la loro.</p><a href=#punto-5-decisioni-razionali><h3 id=punto-5-decisioni-razionali><span class=hanchor arialabel=Anchor># </span>Punto 5: Decisioni Razionali</h3></a><p>Supponiamo che per l&rsquo;individui $i$ inizialmente <code>Y</code> ed <code>N</code> sono alternative equivalenti, ovvero che $v_g p + v_b(1-p) = 0$.
Se dopo le decisioni dei primi $i - 1$ individui la probabilitÃ  che <code>Y</code> sia corretta diventa una certa quantitÃ  $p&rsquo;$, all&rsquo;individui $i$ converrÃ  accettare se e soltanto se $$v_gp&rsquo; + v_b(1 - p&rsquo;) \geq 0$$
e questo accade se $p&rsquo; \geq p$, ovvero se non peggiora la probabilitÃ  che accettare sia la strategia corretta.</p><a href=#punto-6-massa-critica><h3 id=punto-6-massa-critica><span class=hanchor arialabel=Anchor># </span>Punto 6: Massa Critica</h3></a><p>Cerchiamo ora di individuare quanto deve essere grande una massa critica che scatena l&rsquo;<em>herding</em>.</p><p>Indichiamo con $S \in \lbrace A, R \rbrace^<em>$ la sequenza dei <em>segnali privati</em> ricevuti dagli individui.
Consideriamo la scelta del primo individuo, ovvero quando $\vert S \vert = 1$.
Se $S = (A)$, allora la probabilitÃ  che la scelta corretta sia <code>Y</code> Ã¨
$$\begin{align</em>}
\mathcal{P}(Y \vert A)
&= \frac{ \mathcal{P}(A \vert Y) \cdot \mathcal{P}(Y) }{ \mathcal{P}(A \vert Y) \cdot \mathcal{P}(Y) + \mathcal{P}(A \vert N) \cdot \mathcal{P}(N)}\\&= \frac{qp}{qp + (1-q)(1-p)}\\(\bigstar q > 1/2) &> \frac{qp}{qp + q(1-p)} = \frac{qp}{qp + q - qp} = p
\end{align*}$$
viceversa la probabilitÃ  che la scelta corretta sia <code>N</code> ricevendo il segnale <code>A</code> Ã¨ $$\mathcal{P}(N \vert A) = 1 - \mathcal{P}(Y \vert A) &lt; p$$
In maniera simmetrica, se riceviamo come primo segnale privato <code>R</code> avremo che $$\mathcal{P}(Y \vert R) &lt; p ;;;;\mathcal{P}(N \vert R) > p$$
Segue quindi che in assenza di ulteriori informazioni, quando un individuo ha solamente la propria informazione privata, conviene rispondere in accordo ad essa: se riceve <code>A</code> conviene rispondere <code>Y</code>, se riceve <code>R</code> conviene rispondere <code>N</code>.</p><p>Consideriamo ora il caso in cui $\vert S \vert > 1$.
Supponiamo che in qualche maniera l&rsquo;individuo che deve fare la scelta sia riuscito ad inferire tutta la sequanza di $S$ (come in alcuni casi del gioco delle due urne).
Diciamo che nella sequenza $S$ Ã¨ presente $a$ volte l&rsquo;elemento <code>A</code> ed $r$ volte l&rsquo;elemento <code>R</code>.
PerciÃ² la probabilitÃ  <code>Y</code> sia la risposta esatta, sapendo la sequenza $S$ di segnali privati sarÃ 
$$\begin{align*}
\mathcal{P}(Y \vert S)
&= \frac{ \mathcal{P}(S \vert Y) \cdot \mathcal{P}(Y) }{ \mathcal{P}(S \vert Y) \cdot \mathcal{P}(Y) + \mathcal{P}(S \vert N) \cdot \mathcal{P}(N)}\\&= \frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}
\end{align*}$$
Se $a > r$, e dato che $q > 1/2$, avremo al <u>secondo addendo al denominatore</u> che
$$(1-q)^a q^r = (1-q)^{a-r+r} q^r &lt; q^{a-r} (1-q)^r q^r = q^a (1-q)^r$$
e quindi
$$\begin{align*}
\mathcal{P}(Y \vert S)
&= \frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}\\&> \frac{q^a (1-q)^r p}{q^a (1-q)^r p + q^a (1-q)^r (1-p)} = p
\end{align*}$$
Viceversa, se $a &lt; r$, accade che
$$(1-q)^a q^r = (1-q)^a q^a q^{r-a} > (1-q)^a q^a (1-q)^{r-a} = q^a (1-q)^r$$
e quindi
$$\begin{align*}
\mathcal{P}(Y \vert S)
&= \frac{q^a (1-q)^r p}{q^a (1-q)^r p + (1-q)^a q^r (1-p)}\\&&lt; \frac{q^a (1-q)^r p}{q^a (1-q)^r p + q^a (1-q)^r (1-p)} = p
\end{align*}$$
Infine, se $a = r$ allora $q^a (1-q)^r = (1-q)^a q^r$, e quindi $\mathcal{P}(Y \vert S) = p$.</p><p>Ricapitolando
$$\mathcal{P}(Y \vert S) = \begin{cases}</p><blockquote><p>p &\mbox{se } a > r\\&lt; p &\mbox{se } a &lt; r\\= p &\mbox{se } a = r
\end{cases}$$
PerciÃ² se un individuo conosce l&rsquo;intera sequenza di segnali privati dei giocatori precedenti, riesce a prendere la scelta che massimizza la probabilitÃ  di vincita in base alla maggioranza:
se ci sono stati piÃ¹ segnali <code>A</code> conviene votare <code>Y</code>, se ce ne sono stati piÃ¹ <code>R</code> conviene votare <code>N</code>.</p></blockquote><p>Osservare che il caso in cui $a = r$ equivale sostanzialmente al caso in cui non si ha alcuna informazione aggiuntiva riguardo la decisione da prendere ($\mathcal{P}(Y \vert S) = \mathcal{P}(Y)$), e quindi bisogna rifarsi solamente al proprio segnale privato.</p><p>Senza perdita di generalitÃ  supponiamo che l&rsquo;$n$-esimo individuo riesca ad inferire tutta la sequenza $S$ degli $n-1$ precedenti segnali, e che $a = r$.
Sia $\sigma_n \in \lbrace A, R \rbrace$ il segnale privato che riceve l&rsquo;$n$-esimo individuo.
Dato che stiamo assumendo che $a = r$ avremo che
$$\begin{align*}
\sigma_n = A \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) = \mathcal{P}(Y \vert \sigma_n) > p\\\sigma_n = R \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) = \mathcal{P}(Y \vert \sigma_n) &lt; p
\end{align*}$$
perciÃ² l&rsquo;individuo segue il suo segnale privato, qualunque esso sia.</p><p>Se invece $a = r+1$ avremo che
$$\begin{align*}
\sigma_n = A \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) > p\\\sigma_n = R \implies \mathcal{P}(Y \vert S \cup \lbrace \sigma_n \rbrace) = p
\end{align*}$$e anche in questo caso l&rsquo;individuo $n$ segue il suo segnale privato.</p><p>Invece se $a \geq r+2$ all&rsquo;individuo $n$ conviene sempre scommettere su <code>Y</code>, qualunque sia il suo segnale, scatenando cosÃ¬ una cascata imitativa.
Simmetricamente per <code>N</code> quando $r \geq a+2$.</p><p>Quindi, individuato la condizione per la quale scatta la cascata, ci si chiede in che situazione si arriva ad avere $a \geq r+2$ (o $r \geq a+2$)?</p><p>Fin quando i due segnali <code>A</code> ed <code>R</code> si alternano non puÃ² scattare l&rsquo;herding, perchÃ© $\vert a - r \vert \leq 1$.
Allora verrebbe da dire che quando si ottengono <strong>due segnali consecutivi</strong> puÃ² scattare l&rsquo;herding.</p><p>Questa condizione Ã¨ necessaria, ma non sufficiente.
Infatti, in una sequenza del tipo <code>ARAR...ARAA</code> due <code>A</code> consecutive bastano per scatenare la cascata imitativa per <code>Y</code>, ovvero bastano per avere $a \geq r+2$.
Purtroppo perÃ², nella stessa sequenza, se abbiamo due <code>R</code> consecutive non Ã¨ sufficiente per far scattare una cascata imitativa di <code>N</code>.
Infatti nella sequenza <code>ARAR...ARR</code> abbiamo che $a - r= 1$.</p><p>PerciÃ², per essere completamente certi di ottenere una cascata imitativa, si necessita di <strong>almeno 3 segnali identici consecutivi</strong>!</p><p>Calcoliamo ora la probabilitÃ  che una cascata si scateni entro il passo $n$.</p><p>Indichiamo sempre con $\sigma_i \in \lbrace A, R \rbrace$ il segnale privato dell&rsquo;$i$-esimo individuo, e siano gli eventi
$$\begin{align*}
\mathcal{A} &= (\sigma_1 = \sigma_2 = \sigma_3) \vee (\sigma_2 = \sigma_3 = \sigma_4) \vee &mldr; \vee (\sigma_{n-3} = \sigma_{n-2} = \sigma_{n-1}) \vee (\sigma_{n-2} = \sigma_{n-1} = \sigma_n)\\&= \bigvee_{1 \leq i \leq n-2} (\sigma_i = \sigma_{i+1} = \sigma_{i+2})\\\\\mathcal{B} &= (\sigma_1 = \sigma_2 = \sigma_3) \vee (\sigma_4 = \sigma_5 = \sigma_6) \vee &mldr; \vee (\sigma_{n-5} = \sigma_{n-4} = \sigma_{n-3}) \vee (\sigma_{n-2} = \sigma_{n-1} = \sigma_n)\\&= \bigvee_{1 \leq i \leq n/3} (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i})
\end{align*}$$</p><p>Osserviamo che $\mathcal{B} \subseteq \mathcal{A}$, perciÃ² $\mathcal{P}(\mathcal{B}) \leq \mathcal{P}(\mathcal{A})$.</p><p>Indichiamo ora con $\mathcal{H}<em>n$ l&rsquo;evento <em>&ldquo;la cascata imitativa si innesca entro il passo $n&rdquo;</em>.
La sua probabilitÃ  sarÃ  $$\mathcal{P}(\mathcal{H}<em>n) \geq \mathcal{P}(\mathcal{A}) \geq \mathcal{P}(\mathcal{B})$$
Per la legge di <em>De Morgan</em> avremo che $$\mathcal{P}(\lnot \mathcal{H}<em>n) \leq \mathcal{P}(\lnot \mathcal{B}) = \mathcal{P}(\bigwedge</em>{1 \leq i \leq n/3} \lnot (\sigma</em>{3i-2} = \sigma</em>{3i-1} = \sigma_{3i}))$$
Dato che gli eventi in $\mathcal{B}$ sono tutti indipendenti tra di loro, abbiamo che $$\mathcal{P}(\lnot \mathcal{H}<em>n) \leq \prod</em>{1 \leq i \leq n/3} \mathcal{P}(\lnot (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i}))$$</p><p>Per ogni $i \leq n/3$ abbiamo che la probabilitÃ  dell&rsquo;evento $(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i})$ sarÃ 
$$\begin{align*}
\mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i}) &= \mathcal{P}((\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = A) \vee (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = R))\\&= \mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = A) + \mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i} = R)\\&= \mathcal{P}(AAA) + \mathcal{P}(RRR)\\&= \mathcal{P}(AAA) + \mathcal{P}(RRR)\\&= \left[ \mathcal{P}(AAA \vert Y)\mathcal{P}(Y) + \mathcal{P}(AAA \vert N)\mathcal{P}(N)\right] + \left[ \mathcal{P}(RRR \vert Y)\mathcal{P}(Y) + \mathcal{P}(RRR \vert N)\mathcal{P}(N)\right]\\&= \left[ q^3p + (1-q)^3(1-p) \right] + \left[ (1-q)^3p + q^3(1-p) \right]\\&= 1 - 3q + 3q^2
\end{align*}$$</p><p>PerciÃ² il complemento sarÃ 
$$\mathcal{P}(\lnot (\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i})) = 1 - \mathcal{P}(\sigma_{3i-2} = \sigma_{3i-1} = \sigma_{3i}) = 3q - 3q^2$$
Applicando questa uguaglianza per ogni $i$ avremo che
$$\mathcal{P}(\lnot \mathcal{H}_n) \leq (3q - 3q^2)^{n/3}$$
Osserviamo in fine che $(3q - 3q^2) &lt; 1$ per ogni $q \in \left[0,1\right]$.</p><p><img src=https://Alessandrostr95.github.io//ar-lesson12-img1.png width=400 alt="$(3q - 3q^2) &amp;lt; 1$ per ogni $q \in \left(0,1\right)$.|400"></p><p>PerciÃ² possiamo concludere che la cascata imitativa si inneschera <strong>quasi sicuramente</strong> al crescere degli individui.
$$\mathcal{P}(\mathcal{H}<em>n) \geq 1 - (3q - 3q^2)^{n/3} \implies \lim</em>{n \rightarrow \infty} \mathcal{P}(\mathcal{H}_n) = 1$$</p><hr><a href=#considerazioni><h2 id=considerazioni><span class=hanchor arialabel=Anchor># </span>Considerazioni</h2></a><p>Come appena visto, le cascate informative sono fenomeni abbastanza semplici da innescare, in quanto richiedono lo scambio di pochissime informazioni (solo le decisioni prese).
Se si pensa bene, in realtÃ  le uniche informazioni realmente rilevanti sono quelle <em>precedenti</em> all&rsquo;innesco della cascata in quanto, per definizione, una volta iniziata la cascata informativa tutti gli individui prenderanno la stessa decisione <strong>indipendentemente</strong> dalle informazioni in possesso.
Le informazioni che vengono ricevute dopo che la cascata si innesca sono <em>inutili</em>.</p><p>Le cascata informative non sono affidabili, possono portare facilmente a prendere decisioni inesatte.
Proprio perchÃ© non vengono usate tutte le informazioni presenti nella rete, bensÃ¬ un piccolissima parte di esse.</p><p>Inoltre le cascate informative sono anche molto instabili, Ã¨ possibile &ldquo;rompere&rdquo; una cascata semplicemente rendendo pubblica l&rsquo;informazione privata di un individuo oppure che qualcuno voti in disaccordo alla cascata, e questo Ã¨ piÃ¹ probabile che accada tanto piÃ¹ la rete Ã¨ grande.</p><p>Tuttavia nel libro <em><a href=https://www.amazon.it/Wisdom-Crowds-James-Surowiecki/dp/0385721706 rel=noopener>The Wisdom of Crowds</a></em>, James Surowiecki sostiene la tesi secondo la quale</p><blockquote><p><em>il comportamento aggregato di un numero elevato di persone in possesso di informazione molto limitata puÃ² produrre risultati molto accurati</em></p></blockquote><p>^284d1a</p><p>PerÃ² l&rsquo;assuzione alla base di questa tesi Ã¨ che ogni individuo prende la propria decisione solamente sulla base delle proprie informazioni private, <strong>indipendentemente</strong> da ciÃ² che fanno gli altri.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>i pedici $g,b$ per $v_g, v_b$ stanno ad indicare <em>good</em>, <em>bad</em> rispettivamente.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>i pedici $g,b$ per $v_g, v_b$ stanno ad indicare <em>good</em>, <em>bad</em> rispettivamente.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://Alessandrostr95.github.io/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Alessandro Straziota using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><ul><li><a href=https://Alessandrostr95.github.io/>Home</a></li><li><a href=https://twitter.com/Alessandro_357>Twitter</a></li><li><a href=https://github.com/Alessandrostr95>Github</a></li></ul></footer></div></div></body></html>